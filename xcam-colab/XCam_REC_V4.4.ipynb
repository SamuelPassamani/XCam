{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SamuelPassamani/XCam/blob/main/xcam-colab/XCam_REC_V4.4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# C√©lula 1: Configura√ß√£o Global, Par√¢metros e Log √önico Estruturado\n",
        "\n",
        "**Objetivo:**  \n",
        "Esta c√©lula inicializa e centraliza todas as vari√°veis e par√¢metros essenciais para o funcionamento do notebook XCam, al√©m de fornecer um sistema robusto para log centralizado e estruturado.  \n",
        "Seu prop√≥sito √© garantir controle total sobre limites, caminhos, thresholds, rastreabilidade das execu√ß√µes e facilidade de manuten√ß√£o, promovendo padroniza√ß√£o e transpar√™ncia em todas as opera√ß√µes.\n",
        "\n",
        "---\n",
        "\n",
        "## O que esta c√©lula faz?\n",
        "\n",
        "- **Monta e garante o diret√≥rio de logs no Google Drive:**  \n",
        "  Todos os registros do notebook s√£o salvos em um arquivo √∫nico (`xcam_master.log`) dentro do Drive, facilitando backup, compartilhamento e auditoria.\n",
        "- **Define par√¢metros globais edit√°veis:**  \n",
        "  Limites de processamento, controle de grava√ß√£o, thresholds e caminhos s√£o definidos de forma clara e centralizada, podendo ser facilmente ajustados conforme a necessidade do projeto ou do ambiente.\n",
        "- **Propaga vari√°veis para todo o notebook:**  \n",
        "  Com um √∫nico comando, todos os par√¢metros s√£o disponibilizados globalmente, evitando inconsist√™ncias e facilitando o uso em qualquer c√©lula subsequente.\n",
        "- **Implementa um sistema de log √∫nico e modular (JSONL):**  \n",
        "  Todas as opera√ß√µes relevantes (busca, grava√ß√£o, blacklist, falha, sucesso, commit, erro, etc.) s√£o registradas em entradas padronizadas no arquivo de log, incluindo informa√ß√µes como sess√£o, evento, id, username, status, detalhes e timestamp.\n",
        "- **Fornece fun√ß√µes utilit√°rias para manipular o log:**  \n",
        "  Inclui fun√ß√µes para adicionar, buscar, atualizar e remover registros do log de maneira f√°cil e segura ‚Äì atuando como um ‚Äúbanco de dados‚Äù simples para rastreamento e auditoria.\n",
        "- **Cria mecanismo de blacklist e controle por identificador:**  \n",
        "  O controle de falhas, blacklist, reprocessamento e auditoria √© feito sempre por `id` (e `id_username`), garantindo unicidade e evitando erros comuns de duplicidade ou conflito de dados.\n",
        "- **Inclui fun√ß√£o interativa para sele√ß√£o de transmiss√µes espec√≠ficas:**  \n",
        "  Permite ao usu√°rio informar manualmente nomes de usu√°rios de transmiss√µes para processamento priorit√°rio.\n",
        "\n",
        "---\n",
        "\n",
        "## Exemplos de uso pr√°tico\n",
        "\n",
        "### 1. Ajustando par√¢metros globais\n",
        "\n",
        "Se desejar processar apenas 30 transmiss√µes por rodada, basta alterar:\n",
        "```python\n",
        "LIMIT_DEFAULT = 30\n",
        "```\n",
        "Ou para aumentar o tempo m√°ximo de grava√ß√£o:\n",
        "```python\n",
        "RECORD_SECONDS = 14400  # 4 horas\n",
        "```\n",
        "\n",
        "### 2. Registrando um evento no log\n",
        "\n",
        "Ao iniciar a grava√ß√£o de uma transmiss√£o:\n",
        "```python\n",
        "append_log({\n",
        "    \"sessao\": \"grava√ß√£o\",\n",
        "    \"evento\": \"iniciado\",\n",
        "    \"id\": \"tx123\",\n",
        "    \"username\": \"StreamerExemplo\",\n",
        "    \"status\": \"ok\",\n",
        "    \"detalhes\": \"URL v√°lida e grava√ß√£o iniciada\"\n",
        "})\n",
        "```\n",
        "\n",
        "### 3. Consultando registros de blacklist\n",
        "\n",
        "Para buscar todas as transmiss√µes atualmente banidas:\n",
        "```python\n",
        "logs_blacklist = query_logs(sessao=\"blacklist\", status=\"blacklisted\")\n",
        "print(logs_blacklist)\n",
        "```\n",
        "\n",
        "### 4. Removendo registros expirados\n",
        "\n",
        "Para limpar eventos de blacklist que j√° venceram:\n",
        "```python\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "def expirou(entry):\n",
        "    ts = datetime.fromisoformat(entry[\"timestamp\"].replace(\"Z\", \"\"))\n",
        "    return (datetime.utcnow() - ts) > timedelta(seconds=BLACKLIST_TIMEOUT)\n",
        "\n",
        "remove_logs(lambda entry: entry[\"sessao\"] == \"blacklist\" and expirou(entry), log_path=LOG_PATH)\n",
        "```\n",
        "\n",
        "### 5. Atualizando status de uma entrada\n",
        "\n",
        "Para promover o status de uma transmiss√£o ap√≥s sucesso:\n",
        "```python\n",
        "update_log_entry(\n",
        "    lambda e: e[\"id\"] == \"tx123\" and e[\"sessao\"] == \"grava√ß√£o\",\n",
        "    lambda e: e.update({\"status\": \"success\"})\n",
        ")\n",
        "```\n",
        "\n",
        "### 6. Selecionando transmiss√µes espec√≠ficas manualmente\n",
        "\n",
        "O notebook pode perguntar:\n",
        "```\n",
        "Deseja gravar alguma transmiss√£o espec√≠fica? (sim/n√£o):\n",
        "```\n",
        "Se sim, voc√™ informa os nomes separados por v√≠rgula, por exemplo:\n",
        "```\n",
        "StreamerA, StreamerB\n",
        "```\n",
        "E o notebook ir√° priorizar esses nomes na pr√≥xima execu√ß√£o.\n",
        "\n",
        "---\n",
        "\n",
        "## Estrutura detalhada do log (`xcam_master.log`)\n",
        "\n",
        "Cada linha do arquivo √© um JSON no formato:\n",
        "```json\n",
        "{\n",
        "  \"timestamp\": \"2025-06-06T06:15:00Z\",\n",
        "  \"sessao\": \"busca|grava√ß√£o|blacklist|processing|failure|success|commit|erro|...\",\n",
        "  \"evento\": \"iniciado|finalizado|expirado|banido|...\",\n",
        "  \"id\": \"identificador_unico\",\n",
        "  \"username\": \"nome_para_exibicao\",\n",
        "  \"id_username\": \"identificador_unico:nome_para_exibicao\",\n",
        "  \"status\": \"ok|erro|blacklisted|expirado|success|...\",\n",
        "  \"detalhes\": \"informa√ß√µes adicionais, motivo, paths, etc\"\n",
        "}\n",
        "```\n",
        "\n",
        "Exemplo real:\n",
        "```json\n",
        "{\n",
        "  \"timestamp\": \"2025-06-15T20:00:00Z\",\n",
        "  \"sessao\": \"blacklist\",\n",
        "  \"evento\": \"banido\",\n",
        "  \"id\": \"tx987\",\n",
        "  \"username\": \"StreamerB\",\n",
        "  \"id_username\": \"tx987:StreamerB\",\n",
        "  \"status\": \"blacklisted\",\n",
        "  \"detalhes\": \"3 falhas consecutivas na grava√ß√£o\"\n",
        "}\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Seguran√ßa, rastreabilidade e manuten√ß√£o\n",
        "\n",
        "- **Consist√™ncia:** Todos os par√¢metros cr√≠ticos est√£o centralizados e propagados globalmente.\n",
        "- **Rastreabilidade:** Cada opera√ß√£o √© registrada de forma padronizada, permitindo reprocessamento, auditoria e debugging facilitados.\n",
        "- **Facilidade de ajuste:** Qualquer valor relevante pode ser alterado em um s√≥ lugar e imediatamente refletido em todo o notebook.\n",
        "- **Manuten√ß√£o simplificada:** Fun√ß√µes bem documentadas e exemplos pr√°ticos permitem evolu√ß√£o f√°cil por toda a equipe, mesmo para novos membros.\n",
        "\n",
        "---\n",
        "\n",
        "## Recomenda√ß√µes\n",
        "\n",
        "- Sempre execute a c√©lula 1 antes de qualquer processamento.\n",
        "- Ao ajustar limites, thresholds ou caminhos, fa√ßa isso apenas nesta c√©lula.\n",
        "- Consulte e manipule o log usando as fun√ß√µes fornecidas, evitando manipula√ß√£o manual do arquivo.\n",
        "- Utilize o Google Drive para garantir o backup dos logs e facilitar a colabora√ß√£o.\n",
        "- Siga os exemplos para registrar corretamente eventos e manter o hist√≥rico de execu√ß√µes completo.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "c9hve1ySGVAs"
      },
      "id": "c9hve1ySGVAs"
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================\n",
        "# C√©lula 1: Configura√ß√£o Global, Par√¢metros e Log √önico Estruturado\n",
        "# ================================================================\n",
        "# Objetivo:\n",
        "# - Centralizar configura√ß√µes globais e thresholds\n",
        "# - Definir e montar caminhos do notebook\n",
        "# - Fornecer utilit√°rio robusto para LOG √öNICO MODULAR (JSONL)\n",
        "#   => Todas as c√©lulas e fun√ß√µes usar√£o este log para registrar, consultar e manipular eventos\n",
        "# - Garantir padroniza√ß√£o, rastreabilidade, unicidade e f√°cil manuten√ß√£o futura\n",
        "#\n",
        "# Estrat√©gia:\n",
        "# - Log √∫nico estruturado (JSONL): sess√£o, evento, id, username, id_username, timestamps, status, detalhes\n",
        "# - Fun√ß√µes CRUD para log: adicionar, buscar, atualizar, remover (para blacklist, processing, falhas, auditoria)\n",
        "# - Blacklist e controles baseados em id (com username apenas para exibi√ß√£o)\n",
        "# - Par√¢metros globais facilmente edit√°veis e propagados via globals()\n",
        "# - Uso consistente de \"sessao\" para diferenciar tipos de registros\n",
        "# ================================================================\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "import json\n",
        "\n",
        "# ============================\n",
        "# PAR√ÇMETROS GLOBAIS EDIT√ÅVEIS\n",
        "# ============================\n",
        "# Modifique abaixo conforme necessidade do ambiente ou processamento\n",
        "\n",
        "# Limites e thresholds principais de processamento\n",
        "LIMIT_DEFAULT = 100             # M√°ximo de transmiss√µes processadas por rodada\n",
        "PAGE_DEFAULT = 1               # P√°gina padr√£o para busca na API\n",
        "RECORD_SECONDS = 12780         # Dura√ß√£o m√°xima da grava√ß√£o (em segundos)\n",
        "RECORD_SECONDS_MIN = 420       # Dura√ß√£o m√≠nima v√°lida (em segundos)\n",
        "API_SEARCH_LIMIT = 3333        # Limite ao buscar usu√°rios espec√≠ficos\n",
        "# COMMIT_PUSH_THRESHOLD removido pois o commit/push √© gerenciado externamente\n",
        "\n",
        "# Caminhos de arquivos principais\n",
        "BASE_PATH = '/content' # Mantido para refer√™ncia, mas LOG_PATH vai para o Drive\n",
        "DRIVE_BASE_LOG_PATH = '/content/drive/MyDrive/XCam.Drive/logs' # Novo caminho base para logs no Drive\n",
        "LOG_PATH = f\"{DRIVE_BASE_LOG_PATH}/xcam_master.log\"          # Arquivo √∫nico de log central MOVIDO PARA O DRIVE\n",
        "BLACKLIST_TIMEOUT = 15 * 60                        # Blacklist: tempo de expira√ß√£o (segundos)\n",
        "BLACKLIST_MAX_FAILURES = 3                         # Blacklist: falhas para banimento tempor√°rio\n",
        "\n",
        "# Garante que o diret√≥rio de logs no Drive exista\n",
        "os.makedirs(DRIVE_BASE_LOG_PATH, exist_ok=True)\n",
        "print(f\"Diret√≥rio de logs no Drive garantido: {DRIVE_BASE_LOG_PATH}\")\n",
        "\n",
        "\n",
        "# ============================\n",
        "# ATUALIZA√á√ÉO GLOBAL DOS PAR√ÇMETROS\n",
        "# ============================\n",
        "# Propaga par√¢metros como globais do notebook\n",
        "globals().update({\n",
        "    'LIMIT_DEFAULT': LIMIT_DEFAULT,\n",
        "    'PAGE_DEFAULT': PAGE_DEFAULT,\n",
        "    'RECORD_SECONDS': RECORD_SECONDS,\n",
        "    'RECORD_SECONDS_MIN': RECORD_SECONDS_MIN,\n",
        "    'API_SEARCH_LIMIT': API_SEARCH_LIMIT,\n",
        "    'LOG_PATH': LOG_PATH, # Atualizado para o caminho do Drive\n",
        "    'BLACKLIST_TIMEOUT': BLACKLIST_TIMEOUT,\n",
        "    'BLACKLIST_MAX_FAILURES': BLACKLIST_MAX_FAILURES\n",
        "})\n",
        "\n",
        "# =============================================================================\n",
        "# UTILIT√ÅRIO DE LOG √öNICO MODULAR (JSONL) ‚Äî Clean Architecture\n",
        "# -----------------------------------------------------------------------------\n",
        "# Cada entrada: {\n",
        "#   \"timestamp\": \"2025-06-06T06:15:00Z\",\n",
        "#   \"sessao\": \"busca|grava√ß√£o|blacklist|processing|failure|commit|erro|...\",\n",
        "#   \"evento\": \"...\",\n",
        "#   \"id\": \"...\",               # identificador prim√°rio (ex: id da transmiss√£o)\n",
        "#   \"username\": \"...\",         # apenas refer√™ncia humana\n",
        "#   \"id_username\": \"...\",      # padr√£o \"{id}:{username}\" para f√°cil leitura/humano\n",
        "#   \"status\": \"...\",           # ok|erro|blacklisted|expirado|...\n",
        "#   \"detalhes\": \"...\",         # informa√ß√µes adicionais/motivo/paths\n",
        "# }\n",
        "# =============================================================================\n",
        "\n",
        "from datetime import datetime\n",
        "\n",
        "def now_iso():\n",
        "    \"\"\"Retorna timestamp UTC em formato ISO.\"\"\"\n",
        "    return datetime.utcnow().isoformat() + \"Z\"\n",
        "\n",
        "def make_id_username(id, username):\n",
        "    \"\"\"Gera o identificador de refer√™ncia padr√£o para logs: '{id}:{username}'.\"\"\"\n",
        "    return f\"{id}:{username}\"\n",
        "\n",
        "def append_log(entry, log_path=LOG_PATH):\n",
        "    \"\"\"\n",
        "    Adiciona uma nova entrada ao log central (JSONL).\n",
        "    Campos obrigat√≥rios: sessao, evento, id, username, status.\n",
        "    - 'id' DEVE ser chave prim√°ria (√∫nico por transmiss√£o/processo).\n",
        "    - 'username' √© apenas refer√™ncia humana.\n",
        "    - 'id_username' sempre gerado para facilitar auditoria/consulta.\n",
        "    - 'sessao' obrigat√≥rio e padronizado para facilitar filtros e consultas.\n",
        "    \"\"\"\n",
        "    entry.setdefault(\"timestamp\", now_iso())\n",
        "    for field in [\"sessao\", \"evento\", \"id\", \"username\", \"status\"]:\n",
        "        entry.setdefault(field, \"\")\n",
        "    # Padr√£o de refer√™ncia √∫nico e f√°cil busca\n",
        "    entry[\"id_username\"] = make_id_username(entry[\"id\"], entry[\"username\"])\n",
        "    # Evitar duplicidade de id+sessao+evento (unicidade l√≥gica)\n",
        "    logs = []\n",
        "    # Verifica se o arquivo existe ANTES de tentar ler\n",
        "    if os.path.exists(log_path):\n",
        "        try:\n",
        "            with open(log_path, \"r\", encoding=\"utf-8\") as f:\n",
        "                # L√™ linha por linha e tenta parsear JSON. Ignora linhas inv√°lidas com aviso.\n",
        "                for line in f:\n",
        "                    line = line.strip()\n",
        "                    if line:\n",
        "                        try:\n",
        "                            logs.append(json.loads(line))\n",
        "                        except json.JSONDecodeError as e:\n",
        "                            print(f\"‚ö†Ô∏è Aviso: Linha inv√°lida no log '{log_path}', ignorada: {line} - Erro: {e}\")\n",
        "        except Exception as e:\n",
        "             print(f\"‚ùå Erro inesperado ao ler log '{log_path}', inicializando lista vazia: {e}\")\n",
        "             logs = []\n",
        "\n",
        "\n",
        "    # Checa unicidade apenas para eventos que n√£o podem ser duplicados (ex: processing, blacklist, etc)\n",
        "    if entry[\"sessao\"] in {\"processing\", \"blacklist\", \"failure\", \"success\"}:\n",
        "        key = (entry[\"id\"], entry[\"sessao\"], entry[\"evento\"])\n",
        "        # Encontra o √≠ndice da entrada existente, se houver\n",
        "        existing_index = next((i for i, e in enumerate(logs) if (e.get(\"id\"), e.get(\"sessao\"), e.get(\"evento\")) == key), -1)\n",
        "\n",
        "        if existing_index != -1:\n",
        "            # Atualiza o registro existente ao inv√©s de duplicar\n",
        "            logs[existing_index].update(entry)\n",
        "            # Escreve o arquivo completo de volta (substitui)\n",
        "            try:\n",
        "                with open(log_path, \"w\", encoding=\"utf-8\") as f:\n",
        "                    for l in logs:\n",
        "                        f.write(json.dumps(l, ensure_ascii=False) + \"\\n\")\n",
        "                return # Retorna ap√≥s atualizar\n",
        "            except Exception as e:\n",
        "                print(f\"‚ùå Erro ao reescrever log '{log_path}' ap√≥s atualiza√ß√£o: {e}\")\n",
        "                # Em caso de erro ao reescrever, tenta apenas append abaixo como fallback?\n",
        "                # Ou seria melhor parar? Por seguran√ßa, vamos tentar append (pode gerar duplicidade tempor√°ria)\n",
        "                pass # Continua para o append abaixo em caso de erro ao reescrever\n",
        "\n",
        "    # Se n√£o existe ou se houve erro ao reescrever, apenas append a nova entrada\n",
        "    try:\n",
        "        with open(log_path, \"a\", encoding=\"utf-8\") as f:\n",
        "            f.write(json.dumps(entry, ensure_ascii=False) + \"\\n\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Erro ao adicionar entrada ao log '{log_path}': {e}\")\n",
        "\n",
        "\n",
        "def read_logs(log_path=LOG_PATH):\n",
        "    \"\"\"L√™ todas as entradas do log central.\"\"\"\n",
        "    if not os.path.exists(log_path):\n",
        "        return []\n",
        "    logs = []\n",
        "    try:\n",
        "        with open(log_path, \"r\", encoding=\"utf-8\") as f:\n",
        "            for line in f:\n",
        "                line = line.strip()\n",
        "                if line:\n",
        "                    try:\n",
        "                        logs.append(json.loads(line))\n",
        "                    except json.JSONDecodeError as e:\n",
        "                         print(f\"‚ö†Ô∏è Aviso: Linha inv√°lida no log '{log_path}', ignorada: {line} - Erro: {e}\")\n",
        "    except Exception as e:\n",
        "         print(f\"‚ùå Erro inesperado ao ler log '{log_path}': {e}\")\n",
        "         return []\n",
        "    return logs\n",
        "\n",
        "\n",
        "def query_logs(sessao=None, id=None, username=None, id_username=None, evento=None, status=None, after=None, before=None, log_path=LOG_PATH):\n",
        "    \"\"\"\n",
        "    Consulta entradas do log por filtros opcionais.\n",
        "    Filtros dispon√≠veis: sessao, id, username, id_username, evento, status, after, before.\n",
        "    - after/before: string ISO ou datetime\n",
        "    \"\"\"\n",
        "    logs = read_logs(log_path)\n",
        "    result = []\n",
        "    for entry in logs:\n",
        "        if sessao and entry.get(\"sessao\") != sessao:\n",
        "            continue\n",
        "        if id and entry.get(\"id\") != id:\n",
        "            continue\n",
        "        if username and entry.get(\"username\") != username:\n",
        "            continue\n",
        "        if id_username and entry.get(\"id_username\") != id_username:\n",
        "            continue\n",
        "        if evento and entry.get(\"evento\") != evento:\n",
        "            continue\n",
        "        if status and entry.get(\"status\") != status:\n",
        "            continue\n",
        "        ts = entry.get(\"timestamp\")\n",
        "        if after:\n",
        "            after_val = after if isinstance(after, str) else after.isoformat()\n",
        "            if ts < after_val:\n",
        "                continue\n",
        "        if before:\n",
        "            before_val = before if isinstance(before, str) else before.isoformat()\n",
        "            if ts > before_val:\n",
        "                continue\n",
        "        result.append(entry)\n",
        "    return result\n",
        "\n",
        "def remove_logs(condition_fn, log_path=LOG_PATH):\n",
        "    \"\"\"\n",
        "    Remove do log central todas as entradas que satisfa√ßam condition_fn(entry).\n",
        "    √ötil para expurgar logs expirados, blacklists vencidas, eventos processados, etc.\n",
        "    \"\"\"\n",
        "    logs = read_logs(log_path)\n",
        "    kept = [entry for entry in logs if not condition_fn(entry)]\n",
        "    # S√≥ reescreve se houve remo√ß√£o ou se o arquivo existia e agora est√° vazio\n",
        "    if len(kept) < len(logs) or (len(logs) > 0 and len(kept) == 0):\n",
        "        try:\n",
        "            with open(log_path, \"w\", encoding=\"utf-8\") as f:\n",
        "                for entry in kept:\n",
        "                    f.write(json.dumps(entry, ensure_ascii=False) + \"\\n\")\n",
        "            print(f\"‚úÖ {len(logs) - len(kept)} entradas removidas do log '{log_path}'.\")\n",
        "            return len(logs) - len(kept)\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Erro ao reescrever log '{log_path}' ap√≥s remo√ß√£o: {e}\")\n",
        "            return 0 # N√£o podemos confirmar quantas foram removidas no arquivo\n",
        "    else:\n",
        "         print(f\"‚ÑπÔ∏è Nenhuma entrada satisfez a condi√ß√£o de remo√ß√£o no log '{log_path}'.\")\n",
        "         return 0\n",
        "\n",
        "\n",
        "def update_log_entry(match_fn, update_fn, log_path=LOG_PATH):\n",
        "    \"\"\"\n",
        "    Atualiza entradas do log central: se match_fn(entry)==True, aplica update_fn(entry).\n",
        "    Exemplo: promover status de \"pending\" para \"ok\".\n",
        "    \"\"\"\n",
        "    logs = read_logs(log_path)\n",
        "    updated = 0\n",
        "    # Cria uma c√≥pia para iterar enquanto modifica a original (ou uma nova lista)\n",
        "    new_logs = []\n",
        "    made_changes = False\n",
        "    for entry in logs:\n",
        "        # Cria uma c√≥pia da entrada para modificar, se necess√°rio\n",
        "        entry_copy = entry.copy()\n",
        "        if match_fn(entry_copy):\n",
        "            update_fn(entry_copy)\n",
        "            updated += 1\n",
        "            made_changes = True\n",
        "        new_logs.append(entry_copy)\n",
        "\n",
        "    if made_changes:\n",
        "        try:\n",
        "            with open(log_path, \"w\", encoding=\"utf-8\") as f:\n",
        "                for entry in new_logs:\n",
        "                    f.write(json.dumps(entry, ensure_ascii=False) + \"\\n\")\n",
        "            print(f\"‚úÖ {updated} entradas atualizadas no log '{log_path}'.\")\n",
        "        except Exception as e:\n",
        "             print(f\"‚ùå Erro ao reescrever log '{log_path}' ap√≥s atualiza√ß√£o: {e}\")\n",
        "\n",
        "    return updated\n",
        "\n",
        "# Exemplos de uso (para as pr√≥ximas c√©lulas):\n",
        "# append_log({\"sessao\":\"processing\", \"evento\":\"iniciado\", \"id\":\"123456\", \"username\":\"Manugic_\", \"status\":\"ok\", \"detalhes\":\"URL v√°lida\"})\n",
        "# logs_blacklist = query_logs(sessao=\"blacklist\", status=\"blacklisted\")\n",
        "# remove_logs(lambda entry: entry[\"sessao\"]==\"processing\" and expirou(entry), log_path=LOG_PATH)\n",
        "# update_log_entry(lambda e: e[\"id\"]==\"123456\" and e[\"sessao\"]==\"processing\", lambda e: e.update({\"status\":\"ok\"}))\n",
        "\n",
        "# =============================================================================\n",
        "# FUN√á√ÉO INTERATIVA (opcional) PARA ESCOLHA DE TRANSMISS√ïES ESPEC√çFICAS\n",
        "# =============================================================================\n",
        "def perguntar_transmissoes_especificas():\n",
        "    \"\"\"\n",
        "    Pergunta ao usu√°rio se deseja informar transmiss√µes espec√≠ficas para gravar,\n",
        "    recebendo nomes de usu√°rio separados por v√≠rgula e retornando lista limpa.\n",
        "    Retorna lista vazia caso n√£o deseje selecionar usu√°rios.\n",
        "    \"\"\"\n",
        "    resp = input('Deseja gravar alguma transmiss√£o espec√≠fica? (sim/n√£o): ').strip().lower()\n",
        "    if resp.startswith('s'):\n",
        "        usuarios = input('Informe o(s) nome(s) de usu√°rio, separados por v√≠rgula (ex: userNovo234, jovemPT): ')\n",
        "        usuarios_lista = [u.strip() for u in usuarios.split(',') if u.strip()]\n",
        "        return usuarios_lista\n",
        "    return []\n",
        "\n",
        "# =============================================================================\n",
        "# DICAS DE USO EM OUTRAS C√âLULAS:\n",
        "# - Para registrar evento: append_log({...})\n",
        "# - Para consultar blacklist: query_logs(sessao=\"blacklist\", status=\"blacklisted\")\n",
        "# - Para remover registros expirados: remove_logs(lambda e: ...)\n",
        "# - Para atualizar status: update_log_entry(lambda e: ..., lambda e: ...)\n",
        "# - Sempre use o id como chave prim√°ria e id_username para refer√™ncia em relat√≥rios/auditoria\n",
        "# =============================================================================\n",
        "\n",
        "# ============================\n",
        "# FIM DA C√âLULA 1\n",
        "# ============================"
      ],
      "metadata": {
        "id": "j5pPh353GLMD"
      },
      "id": "j5pPh353GLMD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# C√©lula 2: Instala√ß√£o e Valida√ß√£o do ffmpeg\n",
        "\n",
        "**Objetivo:**  \n",
        "Esta c√©lula √© respons√°vel por garantir que o utilit√°rio `ffmpeg` esteja instalado, atualizado e dispon√≠vel no ambiente de execu√ß√£o do notebook XCam (Google Colab ou qualquer sistema baseado em Linux). O ffmpeg √© indispens√°vel para todas as etapas de grava√ß√£o de v√≠deos e processamento de m√≠dia do pipeline.\n",
        "\n",
        "---\n",
        "\n",
        "## Principais pontos e melhorias implementadas\n",
        "\n",
        "- **Verifica√ß√£o autom√°tica e idempotente:**  \n",
        "  Antes de qualquer instala√ß√£o, verifica se o `ffmpeg` j√° est√° dispon√≠vel no PATH do sistema. Assim, evita reinstala√ß√µes desnecess√°rias e torna o processo seguro para m√∫ltiplas execu√ß√µes.\n",
        "- **Instala√ß√£o automatizada via apt-get:**  \n",
        "  Caso o `ffmpeg` n√£o esteja instalado, realiza a instala√ß√£o automatizada usando `apt-get`, garantindo compatibilidade com ambientes Google Colab e servidores Linux.\n",
        "- **Valida√ß√£o e exibi√ß√£o da vers√£o instalada:**  \n",
        "  Ap√≥s a instala√ß√£o (ou confirma√ß√£o pr√©via), exibe a vers√£o do `ffmpeg` instalada, contribuindo para rastreabilidade e diagn√≥stico de ambiente.\n",
        "- **Mensagens de log detalhadas:**  \n",
        "  Cada etapa da checagem, instala√ß√£o e valida√ß√£o fornece feedback detalhado ao usu√°rio, facilitando a identifica√ß√£o de problemas e tornando o notebook mais transparente para uso individual ou colaborativo.\n",
        "- **Design modular e pronto para CI/CD:**  \n",
        "  A estrutura da c√©lula foi desenhada para integra√ß√£o f√°cil em pipelines automatizados, garantindo robustez em ambientes colaborativos, notebooks, scripts e CI/CD.\n",
        "\n",
        "---\n",
        "\n",
        "## Como funciona a c√©lula\n",
        "\n",
        "1. **Checagem inicial:**  \n",
        "   Usa a fun√ß√£o `is_ffmpeg_installed()` para verificar se o comando `ffmpeg` est√° dispon√≠vel no ambiente.\n",
        "2. **Instala√ß√£o autom√°tica (se necess√°rio):**  \n",
        "   Caso `ffmpeg` n√£o esteja presente, executa `install_ffmpeg()`, realizando atualiza√ß√£o dos pacotes e instala√ß√£o silenciosa para manter o log limpo.\n",
        "3. **Valida√ß√£o final e rastreabilidade:**  \n",
        "   Exibe a vers√£o instalada com `show_ffmpeg_version()` para garantir que a instala√ß√£o foi bem-sucedida.\n",
        "4. **Tratamento de erros:**  \n",
        "   Em caso de falha na instala√ß√£o, exibe mensagens de erro detalhadas e interrompe a execu√ß√£o, evitando inconsist√™ncias futuras no pipeline.\n",
        "\n",
        "---\n",
        "\n",
        "## Exemplo de uso das fun√ß√µes desta c√©lula\n",
        "\n",
        "```python\n",
        "if not is_ffmpeg_installed():\n",
        "    install_ffmpeg()\n",
        "show_ffmpeg_version()\n",
        "```\n",
        "Ou, de forma automatizada e segura (como implementado):\n",
        "```python\n",
        "if not is_ffmpeg_installed():\n",
        "    print(\"[WARN] ffmpeg n√£o encontrado no ambiente.\")\n",
        "    try:\n",
        "        install_ffmpeg()\n",
        "    except Exception:\n",
        "        raise RuntimeError(\"[ERRO] Falha ao instalar o ffmpeg. Verifique permiss√µes ou tente novamente.\")\n",
        "    if not is_ffmpeg_installed():\n",
        "        raise RuntimeError(\"[ERRO] Falha ao instalar o ffmpeg. Verifique permiss√µes, root ou tente novamente.\")\n",
        "    else:\n",
        "        print(\"[OK] ffmpeg instalado e pronto para uso.\")\n",
        "else:\n",
        "    print(\"[OK] ffmpeg j√° est√° instalado no ambiente.\")\n",
        "\n",
        "show_ffmpeg_version()\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Seguran√ßa, rastreabilidade e manuten√ß√£o\n",
        "\n",
        "- **Robustez:** Garante que o ambiente est√° sempre pronto para grava√ß√£o e processamento de m√≠dia, mesmo ap√≥s resets ou novas execu√ß√µes.\n",
        "- **Transpar√™ncia:** Mensagens informativas em cada etapa ajudam a equipe a identificar rapidamente problemas de ambiente, permiss√µes ou compatibilidade.\n",
        "- **Modularidade:** C√©lula pronta para ser reutilizada em outros projetos, pipelines ou ambientes CI/CD do ecossistema XCam, bastando adaptar comandos de instala√ß√£o para outros sistemas se necess√°rio.\n",
        "- **Idempot√™ncia:** Pode ser executada m√∫ltiplas vezes sem efeitos colaterais ou duplica√ß√£o de instala√ß√µes, tornando o setup seguro e confi√°vel.\n",
        "\n",
        "---\n",
        "\n",
        "## Observa√ß√µes t√©cnicas\n",
        "\n",
        "- O ffmpeg deve estar dispon√≠vel no PATH do sistema para todas as etapas do pipeline XCam.\n",
        "- Para obter o caminho absoluto do execut√°vel:  \n",
        "  ```python\n",
        "  subprocess.run(['which', 'ffmpeg'], capture_output=True, text=True).stdout.strip()\n",
        "  ```\n",
        "- A c√©lula pode ser adaptada para outros sistemas de gerenciamento de pacotes se necess√°rio (exemplo: yum, brew, choco).\n",
        "- Recomenda-se executar esta c√©lula sempre antes de iniciar qualquer processamento de m√≠dia.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "WXs0o6OPHXbi"
      },
      "id": "WXs0o6OPHXbi"
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================\n",
        "# C√©lula 2: Instala√ß√£o e Valida√ß√£o do FFMPEG no Colab e Linux\n",
        "# ================================================================\n",
        "# Objetivo:\n",
        "# - Garantir que o utilit√°rio ffmpeg est√° instalado e dispon√≠vel no ambiente (Colab ou Linux)\n",
        "# - Validar a instala√ß√£o e exibir a vers√£o instalada para rastreabilidade\n",
        "# - Tornar a etapa idempotente, evitando instala√ß√µes desnecess√°rias (safe to rerun)\n",
        "# - Fornecer feedback detalhado e logs a cada etapa para diagn√≥stico r√°pido\n",
        "#\n",
        "# Estrat√©gia aplicada:\n",
        "# - Checa se ffmpeg est√° dispon√≠vel no PATH do sistema\n",
        "# - Caso n√£o esteja, instala automaticamente via apt-get (compat√≠vel Colab/Linux)\n",
        "# - Valida a instala√ß√£o e exibe a vers√£o instalada\n",
        "# - Modularidade e robustez para uso em pipelines, CI/CD e ambientes colaborativos\n",
        "# ================================================================\n",
        "\n",
        "import subprocess   # Importa√ß√£o obrigat√≥ria para checagem e instala√ß√£o do ffmpeg\n",
        "import sys\n",
        "\n",
        "def is_ffmpeg_installed():\n",
        "    \"\"\"\n",
        "    Verifica se o ffmpeg est√° instalado e dispon√≠vel no PATH do sistema.\n",
        "    Retorna True se estiver, False caso contr√°rio.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        result = subprocess.run([\"ffmpeg\", \"-version\"], capture_output=True, text=True)\n",
        "        return result.returncode == 0\n",
        "    except Exception:\n",
        "        return False\n",
        "\n",
        "def install_ffmpeg():\n",
        "    \"\"\"\n",
        "    Instala o ffmpeg via apt-get caso n√£o esteja presente.\n",
        "    Somente para sistemas baseados em Debian/Ubuntu (inclui Google Colab).\n",
        "    \"\"\"\n",
        "    print(\"[INFO] Iniciando instala√ß√£o do ffmpeg via apt-get...\")\n",
        "    try:\n",
        "        # Atualiza pacotes e instala ffmpeg de forma silenciosa para logs limpos\n",
        "        subprocess.run(\"apt-get update -y\", shell=True, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "        subprocess.run(\"apt-get install -y ffmpeg\", shell=True, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "        print(\"[INFO] ffmpeg instalado com sucesso.\")\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"[ERRO] Falha ao instalar ffmpeg via apt-get: {e}\")\n",
        "        print(\"üî¥ Tente rodar manualmente ou verifique permiss√µes/root.\")\n",
        "        raise\n",
        "\n",
        "def show_ffmpeg_version():\n",
        "    \"\"\"\n",
        "    Exibe a vers√£o instalada do ffmpeg, se dispon√≠vel.\n",
        "    Mostra as duas primeiras linhas para rastreabilidade.\n",
        "    \"\"\"\n",
        "    print(\"[INFO] Vers√£o do ffmpeg instalada:\")\n",
        "    try:\n",
        "        result = subprocess.run([\"ffmpeg\", \"-version\"], capture_output=True, text=True)\n",
        "        if result.returncode == 0:\n",
        "            linhas = result.stdout.strip().split('\\n')\n",
        "            for l in linhas[:2]:\n",
        "                print(l)\n",
        "        else:\n",
        "            print(\"[ERRO] ffmpeg instalado, mas n√£o foi poss√≠vel obter a vers√£o.\")\n",
        "    except Exception as e:\n",
        "        print(f\"[ERRO] N√£o foi poss√≠vel exibir a vers√£o do ffmpeg: {e}\")\n",
        "\n",
        "# ================================================================\n",
        "# EXECU√á√ÉO DA ETAPA DE SETUP ‚Äî Sempre idempotente e segura\n",
        "# ================================================================\n",
        "\n",
        "if not is_ffmpeg_installed():\n",
        "    print(\"[WARN] ffmpeg n√£o encontrado no ambiente.\")\n",
        "    try:\n",
        "        install_ffmpeg()\n",
        "    except Exception:\n",
        "        raise RuntimeError(\"[ERRO] Falha ao instalar o ffmpeg. Verifique permiss√µes ou tente novamente.\")\n",
        "    if not is_ffmpeg_installed():\n",
        "        # √öltima checagem ap√≥s instala√ß√£o\n",
        "        raise RuntimeError(\"[ERRO] Falha ao instalar o ffmpeg. Verifique permiss√µes, root ou tente novamente.\")\n",
        "    else:\n",
        "        print(\"[OK] ffmpeg instalado e pronto para uso.\")\n",
        "else:\n",
        "    print(\"[OK] ffmpeg j√° est√° instalado no ambiente.\")\n",
        "\n",
        "show_ffmpeg_version()\n",
        "\n",
        "# ================================================================\n",
        "# FIM DA C√âLULA 2 ‚Äî Instala√ß√£o e Valida√ß√£o do ffmpeg\n",
        "# ================================================================\n",
        "#\n",
        "# Observa√ß√µes t√©cnicas:\n",
        "# - ffmpeg deve estar dispon√≠vel para todas as etapas do pipeline XCam.\n",
        "# - Para obter o caminho absoluto: subprocess.run(['which', 'ffmpeg'], capture_output=True, text=True).stdout.strip()\n",
        "# - C√©lula idempotente: pode ser executada m√∫ltiplas vezes sem efeitos colaterais.\n",
        "# - Pronta para uso em pipelines, scripts automatizados e ambientes colaborativos."
      ],
      "metadata": {
        "id": "vIODn0c2HiHz"
      },
      "id": "vIODn0c2HiHz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# C√©lula 3: Imports Essenciais, Utilit√°rios e Prepara√ß√£o do Ambiente\n",
        "\n",
        "**Objetivo:**  \n",
        "Esta c√©lula prepara o ambiente de execu√ß√£o do notebook XCam, realizando todos os imports essenciais de bibliotecas Python necess√°rias e centralizando fun√ß√µes utilit√°rias robustas para formata√ß√£o de tempo, exibi√ß√£o de progresso, download e gera√ß√£o de posters (thumbnails) das transmiss√µes.  \n",
        "Toda a l√≥gica de rastreabilidade, fallback, tratamento de exce√ß√µes e integra√ß√£o com o log centralizado √© garantida, promovendo modularidade, clareza e seguran√ßa para as pr√≥ximas etapas do pipeline.\n",
        "\n",
        "---\n",
        "\n",
        "## Principais pontos e melhorias implementadas\n",
        "\n",
        "- **Imports essenciais agrupados:**  \n",
        "  Todos os m√≥dulos b√°sicos e avan√ßados utilizados ao longo do notebook s√£o importados em um s√≥ lugar, incluindo manipula√ß√£o de arquivos, requests HTTP, processamento paralelo, datas, subprocessos, matem√°tica, express√µes regulares, shutil, threading e integra√ß√£o com IPython.\n",
        "- **Fun√ß√µes utilit√°rias padronizadas e seguras:**  \n",
        "  As fun√ß√µes fornecem utilit√°rios para:\n",
        "  - Formatar segundos em tempo leg√≠vel\n",
        "  - Exibir progresso detalhado da grava√ß√£o de transmiss√µes\n",
        "  - Download robusto de posters remotos ou uso direto de arquivos locais\n",
        "  - Gera√ß√£o autom√°tica de poster a partir de stream (.m3u8) usando ffmpeg, com m√∫ltiplas tentativas, tratamento de falha, log centralizado e fallback inteligente para placeholder\n",
        "  - Valida√ß√£o do arquivo de poster gerado\n",
        "- **Integra√ß√£o total ao log centralizado:**  \n",
        "  Todas as falhas, erros e eventos relevantes durante o download ou gera√ß√£o de posters s√£o registrados no log √∫nico do sistema (definido na C√©lula 1), eliminando a necessidade de logs tempor√°rios dispersos.\n",
        "- **Fallbacks inteligentes e robustez:**  \n",
        "  Se n√£o for poss√≠vel gerar um poster com ffmpeg, a fun√ß√£o gera uma imagem placeholder personalizada para manter a experi√™ncia e rastreabilidade, registrando o evento no log.\n",
        "- **Pronto para uso concorrente e distribu√≠do:**  \n",
        "  As fun√ß√µes foram desenhadas para suportar execu√ß√£o paralela, controle de exce√ß√µes e integra√ß√£o transparente com processos multi-thread/multi-processo.\n",
        "\n",
        "---\n",
        "\n",
        "## Fun√ß√µes utilit√°rias dispon√≠veis nesta c√©lula\n",
        "\n",
        "- **`format_seconds(seconds)`**  \n",
        "  Formata um valor em segundos em string leg√≠vel (ex: \"1h23m45s\"), facilitando exibi√ß√£o de progresso.\n",
        "- **`log_progress(username, elapsed_seconds, total_seconds)`**  \n",
        "  Exibe no console o progresso detalhado da grava√ß√£o de cada transmiss√£o, incluindo minutos gravados, minutos restantes e percentual conclu√≠do.\n",
        "- **`download_and_save_poster(poster_url, username, temp_folder)`**  \n",
        "  Faz download do poster a partir de uma URL remota (HTTP/HTTPS) ou retorna o caminho local se j√° existir. Salva o arquivo no diret√≥rio tempor√°rio indicado e fornece feedback detalhado em caso de erro.\n",
        "- **`generate_poster_with_ffmpeg(m3u8_url, username, temp_folder, tries, timeout)`**  \n",
        "  Gera um poster automaticamente a partir de uma stream `.m3u8` usando ffmpeg, tentando m√∫ltiplos pontos no v√≠deo e registrando todas as tentativas, falhas e sucessos no log central. Em caso de falha total, gera um poster placeholder com feedback visual e registro no log.\n",
        "- **`is_poster_valid(poster_path)`**  \n",
        "  Verifica se o poster existe e n√£o est√° vazio, garantindo que apenas imagens v√°lidas sejam usadas no pipeline.\n",
        "\n",
        "---\n",
        "\n",
        "## Exemplos de uso pr√°tico\n",
        "\n",
        "```python\n",
        "# Formatar segundos em string leg√≠vel\n",
        "tempo = format_seconds(5421)   # \"1h30m21s\"\n",
        "\n",
        "# Exibir progresso detalhado de grava√ß√£o\n",
        "log_progress(\"StreamerExemplo\", 385, 12780)\n",
        "\n",
        "# Fazer download do poster da transmiss√£o\n",
        "poster_path = download_and_save_poster(\"https://exemplo.com/poster.jpg\", \"StreamerExemplo\", \"/content/temp\")\n",
        "\n",
        "# Gerar poster automaticamente via ffmpeg (caso o download falhe ou n√£o seja v√°lido)\n",
        "if not is_poster_valid(poster_path):\n",
        "    poster_path = generate_poster_with_ffmpeg(\"https://exemplo.com/stream.m3u8\", \"StreamerExemplo\", \"/content/temp\")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Seguran√ßa, rastreabilidade e manuten√ß√£o\n",
        "\n",
        "- Todas as fun√ß√µes s√£o protegidas contra erros, possuem logs detalhados e fallback inteligente para manter o pipeline funcionando mesmo em cen√°rios adversos.\n",
        "- O log √∫nico centralizado substitui qualquer necessidade de arquivos dispersos para rastreabilidade de processamento, blacklist ou falhas.\n",
        "- Coment√°rios e organiza√ß√£o clara facilitam a compreens√£o, manuten√ß√£o e evolu√ß√£o do notebook por toda a equipe XCam, inclusive para novos membros ou ambientes colaborativos.\n",
        "- O c√≥digo est√° pronto para execu√ß√£o concorrente e pode ser facilmente integrado a pipelines CI/CD ou ambientes distribu√≠dos.\n",
        "\n",
        "---\n",
        "\n",
        "## Recomenda√ß√µes\n",
        "\n",
        "- Utilize sempre as fun√ß√µes utilit√°rias fornecidas nesta c√©lula para qualquer tarefa de formata√ß√£o, progresso, download ou gera√ß√£o de poster.\n",
        "- Consulte e integre o log centralizado para rastreabilidade de todos os eventos relevantes.\n",
        "- Mantenha o diret√≥rio tempor√°rio organizado e monitore os logs para auditoria e diagn√≥stico.\n",
        "- Em caso de erros na gera√ß√£o de poster, utilize o placeholder autom√°tico para n√£o interromper o pipeline.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "90qvXC0rHtWb"
      },
      "id": "90qvXC0rHtWb"
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================\n",
        "# C√©lula 3: Imports Essenciais, Utilit√°rios e Prepara√ß√£o do Ambiente\n",
        "# ================================================================\n",
        "# Objetivo:\n",
        "# - Importar bibliotecas essenciais para todo o notebook\n",
        "# - Centralizar fun√ß√µes auxiliares de formata√ß√£o, download e gera√ß√£o de poster\n",
        "# - Remover depend√™ncias de logs tempor√°rios dispersos, integrando ao log √∫nico do sistema (LOG_PATH)\n",
        "# - Garantir robustez, clareza e modularidade para as pr√≥ximas c√©lulas\n",
        "#\n",
        "# Estrat√©gia aplicada:\n",
        "# - Apenas os imports necess√°rios para o funcionamento do notebook\n",
        "# - Fun√ß√µes auxiliares adaptadas para Clean Architecture e integra√ß√£o com o log centralizado (C√©lula 1)\n",
        "# - Fun√ß√£o de gera√ß√£o de poster com ffmpeg robusta, com m√∫ltiplas tentativas e fallback\n",
        "# - Modularidade: fun√ß√µes isoladas, reus√°veis, prontas para testes e integra√ß√£o\n",
        "# ================================================================\n",
        "\n",
        "import os\n",
        "import requests\n",
        "from multiprocessing import Manager, Process\n",
        "from datetime import datetime\n",
        "import json\n",
        "import time\n",
        "import subprocess\n",
        "import math\n",
        "import re\n",
        "import shutil\n",
        "import threading\n",
        "\n",
        "from IPython import get_ipython\n",
        "from IPython.display import display\n",
        "\n",
        "# ============================\n",
        "# UTILIT√ÅRIOS DE FORMATA√á√ÉO E PROGRESSO\n",
        "# ============================\n",
        "\n",
        "def format_seconds(seconds):\n",
        "    \"\"\"\n",
        "    Formata segundos em string leg√≠vel (e.g., 1h23m45s).\n",
        "    \"\"\"\n",
        "    total_seconds = int(seconds)\n",
        "    hours = total_seconds // 3600\n",
        "    minutes = (total_seconds % 3600) // 60\n",
        "    seconds = total_seconds % 60\n",
        "    parts = []\n",
        "    if hours > 0:\n",
        "        parts.append(f\"{hours}h\")\n",
        "    if minutes > 0 or (hours == 0 and seconds > 0):\n",
        "        parts.append(f\"{minutes}m\")\n",
        "    if seconds > 0 or total_seconds == 0:\n",
        "        parts.append(f\"{seconds}s\")\n",
        "    return \"\".join(parts) if parts else \"0s\"\n",
        "\n",
        "def log_progress(username, elapsed_seconds, total_seconds):\n",
        "    \"\"\"\n",
        "    Exibe progresso da grava√ß√£o de cada transmiss√£o em tempo real.\n",
        "    \"\"\"\n",
        "    percent = min((elapsed_seconds / total_seconds) * 100, 100)\n",
        "    tempo = format_seconds(elapsed_seconds)\n",
        "    minutos_gravados = math.floor(elapsed_seconds / 60)\n",
        "    minutos_restantes = max(0, math.ceil((total_seconds - elapsed_seconds) / 60))\n",
        "    print(f\"‚è±Ô∏è [{username}] Gravados: {minutos_gravados} min | Restantes: {minutos_restantes} min | Tempo total: {tempo} ‚Äî üìä {percent:.1f}% conclu√≠do\")\n",
        "\n",
        "# ============================\n",
        "# UTILIT√ÅRIO PARA DOWNLOAD DE POSTER\n",
        "# ============================\n",
        "\n",
        "def download_and_save_poster(poster_url, username, temp_folder):\n",
        "    \"\"\"\n",
        "    Baixa e salva o poster (thumbnail) a partir de uma URL HTTP/HTTPS.\n",
        "    Se for um caminho local existente, retorna esse caminho.\n",
        "    Retorna o caminho do arquivo salvo, ou None em caso de erro.\n",
        "    \"\"\"\n",
        "    # Se for um caminho local v√°lido, retorna diretamente\n",
        "    if os.path.exists(poster_url):\n",
        "        return poster_url\n",
        "    # Download de URL HTTP/HTTPS\n",
        "    if isinstance(poster_url, str) and (poster_url.startswith(\"http://\") or poster_url.startswith(\"https://\")):\n",
        "        try:\n",
        "            response = requests.get(poster_url, timeout=15)\n",
        "            response.raise_for_status()\n",
        "            ext = os.path.splitext(poster_url)[1].lower()\n",
        "            if ext not in [\".jpg\", \".jpeg\", \".png\"]:\n",
        "                ext = \".jpg\"\n",
        "            poster_temp_path = os.path.join(temp_folder, f\"{username}_poster_temp{ext}\")\n",
        "            with open(poster_temp_path, \"wb\") as f:\n",
        "                f.write(response.content)\n",
        "            print(f\"üñºÔ∏è Poster baixado em: {poster_temp_path}\")\n",
        "            return poster_temp_path\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Erro ao baixar poster {poster_url}: {e}\")\n",
        "            return None\n",
        "    else:\n",
        "        print(f\"‚ùå poster_url inv√°lido ou n√£o encontrado: {poster_url}\")\n",
        "        return None\n",
        "\n",
        "# ============================\n",
        "# UTILIT√ÅRIO PARA GERAR POSTER COM FFMPEG (com fallback e log central)\n",
        "# ============================\n",
        "\n",
        "def generate_poster_with_ffmpeg(m3u8_url, username, temp_folder, tries=(3, 1, 7, 15, 30), timeout=30):\n",
        "    \"\"\"\n",
        "    Gera um poster (screenshot) usando ffmpeg a partir da URL .m3u8 da transmiss√£o.\n",
        "    Tenta m√∫ltiplos pontos no v√≠deo caso haja erro (robustez).\n",
        "    Integra ao log centralizado via append_log em caso de falha.\n",
        "    Retorna o caminho do arquivo gerado ou None em caso de erro.\n",
        "    \"\"\"\n",
        "    from IPython.display import clear_output\n",
        "    import requests # Garantir requests est√° importado aqui\n",
        "\n",
        "    # --- Checa se a URL est√° acess√≠vel antes de rodar ffmpeg ---\n",
        "    try:\n",
        "        # Usar um timeout curto para a checagem inicial\n",
        "        head_resp = requests.head(m3u8_url, timeout=5)\n",
        "        if not head_resp.ok:\n",
        "            msg = f\"Stream offline ou n√£o dispon√≠vel para {username} (status {head_resp.status_code})\"\n",
        "            print(f\"‚ö†Ô∏è {msg}\")\n",
        "            # Registrar falha de conex√£o no log central\n",
        "            if \"register_failure\" in globals():\n",
        "                 register_failure(username, msg)\n",
        "            return None # Retorna None imediatamente se a stream n√£o estiver acess√≠vel\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        msg = f\"Erro de conex√£o ao acessar stream de {username}: {e}\"\n",
        "        print(f\"‚ùå {msg}\")\n",
        "        # Registrar falha de conex√£o no log central\n",
        "        if \"register_failure\" in globals():\n",
        "             register_failure(username, msg)\n",
        "        return None # Retorna None imediatamente em caso de erro de conex√£o\n",
        "    except Exception as e:\n",
        "        msg = f\"Erro inesperado na checagem de stream para {username}: {e}\"\n",
        "        print(f\"‚ùå {msg}\")\n",
        "        # Registrar falha gen√©rica na checagem\n",
        "        if \"register_failure\" in globals():\n",
        "             register_failure(username, msg)\n",
        "        return None # Retorna None em caso de qualquer outra exce√ß√£o na checagem\n",
        "\n",
        "\n",
        "    # --- Tenta gerar poster com ffmpeg (se a checagem inicial passou) ---\n",
        "    for frame_time in tries:\n",
        "        poster_ffmpeg_path = os.path.join(temp_folder, f\"{username}_poster_ffmpeg_{frame_time}.jpg\")\n",
        "        command = [\n",
        "            \"ffmpeg\",\n",
        "            \"-y\",\n",
        "            \"-analyzeduration\", \"10M\",\n",
        "            \"-probesize\", \"50M\",\n",
        "            \"-ss\", str(frame_time),\n",
        "            \"-i\", m3u8_url,\n",
        "            \"-vframes\", \"1\",\n",
        "            \"-q:v\", \"2\",\n",
        "            poster_ffmpeg_path\n",
        "        ]\n",
        "        try:\n",
        "            print(f\"üé¨ Tentando gerar poster para {username} com ffmpeg no segundo {frame_time}...\")\n",
        "            result = subprocess.run(\n",
        "                command,\n",
        "                stdout=subprocess.PIPE,\n",
        "                stderr=subprocess.PIPE,\n",
        "                timeout=timeout\n",
        "            )\n",
        "            if result.returncode == 0 and os.path.exists(poster_ffmpeg_path) and os.path.getsize(poster_ffmpeg_path) > 0:\n",
        "                print(f\"üñºÔ∏è Poster gerado via ffmpeg: {poster_ffmpeg_path}\")\n",
        "                # Limpa falhas relacionadas a poster/ffmpeg se a gera√ß√£o for bem-sucedida\n",
        "                if \"clear_failure\" in globals():\n",
        "                    clear_failure(username)\n",
        "                return poster_ffmpeg_path\n",
        "            else:\n",
        "                msg = f\"ffmpeg n√£o conseguiu gerar poster para {username} no segundo {frame_time}. C√≥digo: {result.returncode}\"\n",
        "                print(f\"‚ùå {msg}\\nSTDOUT:\\n{result.stdout.decode(errors='ignore')}\\nSTDERR:\\n{result.stderr.decode(errors='ignore')}\")\n",
        "                # Registrar falha espec√≠fica de ffmpeg no log central\n",
        "                if \"append_log\" in globals():\n",
        "                    append_log({\n",
        "                        \"sessao\": \"poster\",\n",
        "                        \"evento\": \"erro_ffmpeg_frame\",\n",
        "                        \"id\": username,\n",
        "                        \"username\": username,\n",
        "                        \"status\": \"erro\",\n",
        "                        \"detalhes\": f\"{msg} | stdout: {result.stdout.decode(errors='ignore')[:200]} | stderr: {result.stderr.decode(errors='ignore')[:200]}\"\n",
        "                    })\n",
        "\n",
        "        except subprocess.TimeoutExpired:\n",
        "            msg = f\"Tempo excedido ao tentar gerar poster para {username} via ffmpeg (segundo {frame_time}).\"\n",
        "            print(f\"‚è∞ {msg}\")\n",
        "            # Registrar timeout de ffmpeg no log central\n",
        "            if \"append_log\" in globals():\n",
        "                append_log({\n",
        "                    \"sessao\": \"poster\",\n",
        "                    \"evento\": \"timeout_ffmpeg\",\n",
        "                    \"id\": username,\n",
        "                    \"username\": username,\n",
        "                    \"status\": \"erro\",\n",
        "                    \"detalhes\": msg\n",
        "                })\n",
        "        except Exception as e:\n",
        "            msg = f\"Erro inesperado ao rodar ffmpeg para poster ({username}, segundo {frame_time}): {e}\"\n",
        "            print(f\"‚ùå {msg}\")\n",
        "            # Registrar exce√ß√£o de ffmpeg no log central\n",
        "            if \"append_log\" in globals():\n",
        "                append_log({\n",
        "                    \"sessao\": \"poster\",\n",
        "                    \"evento\": \"excecao_ffmpeg\",\n",
        "                    \"id\": username,\n",
        "                    \"username\": username,\n",
        "                    \"status\": \"erro\",\n",
        "                    \"detalhes\": msg\n",
        "                })\n",
        "\n",
        "\n",
        "    # --- Fallback: gera um poster placeholder se todas as tentativas falharem ---\n",
        "    placeholder_path = os.path.join(temp_folder, f\"{username}_placeholder.jpg\")\n",
        "    try:\n",
        "        from PIL import Image, ImageDraw\n",
        "        img = Image.new('RGB', (640, 360), color=(80, 80, 80))\n",
        "        d = ImageDraw.Draw(img)\n",
        "        d.text((10, 150), f\"Poster indispon√≠vel\\n{username}\", fill=(255, 255, 255))\n",
        "        img.save(placeholder_path)\n",
        "        print(f\"‚ö†Ô∏è Poster placeholder gerado para {username}: {placeholder_path}\")\n",
        "        # Registrar gera√ß√£o de placeholder no log central\n",
        "        if \"append_log\" in globals():\n",
        "             append_log({\n",
        "                 \"sessao\": \"poster\",\n",
        "                 \"evento\": \"placeholder_gerado\",\n",
        "                 \"id\": username,\n",
        "                 \"username\": username,\n",
        "                 \"status\": \"aviso\",\n",
        "                 \"detalhes\": f\"Poster placeholder gerado ap√≥s falha no ffmpeg.\"\n",
        "             })\n",
        "        return placeholder_path\n",
        "    except Exception as e:\n",
        "        msg = f\"Erro ao gerar placeholder para {username}: {e}\"\n",
        "        print(f\"‚ùå {msg}\")\n",
        "        # Registrar falha na gera√ß√£o de placeholder no log central\n",
        "        if \"append_log\" in globals():\n",
        "             append_log({\n",
        "                 \"sessao\": \"poster\",\n",
        "                 \"evento\": \"erro_placeholder\",\n",
        "                 \"id\": username,\n",
        "                 \"username\": username,\n",
        "                 \"status\": \"erro\",\n",
        "                 \"detalhes\": msg\n",
        "             })\n",
        "        return None\n",
        "\n",
        "# ============================\n",
        "# VALIDA√á√ÉO DE POSTER\n",
        "# ============================\n",
        "\n",
        "def is_poster_valid(poster_path):\n",
        "    \"\"\"\n",
        "    Verifica se o poster existe e n√£o est√° vazio.\n",
        "    \"\"\"\n",
        "    return poster_path and os.path.exists(poster_path) and os.path.getsize(poster_path) > 0\n",
        "\n",
        "# ============================\n",
        "# FIM DA C√âLULA 3\n",
        "# ============================\n",
        "\n",
        "# Observa√ß√µes:\n",
        "# - Todas as fun√ß√µes de logging, blacklist, falha e auditoria devem ser feitas via utilit√°rio de log centralizado (C√©lula 1).\n",
        "# - LOG_PROCESSAMENTO_PATH, BLACKLIST_PATH, FAILURE_LOG_PATH e outros logs dispersos n√£o devem mais ser usados.\n",
        "# - O pipeline est√° pronto para Clean Architecture, m√°xima rastreabilidade e integra√ß√£o.\n",
        "# - Fun√ß√µes aqui s√£o modulares, reus√°veis e preparadas para tratamento de exce√ß√µes e logging detalhado."
      ],
      "metadata": {
        "id": "hOetz0nGICkz"
      },
      "id": "hOetz0nGICkz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# C√©lula 4: Clonagem do Reposit√≥rio GitHub no Colab e Google Drive\n",
        "\n",
        "**Objetivo:**  \n",
        "Esta c√©lula tem como finalidade garantir que o reposit√≥rio do projeto XCam esteja sempre dispon√≠vel, atualizado e sincronizado para uso tanto no ambiente tempor√°rio do Google Colab quanto, se dispon√≠vel, de forma persistente no Google Drive.  \n",
        "A c√©lula prepara todo o ambiente para grava√ß√£o, processamento, versionamento de c√≥digo e integra√ß√µes externas, promovendo reprodutibilidade, rastreabilidade e facilidade de manuten√ß√£o em todo o pipeline.\n",
        "\n",
        "---\n",
        "\n",
        "## Descri√ß√£o detalhada das etapas e funcionalidades\n",
        "\n",
        "- **Configura√ß√£o dos dados do reposit√≥rio GitHub:**  \n",
        "  Define as vari√°veis globais de usu√°rio, nome do reposit√≥rio, branch e token pessoal de acesso para autentica√ß√£o e opera√ß√µes seguras de clone e push.\n",
        "- **Gera√ß√£o autom√°tica da URL autenticada:**  \n",
        "  Monta dinamicamente a URL de acesso ao reposit√≥rio j√° com autentica√ß√£o embutida, garantindo que opera√ß√µes automatizadas (clone/push) funcionem mesmo em ambientes CI/CD ou sess√µes reiniciadas.\n",
        "- **Clonagem limpa para o ambiente Colab:**  \n",
        "  Antes de clonar, remove qualquer vest√≠gio do reposit√≥rio anterior no diret√≥rio `/content`. Isso evita conflitos de arquivos, branches corrompidos e res√≠duos de execu√ß√µes antigas, criando um ambiente limpo para cada nova execu√ß√£o.\n",
        "- **Prepara√ß√£o e cria√ß√£o de diret√≥rios tempor√°rios de grava√ß√£o:**  \n",
        "  Cria automaticamente a pasta `/content/temp_recordings` para armazenar grava√ß√µes tempor√°rias, garantindo que o pipeline n√£o falhe por falta de estrutura de diret√≥rios.\n",
        "- **Duplica√ß√£o persistente no Google Drive:**  \n",
        "  Se o Drive estiver montado, remove o reposit√≥rio antigo do Drive e executa o clone atualizado para `/content/drive/MyDrive/XCam.Drive/XCam`. Isso garante persist√™ncia dos arquivos entre sess√µes e protege dados relevantes de reinicializa√ß√µes do ambiente Colab.\n",
        "- **Mensagens informativas e feedback visual:**  \n",
        "  O usu√°rio √© informado em cada etapa do processo por mensagens claras, incluindo alertas caso o Drive n√£o esteja montado, sucesso na clonagem e nos preparos de diret√≥rios, e poss√≠veis erros de autentica√ß√£o ou permiss√£o.\n",
        "- **Configura√ß√£o de endpoint para integra√ß√µes externas:**  \n",
        "  Define e exporta a vari√°vel `ABYSS_UPLOAD_URL`, j√° pronta para integra√ß√µes futuras com servi√ßos de upload ou armazenamento externo, como o Abyss.\n",
        "- **Exporta√ß√£o de todas as vari√°veis de ambiente:**  \n",
        "  Por meio do `globals().update()`, todas as configura√ß√µes (paths, URLs, tokens, pastas) s√£o exportadas para uso global e consistente em qualquer c√©lula do notebook, promovendo reuso e evitando duplicidade de c√≥digo.\n",
        "\n",
        "---\n",
        "\n",
        "## Par√¢metros globais definidos e exportados\n",
        "\n",
        "- **`GITHUB_USER`**, **`GITHUB_REPO`**, **`GITHUB_BRANCH`**, **`GITHUB_TOKEN`**: Dados do reposit√≥rio GitHub e autentica√ß√£o.\n",
        "- **`repo_url`**: URL autenticada para opera√ß√µes Git automatizadas.\n",
        "- **`TEMP_OUTPUT_FOLDER`**: Pasta tempor√°ria para grava√ß√µes no ambiente Colab.\n",
        "- **`BASE_REPO_FOLDER`**: Caminho do reposit√≥rio clonado no ambiente Colab.\n",
        "- **`DRIVE_MOUNT`**, **`DRIVE_REPO_FOLDER`**: Caminhos no Google Drive para persist√™ncia dos dados e do reposit√≥rio.\n",
        "- **`ABYSS_UPLOAD_URL`**: Endpoint de integra√ß√£o externa para uploads ou automa√ß√µes.\n",
        "\n",
        "---\n",
        "\n",
        "## Funcionamento passo a passo\n",
        "\n",
        "1. **Limpa o ambiente:**  \n",
        "   Remove o reposit√≥rio antigo e diret√≥rios tempor√°rios do Colab e, se dispon√≠vel, do Google Drive. Isso evita conflitos, arquivos √≥rf√£os e hist√≥rico inconsistente.\n",
        "2. **Clona o reposit√≥rio para o ambiente tempor√°rio:**  \n",
        "   Realiza o clone autenticado do reposit√≥rio XCam para `/content`, permitindo edi√ß√£o, execu√ß√£o e versionamento imediato do c√≥digo.\n",
        "3. **Cria a estrutura de diret√≥rios tempor√°rios:**  \n",
        "   Garante que a pasta de grava√ß√µes tempor√°rias esteja sempre pronta para uso (evita erros de \"diret√≥rio n√£o encontrado\").\n",
        "4. **Clona o reposit√≥rio para o Drive (persist√™ncia):**  \n",
        "   Se o Drive estiver dispon√≠vel, executa o clone tamb√©m para o diret√≥rio persistente. Isso permite que dados e c√≥digo sobrevivam a reinicializa√ß√µes ou resets do ambiente Colab.\n",
        "5. **Define endpoints e exporta vari√°veis globais:**  \n",
        "   Torna todos os par√¢metros relevantes dispon√≠veis para qualquer c√©lula do notebook, facilitando integra√ß√µes, uploads e futuras automa√ß√µes.\n",
        "\n",
        "---\n",
        "\n",
        "## Exemplos pr√°ticos de uso das vari√°veis exportadas\n",
        "\n",
        "```python\n",
        "print(BASE_REPO_FOLDER)        # Exibe o caminho do reposit√≥rio clonado no Colab\n",
        "print(DRIVE_REPO_FOLDER)       # Exibe o caminho do reposit√≥rio persistente no Drive (se montado)\n",
        "print(TEMP_OUTPUT_FOLDER)      # Exibe a pasta tempor√°ria destinada a grava√ß√µes\n",
        "print(ABYSS_UPLOAD_URL)        # Exibe a URL de upload para integra√ß√µes externas (Abyss, etc)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Seguran√ßa, rastreabilidade e boas pr√°ticas\n",
        "\n",
        "- **Ambiente 100% previs√≠vel:** Cada execu√ß√£o parte de um estado limpo, evitando bugs dif√≠ceis de rastrear e facilitando o debug.\n",
        "- **Persist√™ncia e backup autom√°tico:** A duplica√ß√£o do reposit√≥rio e dados no Drive protege contra perdas acidentais e facilita colabora√ß√£o entre membros do time.\n",
        "- **Pronto para automa√ß√µes e CI/CD:** O uso de token, URL autenticada e exporta√ß√£o de vari√°veis prepara o notebook para automa√ß√µes, integra√ß√µes com pipelines externos, deploys e uploads autom√°ticos.\n",
        "- **Coment√°rio e organiza√ß√£o did√°tica:** Cada bloco e etapa √© documentada, tornando a c√©lula autoexplicativa para manuten√ß√£o, auditoria e treinamento de novos membros.\n",
        "\n",
        "---\n",
        "\n",
        "## Recomenda√ß√µes de uso\n",
        "\n",
        "- **Execute esta c√©lula sempre que iniciar uma nova sess√£o, trocar de branch, atualizar token ou preparar ambiente para grava√ß√£o/execu√ß√£o.**\n",
        "- **Garanta que o Google Drive esteja montado antes de rodar a c√©lula, caso deseje persist√™ncia de dados e backup autom√°tico.**\n",
        "- **Utilize as vari√°veis globais exportadas para padronizar caminhos, URLs e integra√ß√µes em qualquer etapa do pipeline.**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "hpRIMtyFIY0q"
      },
      "id": "hpRIMtyFIY0q"
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================\n",
        "# C√©lula 4: Clonagem do Reposit√≥rio GitHub no Colab e no Google Drive\n",
        "# ================================================================\n",
        "# Objetivo:\n",
        "# - Garantir ambiente limpo e sincronizado para o reposit√≥rio XCam em todas as execu√ß√µes\n",
        "# - Clonar o reposit√≥rio tanto para o ambiente ef√™mero do Colab quanto para o Google Drive (persist√™ncia)\n",
        "# - Preparar diret√≥rios de trabalho para grava√ß√µes e processamento tempor√°rio\n",
        "# - Fornecer feedback claro sobre o status da opera√ß√£o\n",
        "#\n",
        "# Estrat√©gia aplicada:\n",
        "# - Remove reposit√≥rios antigos antes de clonar (evita conflitos e arquivos √≥rf√£os)\n",
        "# - Utiliza token pessoal para autentica√ß√£o segura e push futuro (CI/CD)\n",
        "# - Cria estrutura de diret√≥rios padronizada (m√≥dulos, grava√ß√µes, cache, etc.)\n",
        "# - Valida se o Drive est√° montado antes de tentar opera√ß√µes persistentes\n",
        "# - Coment√°rios detalhados para f√°cil manuten√ß√£o e evolu√ß√£o\n",
        "# ================================================================\n",
        "\n",
        "# ============================\n",
        "# CONFIGURA√á√ïES DO GITHUB\n",
        "# ============================\n",
        "GITHUB_USER = \"SamuelPassamani\"\n",
        "GITHUB_REPO = \"XCam\"\n",
        "GITHUB_BRANCH = \"main\"\n",
        "GITHUB_TOKEN = \"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\"\n",
        "\n",
        "repo_url = f\"https://{GITHUB_USER}:{GITHUB_TOKEN}@github.com/{GITHUB_USER}/{GITHUB_REPO}.git\"\n",
        "\n",
        "# ============================\n",
        "# CLONAGEM PARA O COLAB\n",
        "# ============================\n",
        "print(f\"‚è≥ Limpando ambiente e clonando '{GITHUB_REPO}' para o Colab...\")\n",
        "!rm -rf {GITHUB_REPO}\n",
        "!git clone -b {GITHUB_BRANCH} {repo_url}\n",
        "print(f\"‚úÖ Reposit√≥rio clonado em /content/{GITHUB_REPO}\")\n",
        "\n",
        "# ============================\n",
        "# ESTRUTURA DE DIRET√ìRIOS TEMPOR√ÅRIOS\n",
        "# ============================\n",
        "TEMP_OUTPUT_FOLDER = \"/content/temp_recordings\"  # Para grava√ß√µes tempor√°rias\n",
        "os.makedirs(TEMP_OUTPUT_FOLDER, exist_ok=True)\n",
        "BASE_REPO_FOLDER = f\"/content/{GITHUB_REPO}\"\n",
        "\n",
        "# ============================\n",
        "# CLONAGEM PARA O GOOGLE DRIVE (PERSIST√äNCIA)\n",
        "# ============================\n",
        "DRIVE_MOUNT = \"/content/drive/MyDrive/XCam.Drive\"\n",
        "DRIVE_REPO_FOLDER = f\"{DRIVE_MOUNT}/{GITHUB_REPO}\"\n",
        "\n",
        "if os.path.exists(DRIVE_MOUNT):\n",
        "    print(f\"‚è≥ Limpando reposit√≥rio antigo no Drive (se existir)...\")\n",
        "    !rm -rf \"{DRIVE_REPO_FOLDER}\"\n",
        "    print(f\"‚è≥ Clonando '{GITHUB_REPO}' para o Drive em {DRIVE_REPO_FOLDER} ...\")\n",
        "    !git clone -b {GITHUB_BRANCH} {repo_url} \"{DRIVE_REPO_FOLDER}\"\n",
        "    print(f\"‚úÖ Reposit√≥rio tamb√©m clonado no Drive: {DRIVE_REPO_FOLDER}\")\n",
        "else:\n",
        "    print(f\"‚ö†Ô∏è Google Drive n√£o est√° montado em {DRIVE_MOUNT}.\\n‚ÑπÔ∏è Use a c√©lula de montagem antes de prosseguir para garantir persist√™ncia.\")\n",
        "\n",
        "# ============================\n",
        "# CONFIGURA√á√ÉO DE ENDPOINTS DE UPLOAD/INTEGRA√á√ÉO\n",
        "# ============================\n",
        "ABYSS_UPLOAD_URL = 'http://up.hydrax.net/0128263f78f0b426d617bb61c2a8ff43'\n",
        "globals().update({\n",
        "    'GITHUB_USER': GITHUB_USER,\n",
        "    'GITHUB_REPO': GITHUB_REPO,\n",
        "    'GITHUB_BRANCH': GITHUB_BRANCH,\n",
        "    'GITHUB_TOKEN': GITHUB_TOKEN,\n",
        "    'repo_url': repo_url,\n",
        "    'TEMP_OUTPUT_FOLDER': TEMP_OUTPUT_FOLDER,\n",
        "    'BASE_REPO_FOLDER': BASE_REPO_FOLDER,\n",
        "    'DRIVE_MOUNT': DRIVE_MOUNT,\n",
        "    'DRIVE_REPO_FOLDER': DRIVE_REPO_FOLDER,\n",
        "    'ABYSS_UPLOAD_URL': ABYSS_UPLOAD_URL\n",
        "})\n",
        "\n",
        "# ============================\n",
        "# FIM DA C√âLULA 4\n",
        "# ============================\n",
        "\n",
        "# Observa√ß√µes:\n",
        "# - Os caminhos globais s√£o exportados via globals().update() para uso em todo o notebook.\n",
        "# - Recomenda-se sempre rodar esta c√©lula ap√≥s alterar tokens ou trocar branches para garantir ambiente limpo e sincronizado.\n",
        "# - O endpoint ABYSS_UPLOAD_URL pode ser atualizado conforme integra√ß√µes futuras."
      ],
      "metadata": {
        "id": "Uof_0QCrIlf7"
      },
      "id": "Uof_0QCrIlf7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# C√©lula 5: Commit e Push Autom√°ticos (rec.json, posters, etc.)\n",
        "\n",
        "**Objetivo:**  \n",
        "Automatizar o processo de versionamento e sincroniza√ß√£o dos arquivos modificados no pipeline XCam, como `rec.json`, imagens de poster e demais artefatos, realizando commit e push seguros e audit√°veis para o reposit√≥rio GitHub.  \n",
        "Esta c√©lula garante que as altera√ß√µes sejam rastreadas, publicadas e dispon√≠veis para todo o time, promovendo integra√ß√£o cont√≠nua (CI/CD) e minimizando riscos de perda ou inconsist√™ncia de dados.\n",
        "\n",
        "---\n",
        "\n",
        "## Descri√ß√£o t√©cnica e recursos implementados\n",
        "\n",
        "- **Fun√ß√£o modular e robusta para commit e push:**  \n",
        "  Estrutura pronta para aceitar tanto um caminho de arquivo √∫nico (string) quanto uma lista de arquivos (batch), permitindo estrat√©gias flex√≠veis de commit, seja por evento ou em lote (threshold/batch commit).\n",
        "- **Valida√ß√£o rigorosa do ambiente e dos arquivos:**  \n",
        "  Antes do commit, valida a exist√™ncia do reposit√≥rio local (`repo_dir`) e verifica a exist√™ncia de cada arquivo listado. Arquivos inexistentes s√£o ignorados com aviso expl√≠cito, evitando falhas desnecess√°rias e facilitando troubleshooting.\n",
        "- **Configura√ß√£o automatizada do usu√°rio do Git:**  \n",
        "  Define usu√°rio e e-mail padr√£o para os commits, garantindo rastreabilidade e conformidade com pol√≠ticas de auditoria e automa√ß√£o (essencial para ambientes CI/CD).\n",
        "- **Suporte a commit vazio (`--allow-empty`):**  \n",
        "  Permite commits mesmo sem altera√ß√µes detectadas, assegurando que etapas do pipeline n√£o sejam interrompidas por aus√™ncia de mudan√ßas (importante para sincroniza√ß√µes autom√°ticas e pipelines que dependem de triggers de commit).\n",
        "- **Push autenticado via token pessoal:**  \n",
        "  Utiliza o token do GitHub definido em vari√°veis globais para push seguro, sem necessidade de interven√ß√£o manual, pronto para uso em automa√ß√µes, jobs e ambientes colaborativos.\n",
        "- **Mensagens detalhadas e tratamento de erros:**  \n",
        "  Todo o processo √© acompanhado por mensagens claras sobre sucesso, falha ou condi√ß√£o especial (como arquivo ausente), facilitando rastreabilidade, auditoria e manuten√ß√£o.\n",
        "- **Design extens√≠vel para integra√ß√£o com logs e automa√ß√£o:**  \n",
        "  A fun√ß√£o est√° pronta para ser conectada ao log centralizado do notebook (C√©lula 1), garantindo rastreabilidade total de cada opera√ß√£o de commit/push e facilitando integra√ß√£o com webhooks, jobs ou triggers externos.\n",
        "\n",
        "---\n",
        "\n",
        "## Par√¢metros e vari√°veis globais utilizados\n",
        "\n",
        "- **`GITHUB_USER`**, **`GITHUB_REPO`**, **`GITHUB_TOKEN`**: Vari√°veis globais para autentica√ß√£o e configura√ß√£o, definidas nas etapas iniciais do notebook.\n",
        "- **`repo_dir`**: Caminho absoluto do reposit√≥rio clonado no ambiente Colab, utilizado como diret√≥rio de trabalho para comandos git.\n",
        "- **`file_paths`**: String (arquivo √∫nico) ou lista de strings (m√∫ltiplos arquivos), indicando os arquivos a serem commitados e enviados.\n",
        "- **`commit_message`**: Mensagem de commit, customiz√°vel conforme a opera√ß√£o realizada para maximizar a clareza e o hist√≥rico de versionamento.\n",
        "\n",
        "---\n",
        "\n",
        "## Fluxo operacional detalhado\n",
        "\n",
        "1. **Valida√ß√£o do reposit√≥rio local:**  \n",
        "   Confirma que o diret√≥rio do reposit√≥rio clonado est√° dispon√≠vel no ambiente. Caso contr√°rio, aborta a opera√ß√£o com mensagem de erro expl√≠cita.\n",
        "2. **Prepara√ß√£o dos arquivos para commit:**  \n",
        "   Aceita tanto arquivo √∫nico quanto lista. Apenas arquivos que realmente existem s√£o adicionados ao staging, com logs de aviso para ausentes.\n",
        "3. **Configura√ß√£o do usu√°rio e e-mail do git:**  \n",
        "   Garante autoria rastre√°vel e compat√≠vel com pipelines autom√°ticos, configurando user/email antes do commit.\n",
        "4. **Execu√ß√£o do commit (`--allow-empty`):**  \n",
        "   Realiza o commit das altera√ß√µes, permitindo commits vazios para garantir continuidade do pipeline quando necess√°rio.\n",
        "5. **Push autenticado para o reposit√≥rio remoto:**  \n",
        "   Usa a URL autenticada via token para enviar as altera√ß√µes ao reposit√≥rio GitHub, tornando-as imediatamente dispon√≠veis para o time e sistemas integrados.\n",
        "6. **Mensagens e tratamento de falhas:**  \n",
        "   Todo erro ou condi√ß√£o especial (ex: arquivo n√£o encontrado) √© logado e apresentado ao usu√°rio, facilitando o diagn√≥stico e a evolu√ß√£o do pipeline.\n",
        "\n",
        "---\n",
        "\n",
        "## Exemplo de uso t√©cnico\n",
        "\n",
        "```python\n",
        "# Commit e push de um √∫nico arquivo modificado\n",
        "git_commit_and_push(\"data/rec.json\", \"Atualiza rec.json de grava√ß√£o\")\n",
        "\n",
        "# Commit e push em lote de m√∫ltiplos arquivos (ex. posters atualizados)\n",
        "git_commit_and_push([\n",
        "    \"data/rec.json\",\n",
        "    \"posters/user1_poster.jpg\",\n",
        "    \"posters/user2_poster.jpg\"\n",
        "], \"Batch commit de m√∫ltiplos arquivos\")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Seguran√ßa, rastreabilidade e integra√ß√£o cont√≠nua\n",
        "\n",
        "- **Total rastreabilidade:** Mensagens de commit claras e integra√ß√£o recomendada com o log centralizado garantem hist√≥rico completo e audit√°vel de todas as opera√ß√µes.\n",
        "- **Atomicidade:** Commits em lote evitam inconsist√™ncias, garantindo que conjuntos de arquivos relacionados sejam versionados juntos.\n",
        "- **Pronto para CI/CD:** Design compat√≠vel com automa√ß√µes, pipelines, webhooks e integra√ß√µes externas, minimizando interven√ß√£o manual e acelerando entregas.\n",
        "- **Diagn√≥stico facilitado:** Tratamento de falhas e mensagens detalhadas reduzem tempo de troubleshooting e aumentam a confiabilidade do processo.\n",
        "\n",
        "---\n",
        "\n",
        "## Observa√ß√µes e pr√°ticas recomendadas\n",
        "\n",
        "- **A l√≥gica de commit/push foi movida para script externo:**  \n",
        "  Esta c√©lula serve como refer√™ncia e documenta√ß√£o da estrat√©gia recomendada. Certifique-se de que seu script externo implementa as valida√ß√µes, mensagens e pr√°ticas aqui descritas.\n",
        "- **Monitore os logs do seu script externo** para garantir que todas as opera√ß√µes sejam executadas corretamente e sem perdas.\n",
        "- **Mantenha vari√°veis globais atualizadas** (token, caminhos, etc) para evitar falhas de autentica√ß√£o ou inconsist√™ncias de ambiente.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "M5iL_9BoIoj7"
      },
      "id": "M5iL_9BoIoj7"
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================\n",
        "# C√©lula 5: Commit e Push Autom√°ticos (rec.json, posters, etc.)\n",
        "# ================================================================\n",
        "# Objetivo:\n",
        "# - Automatizar o processo de commit e push dos arquivos modificados (rec.json, posters, etc.) para o reposit√≥rio GitHub\n",
        "# - Suportar tanto commit de arquivo √∫nico como em lote, permitindo estrat√©gia de batch commit baseada em thresholds\n",
        "# - Garantir rastreabilidade, atomicidade e integra√ß√£o segura (CI/CD)\n",
        "#\n",
        "# Estrat√©gia aplicada:\n",
        "# - Fun√ß√£o modular e robusta, preparada para integra√ß√£o com logs e auditoria\n",
        "# - Permite commit vazio por seguran√ßa, evitando falhas em pipelines sincronizados\n",
        "# - Mensagens e tratamento de erros detalhados para facilitar troubleshooting\n",
        "# - Utiliza√ß√£o de vari√°veis globais para caminhos, usu√°rio e token definidos nas c√©lulas anteriores\n",
        "# - Design pronto para evolu√ß√£o, reuso e integra√ß√£o com ferramentas externas (ex: webhooks, jobs, etc.)\n",
        "# ================================================================\n",
        "\n",
        "# A l√≥gica de commit e push agora √© gerenciada por um script externo.\n",
        "# Esta c√©lula foi mantida para refer√™ncia, mas a fun√ß√£o git_commit_and_push\n",
        "# foi removida pois n√£o ser√° mais executada internamente.\n",
        "\n",
        "# def git_commit_and_push(file_paths, commit_message=\"Atualiza rec.json\"):\n",
        "#     \"\"\"\n",
        "#     Realiza git add, commit e push dos arquivos especificados.\n",
        "#     - file_paths pode ser uma string (arquivo √∫nico) ou uma lista de arquivos.\n",
        "#     - commit_message √© a mensagem de commit utilizada.\n",
        "\n",
        "#     Estrat√©gia:\n",
        "#     - Ajusta diret√≥rio para o reposit√≥rio local clonado no Colab\n",
        "#     - Configura usu√°rio e e-mail do git (necess√°rios para CI/CD)\n",
        "#     - Adiciona arquivos ao staging (aceita m√∫ltiplos arquivos)\n",
        "#     - Realiza commit (permite commit vazio)\n",
        "#     - Realiza push autenticado via token\n",
        "#     \"\"\"\n",
        "#     # ============================\n",
        "#     # VALIDA√á√ÉO E AJUSTE DE ENTRADAS\n",
        "#     # ============================\n",
        "#     repo_dir = f\"/content/{GITHUB_REPO}\"\n",
        "#     if not os.path.exists(repo_dir):\n",
        "#         raise FileNotFoundError(f\"Reposit√≥rio '{repo_dir}' n√£o encontrado. Verifique se a c√©lula de clonagem foi executada.\")\n",
        "#     os.chdir(repo_dir)\n",
        "\n",
        "#     # Aceita string ou lista de arquivos\n",
        "#     if isinstance(file_paths, str):\n",
        "#         file_paths = [file_paths]\n",
        "#     elif not isinstance(file_paths, list):\n",
        "#         raise ValueError(\"file_paths deve ser uma string ou uma lista de caminhos.\")\n",
        "\n",
        "#     # ============================\n",
        "#     # CONFIGURA√á√ÉO DO USU√ÅRIO GIT (CI/CD)\n",
        "#     # ============================\n",
        "#     subprocess.run([\"git\", \"config\", \"user.email\", \"contato@aserio.work\"], check=True)\n",
        "#     subprocess.run([\"git\", \"config\", \"user.name\", \"SamuelPassamani\"], check=True)\n",
        "\n",
        "#     # ============================\n",
        "#     # ADI√á√ÉO DOS ARQUIVOS AO STAGING\n",
        "#     # ============================\n",
        "#     for file_path in file_paths:\n",
        "#         # Verifica se o arquivo existe antes de adicionar\n",
        "#         if not os.path.exists(file_path):\n",
        "#             print(f\"‚ö†Ô∏è Aviso: arquivo '{file_path}' n√£o existe e ser√° ignorado no commit.\")\n",
        "#             continue\n",
        "#         subprocess.run([\"git\", \"add\", file_path], check=True)\n",
        "\n",
        "#     # ============================\n",
        "#     # COMMIT (PERMITE COMMIT VAZIO)\n",
        "#     # ============================\n",
        "#     try:\n",
        "#         subprocess.run(\n",
        "#             [\"git\", \"commit\", \"-m\", commit_message, \"--allow-empty\"],\n",
        "#             check=False  # N√£o for√ßa erro se n√£o houver mudan√ßas\n",
        "#         )\n",
        "#     except Exception as e:\n",
        "#         print(f\"‚ùå Erro ao tentar realizar commit: {e}\")\n",
        "\n",
        "#     # ============================\n",
        "#     # PUSH PARA O REPOSIT√ìRIO REMOTO (AUTENTICADO)\n",
        "#     # ============================\n",
        "#     try:\n",
        "#         remote_url = f\"https://{GITHUB_USER}:{GITHUB_TOKEN}@github.com/{GITHUB_USER}/{GITHUB_REPO}.git\"\n",
        "#         subprocess.run(\n",
        "#             [\"git\", \"push\", remote_url],\n",
        "#             check=True\n",
        "#         )\n",
        "#         print(f\"‚úÖ Push realizado com sucesso! ({commit_message})\")\n",
        "#     except Exception as e:\n",
        "#         print(f\"‚ùå Erro ao tentar realizar push: {e}\")\n",
        "\n",
        "# ============================\n",
        "# FIM DA C√âLULA 5\n",
        "# ============================\n",
        "\n",
        "# Dicas e melhores pr√°ticas:\n",
        "# - A l√≥gica de commit e push agora √© gerenciada por um script externo.\n",
        "# - Certifique-se de que seu script externo gerencie corretamente o commit e push\n",
        "#   dos arquivos alterados (como o rec.json e os posters).\n",
        "# - Monitore os logs do seu script externo para verificar o status dos commits e pushes."
      ],
      "metadata": {
        "id": "1aQn1G6yI6Gz"
      },
      "id": "1aQn1G6yI6Gz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# C√©lula 6: Busca de Transmiss√µes na API XCam com Blacklist, Controle de Falhas e Processamento Centralizados por ID ‚Äî Log √önico\n",
        "\n",
        "**Objetivo:**  \n",
        "Automatizar a busca e sele√ß√£o de transmiss√µes ao vivo na API da XCam utilizando um sistema centralizado de controle de blacklist tempor√°ria, falhas e marca√ß√£o de processamento, todos operando exclusivamente via log √∫nico (`xcam_master.log`) e com base no identificador √∫nico (`id`) da API.  \n",
        "Garante m√°xima rastreabilidade, elimina arquivos dispersos, permite fallback inteligente via `/liveInfo`, e assegura a presen√ßa de poster v√°lido para cada transmiss√£o.\n",
        "\n",
        "---\n",
        "\n",
        "## Estrat√©gia, arquitetura e diferenciais t√©cnicos\n",
        "\n",
        "- **Controle total por ID:**  \n",
        "  Todas as opera√ß√µes de blacklist, contagem de falhas e marca√ß√£o de processamento (in√≠cio/fim) s√£o indexadas pelo `id` √∫nico do usu√°rio retornado pela API XCam, eliminando ambiguidade e aumentando a precis√£o no ciclo de vida de cada transmiss√£o.\n",
        "- **Log √∫nico e centralizado:**  \n",
        "  Toda consulta e altera√ß√£o de estado (blacklist, falha, processamento, auditoria) √© feita via fun√ß√µes utilit√°rias do log centralizado ‚Äî `append_log`, `query_logs`, `remove_logs` ‚Äî eliminando completamente o uso de arquivos dispersos, facilitando CI/CD, rastreabilidade e manuten√ß√£o.\n",
        "- **Blacklist e falhas tempor√°rias com expira√ß√£o autom√°tica:**  \n",
        "  Usu√°rios s√£o bloqueados temporariamente ao atingir o limite de falhas (`BLACKLIST_MAX_FAILURES`), com expira√ß√£o e remo√ß√£o automatizadas das entradas antigas para m√°xima performance e precis√£o.\n",
        "- **Fallback automatizado para streams sem src:**  \n",
        "  Se uma transmiss√£o n√£o possui `src` direto na API principal, o sistema utiliza fallback inteligente via endpoint `/liveInfo`, tentando obter o stream e garantir a cobertura m√°xima do lote.\n",
        "- **Poster sempre garantido:**  \n",
        "  Para cada transmiss√£o, o sistema valida se h√° poster v√°lido (baixado ou gerado via ffmpeg). Caso contr√°rio, registra falha e pula para o pr√≥ximo, garantindo consist√™ncia visual e integridade para etapas posteriores do pipeline.\n",
        "- **Execu√ß√£o paralela e pronta para automa√ß√£o:**  \n",
        "  Fun√ß√µes desenhadas para suportar execu√ß√£o concorrente, integra√ß√£o com pipelines CI/CD, jobs automatizados e auditoria detalhada de todas as a√ß√µes por timestamp, id, username e status.\n",
        "- **Design modular e Clean Architecture:**  \n",
        "  Cada bloco funcional √© isolado: controle de blacklist, falha, processamento, busca em lote, busca espec√≠fica e busca unificada, facilitando manuten√ß√£o, testes e evolu√ß√£o do sistema.\n",
        "\n",
        "---\n",
        "\n",
        "## Descri√ß√£o t√©cnica das fun√ß√µes principais\n",
        "\n",
        "- **Fun√ß√µes de Blacklist, Falha e Processamento (todas por id):**\n",
        "  - `is_in_blacklist(user_id)`: Verifica se o usu√°rio est√° bloqueado, expira e remove automaticamente as entradas antigas.\n",
        "  - `add_to_blacklist(user_id, username)`: Adiciona o usu√°rio ao blacklist tempor√°rio, registrando evento e detalhes no log.\n",
        "  - `get_failures(user_id)`: Conta falhas recentes e ignora/expira registros antigos.\n",
        "  - `register_failure(user_id, username, details)`: Registra falha, promove a blacklist se atingir o limite, limpa registros ap√≥s blacklisting.\n",
        "  - `clear_failure(user_id)`: Remove todos os registros de falha do usu√°rio.\n",
        "  - `is_processing(user_id)`: Verifica se o usu√°rio est√° marcado como ‚Äúem processamento ativo‚Äù.\n",
        "  - `mark_processing(user_id, username)`: Marca transmiss√£o como em processamento no log.\n",
        "  - `unmark_processing(user_id)`: Remove marca√ß√£o de processamento.\n",
        "- **Busca de transmiss√µes (com fallback e valida√ß√£o de poster):**\n",
        "  - `get_broadcasts(limit, ...)`: Retorna lote de transmiss√µes v√°lidas (com poster), respeitando blacklist, falhas, processamento e evitando duplicidades, com fallback para `/liveInfo` e registro detalhado no log.\n",
        "  - `buscar_usuarios_especificos(usuarios_lista, ...)`: Busca apenas os usu√°rios informados (por username), protegendo por blacklist/falha/processamento e realizando fallback se necess√°rio.\n",
        "  - `buscar_proxima_transmissao_livre(...)`: Busca a pr√≥xima transmiss√£o livre e v√°lida, pronta para processamento imediato, com valida√ß√£o completa e integra√ß√£o ao log √∫nico.\n",
        "\n",
        "---\n",
        "\n",
        "## Fluxo operacional ‚Äî passo a passo\n",
        "\n",
        "1. **Consulta √† API XCam:**  \n",
        "   Obt√©m lista de transmiss√µes ativas, extrai `id`, `username`, `src` e poster.\n",
        "2. **Filtragem centralizada:**  \n",
        "   Elimina transmiss√µes j√° em processamento, blacklist ou com excesso de falhas, sempre via consulta ao log √∫nico e pelo `id`.\n",
        "3. **Valida√ß√£o e fallback de poster:**  \n",
        "   Garante que cada transmiss√£o s√≥ ser√° considerada se houver poster v√°lido; caso contr√°rio, tenta gera√ß√£o via ffmpeg. Se ainda assim n√£o for poss√≠vel, registra falha no log e segue para o pr√≥ximo.\n",
        "4. **Fallback via liveInfo:**  \n",
        "   Para transmiss√µes sem src na API principal, executa fallback via `/liveInfo`, tentando maximizar o preenchimento do lote ou encontrar usu√°rios espec√≠ficos.\n",
        "5. **Registro e limpeza autom√°ticos:**  \n",
        "   Toda falha, blacklist ou status de processamento √© registrada no log, com limpeza autom√°tica de entradas expiradas e atualiza√ß√£o por evento.\n",
        "\n",
        "---\n",
        "\n",
        "## Exemplos de uso t√©cnico\n",
        "\n",
        "```python\n",
        "# Buscar lote completo de transmiss√µes v√°lidas (com blacklist, falha e poster garantidos)\n",
        "streams = get_broadcasts(limit=LIMIT_DEFAULT)\n",
        "\n",
        "# Buscar apenas usu√°rios espec√≠ficos (com prote√ß√£o centralizada e fallback)\n",
        "streams_especificos = buscar_usuarios_especificos([\"user1\", \"user2\"])\n",
        "\n",
        "# Buscar a pr√≥xima transmiss√£o livre, pronta para processamento (m√°xima rastreabilidade)\n",
        "proxima_stream = buscar_proxima_transmissao_livre()\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Seguran√ßa, rastreabilidade e manuten√ß√£o\n",
        "\n",
        "- **Rastreabilidade total:**  \n",
        "  Todos os eventos cr√≠ticos s√£o registrados no log √∫nico, com campos padronizados (`sessao`, `evento`, `id`, `username`, `status`, `detalhes`, `timestamp`).\n",
        "- **Elimina√ß√£o de arquivos dispersos:**  \n",
        "  N√£o h√° mais arquivos auxiliares para blacklist, falha, processamento ‚Äî tudo √© centralizado e padronizado.\n",
        "- **Execu√ß√£o concorrente e CI/CD-ready:**  \n",
        "  Fun√ß√µes preparadas para paralelismo, automa√ß√£o e integra√ß√£o cont√≠nua.\n",
        "- **Tratamento de erros robusto:**  \n",
        "  Falhas de API, poster, liveInfo e demais eventos s√£o tratados com exce√ß√µes, mensagens claras e registro detalhado para auditoria e manuten√ß√£o.\n",
        "\n",
        "---\n",
        "\n",
        "## Recomenda√ß√µes\n",
        "\n",
        "- Utilize sempre as fun√ß√µes centralizadas para garantir consist√™ncia, rastreabilidade e seguran√ßa.\n",
        "- Monitore o log √∫nico (`xcam_master.log`) para auditoria, troubleshooting e tuning de par√¢metros como timeout e thresholds.\n",
        "- Adapte os limites e par√¢metros conforme o volume de transmiss√µes, mantendo sempre o controle por `id` e log centralizado.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "BZ4c3Uk1I7AK"
      },
      "id": "BZ4c3Uk1I7AK"
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================\n",
        "# C√©lula 6: Busca de Transmiss√µes com Blacklist Tempor√°ria e Controle de Falhas Centralizados\n",
        "# ================================================================\n",
        "# Objetivo:\n",
        "# - Buscar transmiss√µes ao vivo na API XCam, considerando blacklist e controle de falhas por usu√°rio, ambos centralizados no log √∫nico (xcam_master.log)\n",
        "# - Evitar loops infinitos e tentativas repetidas em usu√°rios problem√°ticos via sess√µes de blacklist/falha no log √∫nico\n",
        "# - Garantir sempre poster v√°lido (via download ou ffmpeg) antes de liberar qualquer transmiss√£o para processamento\n",
        "# - Modulariza√ß√£o robusta, integra√ß√£o total com log √∫nico, sem leitura/escrita direta em arquivos dispersos\n",
        "# - CAPTURAR E USAR O \"id\" √öNICO DO USU√ÅRIO DA API PARA CONTROLE NO LOG\n",
        "#\n",
        "# Estrat√©gia aplicada:\n",
        "# - Toda a l√≥gica de blacklist e falhas opera via fun√ß√µes utilit√°rias do log centralizado (C√©lula 1), AGORA USANDO O 'id'\n",
        "# - Sess√µes do log: \"blacklist\" (usu√°rios banidos temporariamente), \"failure\" (falhas por usu√°rio), \"processing\" (transmiss√£o em processamento)\n",
        "# - Cada evento registrado no log cont√©m: sessao, evento, id (AGORA ID √öNICO DA API), username, status, detalhes, timestamp\n",
        "# - N√£o existe mais uso de arquivos como BLACKLIST_PATH, FAILURE_LOG_PATH ou LOG_PROCESSAMENTO_PATH\n",
        "# ================================================================\n",
        "\n",
        "# ============================\n",
        "# FUN√á√ïES DE BLACKLIST E FALHAS CENTRALIZADAS NO LOG (AGORA BASEADO EM ID)\n",
        "# ============================\n",
        "\n",
        "# As fun√ß√µes abaixo usar√£o o 'id' do usu√°rio como chave prim√°ria para consultar/manipular o log central.\n",
        "\n",
        "def is_in_blacklist(user_id, now=None):\n",
        "    \"\"\"\n",
        "    Verifica se o usu√°rio (pelo ID) est√° atualmente na blacklist (sessao='blacklist' e status='blacklisted' e n√£o expirado).\n",
        "    Remove automaticamente entradas expiradas.\n",
        "    \"\"\"\n",
        "    now = now or time.time()\n",
        "    # Busca todos eventos atuais de blacklist desse ID de usu√°rio\n",
        "    entries = query_logs(sessao=\"blacklist\", id=user_id, status=\"blacklisted\")\n",
        "    for entry in entries:\n",
        "        ts_log = entry.get(\"timestamp\")\n",
        "        # timestamp ISO para epoch\n",
        "        try:\n",
        "            ts_epoch = datetime.fromisoformat(ts_log.replace(\"Z\", \"+00:00\")).timestamp() if ts_log else 0\n",
        "        except ValueError: # Tratar poss√≠veis erros de formato ISO\n",
        "            ts_epoch = 0\n",
        "            print(f\"‚ö†Ô∏è Aviso: Formato de timestamp inv√°lido no log para entrada blacklist (id: {user_id}): {ts_log}\")\n",
        "\n",
        "        # Verifica expira√ß√£o\n",
        "        if now - ts_epoch < BLACKLIST_TIMEOUT:\n",
        "            return True\n",
        "        else:\n",
        "            # Remove entrada expirada (usando id e timestamp para garantir unicidade na remo√ß√£o)\n",
        "            removed_count = remove_logs(lambda e: e.get(\"sessao\") == \"blacklist\" and e.get(\"id\") == user_id and e.get(\"timestamp\") == ts_log)\n",
        "            # print(f\"‚ÑπÔ∏è Removidas {removed_count} entradas de blacklist expiradas para ID {user_id}\") # O remove_logs j√° loga\n",
        "    return False\n",
        "\n",
        "def add_to_blacklist(user_id, username):\n",
        "    \"\"\"\n",
        "    Adiciona usu√°rio (pelo ID) √† blacklist tempor√°ria via log central.\n",
        "    Registra tamb√©m o username para refer√™ncia.\n",
        "    \"\"\"\n",
        "    # Primeiro, limpa entradas antigas de blacklist para este ID (garante que s√≥ haja uma ativa)\n",
        "    remove_logs(lambda e: e.get(\"sessao\") == \"blacklist\" and e.get(\"id\") == user_id)\n",
        "\n",
        "    entry = {\n",
        "        \"sessao\": \"blacklist\",\n",
        "        \"evento\": \"add_blacklist\",\n",
        "        \"id\": user_id,\n",
        "        \"username\": username, # Mant√©m username para refer√™ncia\n",
        "        \"status\": \"blacklisted\",\n",
        "        \"detalhes\": f\"Banido temporariamente por atingir o limite de falhas ({BLACKLIST_MAX_FAILURES})\"\n",
        "    }\n",
        "    append_log(entry)\n",
        "    print(f\"‚ö†Ô∏è Usu√°rio '{username}' (ID: {user_id}) adicionado √† blacklist tempor√°ria (registrado no log centralizado).\")\n",
        "\n",
        "def get_failures(user_id):\n",
        "    \"\"\"\n",
        "    Conta o n√∫mero de falhas registradas para o usu√°rio (pelo ID) (sessao='failure' e status='erro' n√£o expiradas).\n",
        "    \"\"\"\n",
        "    # Busca falhas nos √∫ltimos BLACKLIST_TIMEOUT segundos (expira junto com blacklist)\n",
        "    now = time.time()\n",
        "    entries = query_logs(sessao=\"failure\", id=user_id, status=\"erro\")\n",
        "    valid_failures = []\n",
        "    for entry in entries:\n",
        "        ts_log = entry.get(\"timestamp\")\n",
        "        try:\n",
        "            ts_epoch = datetime.fromisoformat(ts_log.replace(\"Z\", \"+00:00\")).timestamp() if ts_log else 0\n",
        "        except ValueError: # Tratar poss√≠veis erros de formato ISO\n",
        "            ts_epoch = 0\n",
        "            print(f\"‚ö†Ô∏è Aviso: Formato de timestamp inv√°lido no log para entrada failure (id: {user_id}): {ts_log}\")\n",
        "\n",
        "        if now - ts_epoch < BLACKLIST_TIMEOUT:\n",
        "            valid_failures.append(entry)\n",
        "        else:\n",
        "            # Remove entrada expirada (usando id e timestamp para garantir unicidade na remo√ß√£o)\n",
        "            removed_count = remove_logs(lambda e: e.get(\"sessao\") == \"failure\" and e.get(\"id\") == user_id and e.get(\"timestamp\") == ts_log)\n",
        "            # print(f\"‚ÑπÔ∏è Removidas {removed_count} entradas de falha expiradas para ID {user_id}\") # O remove_logs j√° loga\n",
        "    return len(valid_failures)\n",
        "\n",
        "def register_failure(user_id, username, details=\"\"):\n",
        "    \"\"\"\n",
        "    Registra uma falha para o usu√°rio (pelo ID). Move para blacklist se exceder o limite.\n",
        "    Registra tamb√©m o username para refer√™ncia.\n",
        "    \"\"\"\n",
        "    # Limpa falhas antigas expiradas antes de adicionar uma nova para este ID\n",
        "    now = time.time()\n",
        "    remove_logs(lambda e: e.get(\"sessao\") == \"failure\" and e.get(\"id\") == user_id and (datetime.fromisoformat(e.get(\"timestamp\",\"\").replace(\"Z\", \"+00:00\")).timestamp() if e.get(\"timestamp\") else 0) < now - BLACKLIST_TIMEOUT)\n",
        "\n",
        "    append_log({\n",
        "        \"sessao\": \"failure\",\n",
        "        \"evento\": \"registrar_falha\",\n",
        "        \"id\": user_id,\n",
        "        \"username\": username, # Mant√©m username para refer√™ncia\n",
        "        \"status\": \"erro\",\n",
        "        \"detalhes\": details\n",
        "    })\n",
        "    failures = get_failures(user_id)\n",
        "    print(f\"‚ùå Falha registrada para '{username}' (ID: {user_id}). Total de falhas recentes: {failures}/{BLACKLIST_MAX_FAILURES}\")\n",
        "\n",
        "    if failures >= BLACKLIST_MAX_FAILURES:\n",
        "        add_to_blacklist(user_id, username)\n",
        "        # Limpa falhas ap√≥s blacklisting para este ID\n",
        "        remove_logs(lambda e: e.get(\"sessao\") == \"failure\" and e.get(\"id\") == user_id)\n",
        "        print(f\"‚úÖ Falhas limpas para ID {user_id} ap√≥s blacklisting.\")\n",
        "\n",
        "\n",
        "def clear_failure(user_id):\n",
        "    \"\"\"\n",
        "    Limpa todas as falhas registradas para o usu√°rio (pelo ID).\n",
        "    \"\"\"\n",
        "    removed = remove_logs(lambda e: e.get(\"sessao\") == \"failure\" and e.get(\"id\") == user_id)\n",
        "    if removed > 0:\n",
        "        # Podemos adicionar um log de sucesso de limpeza aqui, se necess√°rio\n",
        "        # append_log({\"sessao\": \"failure\", \"evento\": \"limpar_falhas\", \"id\": user_id, \"status\": \"ok\", \"detalhes\": f\"{removed} falhas limpas\"})\n",
        "        print(f\"‚úÖ {removed} falhas limpas para ID {user_id}.\")\n",
        "    # else:\n",
        "    #     print(f\"‚ÑπÔ∏è Nenhuma falha encontrada para limpar para ID {user_id}.\") # remove_logs j√° loga se nada foi removido\n",
        "\n",
        "\n",
        "def is_processing(user_id):\n",
        "    \"\"\"\n",
        "    Verifica se o usu√°rio (pelo ID) est√° marcado como em processamento ativo.\n",
        "    \"\"\"\n",
        "    # Procura por entrada de processamento 'in_progress' para este ID\n",
        "    entries = query_logs(sessao=\"processing\", id=user_id, status=\"in_progress\")\n",
        "    return len(entries) > 0\n",
        "\n",
        "def mark_processing(user_id, username):\n",
        "    \"\"\"\n",
        "    Marca o usu√°rio/transmiss√£o (pelo ID) como em processamento ativo via log central.\n",
        "    Registra tamb√©m o username para refer√™ncia.\n",
        "    \"\"\"\n",
        "    # Remove entradas antigas de processamento para este ID antes de adicionar a nova (garante unicidade)\n",
        "    remove_logs(lambda e: e.get(\"sessao\") == \"processing\" and e.get(\"id\") == user_id)\n",
        "\n",
        "    append_log({\n",
        "        \"sessao\": \"processing\",\n",
        "        \"evento\": \"iniciar\",\n",
        "        \"id\": user_id,\n",
        "        \"username\": username, # Mant√©m username para refer√™ncia\n",
        "        \"status\": \"in_progress\",\n",
        "        \"detalhes\": \"\"\n",
        "    })\n",
        "    # print(f\"‚ÑπÔ∏è Usu√°rio '{username}' (ID: {user_id}) marcado como 'in_progress' no log.\")\n",
        "\n",
        "\n",
        "def unmark_processing(user_id):\n",
        "    \"\"\"\n",
        "    Remove marca√ß√£o de processamento ativo para o usu√°rio (pelo ID).\n",
        "    \"\"\"\n",
        "    # Remove entradas de processamento 'in_progress' para este ID\n",
        "    removed = remove_logs(lambda e: e.get(\"sessao\") == \"processing\" and e.get(\"id\") == user_id and e.get(\"status\") == \"in_progress\")\n",
        "    # if removed > 0:\n",
        "    #     print(f\"‚ÑπÔ∏è Marca√ß√£o 'in_progress' removida para ID {user_id}.\")\n",
        "    # else:\n",
        "    #      print(f\"‚ÑπÔ∏è Nenhuma marca√ß√£o 'in_progress' encontrada para remover para ID {user_id}.\") # remove_logs j√° loga se nada foi removido\n",
        "\n",
        "\n",
        "# ============================\n",
        "# BUSCA DE TRANSMISS√ïES NA API XCAM (AGORA CAPTURANDO O ID E USANDO NO CONTROLE)\n",
        "# ============================\n",
        "\n",
        "def get_broadcasts(limit=LIMIT_DEFAULT, page=PAGE_DEFAULT, usuarios_especificos=None, temp_folder=\"/content\"):\n",
        "    \"\"\"\n",
        "    Busca transmiss√µes ao vivo, respeitando blacklist (por ID), falhas (por ID) e log de processamento (por ID) via log centralizado.\n",
        "    Garante poster v√°lido (download ou ffmpeg) e faz fallback autom√°tico.\n",
        "    RETORNA LISTA DE DICION√ÅRIOS INCLUINDO O 'id' DA API.\n",
        "    \"\"\"\n",
        "    # Coleta IDs de usu√°rios atualmente em processamento ou blacklist\n",
        "    ids_em_proc_ou_blacklist = {e[\"id\"] for e in query_logs(sessao=\"processing\", status=\"in_progress\")} | \\\n",
        "                               {e[\"id\"] for e in query_logs(sessao=\"blacklist\", status=\"blacklisted\")}\n",
        "\n",
        "\n",
        "    if usuarios_especificos:\n",
        "        # Note: Buscar por username espec√≠fico na API e depois filtrar por ID no log √© necess√°rio\n",
        "        # A API principal n√£o parece permitir busca por lista de IDs diretamente\n",
        "        api_url_main = f\"https://api.xcam.gay/?limit={API_SEARCH_LIMIT}&page=1\" # Ainda busca um lote grande para encontrar espec√≠ficos\n",
        "        print(f\"üåê Acessando API principal (buscando usu√°rios espec√≠ficos) em: {api_url_main}\")\n",
        "    else:\n",
        "        # Busca um lote grande para ter mais chances de encontrar usu√°rios dispon√≠veis\n",
        "        api_url_main = f\"https://api.xcam.gay/?limit=3333\"\n",
        "        print(f\"üåê Acessando API principal (buscando todas transmiss√µes online) em: {api_url_main}\")\n",
        "\n",
        "    streams_candidates = [] # streams que tem src ou que precisam de liveInfo\n",
        "    streams_without_preview = [] # streams sem src na API principal\n",
        "\n",
        "    try:\n",
        "        response_main = requests.get(api_url_main)\n",
        "        response_main.raise_for_status()\n",
        "        data_main = response_main.json()\n",
        "        broadcasts_data = data_main.get(\"broadcasts\")\n",
        "        if not broadcasts_data:\n",
        "            print(\"‚ö†Ô∏è Chave 'broadcasts' n√£o encontrada na resposta da API principal.\")\n",
        "            return []\n",
        "        items = broadcasts_data.get(\"items\")\n",
        "        if not isinstance(items, list):\n",
        "            print(f\"‚ö†Ô∏è Chave 'items' n√£o encontrada ou n√£o √© uma lista em 'broadcasts'.\")\n",
        "            return []\n",
        "\n",
        "        print(f\"API principal retornou {len(items)} transmiss√µes.\")\n",
        "\n",
        "        for item in items:\n",
        "            # ** CAPTURA O ID AQUI **\n",
        "            user_id = str(item.get(\"id\")) # Garante que o ID seja string\n",
        "            username = item.get(\"username\", \"desconhecido\")\n",
        "            preview = item.get(\"preview\") or {}\n",
        "            src = preview.get(\"src\")\n",
        "            poster = preview.get(\"poster\")\n",
        "\n",
        "            # Ignora se j√° est√° em processamento ou blacklist (AGORA VERIFICA PELO ID)\n",
        "            if user_id in ids_em_proc_ou_blacklist:\n",
        "                # print(f\"‚ÑπÔ∏è Usu√°rio '{username}' (ID: {user_id}) j√° processado/em blacklist/processing, ignorando.\")\n",
        "                continue\n",
        "\n",
        "            # Ignora se est√° buscando espec√≠ficos e este usu√°rio/ID n√£o est√° na lista\n",
        "            if usuarios_especificos and username not in usuarios_especificos: # Continua filtrando por username se especificado\n",
        "                 # Poder√≠amos tamb√©m adicionar uma lista de IDs espec√≠ficos, se a API permitisse buscar por ID.\n",
        "                continue\n",
        "\n",
        "            stream_info = {\n",
        "                 \"id\": user_id, # Inclui o ID\n",
        "                 \"username\": username,\n",
        "                 \"src\": src,\n",
        "                 \"poster\": poster # Isso pode ser URL ou None\n",
        "            }\n",
        "\n",
        "            if src:\n",
        "                streams_candidates.append(stream_info) # Adiciona streams com src para processar/validar poster\n",
        "            else:\n",
        "                 streams_without_preview.append(stream_info) # Adiciona streams sem src para tentar liveInfo\n",
        "\n",
        "        print(f\"‚úÖ {len(streams_candidates)} transmiss√µes com URL na API principal, {len(streams_without_preview)} sem URL.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Erro ao acessar API principal: {e}\")\n",
        "        # Registrar erro de busca no log\n",
        "        if \"append_log\" in globals():\n",
        "             append_log({\n",
        "                 \"sessao\": \"busca\",\n",
        "                 \"evento\": \"erro_api_principal\",\n",
        "                 \"id\": \"global\", # Erro global de API\n",
        "                 \"username\": \"global\",\n",
        "                 \"status\": \"erro\",\n",
        "                 \"detalhes\": f\"Erro ao acessar API principal: {e}\"\n",
        "             })\n",
        "        return [] # Retorna vazio em caso de erro na API principal\n",
        "\n",
        "    # Fallback: busca via liveInfo para streams sem URL na API principal\n",
        "    streams_from_liveinfo = []\n",
        "    if streams_without_preview:\n",
        "        print(f\"üîÅ Buscando liveInfo para {len(streams_without_preview)} streams sem URL na API principal...\")\n",
        "        for stream_info in streams_without_preview:\n",
        "            user_id = stream_info[\"id\"] # Usa o ID capturado\n",
        "            username = stream_info[\"username\"]\n",
        "\n",
        "            # Verifica novamente se entrou em proc/blacklist enquanto process√°vamos a lista\n",
        "            if user_id in ids_em_proc_ou_blacklist:\n",
        "                 # print(f\"‚ÑπÔ∏è Usu√°rio '{username}' (ID: {user_id}) j√° processado/em blacklist/processing durante fallback, ignorando.\")\n",
        "                 continue\n",
        "\n",
        "            api_url_liveinfo = f\"https://api.xcam.gay/user/{username}/liveInfo\" # LiveInfo ainda usa username na URL\n",
        "            try:\n",
        "                response_liveinfo = requests.get(api_url_liveinfo)\n",
        "                response_liveinfo.raise_for_status()\n",
        "                data_liveinfo = response_liveinfo.json()\n",
        "                m3u8_url = data_liveinfo.get(\"cdnURL\") or data_liveinfo.get(\"edgeURL\")\n",
        "                if m3u8_url:\n",
        "                    # Adiciona stream encontrada via liveInfo aos candidatos\n",
        "                    streams_from_liveinfo.append({\n",
        "                        \"id\": user_id, # Inclui o ID\n",
        "                        \"username\": username,\n",
        "                        \"src\": m3u8_url,\n",
        "                        \"poster\": None # Poster do liveInfo geralmente n√£o √© direto, ser√° gerado\n",
        "                    })\n",
        "                else:\n",
        "                    print(f\"‚ö†Ô∏è liveInfo de '{username}' (ID: {user_id}) n√£o retornou cdnURL/edgeURL (usu√°rio possivelmente offline).\")\n",
        "                    # Registrar falha no liveInfo no log (AGORA USA ID)\n",
        "                    if \"register_failure\" in globals():\n",
        "                         register_failure(user_id, username, \"liveInfo sem cdnURL/edgeURL.\")\n",
        "\n",
        "            except Exception as ex:\n",
        "                print(f\"‚ùå Erro ao buscar liveInfo para '{username}' (ID: {user_id}): {ex}\")\n",
        "                 # Registrar erro de liveInfo no log (AGORA USA ID)\n",
        "                if \"register_failure\" in globals():\n",
        "                     register_failure(user_id, username, f\"Erro ao buscar liveInfo: {ex}\")\n",
        "\n",
        "            time.sleep(0.2) # Pequeno delay entre chamadas de liveInfo\n",
        "\n",
        "    # Junta candidatos da API principal e liveInfo.\n",
        "    # Antes de adicionar √† lista final, valida poster e evita duplicidade/blacklist FINAL.\n",
        "    final_streams_list = []\n",
        "    seen_ids = set() # Usa um set de IDs para controlar duplicidade na lista final\n",
        "    all_candidates = streams_candidates + streams_from_liveinfo\n",
        "\n",
        "    print(f\"Validando poster e filtrando {len(all_candidates)} candidatos...\")\n",
        "\n",
        "    for stream in all_candidates:\n",
        "        user_id = stream[\"id\"]\n",
        "        username = stream[\"username\"]\n",
        "        src = stream[\"src\"]\n",
        "        poster_info = stream[\"poster\"] # Pode ser URL ou None\n",
        "\n",
        "        # Verifica pela √öLTIMA VEZ se o ID j√° foi adicionado √† lista final,\n",
        "        # ou se entrou em processamento/blacklist desde a consulta inicial da API.\n",
        "        if user_id in seen_ids or user_id in ids_em_proc_ou_blacklist:\n",
        "            continue\n",
        "\n",
        "        poster_path = None\n",
        "        try:\n",
        "            # Tenta baixar poster original se existir\n",
        "            if poster_info and isinstance(poster_info, str) and poster_info.strip():\n",
        "                poster_path = download_and_save_poster(poster_info, username, temp_folder) # download_and_save_poster n√£o precisa de ID\n",
        "\n",
        "            # Se poster baixado for inv√°lido OU n√£o havia poster original, gera com ffmpeg\n",
        "            if not is_poster_valid(poster_path):\n",
        "                poster_path = generate_poster_with_ffmpeg(src, username, temp_folder) # generate_poster_with_ffmpeg n√£o precisa de ID\n",
        "\n",
        "            # Se mesmo ap√≥s todas as tentativas o poster for inv√°lido\n",
        "            if not is_poster_valid(poster_path):\n",
        "                # Registrar falha de poster no log (AGORA USA ID)\n",
        "                if \"register_failure\" in globals():\n",
        "                     register_failure(user_id, username, \"Poster inv√°lido ap√≥s todas tentativas.\")\n",
        "                continue # Pula para o pr√≥ximo stream se o poster for inv√°lido\n",
        "\n",
        "            # Se o poster √© v√°lido, limpa falhas relacionadas a poster/ffmpeg/conex√£o para este ID\n",
        "            if \"clear_failure\" in globals():\n",
        "                 clear_failure(user_id) # Limpa falhas pelo ID\n",
        "\n",
        "            # Adiciona √† lista final e marca ID como visto\n",
        "            final_streams_list.append({\n",
        "                \"id\": user_id, # Inclui o ID √∫nico no resultado final\n",
        "                \"username\": username,\n",
        "                \"src\": src,\n",
        "                \"poster_path\": poster_path # Passa o caminho LOCAL do poster v√°lido\n",
        "            })\n",
        "            seen_ids.add(user_id)\n",
        "\n",
        "            # Quebra o loop se atingiu o limite desejado\n",
        "            if len(final_streams_list) >= limit:\n",
        "                break\n",
        "\n",
        "        except Exception as e:\n",
        "            msg = f\"Falha inesperada durante valida√ß√£o de poster/stream para '{username}' (ID: {user_id}): {e}\"\n",
        "            print(f\"‚ùå {msg}\")\n",
        "            # Registrar falha gen√©rica no log (AGORA USA ID)\n",
        "            if \"register_failure\" in globals():\n",
        "                 register_failure(user_id, username, msg)\n",
        "\n",
        "\n",
        "    print(f\"üîé Selecionadas {len(final_streams_list)} streams v√°lidas (com poster) ap√≥s fallback (respeitando limit={limit}).\")\n",
        "    return final_streams_list\n",
        "\n",
        "# ============================\n",
        "# BUSCA DE USU√ÅRIOS ESPEC√çFICOS (AGORA COM ID)\n",
        "# ============================\n",
        "\n",
        "def buscar_usuarios_especificos(usuarios_lista, temp_folder=\"/content\"):\n",
        "    \"\"\"\n",
        "    Busca usu√°rios espec√≠ficos via API (por username), agora respeitando blacklist (por ID)\n",
        "    e controle de falhas (por ID) via log central. Inclui fallback via liveInfo e valida poster.\n",
        "    RETORNA LISTA DE DICION√ÅRIOS INCLUINDO O 'id' DA API.\n",
        "    \"\"\"\n",
        "    # Coleta IDs de usu√°rios em processamento ou blacklist\n",
        "    ids_em_proc_ou_blacklist = {e[\"id\"] for e in query_logs(sessao=\"processing\", status=\"in_progress\")} | \\\n",
        "                               {e[\"id\"] for e in query_logs(sessao=\"blacklist\", status=\"blacklisted\")}\n",
        "\n",
        "    # Primeiro, tenta encontrar os usu√°rios na lista na API principal (limite alto para pegar todos se online)\n",
        "    api_url = f\"https://api.xcam.gay/?limit={API_SEARCH_LIMIT}&page=1\"\n",
        "    print(f\"üîç Buscando usu√°rios espec√≠ficos ({len(usuarios_lista)}) em {api_url}\")\n",
        "    found_candidates = []\n",
        "    users_not_found_in_main = set(usuarios_lista) # Acompanha quem n√£o foi encontrado na API principal\n",
        "\n",
        "    try:\n",
        "        response = requests.get(api_url)\n",
        "        response.raise_for_status()\n",
        "        data = response.json()\n",
        "        items = data.get(\"broadcasts\", {}).get(\"items\", [])\n",
        "\n",
        "        for item in items:\n",
        "            user_id = str(item.get(\"id\")) # ** CAPTURA O ID **\n",
        "            username = item.get(\"username\", \"\")\n",
        "\n",
        "            if username in usuarios_lista: # Verifica se este √© um dos usu√°rios que procuramos\n",
        "                 users_not_found_in_main.discard(username) # Remove da lista de n√£o encontrados\n",
        "\n",
        "                 # Verifica se o ID est√° em proc/blacklist (AGORA VERIFICA PELO ID)\n",
        "                 if user_id in ids_em_proc_ou_blacklist:\n",
        "                     # print(f\"‚ÑπÔ∏è Usu√°rio '{username}' (ID: {user_id}) j√° processado/em blacklist/processing, ignorando.\")\n",
        "                     continue\n",
        "\n",
        "                 preview = item.get(\"preview\") or {}\n",
        "                 src = preview.get(\"src\")\n",
        "                 poster = preview.get(\"poster\") # Pode ser URL ou None\n",
        "\n",
        "                 if src:\n",
        "                     # Adiciona como candidato se tiver SRC (valida√ß√£o de poster depois)\n",
        "                     found_candidates.append({\n",
        "                         \"id\": user_id, # Inclui o ID\n",
        "                         \"username\": username,\n",
        "                         \"src\": src,\n",
        "                         \"poster\": poster # Pode ser URL ou None\n",
        "                     })\n",
        "                 else:\n",
        "                     # Marca para tentar via liveInfo se n√£o tiver SRC principal\n",
        "                     # Adiciona a lista de streams_without_preview para liveinfo fallback\n",
        "                     found_candidates.append({\n",
        "                        \"id\": user_id, # Inclui o ID\n",
        "                        \"username\": username,\n",
        "                        \"src\": None, # Indica que precisa de liveInfo\n",
        "                        \"poster\": None\n",
        "                    })\n",
        "\n",
        "\n",
        "        print(f\"Encontrados {len(found_candidates)} dos {len(usuarios_lista)} usu√°rios especificados na API principal (antes de fallback).\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Erro ao buscar usu√°rios espec√≠ficos na API principal: {e}\")\n",
        "        # Registrar erro de busca no log (AGORA USA ID ou Global)\n",
        "        if \"append_log\" in globals():\n",
        "             append_log({\n",
        "                 \"sessao\": \"busca\",\n",
        "                 \"evento\": \"erro_api_especificos\",\n",
        "                 \"id\": \"global\", # Erro global de API\n",
        "                 \"username\": \"global\",\n",
        "                 \"status\": \"erro\",\n",
        "                 \"detalhes\": f\"Erro ao buscar usu√°rios espec√≠ficos na API principal: {e}\"\n",
        "             })\n",
        "        # Em caso de erro na API principal, tenta buscar cada usu√°rio individualmente via liveInfo?\n",
        "        # Para simplificar, se a API principal falha, retornamos o que conseguimos ou vazio.\n",
        "        # Se o erro √© grave, talvez n√£o haja mais o que fazer.\n",
        "\n",
        "    # Fallback: busca via liveInfo para usu√°rios especificados que n√£o tinham SRC na API principal\n",
        "    streams_from_liveinfo = []\n",
        "    # Filtra os candidatos que precisam de liveInfo\n",
        "    candidates_for_liveinfo = [c for c in found_candidates if c.get(\"src\") is None]\n",
        "    # Adiciona usu√°rios que N√ÉO foram encontrados na API principal mas estavam na lista original\n",
        "    # Assume que se n√£o foi encontrado na lista grande da API principal, est√° offline ou precisa de liveInfo direto\n",
        "    # Isso pode gerar falsos positivos se o usu√°rio estiver offline\n",
        "    for uname in users_not_found_in_main:\n",
        "        # Tenta obter o ID antes de tentar liveInfo? LiveInfo n√£o retorna ID...\n",
        "        # Se o usu√°rio n√£o foi encontrado na API principal (com limite alto), √© prov√°vel que esteja offline.\n",
        "        # Buscar liveInfo sem ter um ID √© menos robusto.\n",
        "        # Vamos focar no fallback APENAS para usu√°rios ENCONTRADOS na API principal mas sem SRC.\n",
        "        # Se o usu√°rio da lista espec√≠fica n√£o apareceu na busca grande, assumimos offline por enquanto.\n",
        "        print(f\"‚ö†Ô∏è Usu√°rio '{uname}' especificado n√£o encontrado na busca da API principal. Assumindo offline ou inacess√≠vel.\")\n",
        "\n",
        "\n",
        "    if candidates_for_liveinfo:\n",
        "        print(f\"üîÅ Buscando liveInfo para {len(candidates_for_liveinfo)} usu√°rios espec√≠ficos sem URL na API principal...\")\n",
        "        for stream_info in candidates_for_liveinfo:\n",
        "            user_id = stream_info[\"id\"] # Usa o ID capturado da API principal\n",
        "            username = stream_info[\"username\"]\n",
        "\n",
        "            # Verifica novamente se entrou em proc/blacklist\n",
        "            if user_id in ids_em_proc_ou_blacklist:\n",
        "                 # print(f\"‚ÑπÔ∏è Usu√°rio '{username}' (ID: {user_id}) j√° processado/em blacklist/processing durante fallback, ignorando.\")\n",
        "                 continue\n",
        "\n",
        "            api_url_liveinfo = f\"https://api.xcam.gay/user/{username}/liveInfo\"\n",
        "            try:\n",
        "                response_liveinfo = requests.get(api_url_liveinfo)\n",
        "                response_liveinfo.raise_for_status()\n",
        "                data_liveinfo = response_liveinfo.json()\n",
        "                m3u8_url = data_liveinfo.get(\"cdnURL\") or data_liveinfo.get(\"edgeURL\")\n",
        "                if m3u8_url:\n",
        "                    # Adiciona stream encontrada via liveInfo\n",
        "                    streams_from_liveinfo.append({\n",
        "                        \"id\": user_id, # Inclui o ID\n",
        "                        \"username\": username,\n",
        "                        \"src\": m3u8_url,\n",
        "                        \"poster\": None # Poster do liveInfo geralmente n√£o √© direto, ser√° gerado\n",
        "                    })\n",
        "                else:\n",
        "                    print(f\"‚ö†Ô∏è liveInfo de '{username}' (ID: {user_id}) n√£o retornou cdnURL/edgeURL (usu√°rio possivelmente offline).\")\n",
        "                    # Registrar falha no liveInfo no log (AGORA USA ID)\n",
        "                    if \"register_failure\" in globals():\n",
        "                         register_failure(user_id, username, \"liveInfo sem cdnURL/edgeURL.\")\n",
        "\n",
        "            except Exception as ex:\n",
        "                print(f\"‚ùå Erro ao buscar liveInfo para '{username}' (ID: {user_id}): {ex}\")\n",
        "                # Registrar erro de liveInfo no log (AGORA USA ID)\n",
        "                if \"register_failure\" in globals():\n",
        "                     register_failure(user_id, username, f\"Erro ao buscar liveInfo: {ex}\")\n",
        "\n",
        "            time.sleep(0.2) # Pequeno delay\n",
        "\n",
        "    # Junta candidatos que tinham SRC e os encontrados via liveInfo.\n",
        "    # Antes de adicionar √† lista final, valida poster e evita duplicidade/blacklist FINAL.\n",
        "    final_streams_list = []\n",
        "    seen_ids = set() # Usa um set de IDs para controlar duplicidade na lista final\n",
        "    # Filtra os candidatos que TINHAM SRC na API principal\n",
        "    candidates_with_src = [c for c in found_candidates if c.get(\"src\") is not None]\n",
        "    all_candidates_post_fallback = candidates_with_src + streams_from_liveinfo\n",
        "\n",
        "    print(f\"Validando poster e filtrando {len(all_candidates_post_fallback)} candidatos ap√≥s fallback...\")\n",
        "\n",
        "\n",
        "    for stream in all_candidates_post_fallback:\n",
        "        user_id = stream[\"id\"]\n",
        "        username = stream[\"username\"]\n",
        "        src = stream[\"src\"]\n",
        "        poster_info = stream[\"poster\"] # Pode ser URL ou None\n",
        "\n",
        "        # Verifica pela √öLTIMA VEZ se o ID j√° foi adicionado √† lista final,\n",
        "        # ou se entrou em processamento/blacklist desde a consulta inicial.\n",
        "        if user_id in seen_ids or user_id in ids_em_proc_ou_blacklist:\n",
        "            continue\n",
        "\n",
        "        poster_path = None\n",
        "        try:\n",
        "            # Tenta baixar poster original se existir\n",
        "            if poster_info and isinstance(poster_info, str) and poster_info.strip():\n",
        "                poster_path = download_and_save_poster(poster_info, username, temp_folder)\n",
        "\n",
        "            # Se poster baixado for inv√°lido OU n√£o havia poster original, gera com ffmpeg\n",
        "            if not is_poster_valid(poster_path):\n",
        "                poster_path = generate_poster_with_ffmpeg(src, username, temp_folder)\n",
        "\n",
        "            # Se mesmo ap√≥s todas as tentativas o poster for inv√°lido\n",
        "            if not is_poster_valid(poster_path):\n",
        "                 # Registrar falha de poster no log (AGORA USA ID)\n",
        "                if \"register_failure\" in globals():\n",
        "                     register_failure(user_id, username, \"Poster inv√°lido ap√≥s todas tentativas.\")\n",
        "                continue # Pula para o pr√≥ximo stream\n",
        "\n",
        "            # Se o poster √© v√°lido, limpa falhas relacionadas a poster/ffmpeg/conex√£o para este ID\n",
        "            if \"clear_failure\" in globals():\n",
        "                 clear_failure(user_id) # Limpa falhas pelo ID\n",
        "\n",
        "            # Adiciona √† lista final e marca ID como visto\n",
        "            final_streams_list.append({\n",
        "                \"id\": user_id, # Inclui o ID √∫nico no resultado final\n",
        "                \"username\": username,\n",
        "                \"src\": src,\n",
        "                \"poster_path\": poster_path # Passa o caminho LOCAL do poster v√°lido\n",
        "            })\n",
        "            seen_ids.add(user_id)\n",
        "\n",
        "            # No modo espec√≠fico, buscamos todos da lista, ent√£o n√£o h√° limite de \"len(final_streams_list) >= limit\" aqui.\n",
        "            # Poder√≠amos adicionar um limite se quis√©ssemos parar ap√≥s encontrar N dos espec√≠ficos.\n",
        "\n",
        "        except Exception as e:\n",
        "            msg = f\"Falha inesperada durante valida√ß√£o de poster/stream para '{username}' (ID: {user_id}): {e}\"\n",
        "            print(f\"‚ùå {msg}\")\n",
        "            # Registrar falha gen√©rica no log (AGORA USA ID)\n",
        "            if \"register_failure\" in globals():\n",
        "                 register_failure(user_id, username, msg)\n",
        "\n",
        "    print(f\"üîé Encontrados e validados {len(final_streams_list)} dos {len(usuarios_lista)} usu√°rios especificados.\")\n",
        "    return final_streams_list\n",
        "\n",
        "\n",
        "# ============================\n",
        "# BUSCA DA PR√ìXIMA TRANSMISS√ÉO DISPON√çVEL (AGORA COM ID)\n",
        "# ============================\n",
        "\n",
        "def buscar_proxima_transmissao_livre(temp_folder=\"/content\"):\n",
        "    \"\"\"\n",
        "    Busca a pr√≥xima transmiss√£o ao vivo n√£o processada, com poster v√°lido e ignorando blacklist (por ID), tudo centralizado no log.\n",
        "    RETORNA DICION√ÅRIO INCLUINDO O 'id' DA API, OU None.\n",
        "    \"\"\"\n",
        "    # Coleta IDs de usu√°rios em processamento ou blacklist\n",
        "    ids_em_proc_ou_blacklist = {e[\"id\"] for e in query_logs(sessao=\"processing\", status=\"in_progress\")} | \\\n",
        "                               {e[\"id\"] for e in query_logs(sessao=\"blacklist\", status=\"blacklisted\")}\n",
        "\n",
        "\n",
        "    api_url_main = f\"https://api.xcam.gay/?limit=3333&page=1\" # Busca um lote grande para encontrar o pr√≥ximo r√°pido\n",
        "    print(f\"üîé Buscando pr√≥xima transmiss√£o livre em: {api_url_main}\")\n",
        "    try:\n",
        "        response_main = requests.get(api_url_main)\n",
        "        response_main.raise_for_status()\n",
        "        data_main = response_main.json()\n",
        "        items = data_main.get(\"broadcasts\", {}).get(\"items\", [])\n",
        "        print(f\"API principal retornou {len(items)} transmiss√µes.\")\n",
        "\n",
        "        # Primeiro, itera sobre os itens da API principal que t√™m SRC\n",
        "        for item in items:\n",
        "            # ** CAPTURA O ID AQUI **\n",
        "            user_id = str(item.get(\"id\")) # Garante que o ID seja string\n",
        "            username = item.get(\"username\", \"desconhecido\")\n",
        "            preview = item.get(\"preview\") or {}\n",
        "            src = preview.get(\"src\")\n",
        "            poster_info = preview.get(\"poster\") # Pode ser URL ou None\n",
        "\n",
        "            # Ignora se j√° est√° em processamento ou blacklist (AGORA VERIFICA PELO ID)\n",
        "            if user_id in ids_em_proc_ou_blacklist:\n",
        "                # print(f\"‚ÑπÔ∏è Usu√°rio '{username}' (ID: {user_id}) j√° processado/em blacklist/processing, ignorando.\")\n",
        "                continue\n",
        "\n",
        "            if src:\n",
        "                 # Se tem SRC e n√£o est√° em proc/blacklist, valida poster\n",
        "                poster_path = None\n",
        "                try:\n",
        "                    # Tenta baixar poster original se existir\n",
        "                    if poster_info and isinstance(poster_info, str) and poster_info.strip():\n",
        "                        poster_path = download_and_save_poster(poster_info, username, temp_folder)\n",
        "\n",
        "                    # Se poster baixado for inv√°lido OU n√£o havia poster original, gera com ffmpeg\n",
        "                    if not is_poster_valid(poster_path):\n",
        "                        poster_path = generate_poster_with_ffmpeg(src, username, temp_folder)\n",
        "\n",
        "                    # Se o poster √© v√°lido, limpa falhas relacionadas a poster/ffmpeg/conex√£o e retorna\n",
        "                    if is_poster_valid(poster_path):\n",
        "                        if \"clear_failure\" in globals():\n",
        "                             clear_failure(user_id) # Limpa falhas pelo ID\n",
        "                        print(f\"üéØ Transmiss√£o livre encontrada: '{username}' (ID: {user_id})\")\n",
        "                        return {\n",
        "                            \"id\": user_id, # Inclui o ID √∫nico no resultado\n",
        "                            \"username\": username,\n",
        "                            \"src\": src,\n",
        "                            \"poster_path\": poster_path # Passa o caminho LOCAL do poster v√°lido\n",
        "                        }\n",
        "                    else:\n",
        "                         # Se poster inv√°lido, registra falha e continua buscando\n",
        "                         if \"register_failure\" in globals():\n",
        "                             register_failure(user_id, username, \"Poster inv√°lido ap√≥s todas tentativas (busca pr√≥xima).\")\n",
        "                         continue # Pula para o pr√≥ximo item\n",
        "\n",
        "                except Exception as e:\n",
        "                    msg = f\"Falha inesperada durante valida√ß√£o de poster/stream para '{username}' (ID: {user_id}) na busca pr√≥xima: {e}\"\n",
        "                    print(f\"‚ùå {msg}\")\n",
        "                    # Registrar falha gen√©rica no log (AGORA USA ID)\n",
        "                    if \"register_failure\" in globals():\n",
        "                         register_failure(user_id, username, msg)\n",
        "                    continue # Pula para o pr√≥ximo item\n",
        "\n",
        "\n",
        "        # Se chegou aqui, nenhum item com SRC foi encontrado/validado na busca grande.\n",
        "        # Agora, itera sobre os itens sem SRC para tentar liveInfo\n",
        "        print(\"Nenhuma transmiss√£o livre com SRC encontrada, tentando liveInfo para os demais...\")\n",
        "        for item in items:\n",
        "             user_id = str(item.get(\"id\")) # ** CAPTURA O ID **\n",
        "             username = item.get(\"username\", \"desconhecido\")\n",
        "             preview = item.get(\"preview\") or {}\n",
        "             src = preview.get(\"src\") # Re-verifica SRC\n",
        "\n",
        "             # Ignora se tem SRC (j√° processado acima) ou se j√° est√° em proc/blacklist\n",
        "             if src or user_id in ids_em_proc_ou_blacklist:\n",
        "                  continue\n",
        "\n",
        "             # Se n√£o tem SRC e n√£o est√° em proc/blacklist, tenta liveInfo\n",
        "             api_url_liveinfo = f\"https://api.xcam.gay/user/{username}/liveInfo\"\n",
        "             try:\n",
        "                 response_liveinfo = requests.get(api_url_liveinfo)\n",
        "                 response_liveinfo.raise_for_status()\n",
        "                 data_liveinfo = response_liveinfo.json()\n",
        "                 m3u8_url = data_liveinfo.get(\"cdnURL\") or data_liveinfo.get(\"edgeURL\")\n",
        "                 if m3u8_url:\n",
        "                      # Se encontrou URL via liveInfo, valida poster e retorna\n",
        "                      poster_path = generate_poster_with_ffmpeg(m3u8_url, username, temp_folder)\n",
        "\n",
        "                      if is_poster_valid(poster_path):\n",
        "                           if \"clear_failure\" in globals():\n",
        "                                clear_failure(user_id) # Limpa falhas pelo ID\n",
        "                           print(f\"üéØ Transmiss√£o livre (pelo liveInfo) encontrada: '{username}' (ID: {user_id})\")\n",
        "                           return {\n",
        "                               \"id\": user_id, # Inclui o ID √∫nico no resultado\n",
        "                               \"username\": username,\n",
        "                               \"src\": m3u8_url,\n",
        "                               \"poster_path\": poster_path # Passa o caminho LOCAL do poster v√°lido\n",
        "                           }\n",
        "                      else:\n",
        "                           # Se poster inv√°lido, registra falha e continua buscando\n",
        "                           if \"register_failure\" in globals():\n",
        "                                register_failure(user_id, username, \"Poster inv√°lido (busca pr√≥xima liveInfo).\")\n",
        "                           continue # Pula para o pr√≥ximo item\n",
        "                 else:\n",
        "                      print(f\"‚ö†Ô∏è liveInfo de '{username}' (ID: {user_id}) n√£o retornou cdnURL/edgeURL.\")\n",
        "                      # Registrar falha no liveInfo no log (AGORA USA ID)\n",
        "                      if \"register_failure\" in globals():\n",
        "                           register_failure(user_id, username, \"liveInfo sem cdnURL/edgeURL (busca pr√≥xima).\")\n",
        "\n",
        "\n",
        "             except Exception as ex:\n",
        "                 msg = f\"Erro ao buscar liveInfo para '{username}' (ID: {user_id}) na busca pr√≥xima: {ex}\"\n",
        "                 print(f\"‚ùå {msg}\")\n",
        "                 # Registrar erro de liveInfo no log (AGORA USA ID)\n",
        "                 if \"register_failure\" in globals():\n",
        "                      register_failure(user_id, username, msg)\n",
        "\n",
        "             time.sleep(0.2) # Pequeno delay\n",
        "\n",
        "\n",
        "        # Se nenhum stream foi encontrado/validado ap√≥s varrer toda a lista da API (com SRC e liveInfo)\n",
        "        print(\"üö´ Nenhuma transmiss√£o livre encontrada ap√≥s varrer todas online.\")\n",
        "        return None # Retorna None se nenhum stream livre foi encontrado ap√≥s todas as tentativas\n",
        "\n",
        "    except Exception as e:\n",
        "        msg = f\"‚ùå Erro ao buscar transmiss√µes online (busca pr√≥xima): {e}\"\n",
        "        print(f\"‚ùå {msg}\")\n",
        "        # Registrar erro de busca no log (AGORA USA ID ou Global)\n",
        "        if \"append_log\" in globals():\n",
        "             append_log({\n",
        "                 \"sessao\": \"busca\",\n",
        "                 \"evento\": \"erro_api_proxima\",\n",
        "                 \"id\": \"global\", # Erro global de API\n",
        "                 \"username\": \"global\",\n",
        "                 \"status\": \"erro\",\n",
        "                 \"detalhes\": msg\n",
        "             })\n",
        "        return None # Retorna None em caso de erro na API\n",
        "\n",
        "# ================================================================\n",
        "# FIM DA C√âLULA 6 ‚Äî BUSCA, BLACKLIST E CONTROLE DE FALHAS CENTRALIZADOS (AGORA COM ID)\n",
        "# ================================================================\n",
        "\n",
        "# Observa√ß√µes:\n",
        "# - Toda manipula√ß√£o de blacklist, falha e processamento agora √© feita via fun√ß√µes do log centralizado (C√©lula 1), USANDO O ID √öNICO DA API.\n",
        "# - O username √© mantido nos registros de log para refer√™ncia humana, mas a l√≥gica de controle se baseia no 'id'.\n",
        "# - Nenhum uso de arquivos dispersos. Consultas e remo√ß√µes s√£o sempre via query_logs, append_log, remove_logs.\n",
        "# - Para m√°xima rastreabilidade, todos os eventos relevantes est√£o registrados no log √∫nico."
      ],
      "metadata": {
        "id": "h1jr7D0pJ7jS"
      },
      "id": "h1jr7D0pJ7jS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# C√©lula 7: Grava√ß√£o Autom√°tica de Transmiss√£o, Log Centralizado por ID, Limpeza e Blacklist Inteligente\n",
        "\n",
        "**Objetivo:**  \n",
        "Automatizar a grava√ß√£o de transmiss√µes ao vivo usando ffmpeg, com controle rigoroso e centralizado de status, falhas, blacklist tempor√°ria e limpeza de recursos via log √∫nico (`xcam_master.log`), utilizando sempre o identificador √∫nico (`id`) da API XCam para rastreabilidade.  \n",
        "Esta c√©lula garante gerenciamento seguro do processamento, tratamento autom√°tico de falhas, integra√ß√£o com blacklist escalon√°vel e limpeza completa de arquivos tempor√°rios, pronta para execu√ß√£o concorrente, CI/CD e auditoria.\n",
        "\n",
        "---\n",
        "\n",
        "## Estrat√©gia t√©cnica e diferenciais implementados\n",
        "\n",
        "- **Controle centralizado e seguro por ID:**  \n",
        "  O usu√°rio √© registrado no log centralizado (`sessao=\"processing\"`, `status=\"in_progress\"`) com seu `id` √∫nico antes do in√≠cio da grava√ß√£o, e removido ao final (sucesso ou erro), prevenindo duplicidade e concorr√™ncia indevida. Todos os eventos (in√≠cio, erro, exce√ß√£o, dura√ß√£o insuficiente, sucesso, limpeza) s√£o registrados com rastreabilidade completa.\n",
        "- **Poster sempre garantido:**  \n",
        "  O sistema tenta baixar o poster informado. Se ausente ou inv√°lido, gera automaticamente uma imagem via ffmpeg, garantindo que toda transmiss√£o processada tenha um poster v√°lido associado.\n",
        "- **Valida√ß√£o robusta da grava√ß√£o:**  \n",
        "  Ap√≥s a execu√ß√£o do ffmpeg, a dura√ß√£o real do v√≠deo √© aferida com ffprobe. Se o arquivo for muito curto ou inv√°lido, tanto o v√≠deo quanto o poster s√£o descartados, e uma falha √© registrada para o usu√°rio no log, escalando para blacklist tempor√°ria se necess√°rio.\n",
        "- **Tratamento e escalonamento de falhas:**  \n",
        "  Falhas de ffmpeg, dura√ß√£o insuficiente, ou outras exce√ß√µes s√£o registradas no log central por id. O usu√°rio √© automaticamente escalonado para a blacklist tempor√°ria ao atingir o limite de falhas (`BLACKLIST_MAX_FAILURES`), protegendo o pipeline contra tentativas repetidas e recursos desperdi√ßados.\n",
        "- **Limpeza automatizada de recursos:**  \n",
        "  Qualquer arquivo tempor√°rio (v√≠deo, poster) √© removido logo ap√≥s o upload ou erro, mantendo o ambiente limpo e evitando ac√∫mulo de res√≠duos no Colab.\n",
        "- **Feedback detalhado e rastreabilidade:**  \n",
        "  Todas as etapas cr√≠ticas s√£o logadas e exibidas em tempo real no console, e o log √∫nico pode ser consultado para auditoria, troubleshooting ou integra√ß√£o CI/CD.\n",
        "- **Modularidade e documenta√ß√£o detalhada:**  \n",
        "  O c√≥digo √© segmentado em blocos l√≥gicos, com coment√°rios explicativos, facilitando manuten√ß√£o, revis√£o e evolu√ß√£o pela equipe.\n",
        "\n",
        "---\n",
        "\n",
        "## Fluxo operacional detalhado\n",
        "\n",
        "1. **Registra o usu√°rio no log central (processing/in_progress)**, por id, antes de iniciar a grava√ß√£o.\n",
        "2. **Garante poster v√°lido**, baixando ou gerando automaticamente.\n",
        "3. **Executa ffmpeg** para gravar a transmiss√£o, monitora o progresso e exibe logs em tempo real.\n",
        "4. **Valida a grava√ß√£o**:\n",
        "   - Se ffmpeg falhar, registra erro no log e incrementa contador de falhas do usu√°rio (por id).\n",
        "   - Se a grava√ß√£o for curta demais, descarta v√≠deo/poster e registra falha.\n",
        "   - Se sucesso, limpa contador de falhas e registra evento positivo.\n",
        "5. **Upload e integra√ß√£o externa:**  \n",
        "   Realiza upload do v√≠deo (e poster) e atualiza o banco de dados, logando sucesso ou erro.\n",
        "6. **Limpeza e finaliza√ß√£o:**  \n",
        "   Remove a marca√ß√£o de processamento do usu√°rio (por id) no log central e apaga arquivos tempor√°rios, registrando todos os eventos de limpeza.\n",
        "\n",
        "---\n",
        "\n",
        "## Exemplo de uso t√©cnico\n",
        "\n",
        "```python\n",
        "resultado = gravar_stream(\n",
        "    user_id=\"123456\",\n",
        "    username=\"user123\",\n",
        "    m3u8_url=\"https://cdn.xcam.gay/m3u8/...\",\n",
        "    poster_url=\"https://api.xcam.gay/poster/...\"\n",
        ")\n",
        "if resultado['upload_success']:\n",
        "    print(\"Grava√ß√£o e upload realizados com sucesso!\")\n",
        "else:\n",
        "    print(\"Falha na grava√ß√£o ou upload:\", resultado['abyss_response'])\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Seguran√ßa, rastreabilidade e integra√ß√£o\n",
        "\n",
        "- **Execu√ß√£o concorrente e pronta para CI/CD:**  \n",
        "  O controle centralizado por id e blacklist tempor√°ria garante execu√ß√£o paralela segura e rastre√°vel em pipelines automatizados.\n",
        "- **Integra√ß√£o total com as fun√ß√µes globais do log:**  \n",
        "  Utiliza as fun√ß√µes de status, falha e blacklist da C√©lula 6, dispensando arquivos auxiliares e promovendo padroniza√ß√£o.\n",
        "- **Auditoria e diagn√≥stico facilitados:**  \n",
        "  Mensagens e logs detalhados em cada etapa, todos centralizados no log √∫nico (`xcam_master.log`), prontos para consulta, auditoria ou troubleshooting.\n",
        "\n",
        "---\n",
        "\n",
        "## Observa√ß√µes t√©cnicas\n",
        "\n",
        "- Toda manipula√ß√£o de status, falha, blacklist e processamento √© feita exclusivamente via fun√ß√µes do log centralizado, sempre por id.\n",
        "- A arquitetura √© preparada para paralelismo, manuten√ß√£o e evolu√ß√£o do pipeline, protegendo contra duplicidade e inconsist√™ncia.\n",
        "- O sistema garante que nenhum usu√°rio problem√°tico trave o pipeline, gra√ßas ao escalonamento automatizado para blacklist tempor√°ria.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "jGFyqOUoKEF7"
      },
      "id": "jGFyqOUoKEF7"
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================\n",
        "# C√©lula 7: Grava√ß√£o Autom√°tica de Transmiss√£o, Controle de Log Centralizado, Limpeza e Blacklist Inteligente (AGORA USANDO ID)\n",
        "# ================================================================\n",
        "# Objetivo:\n",
        "# - Gravar transmiss√µes ao vivo utilizando ffmpeg, com controle rigoroso e centralizado de log de processamento, tratamento de falhas e integra√ß√£o com blacklist tempor√°ria (log √∫nico).\n",
        "# - Garantir que cada transmiss√£o seja registrada no log central no in√≠cio e removida ao final (sucesso ou erro), evitando duplicidade/processamento concorrente (sessao=\"processing\").\n",
        "# - Registrar falhas (ffmpeg, dura√ß√£o insuficiente, poster inv√°lido), escalando usu√°rios para a blacklist tempor√°ria via log central ao atingir o limite de tentativas, AGORA USANDO O ID.\n",
        "# - Assegurar limpeza robusta de arquivos tempor√°rios e rastreabilidade total via eventos no log √∫nico e mensagens detalhadas.\n",
        "# - Modular, preparado para integra√ß√£o com pipelines CI/CD, paralelismo e auditoria centralizada.\n",
        "# ================================================================\n",
        "\n",
        "def get_video_duration(filepath):\n",
        "    \"\"\"\n",
        "    Retorna a dura√ß√£o real do arquivo mp4, em segundos, utilizando ffprobe.\n",
        "    Retorna None em caso de erro ou se o arquivo n√£o existir.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        if not os.path.exists(filepath):\n",
        "            print(f\"‚ö†Ô∏è Arquivo para ffprobe n√£o encontrado: {filepath}\")\n",
        "            return None\n",
        "        cmd = [\n",
        "            \"ffprobe\", \"-v\", \"error\",\n",
        "            \"-show_entries\", \"format=duration\",\n",
        "            \"-of\", \"json\",\n",
        "            filepath\n",
        "        ]\n",
        "        result = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
        "        info = json.loads(result.stdout)\n",
        "        duration = float(info[\"format\"][\"duration\"])\n",
        "        return int(round(duration))\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è N√£o foi poss√≠vel obter dura√ß√£o via ffprobe para {filepath}: {e}\")\n",
        "        return None\n",
        "\n",
        "# Adicionando user_id como par√¢metro\n",
        "def gravar_stream(user_id, username, m3u8_url, poster_url=None, poster_frame_time=7):\n",
        "    \"\"\"\n",
        "    Grava a transmiss√£o ao vivo do usu√°rio (pelo ID) usando ffmpeg, com controle de erros, log centralizado e integra√ß√£o √† blacklist.\n",
        "    - Registra no log centralizado (sessao=\"processing\") no in√≠cio (status=\"in_progress\"), USANDO O ID.\n",
        "    - Remove do log ao finalizar, independentemente do resultado, USANDO O ID.\n",
        "    - Em caso de falha do ffmpeg ou grava√ß√£o muito curta, registra falha do usu√°rio no log (sessao=\"failure\"), USANDO O ID.\n",
        "    - Ao atingir N falhas consecutivas, usu√°rio entra na blacklist (fun√ß√µes de log centralizado), USANDO O ID.\n",
        "    - Limpa arquivos tempor√°rios ao final.\n",
        "    - Garante poster v√°lido: baixa da poster_url ou gera automaticamente com ffmpeg.\n",
        "    - poster_frame_time: segundo do v√≠deo onde a captura do poster ser√° feita, se necess√°rio.\n",
        "    \"\"\"\n",
        "    # --- Registro no log centralizado: PROCESSAMENTO INICIADO (USANDO ID) ---\n",
        "    # As fun√ß√µes mark_processing, unmark_processing, register_failure, clear_failure\n",
        "    # na C√©lula 6 j√° foram ajustadas para aceitar e usar user_id.\n",
        "    mark_processing(user_id, username) # Passa user_id e username\n",
        "\n",
        "    start_time_dt = datetime.now()\n",
        "    data_str = start_time_dt.strftime(\"%d-%m-%Y\")\n",
        "    horario_str = start_time_dt.strftime(\"%H-%M\")\n",
        "    temp_filename = f\"{username}_{start_time_dt.strftime('%Y%m%d_%H%M%S')}_temp.mp4\"\n",
        "    filepath = os.path.join(TEMP_OUTPUT_FOLDER, temp_filename)\n",
        "    append_log({\n",
        "        \"sessao\": \"processing\",\n",
        "        \"evento\": \"iniciar_gravacao\",\n",
        "        \"id\": user_id, # Usa o ID\n",
        "        \"username\": username,\n",
        "        \"status\": \"in_progress\",\n",
        "        \"detalhes\": f\"Grava√ß√£o iniciada para '{username}' (ID: {user_id}) em {filepath}\" # Adiciona ID nos detalhes\n",
        "    })\n",
        "\n",
        "    print(f\"\\nüé¨ Iniciando grava√ß√£o de: '{username}' (ID: {user_id}) | URL: {m3u8_url}) em {filepath}\") # Adiciona ID no print\n",
        "\n",
        "    # --- Garante poster v√°lido ---\n",
        "    # As fun√ß√µes de poster (download_and_save_poster, generate_poster_with_ffmpeg)\n",
        "    # n√£o precisam do ID para funcionar, apenas o username para o nome do arquivo tempor√°rio.\n",
        "    poster_temp_path = None\n",
        "    if poster_url:\n",
        "        poster_temp_path = download_and_save_poster(poster_url, username, TEMP_OUTPUT_FOLDER)\n",
        "    # generate_poster_with_ffmpeg j√° foi ajustada na C√©lula 3 para usar a tupla de tries correta\n",
        "    if not is_poster_valid(poster_temp_path) and m3u8_url:\n",
        "        poster_temp_path = generate_poster_with_ffmpeg(m3u8_url, username, TEMP_OUTPUT_FOLDER, frame_time=poster_frame_time)\n",
        "\n",
        "\n",
        "    ffmpeg_cmd = [\n",
        "        \"ffmpeg\", \"-i\", m3u8_url,\n",
        "        \"-t\", str(RECORD_SECONDS),\n",
        "        \"-c\", \"copy\", \"-y\", filepath\n",
        "    ]\n",
        "\n",
        "    start_time_process = time.time()\n",
        "    process = None\n",
        "\n",
        "    try:\n",
        "        process = subprocess.Popen(\n",
        "            ffmpeg_cmd,\n",
        "            stdout=subprocess.PIPE,\n",
        "            stderr=subprocess.STDOUT,\n",
        "            text=True,\n",
        "            bufsize=1,\n",
        "            universal_newlines=True\n",
        "        )\n",
        "\n",
        "        # --- Monitoramento de progresso do ffmpeg (logs em tempo real) ---\n",
        "        # log_progress usa apenas username\n",
        "        elapsed_seconds = 0\n",
        "        last_log_minute = -1\n",
        "        while True:\n",
        "            line = process.stdout.readline()\n",
        "            if not line and process.poll() is not None:\n",
        "                break\n",
        "            if \"time=\" in line:\n",
        "                try:\n",
        "                    match = re.search(r\"time=(\\d+):(\\d+):(\\d+)\", line)\n",
        "                    if match:\n",
        "                        h, m, s = map(int, match.groups())\n",
        "                        elapsed_seconds = h * 3600 + m * 60 + s\n",
        "                        if elapsed_seconds // 60 != last_log_minute:\n",
        "                            log_progress(username, elapsed_seconds, RECORD_SECONDS)\n",
        "                            last_log_minute = elapsed_seconds // 60\n",
        "                except Exception:\n",
        "                    pass\n",
        "\n",
        "        process.wait()\n",
        "        end_time_process = time.time()\n",
        "        elapsed_seconds_proc = round(end_time_process - start_time_process)\n",
        "        log_progress(username, elapsed_seconds_proc, RECORD_SECONDS)\n",
        "\n",
        "        # --- Se FFmpeg falhou, registra no log central e retorna erro (USANDO ID) ---\n",
        "        if process.returncode != 0:\n",
        "            msg = f\"FFmpeg falhou para '{username}' (ID: {user_id}). C√≥digo de sa√≠da: {process.returncode}\" # Adiciona ID na mensagem\n",
        "            print(f\"‚ùå {msg}\")\n",
        "            append_log({\n",
        "                \"sessao\": \"processing\",\n",
        "                \"evento\": \"erro_ffmpeg\",\n",
        "                \"id\": user_id, # Usa o ID\n",
        "                \"username\": username,\n",
        "                \"status\": \"erro\",\n",
        "                \"detalhes\": msg\n",
        "            })\n",
        "            register_failure(user_id, username, \"Erro FFmpeg\") # Passa user_id e username\n",
        "            return {\n",
        "                'user_id': user_id, # Inclui user_id no resultado\n",
        "                'username': username,\n",
        "                'filename': temp_filename,\n",
        "                'filepath': filepath,\n",
        "                'upload_success': False,\n",
        "                'abyss_response': msg\n",
        "            }\n",
        "\n",
        "        # --- Valida√ß√£o pelo tempo real do arquivo gravado (robusta) ---\n",
        "        elapsed_seconds_real = get_video_duration(filepath)\n",
        "        if elapsed_seconds_real is not None:\n",
        "            print(f\"‚úÖ Dura√ß√£o real do arquivo gravado: {elapsed_seconds_real}s (ffprobe)\")\n",
        "        else:\n",
        "            print(f\"‚ö†Ô∏è N√£o foi poss√≠vel aferir dura√ß√£o real, usando a do processo: {elapsed_seconds_proc}s\")\n",
        "            elapsed_seconds_real = elapsed_seconds_proc\n",
        "\n",
        "        if elapsed_seconds_real < RECORD_SECONDS_MIN:\n",
        "            msg = f\"Grava√ß√£o muito curta para '{username}' (ID: {user_id}). Dura√ß√£o gravada ({elapsed_seconds_real}s) menor que o m√≠nimo ({RECORD_SECONDS_MIN}s). Arquivo descartado.\" # Adiciona ID\n",
        "            print(f\"‚è© {msg}\")\n",
        "            append_log({\n",
        "                \"sessao\": \"processing\",\n",
        "                \"evento\": \"erro_duracao\",\n",
        "                \"id\": user_id, # Usa o ID\n",
        "                \"username\": username,\n",
        "                \"status\": \"erro\",\n",
        "                \"detalhes\": msg\n",
        "            })\n",
        "            register_failure(user_id, username, \"Grava√ß√£o muito curta\") # Passa user_id e username\n",
        "            if os.path.exists(filepath): os.remove(filepath)\n",
        "            if poster_temp_path and os.path.exists(poster_temp_path): os.remove(poster_temp_path)\n",
        "            return {\n",
        "                'user_id': user_id, # Inclui user_id no resultado\n",
        "                'username': username,\n",
        "                'filename': temp_filename,\n",
        "                'filepath': filepath,\n",
        "                'upload_success': False,\n",
        "                'abyss_response': \"Grava√ß√£o muito curta (descartada)\"\n",
        "            }\n",
        "\n",
        "        # --- Sucesso: limpa falhas acumuladas do usu√°rio no log central (USANDO ID) ---\n",
        "        clear_failure(user_id) # Passa user_id\n",
        "        tempo_formatado = format_seconds(elapsed_seconds_real)\n",
        "        final_filename = f\"{username}_{data_str}_{horario_str}_{tempo_formatado}.mp4\"\n",
        "        final_filepath = os.path.join(TEMP_OUTPUT_FOLDER, final_filename)\n",
        "\n",
        "        try:\n",
        "            os.rename(filepath, final_filepath)\n",
        "            print(f\"‚úÖ Arquivo renomeado para: {final_filename}\")\n",
        "            filepath_for_upload = final_filepath\n",
        "            filename_for_upload = final_filename\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Erro ao renomear arquivo {temp_filename} para {final_filename}: {e}\")\n",
        "            filepath_for_upload = filepath\n",
        "            filename_for_upload = temp_filename\n",
        "\n",
        "        # --- Realiza upload e atualiza√ß√£o do banco de dados (json) ---\n",
        "        # upload_to_abyss_and_update_json (C√©lula 8) precisar√° receber o user_id\n",
        "        success, abyss_resp, slug = upload_to_abyss_and_update_json(\n",
        "            filepath_for_upload, user_id, username, elapsed_seconds_real, # Passa user_id e username\n",
        "            poster_temp_path=poster_temp_path\n",
        "        )\n",
        "\n",
        "        # --- Loga sucesso de grava√ß√£o no log central (USANDO ID) ---\n",
        "        append_log({\n",
        "            \"sessao\": \"processing\",\n",
        "            \"evento\": \"sucesso_gravacao\",\n",
        "            \"id\": user_id, # Usa o ID\n",
        "            \"username\": username,\n",
        "            \"status\": \"ok\",\n",
        "            \"detalhes\": f\"Arquivo {filename_for_upload} gravado e enviado com sucesso para '{username}' (ID: {user_id}). Dura√ß√£o: {elapsed_seconds_real}s\" # Adiciona ID\n",
        "        })\n",
        "\n",
        "        return {\n",
        "            'user_id': user_id, # Inclui user_id no resultado\n",
        "            'username': username,\n",
        "            'filename': filename_for_upload,\n",
        "            'filepath': filepath_for_upload,\n",
        "            'upload_success': success,\n",
        "            'abyss_response': abyss_resp,\n",
        "            'slug': slug\n",
        "        }\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        msg = \"Comando 'ffmpeg' n√£o encontrado. Certifique-se de que foi instalado corretamente.\"\n",
        "        print(f\"‚ùå {msg}\")\n",
        "        # Registrar falha de ffmpeg n√£o encontrado (USANDO ID)\n",
        "        if 'register_failure' in globals(): # Verifica se a fun√ß√£o existe\n",
        "             register_failure(user_id, username, msg) # Passa user_id e username\n",
        "        append_log({\n",
        "            \"sessao\": \"processing\",\n",
        "            \"evento\": \"erro_ffmpeg_nao_encontrado\",\n",
        "            \"id\": user_id, # Usa o ID\n",
        "            \"username\": username,\n",
        "            \"status\": \"erro\",\n",
        "            \"detalhes\": msg\n",
        "        })\n",
        "        return {\n",
        "            'user_id': user_id, # Inclui user_id no resultado\n",
        "            'username': username,\n",
        "            'filename': None,\n",
        "            'filepath': None,\n",
        "            'upload_success': False,\n",
        "            'abyss_response': msg\n",
        "        }\n",
        "    except Exception as e:\n",
        "        msg = f\"Erro inesperado durante a execu√ß√£o do FFmpeg para '{username}' (ID: {user_id}): {e}\" # Adiciona ID\n",
        "        print(f\"‚ùå {msg}\")\n",
        "        # Registrar falha de execu√ß√£o de ffmpeg (USANDO ID)\n",
        "        if 'register_failure' in globals(): # Verifica se a fun√ß√£o existe\n",
        "             register_failure(user_id, username, msg) # Passa user_id e username\n",
        "        append_log({\n",
        "            \"sessao\": \"processing\",\n",
        "            \"evento\": \"erro_execucao_ffmpeg\",\n",
        "            \"id\": user_id, # Usa o ID\n",
        "            \"username\": username,\n",
        "            \"status\": \"erro\",\n",
        "            \"detalhes\": msg\n",
        "        })\n",
        "        return {\n",
        "            'user_id': user_id, # Inclui user_id no resultado\n",
        "            'username': username,\n",
        "            'filename': None,\n",
        "            'filepath': None,\n",
        "            'upload_success': False,\n",
        "            'abyss_response': msg\n",
        "        }\n",
        "    finally:\n",
        "        # --- Remove marca√ß√£o de processamento ativo no log central (USANDO ID) ---\n",
        "        unmark_processing(user_id) # Passa user_id\n",
        "\n",
        "        # --- Limpeza do arquivo de v√≠deo p√≥s-upload ---\n",
        "        if 'filepath_for_upload' in locals() and os.path.exists(filepath_for_upload):\n",
        "            try:\n",
        "                os.remove(filepath_for_upload)\n",
        "                print(f\"üóëÔ∏è Arquivo de v√≠deo tempor√°rio local removido do Colab: {filepath_for_upload}\")\n",
        "                # Log de limpeza\n",
        "                if 'append_log' in globals():\n",
        "                     append_log({\n",
        "                         \"sessao\": \"cleanup\",\n",
        "                         \"evento\": \"remover_video_temp\",\n",
        "                         \"id\": user_id, # Usa o ID\n",
        "                         \"username\": username,\n",
        "                         \"status\": \"ok\",\n",
        "                         \"detalhes\": f\"Arquivo de v√≠deo tempor√°rio local removido: {filepath_for_upload}\"\n",
        "                     })\n",
        "            except Exception as e:\n",
        "                print(f\"‚ö†Ô∏è N√£o foi poss√≠vel remover o arquivo de v√≠deo tempor√°rio local: {e}\")\n",
        "                # Log de erro de limpeza\n",
        "                if 'append_log' in globals():\n",
        "                     append_log({\n",
        "                         \"sessao\": \"cleanup\",\n",
        "                         \"evento\": \"erro_remover_video_temp\",\n",
        "                         \"id\": user_id, # Usa o ID\n",
        "                         \"username\": username,\n",
        "                         \"status\": \"erro\",\n",
        "                         \"detalhes\": f\"Erro ao remover arquivo de v√≠deo tempor√°rio local: {e}\"\n",
        "                     })\n",
        "\n",
        "\n",
        "        # --- Limpeza do poster tempor√°rio ---\n",
        "        # poster_temp_path √© o caminho ANTES da renomea√ß√£o com slug\n",
        "        if poster_temp_path and os.path.exists(poster_temp_path):\n",
        "            try:\n",
        "                os.remove(poster_temp_path)\n",
        "                # print(f\"üóëÔ∏è Poster tempor√°rio original removido: {poster_temp_path}\") # J√° logado na C√©lula 8 se movido\n",
        "            except Exception as e:\n",
        "                # print(f\"‚ö†Ô∏è N√£o foi poss√≠vel remover o poster tempor√°rio original: {e}\") # J√° logado na C√©lula 8 se movido\n",
        "                pass # A C√©lula 8 lida com a limpeza do poster renomeado/movido\n",
        "\n",
        "\n",
        "# ================================================================\n",
        "# Fim da C√©lula 7 ‚Äî Grava√ß√£o, Log Centralizado e Blacklist Inteligente (AGORA USANDO ID)\n",
        "# ================================================================\n",
        "\n",
        "# Observa√ß√µes e recomenda√ß√µes:\n",
        "# - Toda manipula√ß√£o de status, falha, blacklist e processamento √© feita via fun√ß√µes do log centralizado (C√©lula 1 e 6), AGORA USANDO O ID.\n",
        "# - Mensagens claras e detalhadas e logging estruturado garantem rastreabilidade, CI/CD e manuten√ß√£o.\n",
        "# - Pronto para execu√ß√£o concorrente, pipelines e auditoria centralizada no XCam."
      ],
      "metadata": {
        "id": "eJ_jrfNgKZNr"
      },
      "id": "eJ_jrfNgKZNr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# C√©lula 8: Upload para Abyss.to, Atualiza√ß√£o do rec.json e Poster no Google Drive ‚Äî Log Centralizado, Persist√™ncia e Sincroniza√ß√£o\n",
        "\n",
        "**Objetivo:**  \n",
        "Gerenciar de forma automatizada e robusta o p√≥s-processamento da grava√ß√£o: upload do v√≠deo gravado para o servi√ßo Abyss.to, atualiza√ß√£o e persist√™ncia dos metadados no arquivo `rec.json` do usu√°rio diretamente no Google Drive, manipula√ß√£o segura do poster associado ao v√≠deo, manuten√ß√£o da integridade dos arquivos e limpeza consistente dos tempor√°rios.  \n",
        "Toda a√ß√£o relevante √© registrada no log centralizado (`xcam_master.log`) para m√°xima rastreabilidade, suporte a auditoria, diagn√≥stico r√°pido de falhas e compatibilidade total com execu√ß√£o concorrente e pipelines CI/CD.\n",
        "\n",
        "---\n",
        "\n",
        "## Estrat√©gia t√©cnica, fluxos e diferenciais implementados\n",
        "\n",
        "- **Upload seguro e transacional para Abyss.to:**  \n",
        "  O v√≠deo √© enviado via POST multipart para Abyss.to, recebendo como resposta um JSON padronizado contendo status, slug (identificador √∫nico do v√≠deo), e URLs p√∫blicas do v√≠deo, iframe e poster. O slug serve como v√≠nculo entre o v√≠deo, o poster e os metadados. O processo √© tolerante a falhas, com tratamento de exce√ß√µes e registro detalhado em caso de upload mal-sucedido ou resposta inesperada da API.\n",
        "- **Renomea√ß√£o e movimenta√ß√£o do poster com v√≠nculo ao slug:**  \n",
        "  O poster tempor√°rio √© renomeado para `{slug}.jpg` no diret√≥rio tempor√°rio do Colab, garantindo unicidade e rastreabilidade. Em seguida, √© movido para a pasta definitiva do usu√°rio no Google Drive, permitindo sincroniza√ß√£o, backup e f√°cil acesso externo. A URL do poster no `rec.json` √© constru√≠da para refletir o caminho p√∫blico presumido (ex: `https://db.xcam.gay/user/{username}/{slug}.jpg`).\n",
        "- **Atualiza√ß√£o segura e incremental do rec.json:**  \n",
        "  O arquivo `rec.json` √© lido e atualizado diretamente no Google Drive (sem c√≥pias locais intermedi√°rias), garantindo persist√™ncia e integridade dos registros hist√≥ricos do usu√°rio. Cada entrada adicionada inclui: slug, nome do arquivo, URLs p√∫blicas, poster, urlIframe, data, hor√°rio e dura√ß√£o formatada. Estrutura JSON validada para evitar corrup√ß√£o do hist√≥rico.\n",
        "- **Registro detalhado no log centralizado:**  \n",
        "  Cada etapa cr√≠tica (upload, renomea√ß√£o/movimenta√ß√£o de poster, atualiza√ß√£o do rec.json, limpeza de arquivos) √© registrada no log √∫nico com informa√ß√µes como evento, id/username, status e detalhes. Isso garante rastreabilidade completa, facilita auditoria, troubleshooting e gera√ß√£o de relat√≥rios hist√≥ricos.\n",
        "- **Limpeza autom√°tica e segura dos arquivos tempor√°rios:**  \n",
        "  Ao final do ciclo, o v√≠deo tempor√°rio e o poster remanescentes no Colab s√£o removidos, liberando espa√ßo e evitando ac√∫mulo de res√≠duos. Falhas na limpeza s√£o tamb√©m registradas no log.\n",
        "- **Sincroniza√ß√£o consistente com Google Drive:**  \n",
        "  Os artefatos permanentes s√£o organizados em `/content/drive/MyDrive/XCam.Drive/user/{username}/`. A estrutura facilita backup, versionamento externo e integra√ß√£o com outros sistemas de armazenamento ou distribui√ß√£o.\n",
        "- **Pronto para integra√ß√£o CI/CD, concorr√™ncia e expans√£o:**  \n",
        "  O fluxo √© compat√≠vel com execu√ß√£o concorrente de m√∫ltiplos workers, pipelines automatizados e futuras integra√ß√µes, pois n√£o depende de arquivos tempor√°rios ou opera√ß√µes n√£o transacionais.\n",
        "- **Seguran√ßa e redund√¢ncia:**  \n",
        "  Toda persist√™ncia √© feita diretamente no Drive, reduzindo riscos de perda por falhas do ambiente Colab ou interrup√ß√µes inesperadas do notebook.\n",
        "\n",
        "---\n",
        "\n",
        "## Detalhes t√©cnicos dos campos e opera√ß√µes\n",
        "\n",
        "- **Campos gravados no rec.json:**  \n",
        "  - `video`: slug/identificador √∫nico do v√≠deo no Abyss.to.\n",
        "  - `title`: nome base do arquivo de v√≠deo (sem extens√£o).\n",
        "  - `file`: nome do arquivo .mp4 original.\n",
        "  - `url`: URL p√∫blica do v√≠deo em Abyss.to.\n",
        "  - `poster`: URL p√∫blica do poster (presume acesso externo ao Drive ou CDN).\n",
        "  - `urlIframe`: URL do player incorpor√°vel com thumbnail.\n",
        "  - `data`, `horario`, `tempo`: metadados temporais e dura√ß√£o formatada.\n",
        "- **Estrutura do rec.json:**  \n",
        "  Cada usu√°rio possui um arquivo rec.json com os campos `username`, `records` (total de v√≠deos) e `videos` (lista de entradas como acima).  \n",
        "  O arquivo √© validado antes de cada escrita para garantir integridade.\n",
        "- **Tratamento robusto de falhas:**  \n",
        "  Qualquer falha (upload, leitura/grava√ß√£o do JSON, movimenta√ß√£o de poster, limpeza) √© capturada, logada e n√£o impede a execu√ß√£o das outras etapas, reduzindo impacto no pipeline.\n",
        "- **Visibilidade e rastreamento:**  \n",
        "  O log centralizado permite identificar rapidamente uploads com falha, problemas de sincroniza√ß√£o, arquivos que n√£o foram limpos, e relat√≥rios detalhados por usu√°rio.\n",
        "\n",
        "---\n",
        "\n",
        "## Fluxo operacional detalhado\n",
        "\n",
        "1. **Upload do v√≠deo para Abyss.to:**  \n",
        "   O v√≠deo .mp4 √© enviado via POST para o endpoint, recebendo slug, URL, urlIframe e status. Evento √© logado.\n",
        "2. **Renomea√ß√£o/movimenta√ß√£o do poster:**  \n",
        "   Poster tempor√°rio √© renomeado para `{slug}.jpg` e transferido para o Drive. URLs p√∫blicas s√£o calculadas e logadas.\n",
        "3. **Atualiza√ß√£o do rec.json no Drive:**  \n",
        "   O JSON do usu√°rio √© lido/validado, nova entrada √© adicionada, e o arquivo salvo de volta no Drive. Evento de sucesso ou falha √© sempre registrado.\n",
        "4. **Limpeza dos arquivos tempor√°rios:**  \n",
        "   Ap√≥s movimenta√ß√£o, v√≠deo e poster tempor√°rios no Colab s√£o removidos. Falhas na limpeza s√£o tratadas e logadas.\n",
        "5. **(Commit/push externo):**  \n",
        "   O gerenciamento de commit/push do Drive para o reposit√≥rio remoto √© feito por script externo, garantindo atomicidade e evitando conflitos.\n",
        "\n",
        "---\n",
        "\n",
        "## Exemplo de uso t√©cnico\n",
        "\n",
        "```python\n",
        "upload_success, abyss_response, slug = upload_to_abyss_and_update_json(\n",
        "    filepath=arquivo_video,\n",
        "    username=\"usuario\",\n",
        "    duration_seconds=duracao,\n",
        "    poster_temp_path=caminho_poster_temp\n",
        ")\n",
        "# Ap√≥s processamento em lote, execute o commit externo dos arquivos do Drive, se necess√°rio.\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Seguran√ßa, rastreabilidade e integra√ß√£o\n",
        "\n",
        "- **Execu√ß√£o concorrente e CI/CD-ready:**  \n",
        "  N√£o depende de arquivos tempor√°rios ap√≥s o t√©rmino, e toda persist√™ncia √© feita diretamente no Drive para m√°xima seguran√ßa.\n",
        "- **Rastreabilidade total:**  \n",
        "  Todas as etapas (upload, poster, rec.json, limpeza) s√£o logadas detalhadamente para auditoria, reporting e troubleshooting.\n",
        "- **Design modular e resiliente:**  \n",
        "  Fun√ß√µes com robusto tratamento de exce√ß√µes, logs claros, valida√ß√£o de estrutura JSON e fluxo pronto para expans√£o futura.\n",
        "- **Integra√ß√£o garantida com o pipeline XCam:**  \n",
        "  Estrutura, nomenclatura e fluxo de dados padronizados, compat√≠veis com as demais c√©lulas e necessidades de manuten√ß√£o/evolu√ß√£o.\n",
        "\n",
        "---\n",
        "\n",
        "## Observa√ß√µes e recomenda√ß√µes\n",
        "\n",
        "- Certifique-se de que o Google Drive est√° montado antes de executar esta c√©lula.\n",
        "- O commit/push final dos arquivos no Drive deve ser feito por script externo, preferencialmente ao final do processamento em lote.\n",
        "- A URL do poster no rec.json presume que o conte√∫do do Drive estar√° dispon√≠vel publicamente via CDN, servidor web ou integra√ß√£o adequada.\n",
        "- Recomenda-se monitorar e analisar o log centralizado para garantir integridade do processo, detectar falhas precocemente e gerar relat√≥rios de uso.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "YjGKDlbIKaLs"
      },
      "id": "YjGKDlbIKaLs"
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================\n",
        "# C√©lula 8: Upload para Abyss.to, Atualiza√ß√£o do rec.json e Poster no Google Drive\n",
        "# ================================================================\n",
        "# Objetivo:\n",
        "# - Fazer upload do v√≠deo gravado para Abyss.to e registrar corretamente os metadados.\n",
        "# - Salvar grava√ß√£o e poster temporariamente no Colab.\n",
        "# - Renomear poster tempor√°rio com slug (no Colab temp).\n",
        "# - LER/ESCREVER rec.json DIRETAMENTE no Google Drive.\n",
        "# - MOVER poster renomeado do Colab temp para o Google Drive.\n",
        "# - Limpar arquivos tempor√°rios locais ap√≥s uso.\n",
        "# - Modular, preparado para CI/CD, concorr√™ncia e integra√ß√£o total ao pipeline XCam.\n",
        "# ================================================================\n",
        "\n",
        "# Caminho base no Google Drive para arquivos permanentes (rec.json, posters)\n",
        "DRIVE_USER_BASE = \"/content/drive/MyDrive/XCam.Drive/user\"\n",
        "\n",
        "def upload_to_abyss_and_update_json(\n",
        "    filepath, username, duration_seconds, poster_temp_path=None\n",
        "):\n",
        "    \"\"\"\n",
        "    Realiza upload do v√≠deo, atualiza rec.json do usu√°rio (no Drive),\n",
        "    renomeia poster com slug (no Colab temp) e MOVE para o Google Drive.\n",
        "    - Salva grava√ß√£o e poster temporariamente no Colab.\n",
        "    - L√ä/ESCREVE rec.json DIRETAMENTE no Drive.\n",
        "    - Renomeia poster tempor√°rio no Colab temp com o slug retornado.\n",
        "    - MOVE poster renomeado do Colab temp para o Drive.\n",
        "    - Limpa arquivos tempor√°rios locais ap√≥s uso.\n",
        "    - Toda a√ß√£o relevante √© registrada no log centralizado via append_log().\n",
        "    \"\"\"\n",
        "    file_name = os.path.basename(filepath) # Nome do arquivo de v√≠deo renomeado (username_data_horario_tempo.mp4)\n",
        "    file_type = 'video/mp4'\n",
        "    print(f\"‚¨ÜÔ∏è Upload de: {file_name} para Abyss.to...\")\n",
        "\n",
        "    upload_success = False\n",
        "    abyss_response = \"Upload falhou - Sem resposta\"\n",
        "    uploaded_url = None\n",
        "    video_id = None\n",
        "    slug = None\n",
        "\n",
        "    # ---- Upload do v√≠deo para Abyss.to ----\n",
        "    try:\n",
        "        with open(filepath, 'rb') as f:\n",
        "            files = { 'file': (file_name, f, file_type) }\n",
        "            response = requests.post(ABYSS_UPLOAD_URL, files=files)\n",
        "            resp_json = response.json()\n",
        "            abyss_response = resp_json\n",
        "            if resp_json.get('status'):\n",
        "                upload_success = True\n",
        "                uploaded_url = resp_json.get('url') or resp_json.get('urlIframe')\n",
        "                video_id = resp_json.get('slug') or resp_json.get('video')\n",
        "                slug = video_id\n",
        "                print(f\"üì§ Upload bem-sucedido. URL: {uploaded_url} | SLUG: {slug}\")\n",
        "                append_log({\n",
        "                    \"sessao\": \"upload\",\n",
        "                    \"evento\": \"upload_sucesso\",\n",
        "                    \"id\": username,\n",
        "                    \"username\": username,\n",
        "                    \"status\": \"ok\",\n",
        "                    \"detalhes\": f\"Arquivo {file_name} enviado para Abyss.to. URL: {uploaded_url}, SLUG: {slug}\"\n",
        "                })\n",
        "            else:\n",
        "                print(f\"‚ùå Falha no upload. Mensagem: {resp_json.get('message','')}\")\n",
        "                append_log({\n",
        "                    \"sessao\": \"upload\",\n",
        "                    \"evento\": \"upload_falhou\",\n",
        "                    \"id\": username,\n",
        "                    \"username\": username,\n",
        "                    \"status\": \"erro\",\n",
        "                    \"detalhes\": f\"Falha no upload. Mensagem: {resp_json.get('message','')}\"\n",
        "                })\n",
        "    except Exception as e:\n",
        "        abyss_response = f\"Erro no upload: {e}\"\n",
        "        print(f\"‚ùå Erro no upload: {e}\")\n",
        "        append_log({\n",
        "            \"sessao\": \"upload\",\n",
        "            \"evento\": \"upload_falhou\",\n",
        "            \"id\": username,\n",
        "            \"username\": username,\n",
        "            \"status\": \"erro\",\n",
        "            \"detalhes\": f\"Exce√ß√£o no upload: {e}\"\n",
        "        })\n",
        "\n",
        "    poster_temp_renamed_path = None\n",
        "    drive_json_filepath = os.path.join(DRIVE_USER_BASE, username, \"rec.json\")\n",
        "    drive_user_dir = os.path.join(DRIVE_USER_BASE, username) # Pasta do usu√°rio no Drive\n",
        "\n",
        "    if upload_success and slug:\n",
        "        # ---- Renomeia o poster tempor√°rio com o slug retornado (no diret√≥rio tempor√°rio do Colab) ----\n",
        "        # O poster_temp_path j√° est√° em TEMP_OUTPUT_FOLDER (gerado/baixado pela C√©lula 7)\n",
        "        if poster_temp_path and os.path.exists(poster_temp_path):\n",
        "            try:\n",
        "                # O novo nome ser√° {slug}.jpg\n",
        "                poster_final_name = f\"{slug}.jpg\"\n",
        "                # A renomea√ß√£o ocorre dentro do diret√≥rio TEMPOR√ÅRIO do Colab\n",
        "                poster_temp_renamed_path = os.path.join(TEMP_OUTPUT_FOLDER, poster_final_name)\n",
        "                # Move (renomeia) o poster DENTRO do diret√≥rio tempor√°rio\n",
        "                shutil.move(poster_temp_path, poster_temp_renamed_path)\n",
        "                print(f\"üñºÔ∏è Poster tempor√°rio renomeado para {poster_final_name} em {TEMP_OUTPUT_FOLDER}\")\n",
        "                append_log({\n",
        "                    \"sessao\": \"poster\",\n",
        "                    \"evento\": \"poster_renomeado_temp\",\n",
        "                    \"id\": username,\n",
        "                    \"username\": username,\n",
        "                    \"status\": \"ok\",\n",
        "                    \"detalhes\": f\"Poster tempor√°rio renomeado para {poster_final_name} no Colab temp.\"\n",
        "                })\n",
        "            except Exception as e:\n",
        "                print(f\"‚ùå Erro ao renomear poster tempor√°rio no Colab: {e}\")\n",
        "                # Tenta limpar o poster tempor√°rio original se o renomeio falhar\n",
        "                if os.path.exists(poster_temp_path):\n",
        "                    try:\n",
        "                        os.remove(poster_temp_path)\n",
        "                    except Exception as clean_e:\n",
        "                        print(f\"‚ö†Ô∏è Falha ao limpar poster tempor√°rio original ap√≥s erro: {clean_e}\")\n",
        "                poster_temp_renamed_path = None # Garante que n√£o tentaremos mover um arquivo que n√£o existe\n",
        "                append_log({\n",
        "                    \"sessao\": \"poster\",\n",
        "                    \"evento\": \"erro_renomear_poster_temp\",\n",
        "                    \"id\": username,\n",
        "                    \"username\": username,\n",
        "                    \"status\": \"erro\",\n",
        "                    \"detalhes\": f\"Erro ao renomear poster tempor√°rio no Colab: {e}\"\n",
        "                })\n",
        "        else:\n",
        "             print(f\"‚ö†Ô∏è Poster tempor√°rio n√£o encontrado ou inv√°lido para renomear com slug.\")\n",
        "             append_log({\n",
        "                \"sessao\": \"poster\",\n",
        "                \"evento\": \"poster_temp_nao_encontrado\",\n",
        "                \"id\": username,\n",
        "                \"username\": username,\n",
        "                \"status\": \"aviso\",\n",
        "                \"detalhes\": \"Poster tempor√°rio n√£o encontrado ou inv√°lido para renomear com slug.\"\n",
        "            })\n",
        "\n",
        "\n",
        "        # ---- Atualiza/Cria rec.json do usu√°rio (DIRETAMENTE no Google Drive) ----\n",
        "        try:\n",
        "            # Caminho no Drive onde o rec.json deve estar/ser salvo\n",
        "            os.makedirs(drive_user_dir, exist_ok=True) # Garante que a pasta do usu√°rio no Drive exista\n",
        "\n",
        "            file_base = file_name.replace('.mp4', '')\n",
        "            parts = file_base.split('_')\n",
        "            if len(parts) >= 4:\n",
        "                json_data = parts[-3]\n",
        "                json_horario = parts[-2]\n",
        "                json_tempo = parts[-1]\n",
        "            else:\n",
        "                now = datetime.now()\n",
        "                json_data = now.strftime(\"%d-%m-%Y\")\n",
        "                json_horario = now.strftime(\"%H-%M\")\n",
        "                json_tempo = format_seconds(duration_seconds)\n",
        "\n",
        "            # A URL do poster no rec.json aponta para onde ele estar√° PUBLICAMENTE dispon√≠vel\n",
        "            # (presumindo que o conte√∫do do Drive ser√° servido ou sincronizado externamente)\n",
        "            poster_url_final = f\"https://db.xcam.gay/user/{username}/{slug}.jpg\" if slug else \"\"\n",
        "            url_iframe_final = f\"https://short.icu/{slug}?thumbnail={poster_url_final}\" if slug else \"\"\n",
        "\n",
        "            new_video_entry = {\n",
        "                \"video\": slug if slug else \"ID_n√£o_retornado\",\n",
        "                \"title\": file_base,\n",
        "                \"file\": file_name, # O nome do arquivo de v√≠deo original √© mantido como refer√™ncia\n",
        "                \"url\": uploaded_url if uploaded_url else \"URL_n√£o_retornada\",\n",
        "                \"poster\": poster_url_final, # Esta URL deve ser acess√≠vel publicamente\n",
        "                \"urlIframe\": url_iframe_final, # Esta URL deve ser acess√≠vel publicamente\n",
        "                \"data\": json_data,\n",
        "                \"horario\": json_horario,\n",
        "                \"tempo\": json_tempo\n",
        "            }\n",
        "\n",
        "            def zerar_base(username):\n",
        "                return {\n",
        "                    \"username\": username,\n",
        "                    \"records\": 0,\n",
        "                    \"videos\": []\n",
        "                }\n",
        "\n",
        "            # Carrega ou inicializa rec.json (DIRETAMENTE do Drive)\n",
        "            rec_data = zerar_base(username) # Inicializa com base zero por seguran√ßa\n",
        "            if os.path.exists(drive_json_filepath):\n",
        "                 try:\n",
        "                     with open(drive_json_filepath, 'r', encoding='utf-8') as f:\n",
        "                         loaded = json.load(f)\n",
        "                     # Valida se a estrutura carregada √© razo√°vel, sen√£o cria uma nova\n",
        "                     valid = (\n",
        "                         isinstance(loaded, dict)\n",
        "                         and \"username\" in loaded\n",
        "                         and \"records\" in loaded\n",
        "                         and \"videos\" in loaded\n",
        "                         and isinstance(loaded[\"videos\"], list)\n",
        "                     )\n",
        "                     rec_data = loaded if valid else zerar_base(username)\n",
        "                     print(f\"üìù Carregado rec.json existente do Drive para {username}\")\n",
        "                 except Exception as read_drive_e:\n",
        "                      print(f\"‚ö†Ô∏è Erro ao ler rec.json existente no Drive ({drive_json_filepath}), criando novo: {read_drive_e}\")\n",
        "                      # Se der erro na leitura, rec_data j√° est√° zerada\n",
        "\n",
        "            # Adiciona novo v√≠deo ao hist√≥rico (no objeto carregado/novo)\n",
        "            rec_data[\"records\"] += 1\n",
        "            rec_data[\"videos\"].append(new_video_entry)\n",
        "\n",
        "            # Salva rec.json (DIRETAMENTE no Drive)\n",
        "            with open(drive_json_filepath, 'w', encoding='utf-8') as f:\n",
        "                json.dump(rec_data, f, indent=2, ensure_ascii=False)\n",
        "            print(f\"‚úÖ rec.json para {username} atualizado DIRETAMENTE no Drive: {drive_json_filepath}\")\n",
        "\n",
        "            append_log({\n",
        "                \"sessao\": \"recjson\",\n",
        "                \"evento\": \"recjson_atualizado_drive\",\n",
        "                \"id\": username,\n",
        "                \"username\": username,\n",
        "                \"status\": \"ok\",\n",
        "                \"detalhes\": f\"rec.json atualizado diretamente no Drive em {drive_json_filepath}\"\n",
        "            })\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Erro ao atualizar rec.json no Drive: {e}\")\n",
        "            abyss_response = f\"Upload sucesso, erro no JSON do Drive: {e}\"\n",
        "            # json_temp_path = None # N√£o existe mais json_temp_path neste fluxo\n",
        "            append_log({\n",
        "                \"sessao\": \"recjson\",\n",
        "                \"evento\": \"erro_atualizar_recjson_drive\",\n",
        "                \"id\": username,\n",
        "                \"username\": username,\n",
        "                \"status\": \"erro\",\n",
        "                \"detalhes\": f\"Erro ao atualizar rec.json no Drive: {e}\"\n",
        "            })\n",
        "\n",
        "\n",
        "        # ---- MOVER poster renomeado (do Colab temp) para o Google Drive ----\n",
        "        if poster_temp_renamed_path and os.path.exists(poster_temp_renamed_path):\n",
        "            # O destino √© a pasta do usu√°rio no Drive\n",
        "            drive_poster_filepath = os.path.join(drive_user_dir, os.path.basename(poster_temp_renamed_path))\n",
        "            try:\n",
        "                shutil.move(poster_temp_renamed_path, drive_poster_filepath)\n",
        "                print(f\"üóÇÔ∏è Poster movido para o Drive: {drive_poster_filepath}\")\n",
        "                append_log({\n",
        "                    \"sessao\": \"poster\",\n",
        "                    \"evento\": \"poster_movido_drive\",\n",
        "                    \"id\": username,\n",
        "                    \"username\": username,\n",
        "                    \"status\": \"ok\",\n",
        "                    \"detalhes\": f\"Poster movido para o Drive em {drive_poster_filepath}\"\n",
        "                })\n",
        "            except Exception as e:\n",
        "                print(f\"‚ùå Falha ao MOVER poster para o Drive: {e}\")\n",
        "                append_log({\n",
        "                    \"sessao\": \"poster\",\n",
        "                    \"evento\": \"erro_mover_poster_drive\",\n",
        "                    \"id\": username,\n",
        "                    \"username\": username,\n",
        "                    \"status\": \"erro\",\n",
        "                    \"detalhes\": f\"Erro ao mover poster para o Drive: {e}\"\n",
        "                })\n",
        "        else:\n",
        "             print(f\"‚ö†Ô∏è Poster tempor√°rio renomeado n√£o encontrado para mover para o Drive.\")\n",
        "             append_log({\n",
        "                \"sessao\": \"poster\",\n",
        "                \"evento\": \"poster_temp_renomeado_nao_encontrado\",\n",
        "                \"id\": username,\n",
        "                \"username\": username,\n",
        "                \"status\": \"aviso\",\n",
        "                \"detalhes\": \"Poster tempor√°rio renomeado n√£o encontrado para mover para o Drive.\"\n",
        "            })\n",
        "\n",
        "\n",
        "    # ---- Limpeza do arquivo de v√≠deo tempor√°rio local ----\n",
        "    # Esta limpeza j√° estava presente no bloco finally da gravar_stream (C√©lula 7),\n",
        "    # mas vamos garantir aqui tamb√©m por seguran√ßa, caso a chamada venha de outro lugar.\n",
        "    # O arquivo de v√≠deo renomeado est√° em TEMP_OUTPUT_FOLDER\n",
        "    if os.path.exists(filepath): # filepath √© o caminho do v√≠deo renomeado em TEMP_OUTPUT_FOLDER\n",
        "        try:\n",
        "            os.remove(filepath)\n",
        "            print(f\"üóëÔ∏è Arquivo de v√≠deo tempor√°rio local removido: {filepath}\")\n",
        "            append_log({\n",
        "                \"sessao\": \"cleanup\",\n",
        "                \"evento\": \"remover_video_temp\",\n",
        "                \"id\": username,\n",
        "                \"username\": username,\n",
        "                \"status\": \"ok\",\n",
        "                \"detalhes\": f\"Arquivo de v√≠deo tempor√°rio local removido: {filepath}\"\n",
        "            })\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è N√£o foi poss√≠vel remover o arquivo de v√≠deo tempor√°rio local: {e}\")\n",
        "            append_log({\n",
        "                \"sessao\": \"cleanup\",\n",
        "                \"evento\": \"erro_remover_video_temp\",\n",
        "                \"id\": username,\n",
        "                \"username\": username,\n",
        "                \"status\": \"erro\",\n",
        "                \"detalhes\": f\"Erro ao remover arquivo de v√≠deo tempor√°rio local: {e}\"\n",
        "            })\n",
        "\n",
        "    # ---- Limpeza do diret√≥rio tempor√°rio do usu√°rio, se estiver vazio ----\n",
        "    # O diret√≥rio tempor√°rio do usu√°rio pode n√£o ter sido criado se o upload falhou antes.\n",
        "    # TEMP_OUTPUT_FOLDER √© o diret√≥rio geral. N√£o vamos remover subdiret√≥rios espec√≠ficos aqui.\n",
        "    # A limpeza do diret√≥rio temp do usu√°rio pode ser feita de forma mais robusta em outro local ou manualmente.\n",
        "    # Manteremos a limpeza apenas dos arquivos espec√≠ficos manipulados.\n",
        "\n",
        "    return upload_success, abyss_response, slug\n",
        "\n",
        "# A fun√ß√£o de commit final pendente n√£o √© mais necess√°ria, pois o commit √© gerenciado externamente.\n",
        "# def commit_push_restantes():\n",
        "#     \"\"\"\n",
        "#     Esta fun√ß√£o n√£o √© mais necess√°ria pois o commit/push √© gerenciado externamente.\n",
        "#     \"\"\"\n",
        "#     pass # L√≥gica de commit/push removida\n",
        "\n",
        "# ================================================================\n",
        "# FIM DA C√©lula 8 ‚Äî Upload, Metadados e Posters no Google Drive (com log centralizado)\n",
        "# ================================================================\n",
        "\n",
        "# Observa√ß√µes:\n",
        "# - A grava√ß√£o e o poster inicial ficam no Colab temp.\n",
        "# - O rec.json √© lido e escrito DIRETAMENTE no Drive.\n",
        "# - O poster renomeado √© MOVIDO do Colab temp para o Drive.\n",
        "# - Certifique-se de que o Google Drive esteja montado antes de executar esta c√©lula.\n",
        "# - A URL do poster no rec.json (db.xcam.gay) presume que o conte√∫do do Drive ser√° servido publicamente de alguma forma.\n",
        "# - O commit/push agora √© gerenciado por um script externo que deve ler os arquivos do Drive.\n",
        "# - Toda a√ß√£o relevante registrada no log centralizado para total rastreabilidade/auditoria."
      ],
      "metadata": {
        "id": "vMTiCrJ5Kp81"
      },
      "id": "vMTiCrJ5Kp81",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# C√©lula 9: Supervisor Din√¢mico ‚Äî Execu√ß√£o Paralela, Lote Sempre Cheio, Blacklist Centralizada e Log por ID\n",
        "\n",
        "**Objetivo:**  \n",
        "Orquestrar e controlar automaticamente todo o pipeline de grava√ß√£o de transmiss√µes ao vivo, garantindo execu√ß√£o paralela robusta, processamento cont√≠nuo, m√°xima efici√™ncia no preenchimento do lote e total seguran√ßa contra duplicidade, concorr√™ncia indevida e usu√°rios problem√°ticos.  \n",
        "A c√©lula implementa um supervisor din√¢mico que mant√©m o lote sempre cheio, preenche vagas em tempo real com transmiss√µes v√°lidas, consulta e respeita a blacklist tempor√°ria centralizada (por ID), previne duplicidade de grava√ß√£o consultando o log central de processamento, e integra-se a todas as rotinas cr√≠ticas do pipeline XCam (grava√ß√£o, upload, rec.json, poster, limpeza, commit), promovendo rastreabilidade, resili√™ncia e escalabilidade.\n",
        "\n",
        "---\n",
        "\n",
        "## Estrat√©gia t√©cnica, arquitetura e diferenciais\n",
        "\n",
        "- **Execu√ß√£o paralela segura via multiprocessing:**  \n",
        "  Utiliza m√∫ltiplos processos (`multiprocessing.Process`) para grava√ß√£o simult√¢nea, acelerando o throughput do pipeline e melhorando o aproveitamento de recursos computacionais (CPU, I/O).\n",
        "- **Supervisor din√¢mico e lote sempre cheio:**  \n",
        "  O supervisor monitora ativamente as vagas livres no lote alvo (`pool_size`) e lan√ßa novas grava√ß√µes assim que houver disponibilidade, evitando per√≠odos ociosos e maximizando a produtividade.\n",
        "- **Controle centralizado de blacklist e processamento por ID:**  \n",
        "  Antes de iniciar qualquer grava√ß√£o, consulta o log centralizado para verificar se o usu√°rio (por `id`) est√° em blacklist tempor√°ria (sessao=\"blacklist\", status=\"blacklisted\") ou j√° est√° em processamento ativo (sessao=\"processing\", status=\"in_progress\"), evitando duplicidade e reprocessamento indevido.\n",
        "- **Busca inteligente, sele√ß√£o e escalonamento:**  \n",
        "  Utiliza fun√ß√µes otimizadas para buscar transmiss√µes v√°lidas, tanto para listas espec√≠ficas de usu√°rios quanto para busca autom√°tica. Sempre respeita blacklist, status de processamento e disponibilidade da transmiss√£o.\n",
        "- **Worker modular e integrado:**  \n",
        "  Cada worker processa a grava√ß√£o de uma transmiss√£o (por ID), realiza upload, atualiza√ß√£o do rec.json/poster, limpeza de arquivos tempor√°rios, e integra-se ao log central. O status de cada opera√ß√£o √© registrado detalhadamente.\n",
        "- **Logs robustos, padronizados e detalhados:**  \n",
        "  Todas as etapas cr√≠ticas (in√≠cio, finaliza√ß√£o, busca, erro, status, preenchimento de vagas) geram logs com timestamp, contexto, n√≠vel e detalhes, tanto no console quanto no log centralizado (`xcam_master.log`).  \n",
        "  Eventos s√£o classificados por n√≠vel (INFO, WORKER, BUSCA, ERRO, STATUS, RESUMO, END) e incluem sempre o ID do usu√°rio quando relevante.\n",
        "- **Respeito rigoroso √† blacklist tempor√°ria:**  \n",
        "  Usu√°rios que atingiram o limite de falhas s√£o bloqueados temporariamente por ID e n√£o s√£o reprocessados at√© expira√ß√£o da blacklist, otimizando recursos e evitando loops problem√°ticos.\n",
        "- **Design modular, extens√≠vel e pronto para CI/CD:**  \n",
        "  C√≥digo segmentado em fun√ß√µes (supervisor, worker, busca, log), com separa√ß√£o clara de responsabilidades, facilitando manuten√ß√£o, reuso, testes e integra√ß√£o com pipelines autom√°ticos ou ambientes colaborativos (ex: Google Colab, runners de CI).\n",
        "\n",
        "---\n",
        "\n",
        "## Fluxo operacional detalhado\n",
        "\n",
        "1. **Inicializa√ß√£o e configura√ß√£o:**  \n",
        "   - Determina modo operacional: grava√ß√£o de usu√°rios espec√≠ficos (lista) ou busca autom√°tica.\n",
        "   - Calcula tamanho do lote alvo (`pool_size`), define vari√°veis globais e inicializa estruturas compartilhadas (ex: results via `Manager().list()`).\n",
        "   - Loga in√≠cio do supervisor.\n",
        "\n",
        "2. **Preenchimento do lote inicial:**  \n",
        "   - Busca e seleciona transmiss√µes livres, preenchendo o lote at√© atingir o tamanho alvo ou esgotar op√ß√µes v√°lidas.\n",
        "   - Para cada transmiss√£o v√°lida (n√£o duplicada, n√£o em blacklist, n√£o em processamento), marca o usu√°rio como \"in_progress\" no log centralizado (por ID) e lan√ßa um worker dedicado.\n",
        "\n",
        "3. **Supervis√£o din√¢mica e ciclo de preenchimento cont√≠nuo:**  \n",
        "   - Monitora, em loop, o n√∫mero de processos ativos (grava√ß√µes em andamento).\n",
        "   - Assim que uma grava√ß√£o finaliza, imediatamente busca e lan√ßa nova transmiss√£o para preencher a vaga, mantendo o lote sempre cheio at√© esgotar transmiss√µes dispon√≠veis.\n",
        "   - Cada ciclo de busca e preenchimento √© protegido contra duplicidade por consultas ao log de blacklist/processamento (por ID).\n",
        "\n",
        "4. **Logs e controle detalhados:**  \n",
        "   - Cada a√ß√£o relevante (in√≠cio/fim de grava√ß√£o, erros, busca, preenchimento, status peri√≥dico) √© logada com timestamp, n√≠vel e detalhes no log central e no console.\n",
        "   - Resultados de cada worker s√£o armazenados e podem ser analisados ao final do processamento.\n",
        "\n",
        "5. **Encerramento e resumo:**  \n",
        "   - Quando n√£o h√° mais transmiss√µes dispon√≠veis e todos os processos finalizam, supervisor encerra o ciclo e registra resumo dos resultados.\n",
        "   - Commit/push dos arquivos permanentes √© gerenciado externamente, promovendo atomicidade e consist√™ncia.\n",
        "\n",
        "---\n",
        "\n",
        "## Exemplo de uso t√©cnico\n",
        "\n",
        "```python\n",
        "# Fun√ß√£o principal para disparar o supervisor din√¢mico (interativo para escolha do modo)\n",
        "main()\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Detalhes t√©cnicos e recomenda√ß√µes\n",
        "\n",
        "- **Fonte de verdade centralizada:**  \n",
        "  Toda l√≥gica de blacklist, falhas, processamento ativo e controle de duplicidade √© baseada no log centralizado e no ID √∫nico do usu√°rio, promovendo consist√™ncia, rastreabilidade e integridade em ambientes paralelos.\n",
        "- **Pronto para execu√ß√£o concorrente e ambientes colaborativos:**  \n",
        "  Compat√≠vel com Google Colab, runners de CI/CD, servidores multiusu√°rio e pipelines autom√°ticos.\n",
        "- **Diagn√≥stico e manuten√ß√£o facilitados:**  \n",
        "  Logs detalhados, estrutura modular e documenta√ß√£o clara facilitam troubleshooting, evolu√ß√£o e integra√ß√£o de novos recursos.\n",
        "- **Seguran√ßa, resili√™ncia e efici√™ncia:**  \n",
        "  O supervisor garante que nenhum usu√°rio problem√°tico trave o pipeline, nenhuma transmiss√£o seja processada duas vezes, e o lote permane√ßa sempre no m√°ximo da capacidade.\n",
        "- **Pr√©-requisitos de execu√ß√£o:**  \n",
        "  Certifique-se de executar previamente as C√©lulas 1, 3, 6, 7 e 8 para garantir inicializa√ß√£o correta do ambiente, vari√°veis globais, fun√ß√µes de log, grava√ß√£o, upload e limpeza.\n",
        "\n",
        "---\n",
        "\n",
        "## Observa√ß√µes finais\n",
        "\n",
        "- **Toda l√≥gica de controle (blacklist, falhas, processamento) √© feita por ID, promovendo rastreabilidade e evitando ambiguidades.**\n",
        "- **O supervisor √© o n√∫cleo do pipeline, integrando e coordenando todas as rotinas cr√≠ticas do XCam.**\n",
        "- **Expans√≠vel, pronto para novos modos de busca, integra√ß√£o com notifica√ß√µes, dashboards ou novos sistemas de storage.**\n",
        "- **A arquitetura Clean facilita onboarding de novos desenvolvedores e manuten√ß√£o do ciclo de vida do projeto.**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "iwgt8f8iKq4y"
      },
      "id": "iwgt8f8iKq4y"
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "# ================================================================\n",
        "# C√©lula 9: Supervisor Din√¢mico ‚Äî Execu√ß√£o Paralela, Lote Sempre Cheio, Blacklist e Log Centralizado (AGORA USANDO ID)\n",
        "# ================================================================\n",
        "# Objetivo:\n",
        "# - Manter o lote de grava√ß√µes sempre cheio, preenchendo vagas em tempo real com m√°xima efici√™ncia e seguran√ßa.\n",
        "# - Garantir que usu√°rios problem√°ticos (em blacklist - por ID) n√£o sejam tentados novamente no ciclo vigente.\n",
        "# - Prevenir duplicidade consultando log central de processamento (por ID) antes de iniciar qualquer grava√ß√£o.\n",
        "# - Integrar-se com a l√≥gica de blacklist, commit/push autom√°tico, limpeza de recursos e log robusto, TUDO BASEADO NO ID.\n",
        "# - Modularidade e clareza, pronta para integra√ß√£o com pipelines CI/CD, execu√ß√£o concorrente e ambientes colaborativos.\n",
        "# ================================================================\n",
        "\n",
        "from multiprocessing import Process, Manager # Garantir imports\n",
        "\n",
        "def log_supervisor(msg, level=\"INFO\"):\n",
        "    \"\"\"\n",
        "    Log supervisor padronizado para todas as etapas do pipeline.\n",
        "    Tamb√©m registra cada evento relevante no log centralizado (sessao supervisor).\n",
        "    Pode incluir ID/username se relevante para o evento.\n",
        "    \"\"\"\n",
        "    from datetime import datetime\n",
        "    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "    print(f\"[{timestamp}] [{level}] {msg}\")\n",
        "    # Registro tamb√©m no log central (sessao supervisor)\n",
        "    append_log({\n",
        "        \"sessao\": \"supervisor\",\n",
        "        \"evento\": level,\n",
        "        \"id\": \"global\", # Evento global do supervisor\n",
        "        \"username\": \"global\",\n",
        "        \"status\": \"info\" if level != \"ERRO\" else \"erro\",\n",
        "        \"detalhes\": msg\n",
        "    })\n",
        "\n",
        "# Adicionando user_id como par√¢metro para o worker\n",
        "def worker(user_id, username, m3u8_url, poster_path, results):\n",
        "    \"\"\"\n",
        "    Worker dedicado: grava a stream, faz upload, atualiza rec.json/poster, integra ao log.\n",
        "    Recebe o ID do usu√°rio e o passa para a fun√ß√£o gravar_stream (C√©lula 7).\n",
        "    O processamento √© rastreado via log central, e o status final √© adicionado √† lista de resultados.\n",
        "    \"\"\"\n",
        "    # gravar_stream agora espera user_id como primeiro par√¢metro\n",
        "    log_supervisor(f\"Iniciando grava√ß√£o: '{username}' (ID: {user_id}) | URL: {m3u8_url[:50]}...\", \"WORKER\") # Loga o ID\n",
        "    result = gravar_stream(user_id, username, m3u8_url, poster_url=poster_path) # Passa user_id para gravar_stream\n",
        "    log_supervisor(\n",
        "        f\"Finalizou grava√ß√£o: '{username}' (ID: {user_id}) | Sucesso: {result.get('upload_success')} | \" # Loga o ID\n",
        "        f\"Arquivo: {result.get('filename')} | Abyss: {result.get('abyss_response')}\", \"WORKER\")\n",
        "    results.append(result)\n",
        "    # Registro do resultado no log central (j√° feito dentro de gravar_stream, mas refor√ßa aqui)\n",
        "    # append_log({\n",
        "    #     \"sessao\": \"supervisor\",\n",
        "    #     \"evento\": \"worker_result\",\n",
        "    #     \"id\": user_id, # Usa o ID aqui\n",
        "    #     \"username\": username,\n",
        "    #     \"status\": \"ok\" if result.get(\"upload_success\") else \"erro\",\n",
        "    #     \"detalhes\": str(result)\n",
        "    # })\n",
        "\n",
        "\n",
        "# Supervisor din√¢mico, agora usando ID para controle de estado\n",
        "def supervisor_dinamico(usuarios_especificos=None):\n",
        "    \"\"\"\n",
        "    Supervisor din√¢mico de transmiss√µes ao vivo:\n",
        "    - Mant√©m o lote de grava√ß√µes sempre cheio, preenchendo vagas em tempo real.\n",
        "    - Evita duplicidade e concorr√™ncia consultando log central (sessao=\"processing\", status=\"in_progress\"), AGORA PELO ID.\n",
        "    - Respeita blacklist centralizada (pelo ID), n√£o processando usu√°rios bloqueados no ciclo vigente.\n",
        "    - Log detalhado e modular para diagn√≥stico, CI/CD e rastreabilidade.\n",
        "    \"\"\"\n",
        "\n",
        "    # Determina o tamanho do lote com base no modo operacional\n",
        "    pool_size = LIMIT_DEFAULT if not usuarios_especificos else API_SEARCH_LIMIT\n",
        "    running = []\n",
        "    results = Manager().list()\n",
        "    # N√£o precisamos mais do seen_usernames local, pois o log central √© a fonte de verdade para o estado (is_processing, is_in_blacklist)\n",
        "    # seen_usernames = set()\n",
        "\n",
        "    log_supervisor(f\"Supervisor din√¢mico iniciado | Lote alvo: {pool_size} | Modo: {'espec√≠fico' if usuarios_especificos else 'autom√°tico'}\")\n",
        "\n",
        "    # A fun√ß√£o atualizar_seen_usernames local n√£o √© mais necess√°ria,\n",
        "    # pois is_processing e is_in_blacklist consultam o log central diretamente.\n",
        "    # def atualizar_seen_usernames():\n",
        "    #     \"\"\"\n",
        "    #     Atualiza o conjunto de usernames j√° processados diretamente do log central (sessao='processing').\n",
        "    #     Garante robustez em ambientes concorrentes e previne duplicidade.\n",
        "    #     \"\"\"\n",
        "    #     entries = query_logs(sessao=\"processing\", status=\"in_progress\")\n",
        "    #     seen_usernames.update([e[\"username\"] for e in entries])\n",
        "\n",
        "    def buscar_nova_transmissao():\n",
        "        \"\"\"\n",
        "        Busca uma nova transmiss√£o livre para preencher o lote:\n",
        "        - Modo espec√≠fico: busca em lista fornecida (agora retorna ID).\n",
        "        - Modo autom√°tico: busca pr√≥xima transmiss√£o livre dispon√≠vel (agora retorna ID).\n",
        "        - Sempre consulta blacklist (pelo ID) e log central (pelo ID) antes de liberar.\n",
        "        \"\"\"\n",
        "        # N√£o precisamos mais chamar atualizar_seen_usernames() aqui.\n",
        "        # A l√≥gica dentro de is_in_blacklist e is_processing consulta o log central diretamente.\n",
        "\n",
        "        if usuarios_especificos:\n",
        "            # buscar_usuarios_especificos agora retorna lista com ID\n",
        "            candidatos = buscar_usuarios_especificos(usuarios_especificos)\n",
        "            for s in candidatos:\n",
        "                user_id = s[\"id\"] # Captura o ID retornado pela fun√ß√£o de busca\n",
        "                username = s[\"username\"]\n",
        "                # Verifica se o ID est√° em blacklist ou processando (AGORA CONSULTANDO PELO ID)\n",
        "                if not is_in_blacklist(user_id) and not is_processing(user_id):\n",
        "                    log_supervisor(f\"Nova transmiss√£o encontrada (espec√≠fico): '{username}' (ID: {user_id})\", \"BUSCA\") # Loga o ID\n",
        "                    return s # Retorna o dicion√°rio com id, username, src, poster_path\n",
        "                else:\n",
        "                    # Loga que o ID est√° sendo ignorado\n",
        "                    status_detail = \"\"\n",
        "                    if is_in_blacklist(user_id): status_detail += \"blacklist \"\n",
        "                    if is_processing(user_id): status_detail += \"processing \"\n",
        "                    log_supervisor(f\"Usu√°rio '{username}' (ID: {user_id}) j√° em {status_detail.strip()}, ignorando.\", \"BUSCA\")\n",
        "            log_supervisor(\"Nenhuma transmiss√£o espec√≠fica livre encontrada (todos em blacklist/log ou offline).\", \"BUSCA\")\n",
        "            return None\n",
        "        else:\n",
        "            # Busca otimizada: tenta at√© 10 vezes buscar pr√≥xima transmiss√£o livre\n",
        "            for tentativa in range(1, 11):\n",
        "                log_supervisor(f\"Buscando pr√≥xima transmiss√£o livre: tentativa {tentativa}\", \"BUSCA\")\n",
        "                # buscar_proxima_transmissao_livre agora retorna dicion√°rio com ID\n",
        "                stream = buscar_proxima_transmissao_livre()\n",
        "                if stream:\n",
        "                    user_id = stream[\"id\"] # Captura o ID retornado pela fun√ß√£o de busca\n",
        "                    username = stream[\"username\"]\n",
        "                    # Verifica se o ID est√° em blacklist ou processando (AGORA CONSULTANDO PELO ID)\n",
        "                    if not is_in_blacklist(user_id) and not is_processing(user_id):\n",
        "                        log_supervisor(f\"Nova transmiss√£o encontrada: '{username}' (ID: {user_id})\", \"BUSCA\") # Loga o ID\n",
        "                        return stream # Retorna o dicion√°rio com id, username, src, poster_path\n",
        "                    else:\n",
        "                        # Loga que o ID est√° sendo ignorado\n",
        "                        status_detail = \"\"\n",
        "                        if is_in_blacklist(user_id): status_detail += \"blacklist \"\n",
        "                        if is_processing(user_id): status_detail += \"processing \"\n",
        "                        log_supervisor(f\"Usu√°rio '{username}' (ID: {user_id}) j√° em {status_detail.strip()}, ignorando.\", \"BUSCA\")\n",
        "                else:\n",
        "                    log_supervisor(f\"buscar_proxima_transmissao_livre retornou None na tentativa {tentativa}.\", \"BUSCA\")\n",
        "\n",
        "            log_supervisor(\"Nenhuma transmiss√£o livre encontrada ap√≥s tentativas (todos em blacklist/log ou offline).\", \"BUSCA\")\n",
        "            return None\n",
        "\n",
        "    # ========== Fase 1: Preenchimento do lote inicial ==========\n",
        "    log_supervisor(f\"Preenchendo lote inicial com at√© {pool_size} transmiss√µes...\", \"STARTUP\")\n",
        "    tentativas = 0\n",
        "    max_tentativas = 100 # Limita as tentativas totais para preencher o lote inicial\n",
        "    while len(running) < pool_size and tentativas < max_tentativas:\n",
        "        stream = buscar_nova_transmissao() # Retorna dicion√°rio com id, username, src, poster_path\n",
        "        if not stream:\n",
        "            log_supervisor(\"Fim das transmiss√µes dispon√≠veis para preencher lote inicial.\", \"STARTUP\")\n",
        "            break # Sai do loop se n√£o encontrar mais streams\n",
        "\n",
        "        user_id = stream[\"id\"] # Obt√©m o ID do dicion√°rio retornado\n",
        "        username = stream[\"username\"]\n",
        "        m3u8_url = stream[\"src\"]\n",
        "        poster_path = stream[\"poster_path\"] # Caminho do poster tempor√°rio v√°lido\n",
        "\n",
        "\n",
        "        # Marca no log central como em processamento para evitar duplicidade (USANDO ID)\n",
        "        mark_processing(user_id, username) # Passa user_id e username\n",
        "\n",
        "        log_supervisor(f\"Lan√ßando processo para: '{username}' (ID: {user_id}) | {len(running)+1}/{pool_size}\", \"STARTUP\") # Loga o ID\n",
        "        # Passa o user_id para a fun√ß√£o worker\n",
        "        p = Process(target=worker, args=(user_id, username, m3u8_url, poster_path, results))\n",
        "        running.append(p)\n",
        "        p.start()\n",
        "        tentativas += 1 # Incrementa tentativas\n",
        "\n",
        "    log_supervisor(f\"Lote inicial lan√ßado com {len(running)} transmiss√µes.\", \"STARTUP\")\n",
        "\n",
        "\n",
        "    # ========== Fase 2: Loop din√¢mico de preenchimento cont√≠nuo ==========\n",
        "    # Monitora processos ativos e busca novas streams para manter o lote cheio\n",
        "    while True:\n",
        "        # Atualiza a lista de processos ativos\n",
        "        antes = len(running)\n",
        "        running = [p for p in running if p.is_alive()]\n",
        "        depois = len(running)\n",
        "\n",
        "        # Se algum processo finalizou\n",
        "        if antes != depois:\n",
        "            log_supervisor(f\"{antes-depois} grava√ß√µes finalizaram. Vagas livres: {pool_size-len(running)}\", \"LOOP\")\n",
        "\n",
        "        vagas_livres = pool_size - len(running)\n",
        "\n",
        "        # Se houver vagas livres, busca novas streams para preencher\n",
        "        if vagas_livres > 0:\n",
        "            # Busca at√© o n√∫mero de vagas livres, mas com limite de tentativas para n√£o travar\n",
        "            preenchidas_nesta_rodada = 0\n",
        "            for _ in range(vagas_livres):\n",
        "                stream = buscar_nova_transmissao() # Retorna dicion√°rio com id, username, src, poster_path\n",
        "                if not stream:\n",
        "                    # Se n√£o encontrar mais streams dispon√≠veis ap√≥s todas as tentativas internas, sai do loop de preenchimento\n",
        "                    log_supervisor(\"N√£o h√° mais transmiss√µes para preencher as vagas livres.\", \"LOOP\")\n",
        "                    break # Sai do loop interno de preenchimento de vagas\n",
        "\n",
        "                user_id = stream[\"id\"] # Obt√©m o ID do dicion√°rio retornado\n",
        "                username = stream[\"username\"]\n",
        "                m3u8_url = stream[\"src\"]\n",
        "                poster_path = stream[\"poster_path\"] # Caminho do poster tempor√°rio v√°lido\n",
        "\n",
        "                # Marca no log central como em processamento (USANDO ID)\n",
        "                mark_processing(user_id, username) # Passa user_id e username\n",
        "\n",
        "                log_supervisor(f\"Lan√ßando nova grava√ß√£o: '{username}' (ID: {user_id}) | Vaga preenchida {len(running)+1}/{pool_size}\", \"LOOP\") # Loga o ID\n",
        "                # Passa o user_id para a fun√ß√£o worker\n",
        "                p = Process(target=worker, args=(user_id, username, m3u8_url, poster_path, results))\n",
        "                running.append(p)\n",
        "                p.start()\n",
        "                preenchidas_nesta_rodada += 1 # Conta quantas vagas foram preenchidas nesta rodada\n",
        "\n",
        "            if preenchidas_nesta_rodada == 0 and vagas_livres > 0 and not stream:\n",
        "                 # Condi√ß√£o para sair do loop principal: n√£o h√° processos rodando E n√£o h√° mais streams dispon√≠veis\n",
        "                 # (a busca_nova_transmissao retornou None ap√≥s v√°rias tentativas)\n",
        "                 if not running:\n",
        "                      log_supervisor(\"N√£o h√° processos ativos e n√£o h√° mais transmiss√µes dispon√≠veis.\", \"END\")\n",
        "                      break\n",
        "\n",
        "\n",
        "        # Se n√£o houver processos rodando e n√£o conseguimos preencher nenhuma vaga nesta rodada,\n",
        "        # significa que todas as transmiss√µes dispon√≠veis j√° foram processadas ou est√£o em blacklist/processing.\n",
        "        # A condi√ß√£o `if not stream:` dentro do loop de vagas + `if not running:` fora do loop de vagas\n",
        "        # j√° lida com isso, mas podemos adicionar uma checagem expl√≠cita.\n",
        "        # if not running and vagas_livres == pool_size and stream is None:\n",
        "        #      log_supervisor(\"Todas as transmiss√µes poss√≠veis j√° foram processadas ou est√£o bloqueadas.\", \"END\")\n",
        "        #      break\n",
        "\n",
        "\n",
        "        # Log de status peri√≥dico\n",
        "        log_supervisor(\n",
        "            f\"Transmiss√µes ativas: {len(running)} | Lote alvo: {pool_size} | Buffer de resultados: {len(results)}\",\n",
        "            \"STATUS\"\n",
        "        )\n",
        "\n",
        "        # Aguarda um pouco antes de verificar novamente\n",
        "        time.sleep(5) # Aumentado o sleep para reduzir a frequ√™ncia da busca quando o lote est√° cheio\n",
        "\n",
        "        # Condi√ß√£o de sa√≠da mais robusta: se n√£o h√° processos rodando E a √∫ltima busca n√£o encontrou streams\n",
        "        if not running and (stream is None or (isinstance(stream, list) and len(stream) == 0)):\n",
        "             log_supervisor(\"N√£o h√° processos ativos e a √∫ltima busca n√£o encontrou transmiss√µes.\", \"END\")\n",
        "             break\n",
        "\n",
        "\n",
        "    # ========== Fase 3: Finaliza√ß√£o ==========\n",
        "    log_supervisor(f\"Processamento din√¢mico conclu√≠do! Total de transmiss√µes gravadas/processadas: {len(results)}\", \"RESUMO\")\n",
        "    # A chamada para commit_push_restantes() foi removida pois o commit √© gerenciado externamente.\n",
        "    log_supervisor(\"Supervisor din√¢mico finalizado.\", \"END\")\n",
        "\n",
        "\n",
        "# Fun√ß√£o principal para iniciar o supervisor\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Fun√ß√£o principal: inicia o notebook perguntando se o usu√°rio quer gravar transmiss√µes espec√≠ficas ou autom√°ticas.\n",
        "    Dispara o supervisor din√¢mico na modalidade selecionada.\n",
        "    \"\"\"\n",
        "    # Certificar-se que as vari√°veis globais essenciais da C√©lula 1 est√£o carregadas\n",
        "    # Isso √© feito executando a C√©lula 1 antes desta.\n",
        "    if 'LOG_PATH' not in globals():\n",
        "        print(\"‚ö†Ô∏è Vari√°veis globais da C√©lula 1 n√£o carregadas. Execute a C√©lula 1 primeiro.\")\n",
        "        return # Sai se a C√©lula 1 n√£o foi executada\n",
        "\n",
        "    usuarios_especificos = perguntar_transmissoes_especificas() # perguntar_transmissoes_especificas est√° na C√©lula 1\n",
        "    log_supervisor(\"Iniciando busca e grava√ß√£o de streams (supervisor din√¢mico)...\", \"MAIN\")\n",
        "    supervisor_dinamico(usuarios_especificos=usuarios_especificos)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Garante que as fun√ß√µes de log da C√©lula 1 estejam dispon√≠veis\n",
        "    # Em um notebook, geralmente as c√©lulas s√£o executadas em ordem,\n",
        "    # ent√£o C√©lula 1 j√° teria definido append_log, query_logs, etc.\n",
        "    # Se rodando como script Python, precisaria importar ou definir as fun√ß√µes de log aqui.\n",
        "    # Para o contexto do Colab, assume-se que C√©lula 1 j√° rodou.\n",
        "\n",
        "    # Adicionando um try-except para garantir que main() seja chamada\n",
        "    # apenas se estiver em um ambiente interativo como Colab/IPython\n",
        "    try:\n",
        "        if 'google.colab' in str(get_ipython()):\n",
        "            main()\n",
        "        else:\n",
        "            print(\"N√£o est√° rodando em Colab/IPython. Execute main() manualmente se desejar.\")\n",
        "    except NameError:\n",
        "        print(\"N√£o est√° rodando em Colab/IPython. Execute main() se desejar.\")\n",
        "\n",
        "\n",
        "# ================================================================\n",
        "# FIM DA C√âLULA 9 ‚Äî Supervisor Din√¢mico, Lote Cheio e Blacklist Centralizados (AGORA USANDO ID)\n",
        "# ================================================================\n",
        "\n",
        "# Observa√ß√µes e recomenda√ß√µes:\n",
        "# - Toda l√≥gica de blacklist, processamento e falhas agora se baseia no ID √∫nico do usu√°rio no log centralizado para m√°xima rastreabilidade.\n",
        "# - O log central √© a fonte de verdade para sincroniza√ß√£o entre workers/processos.\n",
        "# - Modularidade, logs claros e tratamento de erro garantem manuten√ß√£o e evolu√ß√£o seguras.\n",
        "# - Pronto para ambientes colaborativos (Colab, CI/CD, pipelines paralelos).\n",
        "# - Certifique-se de executar as C√©lulas 1, 3, 6, 7 e 8 antes desta."
      ],
      "metadata": {
        "id": "5WKQV9g_LB9M"
      },
      "id": "5WKQV9g_LB9M",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2eac76d"
      },
      "source": [
        "# C√©lula XX: Limpeza do Arquivo de Log Central do Google Drive\n",
        "\n",
        "**Objetivo:**\\\n",
        "Esta c√©lula permite remover o arquivo de log central (`xcam_master.log`) do Google Drive. √â uma opera√ß√£o √∫til para limpar um log corrompido que esteja causando erros (como `JSONDecodeError` ou `UnicodeDecodeError`) ou simplesmente para iniciar o registro de eventos do zero.\n",
        "\n",
        "## Principais pontos e funcionalidades\n",
        "\n",
        "- **Remo√ß√£o segura:** Verifica se o arquivo de log existe antes de tentar remov√™-lo.\n",
        "- **Tratamento de erros:** Inclui um bloco `try-except` para capturar e reportar quaisquer problemas que possam ocorrer durante a remo√ß√£o do arquivo.\n",
        "- **Feedback claro:** Imprime mensagens indicando se o arquivo foi removido com sucesso, se houve um erro ou se o arquivo n√£o foi encontrado.\n",
        "- **Utilidade para depura√ß√£o:** Essencial para resetar o estado do log quando ele se corrompe devido a falhas inesperadas de escrita ou outros problemas de sistema de arquivos.\n",
        "\n",
        "* * *\n",
        "\n",
        "## Como funciona a c√©lula\n",
        "\n",
        "- **Define o caminho** completo para o arquivo de log central no Google Drive.\n",
        "- **Verifica** se o arquivo existe nesse local.\n",
        "- **Tenta remover** o arquivo.\n",
        "- **Imprime** o resultado da opera√ß√£o (sucesso, erro ou arquivo n√£o encontrado).\n",
        "\n",
        "* * *\n",
        "\n",
        "## Exemplo de execu√ß√£o"
      ],
      "id": "d2eac76d"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8332447"
      },
      "source": [
        "import os\n",
        "\n",
        "log_file_drive = '/content/drive/MyDrive/XCam.Drive/logs/xcam_master.log'\n",
        "if os.path.exists(log_file_drive):\n",
        "    try:\n",
        "        os.remove(log_file_drive)\n",
        "        print(f\"Arquivo de log do Drive removido: {log_file_drive}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Erro ao remover arquivo de log do Drive: {e}\")\n",
        "else:\n",
        "    print(f\"Arquivo de log do Drive n√£o encontrado: {log_file_drive}\")"
      ],
      "id": "c8332447",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5d23bd8d"
      },
      "source": [
        "# C√©lula 1: Configura√ß√£o Global, Par√¢metros e Log Centralizado Robusto (JSONL no Google Drive, Usando ID)\n",
        "\n",
        "**Objetivo:**\\\n",
        "Esta c√©lula √© a base do pipeline do notebook. Ela centraliza todas as configura√ß√µes globais essenciais, define os caminhos importantes e, crucialmente, estabelece um sistema de log √∫nico, estruturado e robusto para registrar e gerenciar o estado de todo o processo.\n",
        "\n",
        "## Principais pontos e funcionalidades\n",
        "\n",
        "- **Configura√ß√µes Centrais:** Define e propaga vari√°veis globais que controlam diversos aspectos do pipeline (limites de busca, dura√ß√£o de grava√ß√£o, timeouts, etc.).\n",
        "- **Montagem do Google Drive:** Prepara o ambiente montando seu Google Drive, permitindo a persist√™ncia de dados importantes como o log central e os arquivos de usu√°rio (`rec.json`, posters).\n",
        "- **Log √önico Estruturado (JSONL):** Implementa um sistema de log centralizado em um arquivo no formato JSON Lines (`xcam_master.log`). Cada evento relevante do pipeline √© registrado neste arquivo com uma estrutura definida (`sessao`, `evento`, `id`, `username`, `status`, `detalhes`).\n",
        "- **Uso do ID como Chave Prim√°ria no Log:** Garante que a l√≥gica de controle de estado (blacklist, processamento, falhas) no log se baseie no `id` √∫nico do usu√°rio fornecido pela API, aumentando a precis√£o e a robustez, mantendo o `username` para refer√™ncia humana.\n",
        "- **Persist√™ncia no Google Drive:** O arquivo de log central √© salvo diretamente em um diret√≥rio no seu Google Drive (`/content/drive/MyDrive/XCam.Drive/logs/`), garantindo que o hist√≥rico de execu√ß√£o, blacklist e falhas seja mantido entre as sess√µes do Colab. O diret√≥rio √© criado automaticamente se n√£o existir.\n",
        "- **Utilit√°rios Abrangentes de Log:** Fornece um conjunto completo de fun√ß√µes para interagir com o log central:\n",
        "    - **`append_log`:** Adiciona novas entradas, lidando com unicidade l√≥gica para estados cr√≠ticos (como \"em processamento\" ou \"blacklisted\") atualizando entradas existentes em vez de duplicar. Inclui tratamento de erro robusto para ignorar linhas inv√°lidas durante a leitura e garantir a escrita.\n",
        "    - **`read_logs`:** L√™ todas as entradas v√°lidas do arquivo de log, com tratamento de erro linha a linha para ignorar corrup√ß√µes parciais.\n",
        "    - **`query_logs`:** Permite filtrar e buscar entradas do log com base em m√∫ltiplos crit√©rios (sess√£o, ID, username, status, etc.), essencial para verificar o estado do pipeline e de usu√°rios espec√≠ficos.\n",
        "    - **`remove_logs`:** Remove entradas do log que satisfazem uma condi√ß√£o, √∫til para limpar registros expirados (como blacklist tempor√°ria vencida).\n",
        "    - **`update_log_entry`:** Permite modificar entradas existentes que correspondem a uma condi√ß√£o, para atualizar status ou detalhes.\n",
        "- **Tratamento de Erros na Leitura do Log:** As fun√ß√µes de leitura (`append_log`, `read_logs`) s√£o resilientes a `JSONDecodeError` e `UnicodeDecodeError`, ignorando linhas inv√°lidas com avisos em vez de travar a execu√ß√£o completa do notebook, embora a remo√ß√£o do arquivo corrompido seja a solu√ß√£o ideal para a causa raiz.\n",
        "- **Fun√ß√£o Interativa:** Inclui uma fun√ß√£o para perguntar ao usu√°rio se deseja processar usu√°rios espec√≠ficos no in√≠cio da execu√ß√£o.\n",
        "\n",
        "* * *\n",
        "\n",
        "## Como funciona a c√©lula\n",
        "\n",
        "- Monta o Google Drive.\n",
        "- Define e propaga as vari√°veis de configura√ß√£o global via `globals().update()`.\n",
        "- Define a localiza√ß√£o do log central no Google Drive e garante a cria√ß√£o do diret√≥rio necess√°rio.\n",
        "- Define todas as fun√ß√µes do utilit√°rio de log (`now_iso`, `make_id_username`, `append_log`, `read_logs`, `query_logs`, `remove_logs`, `update_log_entry`).\n",
        "- Define a fun√ß√£o interativa `perguntar_transmissoes_especificas`.\n",
        "\n",
        "* * *\n",
        "\n",
        "## Exemplo de execu√ß√£o\n",
        "\n",
        "Esta c√©lula n√£o produz uma sa√≠da vis√≠vel direta (al√©m da montagem do Drive e da mensagem de cria√ß√£o do diret√≥rio de logs), mas sua execu√ß√£o √© **obrigat√≥ria antes de qualquer outra c√©lula** que dependa das configura√ß√µes globais, caminhos ou do sistema de log centralizado."
      ],
      "id": "5d23bd8d"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "c9hve1ySGVAs"
      ],
      "cell_execution_strategy": "setup",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}