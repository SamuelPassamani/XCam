{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SamuelPassamani/XCam/blob/main/xcam-colab/XCam_REC_V4.4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Célula 1: Configuração Global, Parâmetros e Log Único Estruturado\n",
        "\n",
        "**Objetivo:**  \n",
        "Esta célula inicializa e centraliza todas as variáveis e parâmetros essenciais para o funcionamento do notebook XCam, além de fornecer um sistema robusto para log centralizado e estruturado.  \n",
        "Seu propósito é garantir controle total sobre limites, caminhos, thresholds, rastreabilidade das execuções e facilidade de manutenção, promovendo padronização e transparência em todas as operações.\n",
        "\n",
        "---\n",
        "\n",
        "## O que esta célula faz?\n",
        "\n",
        "- **Monta e garante o diretório de logs no Google Drive:**  \n",
        "  Todos os registros do notebook são salvos em um arquivo único (`xcam_master.log`) dentro do Drive, facilitando backup, compartilhamento e auditoria.\n",
        "- **Define parâmetros globais editáveis:**  \n",
        "  Limites de processamento, controle de gravação, thresholds e caminhos são definidos de forma clara e centralizada, podendo ser facilmente ajustados conforme a necessidade do projeto ou do ambiente.\n",
        "- **Propaga variáveis para todo o notebook:**  \n",
        "  Com um único comando, todos os parâmetros são disponibilizados globalmente, evitando inconsistências e facilitando o uso em qualquer célula subsequente.\n",
        "- **Implementa um sistema de log único e modular (JSONL):**  \n",
        "  Todas as operações relevantes (busca, gravação, blacklist, falha, sucesso, commit, erro, etc.) são registradas em entradas padronizadas no arquivo de log, incluindo informações como sessão, evento, id, username, status, detalhes e timestamp.\n",
        "- **Fornece funções utilitárias para manipular o log:**  \n",
        "  Inclui funções para adicionar, buscar, atualizar e remover registros do log de maneira fácil e segura – atuando como um “banco de dados” simples para rastreamento e auditoria.\n",
        "- **Cria mecanismo de blacklist e controle por identificador:**  \n",
        "  O controle de falhas, blacklist, reprocessamento e auditoria é feito sempre por `id` (e `id_username`), garantindo unicidade e evitando erros comuns de duplicidade ou conflito de dados.\n",
        "- **Inclui função interativa para seleção de transmissões específicas:**  \n",
        "  Permite ao usuário informar manualmente nomes de usuários de transmissões para processamento prioritário.\n",
        "\n",
        "---\n",
        "\n",
        "## Exemplos de uso prático\n",
        "\n",
        "### 1. Ajustando parâmetros globais\n",
        "\n",
        "Se desejar processar apenas 30 transmissões por rodada, basta alterar:\n",
        "```python\n",
        "LIMIT_DEFAULT = 30\n",
        "```\n",
        "Ou para aumentar o tempo máximo de gravação:\n",
        "```python\n",
        "RECORD_SECONDS = 14400  # 4 horas\n",
        "```\n",
        "\n",
        "### 2. Registrando um evento no log\n",
        "\n",
        "Ao iniciar a gravação de uma transmissão:\n",
        "```python\n",
        "append_log({\n",
        "    \"sessao\": \"gravação\",\n",
        "    \"evento\": \"iniciado\",\n",
        "    \"id\": \"tx123\",\n",
        "    \"username\": \"StreamerExemplo\",\n",
        "    \"status\": \"ok\",\n",
        "    \"detalhes\": \"URL válida e gravação iniciada\"\n",
        "})\n",
        "```\n",
        "\n",
        "### 3. Consultando registros de blacklist\n",
        "\n",
        "Para buscar todas as transmissões atualmente banidas:\n",
        "```python\n",
        "logs_blacklist = query_logs(sessao=\"blacklist\", status=\"blacklisted\")\n",
        "print(logs_blacklist)\n",
        "```\n",
        "\n",
        "### 4. Removendo registros expirados\n",
        "\n",
        "Para limpar eventos de blacklist que já venceram:\n",
        "```python\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "def expirou(entry):\n",
        "    ts = datetime.fromisoformat(entry[\"timestamp\"].replace(\"Z\", \"\"))\n",
        "    return (datetime.utcnow() - ts) > timedelta(seconds=BLACKLIST_TIMEOUT)\n",
        "\n",
        "remove_logs(lambda entry: entry[\"sessao\"] == \"blacklist\" and expirou(entry), log_path=LOG_PATH)\n",
        "```\n",
        "\n",
        "### 5. Atualizando status de uma entrada\n",
        "\n",
        "Para promover o status de uma transmissão após sucesso:\n",
        "```python\n",
        "update_log_entry(\n",
        "    lambda e: e[\"id\"] == \"tx123\" and e[\"sessao\"] == \"gravação\",\n",
        "    lambda e: e.update({\"status\": \"success\"})\n",
        ")\n",
        "```\n",
        "\n",
        "### 6. Selecionando transmissões específicas manualmente\n",
        "\n",
        "O notebook pode perguntar:\n",
        "```\n",
        "Deseja gravar alguma transmissão específica? (sim/não):\n",
        "```\n",
        "Se sim, você informa os nomes separados por vírgula, por exemplo:\n",
        "```\n",
        "StreamerA, StreamerB\n",
        "```\n",
        "E o notebook irá priorizar esses nomes na próxima execução.\n",
        "\n",
        "---\n",
        "\n",
        "## Estrutura detalhada do log (`xcam_master.log`)\n",
        "\n",
        "Cada linha do arquivo é um JSON no formato:\n",
        "```json\n",
        "{\n",
        "  \"timestamp\": \"2025-06-06T06:15:00Z\",\n",
        "  \"sessao\": \"busca|gravação|blacklist|processing|failure|success|commit|erro|...\",\n",
        "  \"evento\": \"iniciado|finalizado|expirado|banido|...\",\n",
        "  \"id\": \"identificador_unico\",\n",
        "  \"username\": \"nome_para_exibicao\",\n",
        "  \"id_username\": \"identificador_unico:nome_para_exibicao\",\n",
        "  \"status\": \"ok|erro|blacklisted|expirado|success|...\",\n",
        "  \"detalhes\": \"informações adicionais, motivo, paths, etc\"\n",
        "}\n",
        "```\n",
        "\n",
        "Exemplo real:\n",
        "```json\n",
        "{\n",
        "  \"timestamp\": \"2025-06-15T20:00:00Z\",\n",
        "  \"sessao\": \"blacklist\",\n",
        "  \"evento\": \"banido\",\n",
        "  \"id\": \"tx987\",\n",
        "  \"username\": \"StreamerB\",\n",
        "  \"id_username\": \"tx987:StreamerB\",\n",
        "  \"status\": \"blacklisted\",\n",
        "  \"detalhes\": \"3 falhas consecutivas na gravação\"\n",
        "}\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Segurança, rastreabilidade e manutenção\n",
        "\n",
        "- **Consistência:** Todos os parâmetros críticos estão centralizados e propagados globalmente.\n",
        "- **Rastreabilidade:** Cada operação é registrada de forma padronizada, permitindo reprocessamento, auditoria e debugging facilitados.\n",
        "- **Facilidade de ajuste:** Qualquer valor relevante pode ser alterado em um só lugar e imediatamente refletido em todo o notebook.\n",
        "- **Manutenção simplificada:** Funções bem documentadas e exemplos práticos permitem evolução fácil por toda a equipe, mesmo para novos membros.\n",
        "\n",
        "---\n",
        "\n",
        "## Recomendações\n",
        "\n",
        "- Sempre execute a célula 1 antes de qualquer processamento.\n",
        "- Ao ajustar limites, thresholds ou caminhos, faça isso apenas nesta célula.\n",
        "- Consulte e manipule o log usando as funções fornecidas, evitando manipulação manual do arquivo.\n",
        "- Utilize o Google Drive para garantir o backup dos logs e facilitar a colaboração.\n",
        "- Siga os exemplos para registrar corretamente eventos e manter o histórico de execuções completo.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "c9hve1ySGVAs"
      },
      "id": "c9hve1ySGVAs"
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================\n",
        "# Célula 1: Configuração Global, Parâmetros e Log Único Estruturado\n",
        "# ================================================================\n",
        "# Objetivo:\n",
        "# - Centralizar configurações globais e thresholds\n",
        "# - Definir e montar caminhos do notebook\n",
        "# - Fornecer utilitário robusto para LOG ÚNICO MODULAR (JSONL)\n",
        "#   => Todas as células e funções usarão este log para registrar, consultar e manipular eventos\n",
        "# - Garantir padronização, rastreabilidade, unicidade e fácil manutenção futura\n",
        "#\n",
        "# Estratégia:\n",
        "# - Log único estruturado (JSONL): sessão, evento, id, username, id_username, timestamps, status, detalhes\n",
        "# - Funções CRUD para log: adicionar, buscar, atualizar, remover (para blacklist, processing, falhas, auditoria)\n",
        "# - Blacklist e controles baseados em id (com username apenas para exibição)\n",
        "# - Parâmetros globais facilmente editáveis e propagados via globals()\n",
        "# - Uso consistente de \"sessao\" para diferenciar tipos de registros\n",
        "# ================================================================\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "import json\n",
        "\n",
        "# ============================\n",
        "# PARÂMETROS GLOBAIS EDITÁVEIS\n",
        "# ============================\n",
        "# Modifique abaixo conforme necessidade do ambiente ou processamento\n",
        "\n",
        "# Limites e thresholds principais de processamento\n",
        "LIMIT_DEFAULT = 100             # Máximo de transmissões processadas por rodada\n",
        "PAGE_DEFAULT = 1               # Página padrão para busca na API\n",
        "RECORD_SECONDS = 12780         # Duração máxima da gravação (em segundos)\n",
        "RECORD_SECONDS_MIN = 420       # Duração mínima válida (em segundos)\n",
        "API_SEARCH_LIMIT = 3333        # Limite ao buscar usuários específicos\n",
        "# COMMIT_PUSH_THRESHOLD removido pois o commit/push é gerenciado externamente\n",
        "\n",
        "# Caminhos de arquivos principais\n",
        "BASE_PATH = '/content' # Mantido para referência, mas LOG_PATH vai para o Drive\n",
        "DRIVE_BASE_LOG_PATH = '/content/drive/MyDrive/XCam.Drive/logs' # Novo caminho base para logs no Drive\n",
        "LOG_PATH = f\"{DRIVE_BASE_LOG_PATH}/xcam_master.log\"          # Arquivo único de log central MOVIDO PARA O DRIVE\n",
        "BLACKLIST_TIMEOUT = 15 * 60                        # Blacklist: tempo de expiração (segundos)\n",
        "BLACKLIST_MAX_FAILURES = 3                         # Blacklist: falhas para banimento temporário\n",
        "\n",
        "# Garante que o diretório de logs no Drive exista\n",
        "os.makedirs(DRIVE_BASE_LOG_PATH, exist_ok=True)\n",
        "print(f\"Diretório de logs no Drive garantido: {DRIVE_BASE_LOG_PATH}\")\n",
        "\n",
        "\n",
        "# ============================\n",
        "# ATUALIZAÇÃO GLOBAL DOS PARÂMETROS\n",
        "# ============================\n",
        "# Propaga parâmetros como globais do notebook\n",
        "globals().update({\n",
        "    'LIMIT_DEFAULT': LIMIT_DEFAULT,\n",
        "    'PAGE_DEFAULT': PAGE_DEFAULT,\n",
        "    'RECORD_SECONDS': RECORD_SECONDS,\n",
        "    'RECORD_SECONDS_MIN': RECORD_SECONDS_MIN,\n",
        "    'API_SEARCH_LIMIT': API_SEARCH_LIMIT,\n",
        "    'LOG_PATH': LOG_PATH, # Atualizado para o caminho do Drive\n",
        "    'BLACKLIST_TIMEOUT': BLACKLIST_TIMEOUT,\n",
        "    'BLACKLIST_MAX_FAILURES': BLACKLIST_MAX_FAILURES\n",
        "})\n",
        "\n",
        "# =============================================================================\n",
        "# UTILITÁRIO DE LOG ÚNICO MODULAR (JSONL) — Clean Architecture\n",
        "# -----------------------------------------------------------------------------\n",
        "# Cada entrada: {\n",
        "#   \"timestamp\": \"2025-06-06T06:15:00Z\",\n",
        "#   \"sessao\": \"busca|gravação|blacklist|processing|failure|commit|erro|...\",\n",
        "#   \"evento\": \"...\",\n",
        "#   \"id\": \"...\",               # identificador primário (ex: id da transmissão)\n",
        "#   \"username\": \"...\",         # apenas referência humana\n",
        "#   \"id_username\": \"...\",      # padrão \"{id}:{username}\" para fácil leitura/humano\n",
        "#   \"status\": \"...\",           # ok|erro|blacklisted|expirado|...\n",
        "#   \"detalhes\": \"...\",         # informações adicionais/motivo/paths\n",
        "# }\n",
        "# =============================================================================\n",
        "\n",
        "from datetime import datetime\n",
        "\n",
        "def now_iso():\n",
        "    \"\"\"Retorna timestamp UTC em formato ISO.\"\"\"\n",
        "    return datetime.utcnow().isoformat() + \"Z\"\n",
        "\n",
        "def make_id_username(id, username):\n",
        "    \"\"\"Gera o identificador de referência padrão para logs: '{id}:{username}'.\"\"\"\n",
        "    return f\"{id}:{username}\"\n",
        "\n",
        "def append_log(entry, log_path=LOG_PATH):\n",
        "    \"\"\"\n",
        "    Adiciona uma nova entrada ao log central (JSONL).\n",
        "    Campos obrigatórios: sessao, evento, id, username, status.\n",
        "    - 'id' DEVE ser chave primária (único por transmissão/processo).\n",
        "    - 'username' é apenas referência humana.\n",
        "    - 'id_username' sempre gerado para facilitar auditoria/consulta.\n",
        "    - 'sessao' obrigatório e padronizado para facilitar filtros e consultas.\n",
        "    \"\"\"\n",
        "    entry.setdefault(\"timestamp\", now_iso())\n",
        "    for field in [\"sessao\", \"evento\", \"id\", \"username\", \"status\"]:\n",
        "        entry.setdefault(field, \"\")\n",
        "    # Padrão de referência único e fácil busca\n",
        "    entry[\"id_username\"] = make_id_username(entry[\"id\"], entry[\"username\"])\n",
        "    # Evitar duplicidade de id+sessao+evento (unicidade lógica)\n",
        "    logs = []\n",
        "    # Verifica se o arquivo existe ANTES de tentar ler\n",
        "    if os.path.exists(log_path):\n",
        "        try:\n",
        "            with open(log_path, \"r\", encoding=\"utf-8\") as f:\n",
        "                # Lê linha por linha e tenta parsear JSON. Ignora linhas inválidas com aviso.\n",
        "                for line in f:\n",
        "                    line = line.strip()\n",
        "                    if line:\n",
        "                        try:\n",
        "                            logs.append(json.loads(line))\n",
        "                        except json.JSONDecodeError as e:\n",
        "                            print(f\"⚠️ Aviso: Linha inválida no log '{log_path}', ignorada: {line} - Erro: {e}\")\n",
        "        except Exception as e:\n",
        "             print(f\"❌ Erro inesperado ao ler log '{log_path}', inicializando lista vazia: {e}\")\n",
        "             logs = []\n",
        "\n",
        "\n",
        "    # Checa unicidade apenas para eventos que não podem ser duplicados (ex: processing, blacklist, etc)\n",
        "    if entry[\"sessao\"] in {\"processing\", \"blacklist\", \"failure\", \"success\"}:\n",
        "        key = (entry[\"id\"], entry[\"sessao\"], entry[\"evento\"])\n",
        "        # Encontra o índice da entrada existente, se houver\n",
        "        existing_index = next((i for i, e in enumerate(logs) if (e.get(\"id\"), e.get(\"sessao\"), e.get(\"evento\")) == key), -1)\n",
        "\n",
        "        if existing_index != -1:\n",
        "            # Atualiza o registro existente ao invés de duplicar\n",
        "            logs[existing_index].update(entry)\n",
        "            # Escreve o arquivo completo de volta (substitui)\n",
        "            try:\n",
        "                with open(log_path, \"w\", encoding=\"utf-8\") as f:\n",
        "                    for l in logs:\n",
        "                        f.write(json.dumps(l, ensure_ascii=False) + \"\\n\")\n",
        "                return # Retorna após atualizar\n",
        "            except Exception as e:\n",
        "                print(f\"❌ Erro ao reescrever log '{log_path}' após atualização: {e}\")\n",
        "                # Em caso de erro ao reescrever, tenta apenas append abaixo como fallback?\n",
        "                # Ou seria melhor parar? Por segurança, vamos tentar append (pode gerar duplicidade temporária)\n",
        "                pass # Continua para o append abaixo em caso de erro ao reescrever\n",
        "\n",
        "    # Se não existe ou se houve erro ao reescrever, apenas append a nova entrada\n",
        "    try:\n",
        "        with open(log_path, \"a\", encoding=\"utf-8\") as f:\n",
        "            f.write(json.dumps(entry, ensure_ascii=False) + \"\\n\")\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Erro ao adicionar entrada ao log '{log_path}': {e}\")\n",
        "\n",
        "\n",
        "def read_logs(log_path=LOG_PATH):\n",
        "    \"\"\"Lê todas as entradas do log central.\"\"\"\n",
        "    if not os.path.exists(log_path):\n",
        "        return []\n",
        "    logs = []\n",
        "    try:\n",
        "        with open(log_path, \"r\", encoding=\"utf-8\") as f:\n",
        "            for line in f:\n",
        "                line = line.strip()\n",
        "                if line:\n",
        "                    try:\n",
        "                        logs.append(json.loads(line))\n",
        "                    except json.JSONDecodeError as e:\n",
        "                         print(f\"⚠️ Aviso: Linha inválida no log '{log_path}', ignorada: {line} - Erro: {e}\")\n",
        "    except Exception as e:\n",
        "         print(f\"❌ Erro inesperado ao ler log '{log_path}': {e}\")\n",
        "         return []\n",
        "    return logs\n",
        "\n",
        "\n",
        "def query_logs(sessao=None, id=None, username=None, id_username=None, evento=None, status=None, after=None, before=None, log_path=LOG_PATH):\n",
        "    \"\"\"\n",
        "    Consulta entradas do log por filtros opcionais.\n",
        "    Filtros disponíveis: sessao, id, username, id_username, evento, status, after, before.\n",
        "    - after/before: string ISO ou datetime\n",
        "    \"\"\"\n",
        "    logs = read_logs(log_path)\n",
        "    result = []\n",
        "    for entry in logs:\n",
        "        if sessao and entry.get(\"sessao\") != sessao:\n",
        "            continue\n",
        "        if id and entry.get(\"id\") != id:\n",
        "            continue\n",
        "        if username and entry.get(\"username\") != username:\n",
        "            continue\n",
        "        if id_username and entry.get(\"id_username\") != id_username:\n",
        "            continue\n",
        "        if evento and entry.get(\"evento\") != evento:\n",
        "            continue\n",
        "        if status and entry.get(\"status\") != status:\n",
        "            continue\n",
        "        ts = entry.get(\"timestamp\")\n",
        "        if after:\n",
        "            after_val = after if isinstance(after, str) else after.isoformat()\n",
        "            if ts < after_val:\n",
        "                continue\n",
        "        if before:\n",
        "            before_val = before if isinstance(before, str) else before.isoformat()\n",
        "            if ts > before_val:\n",
        "                continue\n",
        "        result.append(entry)\n",
        "    return result\n",
        "\n",
        "def remove_logs(condition_fn, log_path=LOG_PATH):\n",
        "    \"\"\"\n",
        "    Remove do log central todas as entradas que satisfaçam condition_fn(entry).\n",
        "    Útil para expurgar logs expirados, blacklists vencidas, eventos processados, etc.\n",
        "    \"\"\"\n",
        "    logs = read_logs(log_path)\n",
        "    kept = [entry for entry in logs if not condition_fn(entry)]\n",
        "    # Só reescreve se houve remoção ou se o arquivo existia e agora está vazio\n",
        "    if len(kept) < len(logs) or (len(logs) > 0 and len(kept) == 0):\n",
        "        try:\n",
        "            with open(log_path, \"w\", encoding=\"utf-8\") as f:\n",
        "                for entry in kept:\n",
        "                    f.write(json.dumps(entry, ensure_ascii=False) + \"\\n\")\n",
        "            print(f\"✅ {len(logs) - len(kept)} entradas removidas do log '{log_path}'.\")\n",
        "            return len(logs) - len(kept)\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Erro ao reescrever log '{log_path}' após remoção: {e}\")\n",
        "            return 0 # Não podemos confirmar quantas foram removidas no arquivo\n",
        "    else:\n",
        "         print(f\"ℹ️ Nenhuma entrada satisfez a condição de remoção no log '{log_path}'.\")\n",
        "         return 0\n",
        "\n",
        "\n",
        "def update_log_entry(match_fn, update_fn, log_path=LOG_PATH):\n",
        "    \"\"\"\n",
        "    Atualiza entradas do log central: se match_fn(entry)==True, aplica update_fn(entry).\n",
        "    Exemplo: promover status de \"pending\" para \"ok\".\n",
        "    \"\"\"\n",
        "    logs = read_logs(log_path)\n",
        "    updated = 0\n",
        "    # Cria uma cópia para iterar enquanto modifica a original (ou uma nova lista)\n",
        "    new_logs = []\n",
        "    made_changes = False\n",
        "    for entry in logs:\n",
        "        # Cria uma cópia da entrada para modificar, se necessário\n",
        "        entry_copy = entry.copy()\n",
        "        if match_fn(entry_copy):\n",
        "            update_fn(entry_copy)\n",
        "            updated += 1\n",
        "            made_changes = True\n",
        "        new_logs.append(entry_copy)\n",
        "\n",
        "    if made_changes:\n",
        "        try:\n",
        "            with open(log_path, \"w\", encoding=\"utf-8\") as f:\n",
        "                for entry in new_logs:\n",
        "                    f.write(json.dumps(entry, ensure_ascii=False) + \"\\n\")\n",
        "            print(f\"✅ {updated} entradas atualizadas no log '{log_path}'.\")\n",
        "        except Exception as e:\n",
        "             print(f\"❌ Erro ao reescrever log '{log_path}' após atualização: {e}\")\n",
        "\n",
        "    return updated\n",
        "\n",
        "# Exemplos de uso (para as próximas células):\n",
        "# append_log({\"sessao\":\"processing\", \"evento\":\"iniciado\", \"id\":\"123456\", \"username\":\"Manugic_\", \"status\":\"ok\", \"detalhes\":\"URL válida\"})\n",
        "# logs_blacklist = query_logs(sessao=\"blacklist\", status=\"blacklisted\")\n",
        "# remove_logs(lambda entry: entry[\"sessao\"]==\"processing\" and expirou(entry), log_path=LOG_PATH)\n",
        "# update_log_entry(lambda e: e[\"id\"]==\"123456\" and e[\"sessao\"]==\"processing\", lambda e: e.update({\"status\":\"ok\"}))\n",
        "\n",
        "# =============================================================================\n",
        "# FUNÇÃO INTERATIVA (opcional) PARA ESCOLHA DE TRANSMISSÕES ESPECÍFICAS\n",
        "# =============================================================================\n",
        "def perguntar_transmissoes_especificas():\n",
        "    \"\"\"\n",
        "    Pergunta ao usuário se deseja informar transmissões específicas para gravar,\n",
        "    recebendo nomes de usuário separados por vírgula e retornando lista limpa.\n",
        "    Retorna lista vazia caso não deseje selecionar usuários.\n",
        "    \"\"\"\n",
        "    resp = input('Deseja gravar alguma transmissão específica? (sim/não): ').strip().lower()\n",
        "    if resp.startswith('s'):\n",
        "        usuarios = input('Informe o(s) nome(s) de usuário, separados por vírgula (ex: userNovo234, jovemPT): ')\n",
        "        usuarios_lista = [u.strip() for u in usuarios.split(',') if u.strip()]\n",
        "        return usuarios_lista\n",
        "    return []\n",
        "\n",
        "# =============================================================================\n",
        "# DICAS DE USO EM OUTRAS CÉLULAS:\n",
        "# - Para registrar evento: append_log({...})\n",
        "# - Para consultar blacklist: query_logs(sessao=\"blacklist\", status=\"blacklisted\")\n",
        "# - Para remover registros expirados: remove_logs(lambda e: ...)\n",
        "# - Para atualizar status: update_log_entry(lambda e: ..., lambda e: ...)\n",
        "# - Sempre use o id como chave primária e id_username para referência em relatórios/auditoria\n",
        "# =============================================================================\n",
        "\n",
        "# ============================\n",
        "# FIM DA CÉLULA 1\n",
        "# ============================"
      ],
      "metadata": {
        "id": "j5pPh353GLMD"
      },
      "id": "j5pPh353GLMD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Célula 2: Instalação e Validação do ffmpeg\n",
        "\n",
        "**Objetivo:**  \n",
        "Esta célula é responsável por garantir que o utilitário `ffmpeg` esteja instalado, atualizado e disponível no ambiente de execução do notebook XCam (Google Colab ou qualquer sistema baseado em Linux). O ffmpeg é indispensável para todas as etapas de gravação de vídeos e processamento de mídia do pipeline.\n",
        "\n",
        "---\n",
        "\n",
        "## Principais pontos e melhorias implementadas\n",
        "\n",
        "- **Verificação automática e idempotente:**  \n",
        "  Antes de qualquer instalação, verifica se o `ffmpeg` já está disponível no PATH do sistema. Assim, evita reinstalações desnecessárias e torna o processo seguro para múltiplas execuções.\n",
        "- **Instalação automatizada via apt-get:**  \n",
        "  Caso o `ffmpeg` não esteja instalado, realiza a instalação automatizada usando `apt-get`, garantindo compatibilidade com ambientes Google Colab e servidores Linux.\n",
        "- **Validação e exibição da versão instalada:**  \n",
        "  Após a instalação (ou confirmação prévia), exibe a versão do `ffmpeg` instalada, contribuindo para rastreabilidade e diagnóstico de ambiente.\n",
        "- **Mensagens de log detalhadas:**  \n",
        "  Cada etapa da checagem, instalação e validação fornece feedback detalhado ao usuário, facilitando a identificação de problemas e tornando o notebook mais transparente para uso individual ou colaborativo.\n",
        "- **Design modular e pronto para CI/CD:**  \n",
        "  A estrutura da célula foi desenhada para integração fácil em pipelines automatizados, garantindo robustez em ambientes colaborativos, notebooks, scripts e CI/CD.\n",
        "\n",
        "---\n",
        "\n",
        "## Como funciona a célula\n",
        "\n",
        "1. **Checagem inicial:**  \n",
        "   Usa a função `is_ffmpeg_installed()` para verificar se o comando `ffmpeg` está disponível no ambiente.\n",
        "2. **Instalação automática (se necessário):**  \n",
        "   Caso `ffmpeg` não esteja presente, executa `install_ffmpeg()`, realizando atualização dos pacotes e instalação silenciosa para manter o log limpo.\n",
        "3. **Validação final e rastreabilidade:**  \n",
        "   Exibe a versão instalada com `show_ffmpeg_version()` para garantir que a instalação foi bem-sucedida.\n",
        "4. **Tratamento de erros:**  \n",
        "   Em caso de falha na instalação, exibe mensagens de erro detalhadas e interrompe a execução, evitando inconsistências futuras no pipeline.\n",
        "\n",
        "---\n",
        "\n",
        "## Exemplo de uso das funções desta célula\n",
        "\n",
        "```python\n",
        "if not is_ffmpeg_installed():\n",
        "    install_ffmpeg()\n",
        "show_ffmpeg_version()\n",
        "```\n",
        "Ou, de forma automatizada e segura (como implementado):\n",
        "```python\n",
        "if not is_ffmpeg_installed():\n",
        "    print(\"[WARN] ffmpeg não encontrado no ambiente.\")\n",
        "    try:\n",
        "        install_ffmpeg()\n",
        "    except Exception:\n",
        "        raise RuntimeError(\"[ERRO] Falha ao instalar o ffmpeg. Verifique permissões ou tente novamente.\")\n",
        "    if not is_ffmpeg_installed():\n",
        "        raise RuntimeError(\"[ERRO] Falha ao instalar o ffmpeg. Verifique permissões, root ou tente novamente.\")\n",
        "    else:\n",
        "        print(\"[OK] ffmpeg instalado e pronto para uso.\")\n",
        "else:\n",
        "    print(\"[OK] ffmpeg já está instalado no ambiente.\")\n",
        "\n",
        "show_ffmpeg_version()\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Segurança, rastreabilidade e manutenção\n",
        "\n",
        "- **Robustez:** Garante que o ambiente está sempre pronto para gravação e processamento de mídia, mesmo após resets ou novas execuções.\n",
        "- **Transparência:** Mensagens informativas em cada etapa ajudam a equipe a identificar rapidamente problemas de ambiente, permissões ou compatibilidade.\n",
        "- **Modularidade:** Célula pronta para ser reutilizada em outros projetos, pipelines ou ambientes CI/CD do ecossistema XCam, bastando adaptar comandos de instalação para outros sistemas se necessário.\n",
        "- **Idempotência:** Pode ser executada múltiplas vezes sem efeitos colaterais ou duplicação de instalações, tornando o setup seguro e confiável.\n",
        "\n",
        "---\n",
        "\n",
        "## Observações técnicas\n",
        "\n",
        "- O ffmpeg deve estar disponível no PATH do sistema para todas as etapas do pipeline XCam.\n",
        "- Para obter o caminho absoluto do executável:  \n",
        "  ```python\n",
        "  subprocess.run(['which', 'ffmpeg'], capture_output=True, text=True).stdout.strip()\n",
        "  ```\n",
        "- A célula pode ser adaptada para outros sistemas de gerenciamento de pacotes se necessário (exemplo: yum, brew, choco).\n",
        "- Recomenda-se executar esta célula sempre antes de iniciar qualquer processamento de mídia.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "WXs0o6OPHXbi"
      },
      "id": "WXs0o6OPHXbi"
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================\n",
        "# Célula 2: Instalação e Validação do FFMPEG no Colab e Linux\n",
        "# ================================================================\n",
        "# Objetivo:\n",
        "# - Garantir que o utilitário ffmpeg está instalado e disponível no ambiente (Colab ou Linux)\n",
        "# - Validar a instalação e exibir a versão instalada para rastreabilidade\n",
        "# - Tornar a etapa idempotente, evitando instalações desnecessárias (safe to rerun)\n",
        "# - Fornecer feedback detalhado e logs a cada etapa para diagnóstico rápido\n",
        "#\n",
        "# Estratégia aplicada:\n",
        "# - Checa se ffmpeg está disponível no PATH do sistema\n",
        "# - Caso não esteja, instala automaticamente via apt-get (compatível Colab/Linux)\n",
        "# - Valida a instalação e exibe a versão instalada\n",
        "# - Modularidade e robustez para uso em pipelines, CI/CD e ambientes colaborativos\n",
        "# ================================================================\n",
        "\n",
        "import subprocess   # Importação obrigatória para checagem e instalação do ffmpeg\n",
        "import sys\n",
        "\n",
        "def is_ffmpeg_installed():\n",
        "    \"\"\"\n",
        "    Verifica se o ffmpeg está instalado e disponível no PATH do sistema.\n",
        "    Retorna True se estiver, False caso contrário.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        result = subprocess.run([\"ffmpeg\", \"-version\"], capture_output=True, text=True)\n",
        "        return result.returncode == 0\n",
        "    except Exception:\n",
        "        return False\n",
        "\n",
        "def install_ffmpeg():\n",
        "    \"\"\"\n",
        "    Instala o ffmpeg via apt-get caso não esteja presente.\n",
        "    Somente para sistemas baseados em Debian/Ubuntu (inclui Google Colab).\n",
        "    \"\"\"\n",
        "    print(\"[INFO] Iniciando instalação do ffmpeg via apt-get...\")\n",
        "    try:\n",
        "        # Atualiza pacotes e instala ffmpeg de forma silenciosa para logs limpos\n",
        "        subprocess.run(\"apt-get update -y\", shell=True, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "        subprocess.run(\"apt-get install -y ffmpeg\", shell=True, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "        print(\"[INFO] ffmpeg instalado com sucesso.\")\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"[ERRO] Falha ao instalar ffmpeg via apt-get: {e}\")\n",
        "        print(\"🔴 Tente rodar manualmente ou verifique permissões/root.\")\n",
        "        raise\n",
        "\n",
        "def show_ffmpeg_version():\n",
        "    \"\"\"\n",
        "    Exibe a versão instalada do ffmpeg, se disponível.\n",
        "    Mostra as duas primeiras linhas para rastreabilidade.\n",
        "    \"\"\"\n",
        "    print(\"[INFO] Versão do ffmpeg instalada:\")\n",
        "    try:\n",
        "        result = subprocess.run([\"ffmpeg\", \"-version\"], capture_output=True, text=True)\n",
        "        if result.returncode == 0:\n",
        "            linhas = result.stdout.strip().split('\\n')\n",
        "            for l in linhas[:2]:\n",
        "                print(l)\n",
        "        else:\n",
        "            print(\"[ERRO] ffmpeg instalado, mas não foi possível obter a versão.\")\n",
        "    except Exception as e:\n",
        "        print(f\"[ERRO] Não foi possível exibir a versão do ffmpeg: {e}\")\n",
        "\n",
        "# ================================================================\n",
        "# EXECUÇÃO DA ETAPA DE SETUP — Sempre idempotente e segura\n",
        "# ================================================================\n",
        "\n",
        "if not is_ffmpeg_installed():\n",
        "    print(\"[WARN] ffmpeg não encontrado no ambiente.\")\n",
        "    try:\n",
        "        install_ffmpeg()\n",
        "    except Exception:\n",
        "        raise RuntimeError(\"[ERRO] Falha ao instalar o ffmpeg. Verifique permissões ou tente novamente.\")\n",
        "    if not is_ffmpeg_installed():\n",
        "        # Última checagem após instalação\n",
        "        raise RuntimeError(\"[ERRO] Falha ao instalar o ffmpeg. Verifique permissões, root ou tente novamente.\")\n",
        "    else:\n",
        "        print(\"[OK] ffmpeg instalado e pronto para uso.\")\n",
        "else:\n",
        "    print(\"[OK] ffmpeg já está instalado no ambiente.\")\n",
        "\n",
        "show_ffmpeg_version()\n",
        "\n",
        "# ================================================================\n",
        "# FIM DA CÉLULA 2 — Instalação e Validação do ffmpeg\n",
        "# ================================================================\n",
        "#\n",
        "# Observações técnicas:\n",
        "# - ffmpeg deve estar disponível para todas as etapas do pipeline XCam.\n",
        "# - Para obter o caminho absoluto: subprocess.run(['which', 'ffmpeg'], capture_output=True, text=True).stdout.strip()\n",
        "# - Célula idempotente: pode ser executada múltiplas vezes sem efeitos colaterais.\n",
        "# - Pronta para uso em pipelines, scripts automatizados e ambientes colaborativos."
      ],
      "metadata": {
        "id": "vIODn0c2HiHz"
      },
      "id": "vIODn0c2HiHz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Célula 3: Imports Essenciais, Utilitários e Preparação do Ambiente\n",
        "\n",
        "**Objetivo:**  \n",
        "Esta célula prepara o ambiente de execução do notebook XCam, realizando todos os imports essenciais de bibliotecas Python necessárias e centralizando funções utilitárias robustas para formatação de tempo, exibição de progresso, download e geração de posters (thumbnails) das transmissões.  \n",
        "Toda a lógica de rastreabilidade, fallback, tratamento de exceções e integração com o log centralizado é garantida, promovendo modularidade, clareza e segurança para as próximas etapas do pipeline.\n",
        "\n",
        "---\n",
        "\n",
        "## Principais pontos e melhorias implementadas\n",
        "\n",
        "- **Imports essenciais agrupados:**  \n",
        "  Todos os módulos básicos e avançados utilizados ao longo do notebook são importados em um só lugar, incluindo manipulação de arquivos, requests HTTP, processamento paralelo, datas, subprocessos, matemática, expressões regulares, shutil, threading e integração com IPython.\n",
        "- **Funções utilitárias padronizadas e seguras:**  \n",
        "  As funções fornecem utilitários para:\n",
        "  - Formatar segundos em tempo legível\n",
        "  - Exibir progresso detalhado da gravação de transmissões\n",
        "  - Download robusto de posters remotos ou uso direto de arquivos locais\n",
        "  - Geração automática de poster a partir de stream (.m3u8) usando ffmpeg, com múltiplas tentativas, tratamento de falha, log centralizado e fallback inteligente para placeholder\n",
        "  - Validação do arquivo de poster gerado\n",
        "- **Integração total ao log centralizado:**  \n",
        "  Todas as falhas, erros e eventos relevantes durante o download ou geração de posters são registrados no log único do sistema (definido na Célula 1), eliminando a necessidade de logs temporários dispersos.\n",
        "- **Fallbacks inteligentes e robustez:**  \n",
        "  Se não for possível gerar um poster com ffmpeg, a função gera uma imagem placeholder personalizada para manter a experiência e rastreabilidade, registrando o evento no log.\n",
        "- **Pronto para uso concorrente e distribuído:**  \n",
        "  As funções foram desenhadas para suportar execução paralela, controle de exceções e integração transparente com processos multi-thread/multi-processo.\n",
        "\n",
        "---\n",
        "\n",
        "## Funções utilitárias disponíveis nesta célula\n",
        "\n",
        "- **`format_seconds(seconds)`**  \n",
        "  Formata um valor em segundos em string legível (ex: \"1h23m45s\"), facilitando exibição de progresso.\n",
        "- **`log_progress(username, elapsed_seconds, total_seconds)`**  \n",
        "  Exibe no console o progresso detalhado da gravação de cada transmissão, incluindo minutos gravados, minutos restantes e percentual concluído.\n",
        "- **`download_and_save_poster(poster_url, username, temp_folder)`**  \n",
        "  Faz download do poster a partir de uma URL remota (HTTP/HTTPS) ou retorna o caminho local se já existir. Salva o arquivo no diretório temporário indicado e fornece feedback detalhado em caso de erro.\n",
        "- **`generate_poster_with_ffmpeg(m3u8_url, username, temp_folder, tries, timeout)`**  \n",
        "  Gera um poster automaticamente a partir de uma stream `.m3u8` usando ffmpeg, tentando múltiplos pontos no vídeo e registrando todas as tentativas, falhas e sucessos no log central. Em caso de falha total, gera um poster placeholder com feedback visual e registro no log.\n",
        "- **`is_poster_valid(poster_path)`**  \n",
        "  Verifica se o poster existe e não está vazio, garantindo que apenas imagens válidas sejam usadas no pipeline.\n",
        "\n",
        "---\n",
        "\n",
        "## Exemplos de uso prático\n",
        "\n",
        "```python\n",
        "# Formatar segundos em string legível\n",
        "tempo = format_seconds(5421)   # \"1h30m21s\"\n",
        "\n",
        "# Exibir progresso detalhado de gravação\n",
        "log_progress(\"StreamerExemplo\", 385, 12780)\n",
        "\n",
        "# Fazer download do poster da transmissão\n",
        "poster_path = download_and_save_poster(\"https://exemplo.com/poster.jpg\", \"StreamerExemplo\", \"/content/temp\")\n",
        "\n",
        "# Gerar poster automaticamente via ffmpeg (caso o download falhe ou não seja válido)\n",
        "if not is_poster_valid(poster_path):\n",
        "    poster_path = generate_poster_with_ffmpeg(\"https://exemplo.com/stream.m3u8\", \"StreamerExemplo\", \"/content/temp\")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Segurança, rastreabilidade e manutenção\n",
        "\n",
        "- Todas as funções são protegidas contra erros, possuem logs detalhados e fallback inteligente para manter o pipeline funcionando mesmo em cenários adversos.\n",
        "- O log único centralizado substitui qualquer necessidade de arquivos dispersos para rastreabilidade de processamento, blacklist ou falhas.\n",
        "- Comentários e organização clara facilitam a compreensão, manutenção e evolução do notebook por toda a equipe XCam, inclusive para novos membros ou ambientes colaborativos.\n",
        "- O código está pronto para execução concorrente e pode ser facilmente integrado a pipelines CI/CD ou ambientes distribuídos.\n",
        "\n",
        "---\n",
        "\n",
        "## Recomendações\n",
        "\n",
        "- Utilize sempre as funções utilitárias fornecidas nesta célula para qualquer tarefa de formatação, progresso, download ou geração de poster.\n",
        "- Consulte e integre o log centralizado para rastreabilidade de todos os eventos relevantes.\n",
        "- Mantenha o diretório temporário organizado e monitore os logs para auditoria e diagnóstico.\n",
        "- Em caso de erros na geração de poster, utilize o placeholder automático para não interromper o pipeline.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "90qvXC0rHtWb"
      },
      "id": "90qvXC0rHtWb"
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================\n",
        "# Célula 3: Imports Essenciais, Utilitários e Preparação do Ambiente\n",
        "# ================================================================\n",
        "# Objetivo:\n",
        "# - Importar bibliotecas essenciais para todo o notebook\n",
        "# - Centralizar funções auxiliares de formatação, download e geração de poster\n",
        "# - Remover dependências de logs temporários dispersos, integrando ao log único do sistema (LOG_PATH)\n",
        "# - Garantir robustez, clareza e modularidade para as próximas células\n",
        "#\n",
        "# Estratégia aplicada:\n",
        "# - Apenas os imports necessários para o funcionamento do notebook\n",
        "# - Funções auxiliares adaptadas para Clean Architecture e integração com o log centralizado (Célula 1)\n",
        "# - Função de geração de poster com ffmpeg robusta, com múltiplas tentativas e fallback\n",
        "# - Modularidade: funções isoladas, reusáveis, prontas para testes e integração\n",
        "# ================================================================\n",
        "\n",
        "import os\n",
        "import requests\n",
        "from multiprocessing import Manager, Process\n",
        "from datetime import datetime\n",
        "import json\n",
        "import time\n",
        "import subprocess\n",
        "import math\n",
        "import re\n",
        "import shutil\n",
        "import threading\n",
        "\n",
        "from IPython import get_ipython\n",
        "from IPython.display import display\n",
        "\n",
        "# ============================\n",
        "# UTILITÁRIOS DE FORMATAÇÃO E PROGRESSO\n",
        "# ============================\n",
        "\n",
        "def format_seconds(seconds):\n",
        "    \"\"\"\n",
        "    Formata segundos em string legível (e.g., 1h23m45s).\n",
        "    \"\"\"\n",
        "    total_seconds = int(seconds)\n",
        "    hours = total_seconds // 3600\n",
        "    minutes = (total_seconds % 3600) // 60\n",
        "    seconds = total_seconds % 60\n",
        "    parts = []\n",
        "    if hours > 0:\n",
        "        parts.append(f\"{hours}h\")\n",
        "    if minutes > 0 or (hours == 0 and seconds > 0):\n",
        "        parts.append(f\"{minutes}m\")\n",
        "    if seconds > 0 or total_seconds == 0:\n",
        "        parts.append(f\"{seconds}s\")\n",
        "    return \"\".join(parts) if parts else \"0s\"\n",
        "\n",
        "def log_progress(username, elapsed_seconds, total_seconds):\n",
        "    \"\"\"\n",
        "    Exibe progresso da gravação de cada transmissão em tempo real.\n",
        "    \"\"\"\n",
        "    percent = min((elapsed_seconds / total_seconds) * 100, 100)\n",
        "    tempo = format_seconds(elapsed_seconds)\n",
        "    minutos_gravados = math.floor(elapsed_seconds / 60)\n",
        "    minutos_restantes = max(0, math.ceil((total_seconds - elapsed_seconds) / 60))\n",
        "    print(f\"⏱️ [{username}] Gravados: {minutos_gravados} min | Restantes: {minutos_restantes} min | Tempo total: {tempo} — 📊 {percent:.1f}% concluído\")\n",
        "\n",
        "# ============================\n",
        "# UTILITÁRIO PARA DOWNLOAD DE POSTER\n",
        "# ============================\n",
        "\n",
        "def download_and_save_poster(poster_url, username, temp_folder):\n",
        "    \"\"\"\n",
        "    Baixa e salva o poster (thumbnail) a partir de uma URL HTTP/HTTPS.\n",
        "    Se for um caminho local existente, retorna esse caminho.\n",
        "    Retorna o caminho do arquivo salvo, ou None em caso de erro.\n",
        "    \"\"\"\n",
        "    # Se for um caminho local válido, retorna diretamente\n",
        "    if os.path.exists(poster_url):\n",
        "        return poster_url\n",
        "    # Download de URL HTTP/HTTPS\n",
        "    if isinstance(poster_url, str) and (poster_url.startswith(\"http://\") or poster_url.startswith(\"https://\")):\n",
        "        try:\n",
        "            response = requests.get(poster_url, timeout=15)\n",
        "            response.raise_for_status()\n",
        "            ext = os.path.splitext(poster_url)[1].lower()\n",
        "            if ext not in [\".jpg\", \".jpeg\", \".png\"]:\n",
        "                ext = \".jpg\"\n",
        "            poster_temp_path = os.path.join(temp_folder, f\"{username}_poster_temp{ext}\")\n",
        "            with open(poster_temp_path, \"wb\") as f:\n",
        "                f.write(response.content)\n",
        "            print(f\"🖼️ Poster baixado em: {poster_temp_path}\")\n",
        "            return poster_temp_path\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Erro ao baixar poster {poster_url}: {e}\")\n",
        "            return None\n",
        "    else:\n",
        "        print(f\"❌ poster_url inválido ou não encontrado: {poster_url}\")\n",
        "        return None\n",
        "\n",
        "# ============================\n",
        "# UTILITÁRIO PARA GERAR POSTER COM FFMPEG (com fallback e log central)\n",
        "# ============================\n",
        "\n",
        "def generate_poster_with_ffmpeg(m3u8_url, username, temp_folder, tries=(3, 1, 7, 15, 30), timeout=30):\n",
        "    \"\"\"\n",
        "    Gera um poster (screenshot) usando ffmpeg a partir da URL .m3u8 da transmissão.\n",
        "    Tenta múltiplos pontos no vídeo caso haja erro (robustez).\n",
        "    Integra ao log centralizado via append_log em caso de falha.\n",
        "    Retorna o caminho do arquivo gerado ou None em caso de erro.\n",
        "    \"\"\"\n",
        "    from IPython.display import clear_output\n",
        "    import requests # Garantir requests está importado aqui\n",
        "\n",
        "    # --- Checa se a URL está acessível antes de rodar ffmpeg ---\n",
        "    try:\n",
        "        # Usar um timeout curto para a checagem inicial\n",
        "        head_resp = requests.head(m3u8_url, timeout=5)\n",
        "        if not head_resp.ok:\n",
        "            msg = f\"Stream offline ou não disponível para {username} (status {head_resp.status_code})\"\n",
        "            print(f\"⚠️ {msg}\")\n",
        "            # Registrar falha de conexão no log central\n",
        "            if \"register_failure\" in globals():\n",
        "                 register_failure(username, msg)\n",
        "            return None # Retorna None imediatamente se a stream não estiver acessível\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        msg = f\"Erro de conexão ao acessar stream de {username}: {e}\"\n",
        "        print(f\"❌ {msg}\")\n",
        "        # Registrar falha de conexão no log central\n",
        "        if \"register_failure\" in globals():\n",
        "             register_failure(username, msg)\n",
        "        return None # Retorna None imediatamente em caso de erro de conexão\n",
        "    except Exception as e:\n",
        "        msg = f\"Erro inesperado na checagem de stream para {username}: {e}\"\n",
        "        print(f\"❌ {msg}\")\n",
        "        # Registrar falha genérica na checagem\n",
        "        if \"register_failure\" in globals():\n",
        "             register_failure(username, msg)\n",
        "        return None # Retorna None em caso de qualquer outra exceção na checagem\n",
        "\n",
        "\n",
        "    # --- Tenta gerar poster com ffmpeg (se a checagem inicial passou) ---\n",
        "    for frame_time in tries:\n",
        "        poster_ffmpeg_path = os.path.join(temp_folder, f\"{username}_poster_ffmpeg_{frame_time}.jpg\")\n",
        "        command = [\n",
        "            \"ffmpeg\",\n",
        "            \"-y\",\n",
        "            \"-analyzeduration\", \"10M\",\n",
        "            \"-probesize\", \"50M\",\n",
        "            \"-ss\", str(frame_time),\n",
        "            \"-i\", m3u8_url,\n",
        "            \"-vframes\", \"1\",\n",
        "            \"-q:v\", \"2\",\n",
        "            poster_ffmpeg_path\n",
        "        ]\n",
        "        try:\n",
        "            print(f\"🎬 Tentando gerar poster para {username} com ffmpeg no segundo {frame_time}...\")\n",
        "            result = subprocess.run(\n",
        "                command,\n",
        "                stdout=subprocess.PIPE,\n",
        "                stderr=subprocess.PIPE,\n",
        "                timeout=timeout\n",
        "            )\n",
        "            if result.returncode == 0 and os.path.exists(poster_ffmpeg_path) and os.path.getsize(poster_ffmpeg_path) > 0:\n",
        "                print(f\"🖼️ Poster gerado via ffmpeg: {poster_ffmpeg_path}\")\n",
        "                # Limpa falhas relacionadas a poster/ffmpeg se a geração for bem-sucedida\n",
        "                if \"clear_failure\" in globals():\n",
        "                    clear_failure(username)\n",
        "                return poster_ffmpeg_path\n",
        "            else:\n",
        "                msg = f\"ffmpeg não conseguiu gerar poster para {username} no segundo {frame_time}. Código: {result.returncode}\"\n",
        "                print(f\"❌ {msg}\\nSTDOUT:\\n{result.stdout.decode(errors='ignore')}\\nSTDERR:\\n{result.stderr.decode(errors='ignore')}\")\n",
        "                # Registrar falha específica de ffmpeg no log central\n",
        "                if \"append_log\" in globals():\n",
        "                    append_log({\n",
        "                        \"sessao\": \"poster\",\n",
        "                        \"evento\": \"erro_ffmpeg_frame\",\n",
        "                        \"id\": username,\n",
        "                        \"username\": username,\n",
        "                        \"status\": \"erro\",\n",
        "                        \"detalhes\": f\"{msg} | stdout: {result.stdout.decode(errors='ignore')[:200]} | stderr: {result.stderr.decode(errors='ignore')[:200]}\"\n",
        "                    })\n",
        "\n",
        "        except subprocess.TimeoutExpired:\n",
        "            msg = f\"Tempo excedido ao tentar gerar poster para {username} via ffmpeg (segundo {frame_time}).\"\n",
        "            print(f\"⏰ {msg}\")\n",
        "            # Registrar timeout de ffmpeg no log central\n",
        "            if \"append_log\" in globals():\n",
        "                append_log({\n",
        "                    \"sessao\": \"poster\",\n",
        "                    \"evento\": \"timeout_ffmpeg\",\n",
        "                    \"id\": username,\n",
        "                    \"username\": username,\n",
        "                    \"status\": \"erro\",\n",
        "                    \"detalhes\": msg\n",
        "                })\n",
        "        except Exception as e:\n",
        "            msg = f\"Erro inesperado ao rodar ffmpeg para poster ({username}, segundo {frame_time}): {e}\"\n",
        "            print(f\"❌ {msg}\")\n",
        "            # Registrar exceção de ffmpeg no log central\n",
        "            if \"append_log\" in globals():\n",
        "                append_log({\n",
        "                    \"sessao\": \"poster\",\n",
        "                    \"evento\": \"excecao_ffmpeg\",\n",
        "                    \"id\": username,\n",
        "                    \"username\": username,\n",
        "                    \"status\": \"erro\",\n",
        "                    \"detalhes\": msg\n",
        "                })\n",
        "\n",
        "\n",
        "    # --- Fallback: gera um poster placeholder se todas as tentativas falharem ---\n",
        "    placeholder_path = os.path.join(temp_folder, f\"{username}_placeholder.jpg\")\n",
        "    try:\n",
        "        from PIL import Image, ImageDraw\n",
        "        img = Image.new('RGB', (640, 360), color=(80, 80, 80))\n",
        "        d = ImageDraw.Draw(img)\n",
        "        d.text((10, 150), f\"Poster indisponível\\n{username}\", fill=(255, 255, 255))\n",
        "        img.save(placeholder_path)\n",
        "        print(f\"⚠️ Poster placeholder gerado para {username}: {placeholder_path}\")\n",
        "        # Registrar geração de placeholder no log central\n",
        "        if \"append_log\" in globals():\n",
        "             append_log({\n",
        "                 \"sessao\": \"poster\",\n",
        "                 \"evento\": \"placeholder_gerado\",\n",
        "                 \"id\": username,\n",
        "                 \"username\": username,\n",
        "                 \"status\": \"aviso\",\n",
        "                 \"detalhes\": f\"Poster placeholder gerado após falha no ffmpeg.\"\n",
        "             })\n",
        "        return placeholder_path\n",
        "    except Exception as e:\n",
        "        msg = f\"Erro ao gerar placeholder para {username}: {e}\"\n",
        "        print(f\"❌ {msg}\")\n",
        "        # Registrar falha na geração de placeholder no log central\n",
        "        if \"append_log\" in globals():\n",
        "             append_log({\n",
        "                 \"sessao\": \"poster\",\n",
        "                 \"evento\": \"erro_placeholder\",\n",
        "                 \"id\": username,\n",
        "                 \"username\": username,\n",
        "                 \"status\": \"erro\",\n",
        "                 \"detalhes\": msg\n",
        "             })\n",
        "        return None\n",
        "\n",
        "# ============================\n",
        "# VALIDAÇÃO DE POSTER\n",
        "# ============================\n",
        "\n",
        "def is_poster_valid(poster_path):\n",
        "    \"\"\"\n",
        "    Verifica se o poster existe e não está vazio.\n",
        "    \"\"\"\n",
        "    return poster_path and os.path.exists(poster_path) and os.path.getsize(poster_path) > 0\n",
        "\n",
        "# ============================\n",
        "# FIM DA CÉLULA 3\n",
        "# ============================\n",
        "\n",
        "# Observações:\n",
        "# - Todas as funções de logging, blacklist, falha e auditoria devem ser feitas via utilitário de log centralizado (Célula 1).\n",
        "# - LOG_PROCESSAMENTO_PATH, BLACKLIST_PATH, FAILURE_LOG_PATH e outros logs dispersos não devem mais ser usados.\n",
        "# - O pipeline está pronto para Clean Architecture, máxima rastreabilidade e integração.\n",
        "# - Funções aqui são modulares, reusáveis e preparadas para tratamento de exceções e logging detalhado."
      ],
      "metadata": {
        "id": "hOetz0nGICkz"
      },
      "id": "hOetz0nGICkz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Célula 4: Clonagem do Repositório GitHub no Colab e Google Drive\n",
        "\n",
        "**Objetivo:**  \n",
        "Esta célula tem como finalidade garantir que o repositório do projeto XCam esteja sempre disponível, atualizado e sincronizado para uso tanto no ambiente temporário do Google Colab quanto, se disponível, de forma persistente no Google Drive.  \n",
        "A célula prepara todo o ambiente para gravação, processamento, versionamento de código e integrações externas, promovendo reprodutibilidade, rastreabilidade e facilidade de manutenção em todo o pipeline.\n",
        "\n",
        "---\n",
        "\n",
        "## Descrição detalhada das etapas e funcionalidades\n",
        "\n",
        "- **Configuração dos dados do repositório GitHub:**  \n",
        "  Define as variáveis globais de usuário, nome do repositório, branch e token pessoal de acesso para autenticação e operações seguras de clone e push.\n",
        "- **Geração automática da URL autenticada:**  \n",
        "  Monta dinamicamente a URL de acesso ao repositório já com autenticação embutida, garantindo que operações automatizadas (clone/push) funcionem mesmo em ambientes CI/CD ou sessões reiniciadas.\n",
        "- **Clonagem limpa para o ambiente Colab:**  \n",
        "  Antes de clonar, remove qualquer vestígio do repositório anterior no diretório `/content`. Isso evita conflitos de arquivos, branches corrompidos e resíduos de execuções antigas, criando um ambiente limpo para cada nova execução.\n",
        "- **Preparação e criação de diretórios temporários de gravação:**  \n",
        "  Cria automaticamente a pasta `/content/temp_recordings` para armazenar gravações temporárias, garantindo que o pipeline não falhe por falta de estrutura de diretórios.\n",
        "- **Duplicação persistente no Google Drive:**  \n",
        "  Se o Drive estiver montado, remove o repositório antigo do Drive e executa o clone atualizado para `/content/drive/MyDrive/XCam.Drive/XCam`. Isso garante persistência dos arquivos entre sessões e protege dados relevantes de reinicializações do ambiente Colab.\n",
        "- **Mensagens informativas e feedback visual:**  \n",
        "  O usuário é informado em cada etapa do processo por mensagens claras, incluindo alertas caso o Drive não esteja montado, sucesso na clonagem e nos preparos de diretórios, e possíveis erros de autenticação ou permissão.\n",
        "- **Configuração de endpoint para integrações externas:**  \n",
        "  Define e exporta a variável `ABYSS_UPLOAD_URL`, já pronta para integrações futuras com serviços de upload ou armazenamento externo, como o Abyss.\n",
        "- **Exportação de todas as variáveis de ambiente:**  \n",
        "  Por meio do `globals().update()`, todas as configurações (paths, URLs, tokens, pastas) são exportadas para uso global e consistente em qualquer célula do notebook, promovendo reuso e evitando duplicidade de código.\n",
        "\n",
        "---\n",
        "\n",
        "## Parâmetros globais definidos e exportados\n",
        "\n",
        "- **`GITHUB_USER`**, **`GITHUB_REPO`**, **`GITHUB_BRANCH`**, **`GITHUB_TOKEN`**: Dados do repositório GitHub e autenticação.\n",
        "- **`repo_url`**: URL autenticada para operações Git automatizadas.\n",
        "- **`TEMP_OUTPUT_FOLDER`**: Pasta temporária para gravações no ambiente Colab.\n",
        "- **`BASE_REPO_FOLDER`**: Caminho do repositório clonado no ambiente Colab.\n",
        "- **`DRIVE_MOUNT`**, **`DRIVE_REPO_FOLDER`**: Caminhos no Google Drive para persistência dos dados e do repositório.\n",
        "- **`ABYSS_UPLOAD_URL`**: Endpoint de integração externa para uploads ou automações.\n",
        "\n",
        "---\n",
        "\n",
        "## Funcionamento passo a passo\n",
        "\n",
        "1. **Limpa o ambiente:**  \n",
        "   Remove o repositório antigo e diretórios temporários do Colab e, se disponível, do Google Drive. Isso evita conflitos, arquivos órfãos e histórico inconsistente.\n",
        "2. **Clona o repositório para o ambiente temporário:**  \n",
        "   Realiza o clone autenticado do repositório XCam para `/content`, permitindo edição, execução e versionamento imediato do código.\n",
        "3. **Cria a estrutura de diretórios temporários:**  \n",
        "   Garante que a pasta de gravações temporárias esteja sempre pronta para uso (evita erros de \"diretório não encontrado\").\n",
        "4. **Clona o repositório para o Drive (persistência):**  \n",
        "   Se o Drive estiver disponível, executa o clone também para o diretório persistente. Isso permite que dados e código sobrevivam a reinicializações ou resets do ambiente Colab.\n",
        "5. **Define endpoints e exporta variáveis globais:**  \n",
        "   Torna todos os parâmetros relevantes disponíveis para qualquer célula do notebook, facilitando integrações, uploads e futuras automações.\n",
        "\n",
        "---\n",
        "\n",
        "## Exemplos práticos de uso das variáveis exportadas\n",
        "\n",
        "```python\n",
        "print(BASE_REPO_FOLDER)        # Exibe o caminho do repositório clonado no Colab\n",
        "print(DRIVE_REPO_FOLDER)       # Exibe o caminho do repositório persistente no Drive (se montado)\n",
        "print(TEMP_OUTPUT_FOLDER)      # Exibe a pasta temporária destinada a gravações\n",
        "print(ABYSS_UPLOAD_URL)        # Exibe a URL de upload para integrações externas (Abyss, etc)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Segurança, rastreabilidade e boas práticas\n",
        "\n",
        "- **Ambiente 100% previsível:** Cada execução parte de um estado limpo, evitando bugs difíceis de rastrear e facilitando o debug.\n",
        "- **Persistência e backup automático:** A duplicação do repositório e dados no Drive protege contra perdas acidentais e facilita colaboração entre membros do time.\n",
        "- **Pronto para automações e CI/CD:** O uso de token, URL autenticada e exportação de variáveis prepara o notebook para automações, integrações com pipelines externos, deploys e uploads automáticos.\n",
        "- **Comentário e organização didática:** Cada bloco e etapa é documentada, tornando a célula autoexplicativa para manutenção, auditoria e treinamento de novos membros.\n",
        "\n",
        "---\n",
        "\n",
        "## Recomendações de uso\n",
        "\n",
        "- **Execute esta célula sempre que iniciar uma nova sessão, trocar de branch, atualizar token ou preparar ambiente para gravação/execução.**\n",
        "- **Garanta que o Google Drive esteja montado antes de rodar a célula, caso deseje persistência de dados e backup automático.**\n",
        "- **Utilize as variáveis globais exportadas para padronizar caminhos, URLs e integrações em qualquer etapa do pipeline.**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "hpRIMtyFIY0q"
      },
      "id": "hpRIMtyFIY0q"
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================\n",
        "# Célula 4: Clonagem do Repositório GitHub no Colab e no Google Drive\n",
        "# ================================================================\n",
        "# Objetivo:\n",
        "# - Garantir ambiente limpo e sincronizado para o repositório XCam em todas as execuções\n",
        "# - Clonar o repositório tanto para o ambiente efêmero do Colab quanto para o Google Drive (persistência)\n",
        "# - Preparar diretórios de trabalho para gravações e processamento temporário\n",
        "# - Fornecer feedback claro sobre o status da operação\n",
        "#\n",
        "# Estratégia aplicada:\n",
        "# - Remove repositórios antigos antes de clonar (evita conflitos e arquivos órfãos)\n",
        "# - Utiliza token pessoal para autenticação segura e push futuro (CI/CD)\n",
        "# - Cria estrutura de diretórios padronizada (módulos, gravações, cache, etc.)\n",
        "# - Valida se o Drive está montado antes de tentar operações persistentes\n",
        "# - Comentários detalhados para fácil manutenção e evolução\n",
        "# ================================================================\n",
        "\n",
        "# ============================\n",
        "# CONFIGURAÇÕES DO GITHUB\n",
        "# ============================\n",
        "GITHUB_USER = \"SamuelPassamani\"\n",
        "GITHUB_REPO = \"XCam\"\n",
        "GITHUB_BRANCH = \"main\"\n",
        "GITHUB_TOKEN = \"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\"\n",
        "\n",
        "repo_url = f\"https://{GITHUB_USER}:{GITHUB_TOKEN}@github.com/{GITHUB_USER}/{GITHUB_REPO}.git\"\n",
        "\n",
        "# ============================\n",
        "# CLONAGEM PARA O COLAB\n",
        "# ============================\n",
        "print(f\"⏳ Limpando ambiente e clonando '{GITHUB_REPO}' para o Colab...\")\n",
        "!rm -rf {GITHUB_REPO}\n",
        "!git clone -b {GITHUB_BRANCH} {repo_url}\n",
        "print(f\"✅ Repositório clonado em /content/{GITHUB_REPO}\")\n",
        "\n",
        "# ============================\n",
        "# ESTRUTURA DE DIRETÓRIOS TEMPORÁRIOS\n",
        "# ============================\n",
        "TEMP_OUTPUT_FOLDER = \"/content/temp_recordings\"  # Para gravações temporárias\n",
        "os.makedirs(TEMP_OUTPUT_FOLDER, exist_ok=True)\n",
        "BASE_REPO_FOLDER = f\"/content/{GITHUB_REPO}\"\n",
        "\n",
        "# ============================\n",
        "# CLONAGEM PARA O GOOGLE DRIVE (PERSISTÊNCIA)\n",
        "# ============================\n",
        "DRIVE_MOUNT = \"/content/drive/MyDrive/XCam.Drive\"\n",
        "DRIVE_REPO_FOLDER = f\"{DRIVE_MOUNT}/{GITHUB_REPO}\"\n",
        "\n",
        "if os.path.exists(DRIVE_MOUNT):\n",
        "    print(f\"⏳ Limpando repositório antigo no Drive (se existir)...\")\n",
        "    !rm -rf \"{DRIVE_REPO_FOLDER}\"\n",
        "    print(f\"⏳ Clonando '{GITHUB_REPO}' para o Drive em {DRIVE_REPO_FOLDER} ...\")\n",
        "    !git clone -b {GITHUB_BRANCH} {repo_url} \"{DRIVE_REPO_FOLDER}\"\n",
        "    print(f\"✅ Repositório também clonado no Drive: {DRIVE_REPO_FOLDER}\")\n",
        "else:\n",
        "    print(f\"⚠️ Google Drive não está montado em {DRIVE_MOUNT}.\\nℹ️ Use a célula de montagem antes de prosseguir para garantir persistência.\")\n",
        "\n",
        "# ============================\n",
        "# CONFIGURAÇÃO DE ENDPOINTS DE UPLOAD/INTEGRAÇÃO\n",
        "# ============================\n",
        "ABYSS_UPLOAD_URL = 'http://up.hydrax.net/0128263f78f0b426d617bb61c2a8ff43'\n",
        "globals().update({\n",
        "    'GITHUB_USER': GITHUB_USER,\n",
        "    'GITHUB_REPO': GITHUB_REPO,\n",
        "    'GITHUB_BRANCH': GITHUB_BRANCH,\n",
        "    'GITHUB_TOKEN': GITHUB_TOKEN,\n",
        "    'repo_url': repo_url,\n",
        "    'TEMP_OUTPUT_FOLDER': TEMP_OUTPUT_FOLDER,\n",
        "    'BASE_REPO_FOLDER': BASE_REPO_FOLDER,\n",
        "    'DRIVE_MOUNT': DRIVE_MOUNT,\n",
        "    'DRIVE_REPO_FOLDER': DRIVE_REPO_FOLDER,\n",
        "    'ABYSS_UPLOAD_URL': ABYSS_UPLOAD_URL\n",
        "})\n",
        "\n",
        "# ============================\n",
        "# FIM DA CÉLULA 4\n",
        "# ============================\n",
        "\n",
        "# Observações:\n",
        "# - Os caminhos globais são exportados via globals().update() para uso em todo o notebook.\n",
        "# - Recomenda-se sempre rodar esta célula após alterar tokens ou trocar branches para garantir ambiente limpo e sincronizado.\n",
        "# - O endpoint ABYSS_UPLOAD_URL pode ser atualizado conforme integrações futuras."
      ],
      "metadata": {
        "id": "Uof_0QCrIlf7"
      },
      "id": "Uof_0QCrIlf7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Célula 5: Commit e Push Automáticos (rec.json, posters, etc.)\n",
        "\n",
        "**Objetivo:**  \n",
        "Automatizar o processo de versionamento e sincronização dos arquivos modificados no pipeline XCam, como `rec.json`, imagens de poster e demais artefatos, realizando commit e push seguros e auditáveis para o repositório GitHub.  \n",
        "Esta célula garante que as alterações sejam rastreadas, publicadas e disponíveis para todo o time, promovendo integração contínua (CI/CD) e minimizando riscos de perda ou inconsistência de dados.\n",
        "\n",
        "---\n",
        "\n",
        "## Descrição técnica e recursos implementados\n",
        "\n",
        "- **Função modular e robusta para commit e push:**  \n",
        "  Estrutura pronta para aceitar tanto um caminho de arquivo único (string) quanto uma lista de arquivos (batch), permitindo estratégias flexíveis de commit, seja por evento ou em lote (threshold/batch commit).\n",
        "- **Validação rigorosa do ambiente e dos arquivos:**  \n",
        "  Antes do commit, valida a existência do repositório local (`repo_dir`) e verifica a existência de cada arquivo listado. Arquivos inexistentes são ignorados com aviso explícito, evitando falhas desnecessárias e facilitando troubleshooting.\n",
        "- **Configuração automatizada do usuário do Git:**  \n",
        "  Define usuário e e-mail padrão para os commits, garantindo rastreabilidade e conformidade com políticas de auditoria e automação (essencial para ambientes CI/CD).\n",
        "- **Suporte a commit vazio (`--allow-empty`):**  \n",
        "  Permite commits mesmo sem alterações detectadas, assegurando que etapas do pipeline não sejam interrompidas por ausência de mudanças (importante para sincronizações automáticas e pipelines que dependem de triggers de commit).\n",
        "- **Push autenticado via token pessoal:**  \n",
        "  Utiliza o token do GitHub definido em variáveis globais para push seguro, sem necessidade de intervenção manual, pronto para uso em automações, jobs e ambientes colaborativos.\n",
        "- **Mensagens detalhadas e tratamento de erros:**  \n",
        "  Todo o processo é acompanhado por mensagens claras sobre sucesso, falha ou condição especial (como arquivo ausente), facilitando rastreabilidade, auditoria e manutenção.\n",
        "- **Design extensível para integração com logs e automação:**  \n",
        "  A função está pronta para ser conectada ao log centralizado do notebook (Célula 1), garantindo rastreabilidade total de cada operação de commit/push e facilitando integração com webhooks, jobs ou triggers externos.\n",
        "\n",
        "---\n",
        "\n",
        "## Parâmetros e variáveis globais utilizados\n",
        "\n",
        "- **`GITHUB_USER`**, **`GITHUB_REPO`**, **`GITHUB_TOKEN`**: Variáveis globais para autenticação e configuração, definidas nas etapas iniciais do notebook.\n",
        "- **`repo_dir`**: Caminho absoluto do repositório clonado no ambiente Colab, utilizado como diretório de trabalho para comandos git.\n",
        "- **`file_paths`**: String (arquivo único) ou lista de strings (múltiplos arquivos), indicando os arquivos a serem commitados e enviados.\n",
        "- **`commit_message`**: Mensagem de commit, customizável conforme a operação realizada para maximizar a clareza e o histórico de versionamento.\n",
        "\n",
        "---\n",
        "\n",
        "## Fluxo operacional detalhado\n",
        "\n",
        "1. **Validação do repositório local:**  \n",
        "   Confirma que o diretório do repositório clonado está disponível no ambiente. Caso contrário, aborta a operação com mensagem de erro explícita.\n",
        "2. **Preparação dos arquivos para commit:**  \n",
        "   Aceita tanto arquivo único quanto lista. Apenas arquivos que realmente existem são adicionados ao staging, com logs de aviso para ausentes.\n",
        "3. **Configuração do usuário e e-mail do git:**  \n",
        "   Garante autoria rastreável e compatível com pipelines automáticos, configurando user/email antes do commit.\n",
        "4. **Execução do commit (`--allow-empty`):**  \n",
        "   Realiza o commit das alterações, permitindo commits vazios para garantir continuidade do pipeline quando necessário.\n",
        "5. **Push autenticado para o repositório remoto:**  \n",
        "   Usa a URL autenticada via token para enviar as alterações ao repositório GitHub, tornando-as imediatamente disponíveis para o time e sistemas integrados.\n",
        "6. **Mensagens e tratamento de falhas:**  \n",
        "   Todo erro ou condição especial (ex: arquivo não encontrado) é logado e apresentado ao usuário, facilitando o diagnóstico e a evolução do pipeline.\n",
        "\n",
        "---\n",
        "\n",
        "## Exemplo de uso técnico\n",
        "\n",
        "```python\n",
        "# Commit e push de um único arquivo modificado\n",
        "git_commit_and_push(\"data/rec.json\", \"Atualiza rec.json de gravação\")\n",
        "\n",
        "# Commit e push em lote de múltiplos arquivos (ex. posters atualizados)\n",
        "git_commit_and_push([\n",
        "    \"data/rec.json\",\n",
        "    \"posters/user1_poster.jpg\",\n",
        "    \"posters/user2_poster.jpg\"\n",
        "], \"Batch commit de múltiplos arquivos\")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Segurança, rastreabilidade e integração contínua\n",
        "\n",
        "- **Total rastreabilidade:** Mensagens de commit claras e integração recomendada com o log centralizado garantem histórico completo e auditável de todas as operações.\n",
        "- **Atomicidade:** Commits em lote evitam inconsistências, garantindo que conjuntos de arquivos relacionados sejam versionados juntos.\n",
        "- **Pronto para CI/CD:** Design compatível com automações, pipelines, webhooks e integrações externas, minimizando intervenção manual e acelerando entregas.\n",
        "- **Diagnóstico facilitado:** Tratamento de falhas e mensagens detalhadas reduzem tempo de troubleshooting e aumentam a confiabilidade do processo.\n",
        "\n",
        "---\n",
        "\n",
        "## Observações e práticas recomendadas\n",
        "\n",
        "- **A lógica de commit/push foi movida para script externo:**  \n",
        "  Esta célula serve como referência e documentação da estratégia recomendada. Certifique-se de que seu script externo implementa as validações, mensagens e práticas aqui descritas.\n",
        "- **Monitore os logs do seu script externo** para garantir que todas as operações sejam executadas corretamente e sem perdas.\n",
        "- **Mantenha variáveis globais atualizadas** (token, caminhos, etc) para evitar falhas de autenticação ou inconsistências de ambiente.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "M5iL_9BoIoj7"
      },
      "id": "M5iL_9BoIoj7"
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================\n",
        "# Célula 5: Commit e Push Automáticos (rec.json, posters, etc.)\n",
        "# ================================================================\n",
        "# Objetivo:\n",
        "# - Automatizar o processo de commit e push dos arquivos modificados (rec.json, posters, etc.) para o repositório GitHub\n",
        "# - Suportar tanto commit de arquivo único como em lote, permitindo estratégia de batch commit baseada em thresholds\n",
        "# - Garantir rastreabilidade, atomicidade e integração segura (CI/CD)\n",
        "#\n",
        "# Estratégia aplicada:\n",
        "# - Função modular e robusta, preparada para integração com logs e auditoria\n",
        "# - Permite commit vazio por segurança, evitando falhas em pipelines sincronizados\n",
        "# - Mensagens e tratamento de erros detalhados para facilitar troubleshooting\n",
        "# - Utilização de variáveis globais para caminhos, usuário e token definidos nas células anteriores\n",
        "# - Design pronto para evolução, reuso e integração com ferramentas externas (ex: webhooks, jobs, etc.)\n",
        "# ================================================================\n",
        "\n",
        "# A lógica de commit e push agora é gerenciada por um script externo.\n",
        "# Esta célula foi mantida para referência, mas a função git_commit_and_push\n",
        "# foi removida pois não será mais executada internamente.\n",
        "\n",
        "# def git_commit_and_push(file_paths, commit_message=\"Atualiza rec.json\"):\n",
        "#     \"\"\"\n",
        "#     Realiza git add, commit e push dos arquivos especificados.\n",
        "#     - file_paths pode ser uma string (arquivo único) ou uma lista de arquivos.\n",
        "#     - commit_message é a mensagem de commit utilizada.\n",
        "\n",
        "#     Estratégia:\n",
        "#     - Ajusta diretório para o repositório local clonado no Colab\n",
        "#     - Configura usuário e e-mail do git (necessários para CI/CD)\n",
        "#     - Adiciona arquivos ao staging (aceita múltiplos arquivos)\n",
        "#     - Realiza commit (permite commit vazio)\n",
        "#     - Realiza push autenticado via token\n",
        "#     \"\"\"\n",
        "#     # ============================\n",
        "#     # VALIDAÇÃO E AJUSTE DE ENTRADAS\n",
        "#     # ============================\n",
        "#     repo_dir = f\"/content/{GITHUB_REPO}\"\n",
        "#     if not os.path.exists(repo_dir):\n",
        "#         raise FileNotFoundError(f\"Repositório '{repo_dir}' não encontrado. Verifique se a célula de clonagem foi executada.\")\n",
        "#     os.chdir(repo_dir)\n",
        "\n",
        "#     # Aceita string ou lista de arquivos\n",
        "#     if isinstance(file_paths, str):\n",
        "#         file_paths = [file_paths]\n",
        "#     elif not isinstance(file_paths, list):\n",
        "#         raise ValueError(\"file_paths deve ser uma string ou uma lista de caminhos.\")\n",
        "\n",
        "#     # ============================\n",
        "#     # CONFIGURAÇÃO DO USUÁRIO GIT (CI/CD)\n",
        "#     # ============================\n",
        "#     subprocess.run([\"git\", \"config\", \"user.email\", \"contato@aserio.work\"], check=True)\n",
        "#     subprocess.run([\"git\", \"config\", \"user.name\", \"SamuelPassamani\"], check=True)\n",
        "\n",
        "#     # ============================\n",
        "#     # ADIÇÃO DOS ARQUIVOS AO STAGING\n",
        "#     # ============================\n",
        "#     for file_path in file_paths:\n",
        "#         # Verifica se o arquivo existe antes de adicionar\n",
        "#         if not os.path.exists(file_path):\n",
        "#             print(f\"⚠️ Aviso: arquivo '{file_path}' não existe e será ignorado no commit.\")\n",
        "#             continue\n",
        "#         subprocess.run([\"git\", \"add\", file_path], check=True)\n",
        "\n",
        "#     # ============================\n",
        "#     # COMMIT (PERMITE COMMIT VAZIO)\n",
        "#     # ============================\n",
        "#     try:\n",
        "#         subprocess.run(\n",
        "#             [\"git\", \"commit\", \"-m\", commit_message, \"--allow-empty\"],\n",
        "#             check=False  # Não força erro se não houver mudanças\n",
        "#         )\n",
        "#     except Exception as e:\n",
        "#         print(f\"❌ Erro ao tentar realizar commit: {e}\")\n",
        "\n",
        "#     # ============================\n",
        "#     # PUSH PARA O REPOSITÓRIO REMOTO (AUTENTICADO)\n",
        "#     # ============================\n",
        "#     try:\n",
        "#         remote_url = f\"https://{GITHUB_USER}:{GITHUB_TOKEN}@github.com/{GITHUB_USER}/{GITHUB_REPO}.git\"\n",
        "#         subprocess.run(\n",
        "#             [\"git\", \"push\", remote_url],\n",
        "#             check=True\n",
        "#         )\n",
        "#         print(f\"✅ Push realizado com sucesso! ({commit_message})\")\n",
        "#     except Exception as e:\n",
        "#         print(f\"❌ Erro ao tentar realizar push: {e}\")\n",
        "\n",
        "# ============================\n",
        "# FIM DA CÉLULA 5\n",
        "# ============================\n",
        "\n",
        "# Dicas e melhores práticas:\n",
        "# - A lógica de commit e push agora é gerenciada por um script externo.\n",
        "# - Certifique-se de que seu script externo gerencie corretamente o commit e push\n",
        "#   dos arquivos alterados (como o rec.json e os posters).\n",
        "# - Monitore os logs do seu script externo para verificar o status dos commits e pushes."
      ],
      "metadata": {
        "id": "1aQn1G6yI6Gz"
      },
      "id": "1aQn1G6yI6Gz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Célula 6: Busca de Transmissões na API XCam com Blacklist, Controle de Falhas e Processamento Centralizados por ID — Log Único\n",
        "\n",
        "**Objetivo:**  \n",
        "Automatizar a busca e seleção de transmissões ao vivo na API da XCam utilizando um sistema centralizado de controle de blacklist temporária, falhas e marcação de processamento, todos operando exclusivamente via log único (`xcam_master.log`) e com base no identificador único (`id`) da API.  \n",
        "Garante máxima rastreabilidade, elimina arquivos dispersos, permite fallback inteligente via `/liveInfo`, e assegura a presença de poster válido para cada transmissão.\n",
        "\n",
        "---\n",
        "\n",
        "## Estratégia, arquitetura e diferenciais técnicos\n",
        "\n",
        "- **Controle total por ID:**  \n",
        "  Todas as operações de blacklist, contagem de falhas e marcação de processamento (início/fim) são indexadas pelo `id` único do usuário retornado pela API XCam, eliminando ambiguidade e aumentando a precisão no ciclo de vida de cada transmissão.\n",
        "- **Log único e centralizado:**  \n",
        "  Toda consulta e alteração de estado (blacklist, falha, processamento, auditoria) é feita via funções utilitárias do log centralizado — `append_log`, `query_logs`, `remove_logs` — eliminando completamente o uso de arquivos dispersos, facilitando CI/CD, rastreabilidade e manutenção.\n",
        "- **Blacklist e falhas temporárias com expiração automática:**  \n",
        "  Usuários são bloqueados temporariamente ao atingir o limite de falhas (`BLACKLIST_MAX_FAILURES`), com expiração e remoção automatizadas das entradas antigas para máxima performance e precisão.\n",
        "- **Fallback automatizado para streams sem src:**  \n",
        "  Se uma transmissão não possui `src` direto na API principal, o sistema utiliza fallback inteligente via endpoint `/liveInfo`, tentando obter o stream e garantir a cobertura máxima do lote.\n",
        "- **Poster sempre garantido:**  \n",
        "  Para cada transmissão, o sistema valida se há poster válido (baixado ou gerado via ffmpeg). Caso contrário, registra falha e pula para o próximo, garantindo consistência visual e integridade para etapas posteriores do pipeline.\n",
        "- **Execução paralela e pronta para automação:**  \n",
        "  Funções desenhadas para suportar execução concorrente, integração com pipelines CI/CD, jobs automatizados e auditoria detalhada de todas as ações por timestamp, id, username e status.\n",
        "- **Design modular e Clean Architecture:**  \n",
        "  Cada bloco funcional é isolado: controle de blacklist, falha, processamento, busca em lote, busca específica e busca unificada, facilitando manutenção, testes e evolução do sistema.\n",
        "\n",
        "---\n",
        "\n",
        "## Descrição técnica das funções principais\n",
        "\n",
        "- **Funções de Blacklist, Falha e Processamento (todas por id):**\n",
        "  - `is_in_blacklist(user_id)`: Verifica se o usuário está bloqueado, expira e remove automaticamente as entradas antigas.\n",
        "  - `add_to_blacklist(user_id, username)`: Adiciona o usuário ao blacklist temporário, registrando evento e detalhes no log.\n",
        "  - `get_failures(user_id)`: Conta falhas recentes e ignora/expira registros antigos.\n",
        "  - `register_failure(user_id, username, details)`: Registra falha, promove a blacklist se atingir o limite, limpa registros após blacklisting.\n",
        "  - `clear_failure(user_id)`: Remove todos os registros de falha do usuário.\n",
        "  - `is_processing(user_id)`: Verifica se o usuário está marcado como “em processamento ativo”.\n",
        "  - `mark_processing(user_id, username)`: Marca transmissão como em processamento no log.\n",
        "  - `unmark_processing(user_id)`: Remove marcação de processamento.\n",
        "- **Busca de transmissões (com fallback e validação de poster):**\n",
        "  - `get_broadcasts(limit, ...)`: Retorna lote de transmissões válidas (com poster), respeitando blacklist, falhas, processamento e evitando duplicidades, com fallback para `/liveInfo` e registro detalhado no log.\n",
        "  - `buscar_usuarios_especificos(usuarios_lista, ...)`: Busca apenas os usuários informados (por username), protegendo por blacklist/falha/processamento e realizando fallback se necessário.\n",
        "  - `buscar_proxima_transmissao_livre(...)`: Busca a próxima transmissão livre e válida, pronta para processamento imediato, com validação completa e integração ao log único.\n",
        "\n",
        "---\n",
        "\n",
        "## Fluxo operacional — passo a passo\n",
        "\n",
        "1. **Consulta à API XCam:**  \n",
        "   Obtém lista de transmissões ativas, extrai `id`, `username`, `src` e poster.\n",
        "2. **Filtragem centralizada:**  \n",
        "   Elimina transmissões já em processamento, blacklist ou com excesso de falhas, sempre via consulta ao log único e pelo `id`.\n",
        "3. **Validação e fallback de poster:**  \n",
        "   Garante que cada transmissão só será considerada se houver poster válido; caso contrário, tenta geração via ffmpeg. Se ainda assim não for possível, registra falha no log e segue para o próximo.\n",
        "4. **Fallback via liveInfo:**  \n",
        "   Para transmissões sem src na API principal, executa fallback via `/liveInfo`, tentando maximizar o preenchimento do lote ou encontrar usuários específicos.\n",
        "5. **Registro e limpeza automáticos:**  \n",
        "   Toda falha, blacklist ou status de processamento é registrada no log, com limpeza automática de entradas expiradas e atualização por evento.\n",
        "\n",
        "---\n",
        "\n",
        "## Exemplos de uso técnico\n",
        "\n",
        "```python\n",
        "# Buscar lote completo de transmissões válidas (com blacklist, falha e poster garantidos)\n",
        "streams = get_broadcasts(limit=LIMIT_DEFAULT)\n",
        "\n",
        "# Buscar apenas usuários específicos (com proteção centralizada e fallback)\n",
        "streams_especificos = buscar_usuarios_especificos([\"user1\", \"user2\"])\n",
        "\n",
        "# Buscar a próxima transmissão livre, pronta para processamento (máxima rastreabilidade)\n",
        "proxima_stream = buscar_proxima_transmissao_livre()\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Segurança, rastreabilidade e manutenção\n",
        "\n",
        "- **Rastreabilidade total:**  \n",
        "  Todos os eventos críticos são registrados no log único, com campos padronizados (`sessao`, `evento`, `id`, `username`, `status`, `detalhes`, `timestamp`).\n",
        "- **Eliminação de arquivos dispersos:**  \n",
        "  Não há mais arquivos auxiliares para blacklist, falha, processamento — tudo é centralizado e padronizado.\n",
        "- **Execução concorrente e CI/CD-ready:**  \n",
        "  Funções preparadas para paralelismo, automação e integração contínua.\n",
        "- **Tratamento de erros robusto:**  \n",
        "  Falhas de API, poster, liveInfo e demais eventos são tratados com exceções, mensagens claras e registro detalhado para auditoria e manutenção.\n",
        "\n",
        "---\n",
        "\n",
        "## Recomendações\n",
        "\n",
        "- Utilize sempre as funções centralizadas para garantir consistência, rastreabilidade e segurança.\n",
        "- Monitore o log único (`xcam_master.log`) para auditoria, troubleshooting e tuning de parâmetros como timeout e thresholds.\n",
        "- Adapte os limites e parâmetros conforme o volume de transmissões, mantendo sempre o controle por `id` e log centralizado.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "BZ4c3Uk1I7AK"
      },
      "id": "BZ4c3Uk1I7AK"
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================\n",
        "# Célula 6: Busca de Transmissões com Blacklist Temporária e Controle de Falhas Centralizados\n",
        "# ================================================================\n",
        "# Objetivo:\n",
        "# - Buscar transmissões ao vivo na API XCam, considerando blacklist e controle de falhas por usuário, ambos centralizados no log único (xcam_master.log)\n",
        "# - Evitar loops infinitos e tentativas repetidas em usuários problemáticos via sessões de blacklist/falha no log único\n",
        "# - Garantir sempre poster válido (via download ou ffmpeg) antes de liberar qualquer transmissão para processamento\n",
        "# - Modularização robusta, integração total com log único, sem leitura/escrita direta em arquivos dispersos\n",
        "# - CAPTURAR E USAR O \"id\" ÚNICO DO USUÁRIO DA API PARA CONTROLE NO LOG\n",
        "#\n",
        "# Estratégia aplicada:\n",
        "# - Toda a lógica de blacklist e falhas opera via funções utilitárias do log centralizado (Célula 1), AGORA USANDO O 'id'\n",
        "# - Sessões do log: \"blacklist\" (usuários banidos temporariamente), \"failure\" (falhas por usuário), \"processing\" (transmissão em processamento)\n",
        "# - Cada evento registrado no log contém: sessao, evento, id (AGORA ID ÚNICO DA API), username, status, detalhes, timestamp\n",
        "# - Não existe mais uso de arquivos como BLACKLIST_PATH, FAILURE_LOG_PATH ou LOG_PROCESSAMENTO_PATH\n",
        "# ================================================================\n",
        "\n",
        "# ============================\n",
        "# FUNÇÕES DE BLACKLIST E FALHAS CENTRALIZADAS NO LOG (AGORA BASEADO EM ID)\n",
        "# ============================\n",
        "\n",
        "# As funções abaixo usarão o 'id' do usuário como chave primária para consultar/manipular o log central.\n",
        "\n",
        "def is_in_blacklist(user_id, now=None):\n",
        "    \"\"\"\n",
        "    Verifica se o usuário (pelo ID) está atualmente na blacklist (sessao='blacklist' e status='blacklisted' e não expirado).\n",
        "    Remove automaticamente entradas expiradas.\n",
        "    \"\"\"\n",
        "    now = now or time.time()\n",
        "    # Busca todos eventos atuais de blacklist desse ID de usuário\n",
        "    entries = query_logs(sessao=\"blacklist\", id=user_id, status=\"blacklisted\")\n",
        "    for entry in entries:\n",
        "        ts_log = entry.get(\"timestamp\")\n",
        "        # timestamp ISO para epoch\n",
        "        try:\n",
        "            ts_epoch = datetime.fromisoformat(ts_log.replace(\"Z\", \"+00:00\")).timestamp() if ts_log else 0\n",
        "        except ValueError: # Tratar possíveis erros de formato ISO\n",
        "            ts_epoch = 0\n",
        "            print(f\"⚠️ Aviso: Formato de timestamp inválido no log para entrada blacklist (id: {user_id}): {ts_log}\")\n",
        "\n",
        "        # Verifica expiração\n",
        "        if now - ts_epoch < BLACKLIST_TIMEOUT:\n",
        "            return True\n",
        "        else:\n",
        "            # Remove entrada expirada (usando id e timestamp para garantir unicidade na remoção)\n",
        "            removed_count = remove_logs(lambda e: e.get(\"sessao\") == \"blacklist\" and e.get(\"id\") == user_id and e.get(\"timestamp\") == ts_log)\n",
        "            # print(f\"ℹ️ Removidas {removed_count} entradas de blacklist expiradas para ID {user_id}\") # O remove_logs já loga\n",
        "    return False\n",
        "\n",
        "def add_to_blacklist(user_id, username):\n",
        "    \"\"\"\n",
        "    Adiciona usuário (pelo ID) à blacklist temporária via log central.\n",
        "    Registra também o username para referência.\n",
        "    \"\"\"\n",
        "    # Primeiro, limpa entradas antigas de blacklist para este ID (garante que só haja uma ativa)\n",
        "    remove_logs(lambda e: e.get(\"sessao\") == \"blacklist\" and e.get(\"id\") == user_id)\n",
        "\n",
        "    entry = {\n",
        "        \"sessao\": \"blacklist\",\n",
        "        \"evento\": \"add_blacklist\",\n",
        "        \"id\": user_id,\n",
        "        \"username\": username, # Mantém username para referência\n",
        "        \"status\": \"blacklisted\",\n",
        "        \"detalhes\": f\"Banido temporariamente por atingir o limite de falhas ({BLACKLIST_MAX_FAILURES})\"\n",
        "    }\n",
        "    append_log(entry)\n",
        "    print(f\"⚠️ Usuário '{username}' (ID: {user_id}) adicionado à blacklist temporária (registrado no log centralizado).\")\n",
        "\n",
        "def get_failures(user_id):\n",
        "    \"\"\"\n",
        "    Conta o número de falhas registradas para o usuário (pelo ID) (sessao='failure' e status='erro' não expiradas).\n",
        "    \"\"\"\n",
        "    # Busca falhas nos últimos BLACKLIST_TIMEOUT segundos (expira junto com blacklist)\n",
        "    now = time.time()\n",
        "    entries = query_logs(sessao=\"failure\", id=user_id, status=\"erro\")\n",
        "    valid_failures = []\n",
        "    for entry in entries:\n",
        "        ts_log = entry.get(\"timestamp\")\n",
        "        try:\n",
        "            ts_epoch = datetime.fromisoformat(ts_log.replace(\"Z\", \"+00:00\")).timestamp() if ts_log else 0\n",
        "        except ValueError: # Tratar possíveis erros de formato ISO\n",
        "            ts_epoch = 0\n",
        "            print(f\"⚠️ Aviso: Formato de timestamp inválido no log para entrada failure (id: {user_id}): {ts_log}\")\n",
        "\n",
        "        if now - ts_epoch < BLACKLIST_TIMEOUT:\n",
        "            valid_failures.append(entry)\n",
        "        else:\n",
        "            # Remove entrada expirada (usando id e timestamp para garantir unicidade na remoção)\n",
        "            removed_count = remove_logs(lambda e: e.get(\"sessao\") == \"failure\" and e.get(\"id\") == user_id and e.get(\"timestamp\") == ts_log)\n",
        "            # print(f\"ℹ️ Removidas {removed_count} entradas de falha expiradas para ID {user_id}\") # O remove_logs já loga\n",
        "    return len(valid_failures)\n",
        "\n",
        "def register_failure(user_id, username, details=\"\"):\n",
        "    \"\"\"\n",
        "    Registra uma falha para o usuário (pelo ID). Move para blacklist se exceder o limite.\n",
        "    Registra também o username para referência.\n",
        "    \"\"\"\n",
        "    # Limpa falhas antigas expiradas antes de adicionar uma nova para este ID\n",
        "    now = time.time()\n",
        "    remove_logs(lambda e: e.get(\"sessao\") == \"failure\" and e.get(\"id\") == user_id and (datetime.fromisoformat(e.get(\"timestamp\",\"\").replace(\"Z\", \"+00:00\")).timestamp() if e.get(\"timestamp\") else 0) < now - BLACKLIST_TIMEOUT)\n",
        "\n",
        "    append_log({\n",
        "        \"sessao\": \"failure\",\n",
        "        \"evento\": \"registrar_falha\",\n",
        "        \"id\": user_id,\n",
        "        \"username\": username, # Mantém username para referência\n",
        "        \"status\": \"erro\",\n",
        "        \"detalhes\": details\n",
        "    })\n",
        "    failures = get_failures(user_id)\n",
        "    print(f\"❌ Falha registrada para '{username}' (ID: {user_id}). Total de falhas recentes: {failures}/{BLACKLIST_MAX_FAILURES}\")\n",
        "\n",
        "    if failures >= BLACKLIST_MAX_FAILURES:\n",
        "        add_to_blacklist(user_id, username)\n",
        "        # Limpa falhas após blacklisting para este ID\n",
        "        remove_logs(lambda e: e.get(\"sessao\") == \"failure\" and e.get(\"id\") == user_id)\n",
        "        print(f\"✅ Falhas limpas para ID {user_id} após blacklisting.\")\n",
        "\n",
        "\n",
        "def clear_failure(user_id):\n",
        "    \"\"\"\n",
        "    Limpa todas as falhas registradas para o usuário (pelo ID).\n",
        "    \"\"\"\n",
        "    removed = remove_logs(lambda e: e.get(\"sessao\") == \"failure\" and e.get(\"id\") == user_id)\n",
        "    if removed > 0:\n",
        "        # Podemos adicionar um log de sucesso de limpeza aqui, se necessário\n",
        "        # append_log({\"sessao\": \"failure\", \"evento\": \"limpar_falhas\", \"id\": user_id, \"status\": \"ok\", \"detalhes\": f\"{removed} falhas limpas\"})\n",
        "        print(f\"✅ {removed} falhas limpas para ID {user_id}.\")\n",
        "    # else:\n",
        "    #     print(f\"ℹ️ Nenhuma falha encontrada para limpar para ID {user_id}.\") # remove_logs já loga se nada foi removido\n",
        "\n",
        "\n",
        "def is_processing(user_id):\n",
        "    \"\"\"\n",
        "    Verifica se o usuário (pelo ID) está marcado como em processamento ativo.\n",
        "    \"\"\"\n",
        "    # Procura por entrada de processamento 'in_progress' para este ID\n",
        "    entries = query_logs(sessao=\"processing\", id=user_id, status=\"in_progress\")\n",
        "    return len(entries) > 0\n",
        "\n",
        "def mark_processing(user_id, username):\n",
        "    \"\"\"\n",
        "    Marca o usuário/transmissão (pelo ID) como em processamento ativo via log central.\n",
        "    Registra também o username para referência.\n",
        "    \"\"\"\n",
        "    # Remove entradas antigas de processamento para este ID antes de adicionar a nova (garante unicidade)\n",
        "    remove_logs(lambda e: e.get(\"sessao\") == \"processing\" and e.get(\"id\") == user_id)\n",
        "\n",
        "    append_log({\n",
        "        \"sessao\": \"processing\",\n",
        "        \"evento\": \"iniciar\",\n",
        "        \"id\": user_id,\n",
        "        \"username\": username, # Mantém username para referência\n",
        "        \"status\": \"in_progress\",\n",
        "        \"detalhes\": \"\"\n",
        "    })\n",
        "    # print(f\"ℹ️ Usuário '{username}' (ID: {user_id}) marcado como 'in_progress' no log.\")\n",
        "\n",
        "\n",
        "def unmark_processing(user_id):\n",
        "    \"\"\"\n",
        "    Remove marcação de processamento ativo para o usuário (pelo ID).\n",
        "    \"\"\"\n",
        "    # Remove entradas de processamento 'in_progress' para este ID\n",
        "    removed = remove_logs(lambda e: e.get(\"sessao\") == \"processing\" and e.get(\"id\") == user_id and e.get(\"status\") == \"in_progress\")\n",
        "    # if removed > 0:\n",
        "    #     print(f\"ℹ️ Marcação 'in_progress' removida para ID {user_id}.\")\n",
        "    # else:\n",
        "    #      print(f\"ℹ️ Nenhuma marcação 'in_progress' encontrada para remover para ID {user_id}.\") # remove_logs já loga se nada foi removido\n",
        "\n",
        "\n",
        "# ============================\n",
        "# BUSCA DE TRANSMISSÕES NA API XCAM (AGORA CAPTURANDO O ID E USANDO NO CONTROLE)\n",
        "# ============================\n",
        "\n",
        "def get_broadcasts(limit=LIMIT_DEFAULT, page=PAGE_DEFAULT, usuarios_especificos=None, temp_folder=\"/content\"):\n",
        "    \"\"\"\n",
        "    Busca transmissões ao vivo, respeitando blacklist (por ID), falhas (por ID) e log de processamento (por ID) via log centralizado.\n",
        "    Garante poster válido (download ou ffmpeg) e faz fallback automático.\n",
        "    RETORNA LISTA DE DICIONÁRIOS INCLUINDO O 'id' DA API.\n",
        "    \"\"\"\n",
        "    # Coleta IDs de usuários atualmente em processamento ou blacklist\n",
        "    ids_em_proc_ou_blacklist = {e[\"id\"] for e in query_logs(sessao=\"processing\", status=\"in_progress\")} | \\\n",
        "                               {e[\"id\"] for e in query_logs(sessao=\"blacklist\", status=\"blacklisted\")}\n",
        "\n",
        "\n",
        "    if usuarios_especificos:\n",
        "        # Note: Buscar por username específico na API e depois filtrar por ID no log é necessário\n",
        "        # A API principal não parece permitir busca por lista de IDs diretamente\n",
        "        api_url_main = f\"https://api.xcam.gay/?limit={API_SEARCH_LIMIT}&page=1\" # Ainda busca um lote grande para encontrar específicos\n",
        "        print(f\"🌐 Acessando API principal (buscando usuários específicos) em: {api_url_main}\")\n",
        "    else:\n",
        "        # Busca um lote grande para ter mais chances de encontrar usuários disponíveis\n",
        "        api_url_main = f\"https://api.xcam.gay/?limit=3333\"\n",
        "        print(f\"🌐 Acessando API principal (buscando todas transmissões online) em: {api_url_main}\")\n",
        "\n",
        "    streams_candidates = [] # streams que tem src ou que precisam de liveInfo\n",
        "    streams_without_preview = [] # streams sem src na API principal\n",
        "\n",
        "    try:\n",
        "        response_main = requests.get(api_url_main)\n",
        "        response_main.raise_for_status()\n",
        "        data_main = response_main.json()\n",
        "        broadcasts_data = data_main.get(\"broadcasts\")\n",
        "        if not broadcasts_data:\n",
        "            print(\"⚠️ Chave 'broadcasts' não encontrada na resposta da API principal.\")\n",
        "            return []\n",
        "        items = broadcasts_data.get(\"items\")\n",
        "        if not isinstance(items, list):\n",
        "            print(f\"⚠️ Chave 'items' não encontrada ou não é uma lista em 'broadcasts'.\")\n",
        "            return []\n",
        "\n",
        "        print(f\"API principal retornou {len(items)} transmissões.\")\n",
        "\n",
        "        for item in items:\n",
        "            # ** CAPTURA O ID AQUI **\n",
        "            user_id = str(item.get(\"id\")) # Garante que o ID seja string\n",
        "            username = item.get(\"username\", \"desconhecido\")\n",
        "            preview = item.get(\"preview\") or {}\n",
        "            src = preview.get(\"src\")\n",
        "            poster = preview.get(\"poster\")\n",
        "\n",
        "            # Ignora se já está em processamento ou blacklist (AGORA VERIFICA PELO ID)\n",
        "            if user_id in ids_em_proc_ou_blacklist:\n",
        "                # print(f\"ℹ️ Usuário '{username}' (ID: {user_id}) já processado/em blacklist/processing, ignorando.\")\n",
        "                continue\n",
        "\n",
        "            # Ignora se está buscando específicos e este usuário/ID não está na lista\n",
        "            if usuarios_especificos and username not in usuarios_especificos: # Continua filtrando por username se especificado\n",
        "                 # Poderíamos também adicionar uma lista de IDs específicos, se a API permitisse buscar por ID.\n",
        "                continue\n",
        "\n",
        "            stream_info = {\n",
        "                 \"id\": user_id, # Inclui o ID\n",
        "                 \"username\": username,\n",
        "                 \"src\": src,\n",
        "                 \"poster\": poster # Isso pode ser URL ou None\n",
        "            }\n",
        "\n",
        "            if src:\n",
        "                streams_candidates.append(stream_info) # Adiciona streams com src para processar/validar poster\n",
        "            else:\n",
        "                 streams_without_preview.append(stream_info) # Adiciona streams sem src para tentar liveInfo\n",
        "\n",
        "        print(f\"✅ {len(streams_candidates)} transmissões com URL na API principal, {len(streams_without_preview)} sem URL.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Erro ao acessar API principal: {e}\")\n",
        "        # Registrar erro de busca no log\n",
        "        if \"append_log\" in globals():\n",
        "             append_log({\n",
        "                 \"sessao\": \"busca\",\n",
        "                 \"evento\": \"erro_api_principal\",\n",
        "                 \"id\": \"global\", # Erro global de API\n",
        "                 \"username\": \"global\",\n",
        "                 \"status\": \"erro\",\n",
        "                 \"detalhes\": f\"Erro ao acessar API principal: {e}\"\n",
        "             })\n",
        "        return [] # Retorna vazio em caso de erro na API principal\n",
        "\n",
        "    # Fallback: busca via liveInfo para streams sem URL na API principal\n",
        "    streams_from_liveinfo = []\n",
        "    if streams_without_preview:\n",
        "        print(f\"🔁 Buscando liveInfo para {len(streams_without_preview)} streams sem URL na API principal...\")\n",
        "        for stream_info in streams_without_preview:\n",
        "            user_id = stream_info[\"id\"] # Usa o ID capturado\n",
        "            username = stream_info[\"username\"]\n",
        "\n",
        "            # Verifica novamente se entrou em proc/blacklist enquanto processávamos a lista\n",
        "            if user_id in ids_em_proc_ou_blacklist:\n",
        "                 # print(f\"ℹ️ Usuário '{username}' (ID: {user_id}) já processado/em blacklist/processing durante fallback, ignorando.\")\n",
        "                 continue\n",
        "\n",
        "            api_url_liveinfo = f\"https://api.xcam.gay/user/{username}/liveInfo\" # LiveInfo ainda usa username na URL\n",
        "            try:\n",
        "                response_liveinfo = requests.get(api_url_liveinfo)\n",
        "                response_liveinfo.raise_for_status()\n",
        "                data_liveinfo = response_liveinfo.json()\n",
        "                m3u8_url = data_liveinfo.get(\"cdnURL\") or data_liveinfo.get(\"edgeURL\")\n",
        "                if m3u8_url:\n",
        "                    # Adiciona stream encontrada via liveInfo aos candidatos\n",
        "                    streams_from_liveinfo.append({\n",
        "                        \"id\": user_id, # Inclui o ID\n",
        "                        \"username\": username,\n",
        "                        \"src\": m3u8_url,\n",
        "                        \"poster\": None # Poster do liveInfo geralmente não é direto, será gerado\n",
        "                    })\n",
        "                else:\n",
        "                    print(f\"⚠️ liveInfo de '{username}' (ID: {user_id}) não retornou cdnURL/edgeURL (usuário possivelmente offline).\")\n",
        "                    # Registrar falha no liveInfo no log (AGORA USA ID)\n",
        "                    if \"register_failure\" in globals():\n",
        "                         register_failure(user_id, username, \"liveInfo sem cdnURL/edgeURL.\")\n",
        "\n",
        "            except Exception as ex:\n",
        "                print(f\"❌ Erro ao buscar liveInfo para '{username}' (ID: {user_id}): {ex}\")\n",
        "                 # Registrar erro de liveInfo no log (AGORA USA ID)\n",
        "                if \"register_failure\" in globals():\n",
        "                     register_failure(user_id, username, f\"Erro ao buscar liveInfo: {ex}\")\n",
        "\n",
        "            time.sleep(0.2) # Pequeno delay entre chamadas de liveInfo\n",
        "\n",
        "    # Junta candidatos da API principal e liveInfo.\n",
        "    # Antes de adicionar à lista final, valida poster e evita duplicidade/blacklist FINAL.\n",
        "    final_streams_list = []\n",
        "    seen_ids = set() # Usa um set de IDs para controlar duplicidade na lista final\n",
        "    all_candidates = streams_candidates + streams_from_liveinfo\n",
        "\n",
        "    print(f\"Validando poster e filtrando {len(all_candidates)} candidatos...\")\n",
        "\n",
        "    for stream in all_candidates:\n",
        "        user_id = stream[\"id\"]\n",
        "        username = stream[\"username\"]\n",
        "        src = stream[\"src\"]\n",
        "        poster_info = stream[\"poster\"] # Pode ser URL ou None\n",
        "\n",
        "        # Verifica pela ÚLTIMA VEZ se o ID já foi adicionado à lista final,\n",
        "        # ou se entrou em processamento/blacklist desde a consulta inicial da API.\n",
        "        if user_id in seen_ids or user_id in ids_em_proc_ou_blacklist:\n",
        "            continue\n",
        "\n",
        "        poster_path = None\n",
        "        try:\n",
        "            # Tenta baixar poster original se existir\n",
        "            if poster_info and isinstance(poster_info, str) and poster_info.strip():\n",
        "                poster_path = download_and_save_poster(poster_info, username, temp_folder) # download_and_save_poster não precisa de ID\n",
        "\n",
        "            # Se poster baixado for inválido OU não havia poster original, gera com ffmpeg\n",
        "            if not is_poster_valid(poster_path):\n",
        "                poster_path = generate_poster_with_ffmpeg(src, username, temp_folder) # generate_poster_with_ffmpeg não precisa de ID\n",
        "\n",
        "            # Se mesmo após todas as tentativas o poster for inválido\n",
        "            if not is_poster_valid(poster_path):\n",
        "                # Registrar falha de poster no log (AGORA USA ID)\n",
        "                if \"register_failure\" in globals():\n",
        "                     register_failure(user_id, username, \"Poster inválido após todas tentativas.\")\n",
        "                continue # Pula para o próximo stream se o poster for inválido\n",
        "\n",
        "            # Se o poster é válido, limpa falhas relacionadas a poster/ffmpeg/conexão para este ID\n",
        "            if \"clear_failure\" in globals():\n",
        "                 clear_failure(user_id) # Limpa falhas pelo ID\n",
        "\n",
        "            # Adiciona à lista final e marca ID como visto\n",
        "            final_streams_list.append({\n",
        "                \"id\": user_id, # Inclui o ID único no resultado final\n",
        "                \"username\": username,\n",
        "                \"src\": src,\n",
        "                \"poster_path\": poster_path # Passa o caminho LOCAL do poster válido\n",
        "            })\n",
        "            seen_ids.add(user_id)\n",
        "\n",
        "            # Quebra o loop se atingiu o limite desejado\n",
        "            if len(final_streams_list) >= limit:\n",
        "                break\n",
        "\n",
        "        except Exception as e:\n",
        "            msg = f\"Falha inesperada durante validação de poster/stream para '{username}' (ID: {user_id}): {e}\"\n",
        "            print(f\"❌ {msg}\")\n",
        "            # Registrar falha genérica no log (AGORA USA ID)\n",
        "            if \"register_failure\" in globals():\n",
        "                 register_failure(user_id, username, msg)\n",
        "\n",
        "\n",
        "    print(f\"🔎 Selecionadas {len(final_streams_list)} streams válidas (com poster) após fallback (respeitando limit={limit}).\")\n",
        "    return final_streams_list\n",
        "\n",
        "# ============================\n",
        "# BUSCA DE USUÁRIOS ESPECÍFICOS (AGORA COM ID)\n",
        "# ============================\n",
        "\n",
        "def buscar_usuarios_especificos(usuarios_lista, temp_folder=\"/content\"):\n",
        "    \"\"\"\n",
        "    Busca usuários específicos via API (por username), agora respeitando blacklist (por ID)\n",
        "    e controle de falhas (por ID) via log central. Inclui fallback via liveInfo e valida poster.\n",
        "    RETORNA LISTA DE DICIONÁRIOS INCLUINDO O 'id' DA API.\n",
        "    \"\"\"\n",
        "    # Coleta IDs de usuários em processamento ou blacklist\n",
        "    ids_em_proc_ou_blacklist = {e[\"id\"] for e in query_logs(sessao=\"processing\", status=\"in_progress\")} | \\\n",
        "                               {e[\"id\"] for e in query_logs(sessao=\"blacklist\", status=\"blacklisted\")}\n",
        "\n",
        "    # Primeiro, tenta encontrar os usuários na lista na API principal (limite alto para pegar todos se online)\n",
        "    api_url = f\"https://api.xcam.gay/?limit={API_SEARCH_LIMIT}&page=1\"\n",
        "    print(f\"🔍 Buscando usuários específicos ({len(usuarios_lista)}) em {api_url}\")\n",
        "    found_candidates = []\n",
        "    users_not_found_in_main = set(usuarios_lista) # Acompanha quem não foi encontrado na API principal\n",
        "\n",
        "    try:\n",
        "        response = requests.get(api_url)\n",
        "        response.raise_for_status()\n",
        "        data = response.json()\n",
        "        items = data.get(\"broadcasts\", {}).get(\"items\", [])\n",
        "\n",
        "        for item in items:\n",
        "            user_id = str(item.get(\"id\")) # ** CAPTURA O ID **\n",
        "            username = item.get(\"username\", \"\")\n",
        "\n",
        "            if username in usuarios_lista: # Verifica se este é um dos usuários que procuramos\n",
        "                 users_not_found_in_main.discard(username) # Remove da lista de não encontrados\n",
        "\n",
        "                 # Verifica se o ID está em proc/blacklist (AGORA VERIFICA PELO ID)\n",
        "                 if user_id in ids_em_proc_ou_blacklist:\n",
        "                     # print(f\"ℹ️ Usuário '{username}' (ID: {user_id}) já processado/em blacklist/processing, ignorando.\")\n",
        "                     continue\n",
        "\n",
        "                 preview = item.get(\"preview\") or {}\n",
        "                 src = preview.get(\"src\")\n",
        "                 poster = preview.get(\"poster\") # Pode ser URL ou None\n",
        "\n",
        "                 if src:\n",
        "                     # Adiciona como candidato se tiver SRC (validação de poster depois)\n",
        "                     found_candidates.append({\n",
        "                         \"id\": user_id, # Inclui o ID\n",
        "                         \"username\": username,\n",
        "                         \"src\": src,\n",
        "                         \"poster\": poster # Pode ser URL ou None\n",
        "                     })\n",
        "                 else:\n",
        "                     # Marca para tentar via liveInfo se não tiver SRC principal\n",
        "                     # Adiciona a lista de streams_without_preview para liveinfo fallback\n",
        "                     found_candidates.append({\n",
        "                        \"id\": user_id, # Inclui o ID\n",
        "                        \"username\": username,\n",
        "                        \"src\": None, # Indica que precisa de liveInfo\n",
        "                        \"poster\": None\n",
        "                    })\n",
        "\n",
        "\n",
        "        print(f\"Encontrados {len(found_candidates)} dos {len(usuarios_lista)} usuários especificados na API principal (antes de fallback).\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Erro ao buscar usuários específicos na API principal: {e}\")\n",
        "        # Registrar erro de busca no log (AGORA USA ID ou Global)\n",
        "        if \"append_log\" in globals():\n",
        "             append_log({\n",
        "                 \"sessao\": \"busca\",\n",
        "                 \"evento\": \"erro_api_especificos\",\n",
        "                 \"id\": \"global\", # Erro global de API\n",
        "                 \"username\": \"global\",\n",
        "                 \"status\": \"erro\",\n",
        "                 \"detalhes\": f\"Erro ao buscar usuários específicos na API principal: {e}\"\n",
        "             })\n",
        "        # Em caso de erro na API principal, tenta buscar cada usuário individualmente via liveInfo?\n",
        "        # Para simplificar, se a API principal falha, retornamos o que conseguimos ou vazio.\n",
        "        # Se o erro é grave, talvez não haja mais o que fazer.\n",
        "\n",
        "    # Fallback: busca via liveInfo para usuários especificados que não tinham SRC na API principal\n",
        "    streams_from_liveinfo = []\n",
        "    # Filtra os candidatos que precisam de liveInfo\n",
        "    candidates_for_liveinfo = [c for c in found_candidates if c.get(\"src\") is None]\n",
        "    # Adiciona usuários que NÃO foram encontrados na API principal mas estavam na lista original\n",
        "    # Assume que se não foi encontrado na lista grande da API principal, está offline ou precisa de liveInfo direto\n",
        "    # Isso pode gerar falsos positivos se o usuário estiver offline\n",
        "    for uname in users_not_found_in_main:\n",
        "        # Tenta obter o ID antes de tentar liveInfo? LiveInfo não retorna ID...\n",
        "        # Se o usuário não foi encontrado na API principal (com limite alto), é provável que esteja offline.\n",
        "        # Buscar liveInfo sem ter um ID é menos robusto.\n",
        "        # Vamos focar no fallback APENAS para usuários ENCONTRADOS na API principal mas sem SRC.\n",
        "        # Se o usuário da lista específica não apareceu na busca grande, assumimos offline por enquanto.\n",
        "        print(f\"⚠️ Usuário '{uname}' especificado não encontrado na busca da API principal. Assumindo offline ou inacessível.\")\n",
        "\n",
        "\n",
        "    if candidates_for_liveinfo:\n",
        "        print(f\"🔁 Buscando liveInfo para {len(candidates_for_liveinfo)} usuários específicos sem URL na API principal...\")\n",
        "        for stream_info in candidates_for_liveinfo:\n",
        "            user_id = stream_info[\"id\"] # Usa o ID capturado da API principal\n",
        "            username = stream_info[\"username\"]\n",
        "\n",
        "            # Verifica novamente se entrou em proc/blacklist\n",
        "            if user_id in ids_em_proc_ou_blacklist:\n",
        "                 # print(f\"ℹ️ Usuário '{username}' (ID: {user_id}) já processado/em blacklist/processing durante fallback, ignorando.\")\n",
        "                 continue\n",
        "\n",
        "            api_url_liveinfo = f\"https://api.xcam.gay/user/{username}/liveInfo\"\n",
        "            try:\n",
        "                response_liveinfo = requests.get(api_url_liveinfo)\n",
        "                response_liveinfo.raise_for_status()\n",
        "                data_liveinfo = response_liveinfo.json()\n",
        "                m3u8_url = data_liveinfo.get(\"cdnURL\") or data_liveinfo.get(\"edgeURL\")\n",
        "                if m3u8_url:\n",
        "                    # Adiciona stream encontrada via liveInfo\n",
        "                    streams_from_liveinfo.append({\n",
        "                        \"id\": user_id, # Inclui o ID\n",
        "                        \"username\": username,\n",
        "                        \"src\": m3u8_url,\n",
        "                        \"poster\": None # Poster do liveInfo geralmente não é direto, será gerado\n",
        "                    })\n",
        "                else:\n",
        "                    print(f\"⚠️ liveInfo de '{username}' (ID: {user_id}) não retornou cdnURL/edgeURL (usuário possivelmente offline).\")\n",
        "                    # Registrar falha no liveInfo no log (AGORA USA ID)\n",
        "                    if \"register_failure\" in globals():\n",
        "                         register_failure(user_id, username, \"liveInfo sem cdnURL/edgeURL.\")\n",
        "\n",
        "            except Exception as ex:\n",
        "                print(f\"❌ Erro ao buscar liveInfo para '{username}' (ID: {user_id}): {ex}\")\n",
        "                # Registrar erro de liveInfo no log (AGORA USA ID)\n",
        "                if \"register_failure\" in globals():\n",
        "                     register_failure(user_id, username, f\"Erro ao buscar liveInfo: {ex}\")\n",
        "\n",
        "            time.sleep(0.2) # Pequeno delay\n",
        "\n",
        "    # Junta candidatos que tinham SRC e os encontrados via liveInfo.\n",
        "    # Antes de adicionar à lista final, valida poster e evita duplicidade/blacklist FINAL.\n",
        "    final_streams_list = []\n",
        "    seen_ids = set() # Usa um set de IDs para controlar duplicidade na lista final\n",
        "    # Filtra os candidatos que TINHAM SRC na API principal\n",
        "    candidates_with_src = [c for c in found_candidates if c.get(\"src\") is not None]\n",
        "    all_candidates_post_fallback = candidates_with_src + streams_from_liveinfo\n",
        "\n",
        "    print(f\"Validando poster e filtrando {len(all_candidates_post_fallback)} candidatos após fallback...\")\n",
        "\n",
        "\n",
        "    for stream in all_candidates_post_fallback:\n",
        "        user_id = stream[\"id\"]\n",
        "        username = stream[\"username\"]\n",
        "        src = stream[\"src\"]\n",
        "        poster_info = stream[\"poster\"] # Pode ser URL ou None\n",
        "\n",
        "        # Verifica pela ÚLTIMA VEZ se o ID já foi adicionado à lista final,\n",
        "        # ou se entrou em processamento/blacklist desde a consulta inicial.\n",
        "        if user_id in seen_ids or user_id in ids_em_proc_ou_blacklist:\n",
        "            continue\n",
        "\n",
        "        poster_path = None\n",
        "        try:\n",
        "            # Tenta baixar poster original se existir\n",
        "            if poster_info and isinstance(poster_info, str) and poster_info.strip():\n",
        "                poster_path = download_and_save_poster(poster_info, username, temp_folder)\n",
        "\n",
        "            # Se poster baixado for inválido OU não havia poster original, gera com ffmpeg\n",
        "            if not is_poster_valid(poster_path):\n",
        "                poster_path = generate_poster_with_ffmpeg(src, username, temp_folder)\n",
        "\n",
        "            # Se mesmo após todas as tentativas o poster for inválido\n",
        "            if not is_poster_valid(poster_path):\n",
        "                 # Registrar falha de poster no log (AGORA USA ID)\n",
        "                if \"register_failure\" in globals():\n",
        "                     register_failure(user_id, username, \"Poster inválido após todas tentativas.\")\n",
        "                continue # Pula para o próximo stream\n",
        "\n",
        "            # Se o poster é válido, limpa falhas relacionadas a poster/ffmpeg/conexão para este ID\n",
        "            if \"clear_failure\" in globals():\n",
        "                 clear_failure(user_id) # Limpa falhas pelo ID\n",
        "\n",
        "            # Adiciona à lista final e marca ID como visto\n",
        "            final_streams_list.append({\n",
        "                \"id\": user_id, # Inclui o ID único no resultado final\n",
        "                \"username\": username,\n",
        "                \"src\": src,\n",
        "                \"poster_path\": poster_path # Passa o caminho LOCAL do poster válido\n",
        "            })\n",
        "            seen_ids.add(user_id)\n",
        "\n",
        "            # No modo específico, buscamos todos da lista, então não há limite de \"len(final_streams_list) >= limit\" aqui.\n",
        "            # Poderíamos adicionar um limite se quiséssemos parar após encontrar N dos específicos.\n",
        "\n",
        "        except Exception as e:\n",
        "            msg = f\"Falha inesperada durante validação de poster/stream para '{username}' (ID: {user_id}): {e}\"\n",
        "            print(f\"❌ {msg}\")\n",
        "            # Registrar falha genérica no log (AGORA USA ID)\n",
        "            if \"register_failure\" in globals():\n",
        "                 register_failure(user_id, username, msg)\n",
        "\n",
        "    print(f\"🔎 Encontrados e validados {len(final_streams_list)} dos {len(usuarios_lista)} usuários especificados.\")\n",
        "    return final_streams_list\n",
        "\n",
        "\n",
        "# ============================\n",
        "# BUSCA DA PRÓXIMA TRANSMISSÃO DISPONÍVEL (AGORA COM ID)\n",
        "# ============================\n",
        "\n",
        "def buscar_proxima_transmissao_livre(temp_folder=\"/content\"):\n",
        "    \"\"\"\n",
        "    Busca a próxima transmissão ao vivo não processada, com poster válido e ignorando blacklist (por ID), tudo centralizado no log.\n",
        "    RETORNA DICIONÁRIO INCLUINDO O 'id' DA API, OU None.\n",
        "    \"\"\"\n",
        "    # Coleta IDs de usuários em processamento ou blacklist\n",
        "    ids_em_proc_ou_blacklist = {e[\"id\"] for e in query_logs(sessao=\"processing\", status=\"in_progress\")} | \\\n",
        "                               {e[\"id\"] for e in query_logs(sessao=\"blacklist\", status=\"blacklisted\")}\n",
        "\n",
        "\n",
        "    api_url_main = f\"https://api.xcam.gay/?limit=3333&page=1\" # Busca um lote grande para encontrar o próximo rápido\n",
        "    print(f\"🔎 Buscando próxima transmissão livre em: {api_url_main}\")\n",
        "    try:\n",
        "        response_main = requests.get(api_url_main)\n",
        "        response_main.raise_for_status()\n",
        "        data_main = response_main.json()\n",
        "        items = data_main.get(\"broadcasts\", {}).get(\"items\", [])\n",
        "        print(f\"API principal retornou {len(items)} transmissões.\")\n",
        "\n",
        "        # Primeiro, itera sobre os itens da API principal que têm SRC\n",
        "        for item in items:\n",
        "            # ** CAPTURA O ID AQUI **\n",
        "            user_id = str(item.get(\"id\")) # Garante que o ID seja string\n",
        "            username = item.get(\"username\", \"desconhecido\")\n",
        "            preview = item.get(\"preview\") or {}\n",
        "            src = preview.get(\"src\")\n",
        "            poster_info = preview.get(\"poster\") # Pode ser URL ou None\n",
        "\n",
        "            # Ignora se já está em processamento ou blacklist (AGORA VERIFICA PELO ID)\n",
        "            if user_id in ids_em_proc_ou_blacklist:\n",
        "                # print(f\"ℹ️ Usuário '{username}' (ID: {user_id}) já processado/em blacklist/processing, ignorando.\")\n",
        "                continue\n",
        "\n",
        "            if src:\n",
        "                 # Se tem SRC e não está em proc/blacklist, valida poster\n",
        "                poster_path = None\n",
        "                try:\n",
        "                    # Tenta baixar poster original se existir\n",
        "                    if poster_info and isinstance(poster_info, str) and poster_info.strip():\n",
        "                        poster_path = download_and_save_poster(poster_info, username, temp_folder)\n",
        "\n",
        "                    # Se poster baixado for inválido OU não havia poster original, gera com ffmpeg\n",
        "                    if not is_poster_valid(poster_path):\n",
        "                        poster_path = generate_poster_with_ffmpeg(src, username, temp_folder)\n",
        "\n",
        "                    # Se o poster é válido, limpa falhas relacionadas a poster/ffmpeg/conexão e retorna\n",
        "                    if is_poster_valid(poster_path):\n",
        "                        if \"clear_failure\" in globals():\n",
        "                             clear_failure(user_id) # Limpa falhas pelo ID\n",
        "                        print(f\"🎯 Transmissão livre encontrada: '{username}' (ID: {user_id})\")\n",
        "                        return {\n",
        "                            \"id\": user_id, # Inclui o ID único no resultado\n",
        "                            \"username\": username,\n",
        "                            \"src\": src,\n",
        "                            \"poster_path\": poster_path # Passa o caminho LOCAL do poster válido\n",
        "                        }\n",
        "                    else:\n",
        "                         # Se poster inválido, registra falha e continua buscando\n",
        "                         if \"register_failure\" in globals():\n",
        "                             register_failure(user_id, username, \"Poster inválido após todas tentativas (busca próxima).\")\n",
        "                         continue # Pula para o próximo item\n",
        "\n",
        "                except Exception as e:\n",
        "                    msg = f\"Falha inesperada durante validação de poster/stream para '{username}' (ID: {user_id}) na busca próxima: {e}\"\n",
        "                    print(f\"❌ {msg}\")\n",
        "                    # Registrar falha genérica no log (AGORA USA ID)\n",
        "                    if \"register_failure\" in globals():\n",
        "                         register_failure(user_id, username, msg)\n",
        "                    continue # Pula para o próximo item\n",
        "\n",
        "\n",
        "        # Se chegou aqui, nenhum item com SRC foi encontrado/validado na busca grande.\n",
        "        # Agora, itera sobre os itens sem SRC para tentar liveInfo\n",
        "        print(\"Nenhuma transmissão livre com SRC encontrada, tentando liveInfo para os demais...\")\n",
        "        for item in items:\n",
        "             user_id = str(item.get(\"id\")) # ** CAPTURA O ID **\n",
        "             username = item.get(\"username\", \"desconhecido\")\n",
        "             preview = item.get(\"preview\") or {}\n",
        "             src = preview.get(\"src\") # Re-verifica SRC\n",
        "\n",
        "             # Ignora se tem SRC (já processado acima) ou se já está em proc/blacklist\n",
        "             if src or user_id in ids_em_proc_ou_blacklist:\n",
        "                  continue\n",
        "\n",
        "             # Se não tem SRC e não está em proc/blacklist, tenta liveInfo\n",
        "             api_url_liveinfo = f\"https://api.xcam.gay/user/{username}/liveInfo\"\n",
        "             try:\n",
        "                 response_liveinfo = requests.get(api_url_liveinfo)\n",
        "                 response_liveinfo.raise_for_status()\n",
        "                 data_liveinfo = response_liveinfo.json()\n",
        "                 m3u8_url = data_liveinfo.get(\"cdnURL\") or data_liveinfo.get(\"edgeURL\")\n",
        "                 if m3u8_url:\n",
        "                      # Se encontrou URL via liveInfo, valida poster e retorna\n",
        "                      poster_path = generate_poster_with_ffmpeg(m3u8_url, username, temp_folder)\n",
        "\n",
        "                      if is_poster_valid(poster_path):\n",
        "                           if \"clear_failure\" in globals():\n",
        "                                clear_failure(user_id) # Limpa falhas pelo ID\n",
        "                           print(f\"🎯 Transmissão livre (pelo liveInfo) encontrada: '{username}' (ID: {user_id})\")\n",
        "                           return {\n",
        "                               \"id\": user_id, # Inclui o ID único no resultado\n",
        "                               \"username\": username,\n",
        "                               \"src\": m3u8_url,\n",
        "                               \"poster_path\": poster_path # Passa o caminho LOCAL do poster válido\n",
        "                           }\n",
        "                      else:\n",
        "                           # Se poster inválido, registra falha e continua buscando\n",
        "                           if \"register_failure\" in globals():\n",
        "                                register_failure(user_id, username, \"Poster inválido (busca próxima liveInfo).\")\n",
        "                           continue # Pula para o próximo item\n",
        "                 else:\n",
        "                      print(f\"⚠️ liveInfo de '{username}' (ID: {user_id}) não retornou cdnURL/edgeURL.\")\n",
        "                      # Registrar falha no liveInfo no log (AGORA USA ID)\n",
        "                      if \"register_failure\" in globals():\n",
        "                           register_failure(user_id, username, \"liveInfo sem cdnURL/edgeURL (busca próxima).\")\n",
        "\n",
        "\n",
        "             except Exception as ex:\n",
        "                 msg = f\"Erro ao buscar liveInfo para '{username}' (ID: {user_id}) na busca próxima: {ex}\"\n",
        "                 print(f\"❌ {msg}\")\n",
        "                 # Registrar erro de liveInfo no log (AGORA USA ID)\n",
        "                 if \"register_failure\" in globals():\n",
        "                      register_failure(user_id, username, msg)\n",
        "\n",
        "             time.sleep(0.2) # Pequeno delay\n",
        "\n",
        "\n",
        "        # Se nenhum stream foi encontrado/validado após varrer toda a lista da API (com SRC e liveInfo)\n",
        "        print(\"🚫 Nenhuma transmissão livre encontrada após varrer todas online.\")\n",
        "        return None # Retorna None se nenhum stream livre foi encontrado após todas as tentativas\n",
        "\n",
        "    except Exception as e:\n",
        "        msg = f\"❌ Erro ao buscar transmissões online (busca próxima): {e}\"\n",
        "        print(f\"❌ {msg}\")\n",
        "        # Registrar erro de busca no log (AGORA USA ID ou Global)\n",
        "        if \"append_log\" in globals():\n",
        "             append_log({\n",
        "                 \"sessao\": \"busca\",\n",
        "                 \"evento\": \"erro_api_proxima\",\n",
        "                 \"id\": \"global\", # Erro global de API\n",
        "                 \"username\": \"global\",\n",
        "                 \"status\": \"erro\",\n",
        "                 \"detalhes\": msg\n",
        "             })\n",
        "        return None # Retorna None em caso de erro na API\n",
        "\n",
        "# ================================================================\n",
        "# FIM DA CÉLULA 6 — BUSCA, BLACKLIST E CONTROLE DE FALHAS CENTRALIZADOS (AGORA COM ID)\n",
        "# ================================================================\n",
        "\n",
        "# Observações:\n",
        "# - Toda manipulação de blacklist, falha e processamento agora é feita via funções do log centralizado (Célula 1), USANDO O ID ÚNICO DA API.\n",
        "# - O username é mantido nos registros de log para referência humana, mas a lógica de controle se baseia no 'id'.\n",
        "# - Nenhum uso de arquivos dispersos. Consultas e remoções são sempre via query_logs, append_log, remove_logs.\n",
        "# - Para máxima rastreabilidade, todos os eventos relevantes estão registrados no log único."
      ],
      "metadata": {
        "id": "h1jr7D0pJ7jS"
      },
      "id": "h1jr7D0pJ7jS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Célula 7: Gravação Automática de Transmissão, Log Centralizado por ID, Limpeza e Blacklist Inteligente\n",
        "\n",
        "**Objetivo:**  \n",
        "Automatizar a gravação de transmissões ao vivo usando ffmpeg, com controle rigoroso e centralizado de status, falhas, blacklist temporária e limpeza de recursos via log único (`xcam_master.log`), utilizando sempre o identificador único (`id`) da API XCam para rastreabilidade.  \n",
        "Esta célula garante gerenciamento seguro do processamento, tratamento automático de falhas, integração com blacklist escalonável e limpeza completa de arquivos temporários, pronta para execução concorrente, CI/CD e auditoria.\n",
        "\n",
        "---\n",
        "\n",
        "## Estratégia técnica e diferenciais implementados\n",
        "\n",
        "- **Controle centralizado e seguro por ID:**  \n",
        "  O usuário é registrado no log centralizado (`sessao=\"processing\"`, `status=\"in_progress\"`) com seu `id` único antes do início da gravação, e removido ao final (sucesso ou erro), prevenindo duplicidade e concorrência indevida. Todos os eventos (início, erro, exceção, duração insuficiente, sucesso, limpeza) são registrados com rastreabilidade completa.\n",
        "- **Poster sempre garantido:**  \n",
        "  O sistema tenta baixar o poster informado. Se ausente ou inválido, gera automaticamente uma imagem via ffmpeg, garantindo que toda transmissão processada tenha um poster válido associado.\n",
        "- **Validação robusta da gravação:**  \n",
        "  Após a execução do ffmpeg, a duração real do vídeo é aferida com ffprobe. Se o arquivo for muito curto ou inválido, tanto o vídeo quanto o poster são descartados, e uma falha é registrada para o usuário no log, escalando para blacklist temporária se necessário.\n",
        "- **Tratamento e escalonamento de falhas:**  \n",
        "  Falhas de ffmpeg, duração insuficiente, ou outras exceções são registradas no log central por id. O usuário é automaticamente escalonado para a blacklist temporária ao atingir o limite de falhas (`BLACKLIST_MAX_FAILURES`), protegendo o pipeline contra tentativas repetidas e recursos desperdiçados.\n",
        "- **Limpeza automatizada de recursos:**  \n",
        "  Qualquer arquivo temporário (vídeo, poster) é removido logo após o upload ou erro, mantendo o ambiente limpo e evitando acúmulo de resíduos no Colab.\n",
        "- **Feedback detalhado e rastreabilidade:**  \n",
        "  Todas as etapas críticas são logadas e exibidas em tempo real no console, e o log único pode ser consultado para auditoria, troubleshooting ou integração CI/CD.\n",
        "- **Modularidade e documentação detalhada:**  \n",
        "  O código é segmentado em blocos lógicos, com comentários explicativos, facilitando manutenção, revisão e evolução pela equipe.\n",
        "\n",
        "---\n",
        "\n",
        "## Fluxo operacional detalhado\n",
        "\n",
        "1. **Registra o usuário no log central (processing/in_progress)**, por id, antes de iniciar a gravação.\n",
        "2. **Garante poster válido**, baixando ou gerando automaticamente.\n",
        "3. **Executa ffmpeg** para gravar a transmissão, monitora o progresso e exibe logs em tempo real.\n",
        "4. **Valida a gravação**:\n",
        "   - Se ffmpeg falhar, registra erro no log e incrementa contador de falhas do usuário (por id).\n",
        "   - Se a gravação for curta demais, descarta vídeo/poster e registra falha.\n",
        "   - Se sucesso, limpa contador de falhas e registra evento positivo.\n",
        "5. **Upload e integração externa:**  \n",
        "   Realiza upload do vídeo (e poster) e atualiza o banco de dados, logando sucesso ou erro.\n",
        "6. **Limpeza e finalização:**  \n",
        "   Remove a marcação de processamento do usuário (por id) no log central e apaga arquivos temporários, registrando todos os eventos de limpeza.\n",
        "\n",
        "---\n",
        "\n",
        "## Exemplo de uso técnico\n",
        "\n",
        "```python\n",
        "resultado = gravar_stream(\n",
        "    user_id=\"123456\",\n",
        "    username=\"user123\",\n",
        "    m3u8_url=\"https://cdn.xcam.gay/m3u8/...\",\n",
        "    poster_url=\"https://api.xcam.gay/poster/...\"\n",
        ")\n",
        "if resultado['upload_success']:\n",
        "    print(\"Gravação e upload realizados com sucesso!\")\n",
        "else:\n",
        "    print(\"Falha na gravação ou upload:\", resultado['abyss_response'])\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Segurança, rastreabilidade e integração\n",
        "\n",
        "- **Execução concorrente e pronta para CI/CD:**  \n",
        "  O controle centralizado por id e blacklist temporária garante execução paralela segura e rastreável em pipelines automatizados.\n",
        "- **Integração total com as funções globais do log:**  \n",
        "  Utiliza as funções de status, falha e blacklist da Célula 6, dispensando arquivos auxiliares e promovendo padronização.\n",
        "- **Auditoria e diagnóstico facilitados:**  \n",
        "  Mensagens e logs detalhados em cada etapa, todos centralizados no log único (`xcam_master.log`), prontos para consulta, auditoria ou troubleshooting.\n",
        "\n",
        "---\n",
        "\n",
        "## Observações técnicas\n",
        "\n",
        "- Toda manipulação de status, falha, blacklist e processamento é feita exclusivamente via funções do log centralizado, sempre por id.\n",
        "- A arquitetura é preparada para paralelismo, manutenção e evolução do pipeline, protegendo contra duplicidade e inconsistência.\n",
        "- O sistema garante que nenhum usuário problemático trave o pipeline, graças ao escalonamento automatizado para blacklist temporária.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "jGFyqOUoKEF7"
      },
      "id": "jGFyqOUoKEF7"
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================\n",
        "# Célula 7: Gravação Automática de Transmissão, Controle de Log Centralizado, Limpeza e Blacklist Inteligente (AGORA USANDO ID)\n",
        "# ================================================================\n",
        "# Objetivo:\n",
        "# - Gravar transmissões ao vivo utilizando ffmpeg, com controle rigoroso e centralizado de log de processamento, tratamento de falhas e integração com blacklist temporária (log único).\n",
        "# - Garantir que cada transmissão seja registrada no log central no início e removida ao final (sucesso ou erro), evitando duplicidade/processamento concorrente (sessao=\"processing\").\n",
        "# - Registrar falhas (ffmpeg, duração insuficiente, poster inválido), escalando usuários para a blacklist temporária via log central ao atingir o limite de tentativas, AGORA USANDO O ID.\n",
        "# - Assegurar limpeza robusta de arquivos temporários e rastreabilidade total via eventos no log único e mensagens detalhadas.\n",
        "# - Modular, preparado para integração com pipelines CI/CD, paralelismo e auditoria centralizada.\n",
        "# ================================================================\n",
        "\n",
        "def get_video_duration(filepath):\n",
        "    \"\"\"\n",
        "    Retorna a duração real do arquivo mp4, em segundos, utilizando ffprobe.\n",
        "    Retorna None em caso de erro ou se o arquivo não existir.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        if not os.path.exists(filepath):\n",
        "            print(f\"⚠️ Arquivo para ffprobe não encontrado: {filepath}\")\n",
        "            return None\n",
        "        cmd = [\n",
        "            \"ffprobe\", \"-v\", \"error\",\n",
        "            \"-show_entries\", \"format=duration\",\n",
        "            \"-of\", \"json\",\n",
        "            filepath\n",
        "        ]\n",
        "        result = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
        "        info = json.loads(result.stdout)\n",
        "        duration = float(info[\"format\"][\"duration\"])\n",
        "        return int(round(duration))\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ Não foi possível obter duração via ffprobe para {filepath}: {e}\")\n",
        "        return None\n",
        "\n",
        "# Adicionando user_id como parâmetro\n",
        "def gravar_stream(user_id, username, m3u8_url, poster_url=None, poster_frame_time=7):\n",
        "    \"\"\"\n",
        "    Grava a transmissão ao vivo do usuário (pelo ID) usando ffmpeg, com controle de erros, log centralizado e integração à blacklist.\n",
        "    - Registra no log centralizado (sessao=\"processing\") no início (status=\"in_progress\"), USANDO O ID.\n",
        "    - Remove do log ao finalizar, independentemente do resultado, USANDO O ID.\n",
        "    - Em caso de falha do ffmpeg ou gravação muito curta, registra falha do usuário no log (sessao=\"failure\"), USANDO O ID.\n",
        "    - Ao atingir N falhas consecutivas, usuário entra na blacklist (funções de log centralizado), USANDO O ID.\n",
        "    - Limpa arquivos temporários ao final.\n",
        "    - Garante poster válido: baixa da poster_url ou gera automaticamente com ffmpeg.\n",
        "    - poster_frame_time: segundo do vídeo onde a captura do poster será feita, se necessário.\n",
        "    \"\"\"\n",
        "    # --- Registro no log centralizado: PROCESSAMENTO INICIADO (USANDO ID) ---\n",
        "    # As funções mark_processing, unmark_processing, register_failure, clear_failure\n",
        "    # na Célula 6 já foram ajustadas para aceitar e usar user_id.\n",
        "    mark_processing(user_id, username) # Passa user_id e username\n",
        "\n",
        "    start_time_dt = datetime.now()\n",
        "    data_str = start_time_dt.strftime(\"%d-%m-%Y\")\n",
        "    horario_str = start_time_dt.strftime(\"%H-%M\")\n",
        "    temp_filename = f\"{username}_{start_time_dt.strftime('%Y%m%d_%H%M%S')}_temp.mp4\"\n",
        "    filepath = os.path.join(TEMP_OUTPUT_FOLDER, temp_filename)\n",
        "    append_log({\n",
        "        \"sessao\": \"processing\",\n",
        "        \"evento\": \"iniciar_gravacao\",\n",
        "        \"id\": user_id, # Usa o ID\n",
        "        \"username\": username,\n",
        "        \"status\": \"in_progress\",\n",
        "        \"detalhes\": f\"Gravação iniciada para '{username}' (ID: {user_id}) em {filepath}\" # Adiciona ID nos detalhes\n",
        "    })\n",
        "\n",
        "    print(f\"\\n🎬 Iniciando gravação de: '{username}' (ID: {user_id}) | URL: {m3u8_url}) em {filepath}\") # Adiciona ID no print\n",
        "\n",
        "    # --- Garante poster válido ---\n",
        "    # As funções de poster (download_and_save_poster, generate_poster_with_ffmpeg)\n",
        "    # não precisam do ID para funcionar, apenas o username para o nome do arquivo temporário.\n",
        "    poster_temp_path = None\n",
        "    if poster_url:\n",
        "        poster_temp_path = download_and_save_poster(poster_url, username, TEMP_OUTPUT_FOLDER)\n",
        "    # generate_poster_with_ffmpeg já foi ajustada na Célula 3 para usar a tupla de tries correta\n",
        "    if not is_poster_valid(poster_temp_path) and m3u8_url:\n",
        "        poster_temp_path = generate_poster_with_ffmpeg(m3u8_url, username, TEMP_OUTPUT_FOLDER, frame_time=poster_frame_time)\n",
        "\n",
        "\n",
        "    ffmpeg_cmd = [\n",
        "        \"ffmpeg\", \"-i\", m3u8_url,\n",
        "        \"-t\", str(RECORD_SECONDS),\n",
        "        \"-c\", \"copy\", \"-y\", filepath\n",
        "    ]\n",
        "\n",
        "    start_time_process = time.time()\n",
        "    process = None\n",
        "\n",
        "    try:\n",
        "        process = subprocess.Popen(\n",
        "            ffmpeg_cmd,\n",
        "            stdout=subprocess.PIPE,\n",
        "            stderr=subprocess.STDOUT,\n",
        "            text=True,\n",
        "            bufsize=1,\n",
        "            universal_newlines=True\n",
        "        )\n",
        "\n",
        "        # --- Monitoramento de progresso do ffmpeg (logs em tempo real) ---\n",
        "        # log_progress usa apenas username\n",
        "        elapsed_seconds = 0\n",
        "        last_log_minute = -1\n",
        "        while True:\n",
        "            line = process.stdout.readline()\n",
        "            if not line and process.poll() is not None:\n",
        "                break\n",
        "            if \"time=\" in line:\n",
        "                try:\n",
        "                    match = re.search(r\"time=(\\d+):(\\d+):(\\d+)\", line)\n",
        "                    if match:\n",
        "                        h, m, s = map(int, match.groups())\n",
        "                        elapsed_seconds = h * 3600 + m * 60 + s\n",
        "                        if elapsed_seconds // 60 != last_log_minute:\n",
        "                            log_progress(username, elapsed_seconds, RECORD_SECONDS)\n",
        "                            last_log_minute = elapsed_seconds // 60\n",
        "                except Exception:\n",
        "                    pass\n",
        "\n",
        "        process.wait()\n",
        "        end_time_process = time.time()\n",
        "        elapsed_seconds_proc = round(end_time_process - start_time_process)\n",
        "        log_progress(username, elapsed_seconds_proc, RECORD_SECONDS)\n",
        "\n",
        "        # --- Se FFmpeg falhou, registra no log central e retorna erro (USANDO ID) ---\n",
        "        if process.returncode != 0:\n",
        "            msg = f\"FFmpeg falhou para '{username}' (ID: {user_id}). Código de saída: {process.returncode}\" # Adiciona ID na mensagem\n",
        "            print(f\"❌ {msg}\")\n",
        "            append_log({\n",
        "                \"sessao\": \"processing\",\n",
        "                \"evento\": \"erro_ffmpeg\",\n",
        "                \"id\": user_id, # Usa o ID\n",
        "                \"username\": username,\n",
        "                \"status\": \"erro\",\n",
        "                \"detalhes\": msg\n",
        "            })\n",
        "            register_failure(user_id, username, \"Erro FFmpeg\") # Passa user_id e username\n",
        "            return {\n",
        "                'user_id': user_id, # Inclui user_id no resultado\n",
        "                'username': username,\n",
        "                'filename': temp_filename,\n",
        "                'filepath': filepath,\n",
        "                'upload_success': False,\n",
        "                'abyss_response': msg\n",
        "            }\n",
        "\n",
        "        # --- Validação pelo tempo real do arquivo gravado (robusta) ---\n",
        "        elapsed_seconds_real = get_video_duration(filepath)\n",
        "        if elapsed_seconds_real is not None:\n",
        "            print(f\"✅ Duração real do arquivo gravado: {elapsed_seconds_real}s (ffprobe)\")\n",
        "        else:\n",
        "            print(f\"⚠️ Não foi possível aferir duração real, usando a do processo: {elapsed_seconds_proc}s\")\n",
        "            elapsed_seconds_real = elapsed_seconds_proc\n",
        "\n",
        "        if elapsed_seconds_real < RECORD_SECONDS_MIN:\n",
        "            msg = f\"Gravação muito curta para '{username}' (ID: {user_id}). Duração gravada ({elapsed_seconds_real}s) menor que o mínimo ({RECORD_SECONDS_MIN}s). Arquivo descartado.\" # Adiciona ID\n",
        "            print(f\"⏩ {msg}\")\n",
        "            append_log({\n",
        "                \"sessao\": \"processing\",\n",
        "                \"evento\": \"erro_duracao\",\n",
        "                \"id\": user_id, # Usa o ID\n",
        "                \"username\": username,\n",
        "                \"status\": \"erro\",\n",
        "                \"detalhes\": msg\n",
        "            })\n",
        "            register_failure(user_id, username, \"Gravação muito curta\") # Passa user_id e username\n",
        "            if os.path.exists(filepath): os.remove(filepath)\n",
        "            if poster_temp_path and os.path.exists(poster_temp_path): os.remove(poster_temp_path)\n",
        "            return {\n",
        "                'user_id': user_id, # Inclui user_id no resultado\n",
        "                'username': username,\n",
        "                'filename': temp_filename,\n",
        "                'filepath': filepath,\n",
        "                'upload_success': False,\n",
        "                'abyss_response': \"Gravação muito curta (descartada)\"\n",
        "            }\n",
        "\n",
        "        # --- Sucesso: limpa falhas acumuladas do usuário no log central (USANDO ID) ---\n",
        "        clear_failure(user_id) # Passa user_id\n",
        "        tempo_formatado = format_seconds(elapsed_seconds_real)\n",
        "        final_filename = f\"{username}_{data_str}_{horario_str}_{tempo_formatado}.mp4\"\n",
        "        final_filepath = os.path.join(TEMP_OUTPUT_FOLDER, final_filename)\n",
        "\n",
        "        try:\n",
        "            os.rename(filepath, final_filepath)\n",
        "            print(f\"✅ Arquivo renomeado para: {final_filename}\")\n",
        "            filepath_for_upload = final_filepath\n",
        "            filename_for_upload = final_filename\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Erro ao renomear arquivo {temp_filename} para {final_filename}: {e}\")\n",
        "            filepath_for_upload = filepath\n",
        "            filename_for_upload = temp_filename\n",
        "\n",
        "        # --- Realiza upload e atualização do banco de dados (json) ---\n",
        "        # upload_to_abyss_and_update_json (Célula 8) precisará receber o user_id\n",
        "        success, abyss_resp, slug = upload_to_abyss_and_update_json(\n",
        "            filepath_for_upload, user_id, username, elapsed_seconds_real, # Passa user_id e username\n",
        "            poster_temp_path=poster_temp_path\n",
        "        )\n",
        "\n",
        "        # --- Loga sucesso de gravação no log central (USANDO ID) ---\n",
        "        append_log({\n",
        "            \"sessao\": \"processing\",\n",
        "            \"evento\": \"sucesso_gravacao\",\n",
        "            \"id\": user_id, # Usa o ID\n",
        "            \"username\": username,\n",
        "            \"status\": \"ok\",\n",
        "            \"detalhes\": f\"Arquivo {filename_for_upload} gravado e enviado com sucesso para '{username}' (ID: {user_id}). Duração: {elapsed_seconds_real}s\" # Adiciona ID\n",
        "        })\n",
        "\n",
        "        return {\n",
        "            'user_id': user_id, # Inclui user_id no resultado\n",
        "            'username': username,\n",
        "            'filename': filename_for_upload,\n",
        "            'filepath': filepath_for_upload,\n",
        "            'upload_success': success,\n",
        "            'abyss_response': abyss_resp,\n",
        "            'slug': slug\n",
        "        }\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        msg = \"Comando 'ffmpeg' não encontrado. Certifique-se de que foi instalado corretamente.\"\n",
        "        print(f\"❌ {msg}\")\n",
        "        # Registrar falha de ffmpeg não encontrado (USANDO ID)\n",
        "        if 'register_failure' in globals(): # Verifica se a função existe\n",
        "             register_failure(user_id, username, msg) # Passa user_id e username\n",
        "        append_log({\n",
        "            \"sessao\": \"processing\",\n",
        "            \"evento\": \"erro_ffmpeg_nao_encontrado\",\n",
        "            \"id\": user_id, # Usa o ID\n",
        "            \"username\": username,\n",
        "            \"status\": \"erro\",\n",
        "            \"detalhes\": msg\n",
        "        })\n",
        "        return {\n",
        "            'user_id': user_id, # Inclui user_id no resultado\n",
        "            'username': username,\n",
        "            'filename': None,\n",
        "            'filepath': None,\n",
        "            'upload_success': False,\n",
        "            'abyss_response': msg\n",
        "        }\n",
        "    except Exception as e:\n",
        "        msg = f\"Erro inesperado durante a execução do FFmpeg para '{username}' (ID: {user_id}): {e}\" # Adiciona ID\n",
        "        print(f\"❌ {msg}\")\n",
        "        # Registrar falha de execução de ffmpeg (USANDO ID)\n",
        "        if 'register_failure' in globals(): # Verifica se a função existe\n",
        "             register_failure(user_id, username, msg) # Passa user_id e username\n",
        "        append_log({\n",
        "            \"sessao\": \"processing\",\n",
        "            \"evento\": \"erro_execucao_ffmpeg\",\n",
        "            \"id\": user_id, # Usa o ID\n",
        "            \"username\": username,\n",
        "            \"status\": \"erro\",\n",
        "            \"detalhes\": msg\n",
        "        })\n",
        "        return {\n",
        "            'user_id': user_id, # Inclui user_id no resultado\n",
        "            'username': username,\n",
        "            'filename': None,\n",
        "            'filepath': None,\n",
        "            'upload_success': False,\n",
        "            'abyss_response': msg\n",
        "        }\n",
        "    finally:\n",
        "        # --- Remove marcação de processamento ativo no log central (USANDO ID) ---\n",
        "        unmark_processing(user_id) # Passa user_id\n",
        "\n",
        "        # --- Limpeza do arquivo de vídeo pós-upload ---\n",
        "        if 'filepath_for_upload' in locals() and os.path.exists(filepath_for_upload):\n",
        "            try:\n",
        "                os.remove(filepath_for_upload)\n",
        "                print(f\"🗑️ Arquivo de vídeo temporário local removido do Colab: {filepath_for_upload}\")\n",
        "                # Log de limpeza\n",
        "                if 'append_log' in globals():\n",
        "                     append_log({\n",
        "                         \"sessao\": \"cleanup\",\n",
        "                         \"evento\": \"remover_video_temp\",\n",
        "                         \"id\": user_id, # Usa o ID\n",
        "                         \"username\": username,\n",
        "                         \"status\": \"ok\",\n",
        "                         \"detalhes\": f\"Arquivo de vídeo temporário local removido: {filepath_for_upload}\"\n",
        "                     })\n",
        "            except Exception as e:\n",
        "                print(f\"⚠️ Não foi possível remover o arquivo de vídeo temporário local: {e}\")\n",
        "                # Log de erro de limpeza\n",
        "                if 'append_log' in globals():\n",
        "                     append_log({\n",
        "                         \"sessao\": \"cleanup\",\n",
        "                         \"evento\": \"erro_remover_video_temp\",\n",
        "                         \"id\": user_id, # Usa o ID\n",
        "                         \"username\": username,\n",
        "                         \"status\": \"erro\",\n",
        "                         \"detalhes\": f\"Erro ao remover arquivo de vídeo temporário local: {e}\"\n",
        "                     })\n",
        "\n",
        "\n",
        "        # --- Limpeza do poster temporário ---\n",
        "        # poster_temp_path é o caminho ANTES da renomeação com slug\n",
        "        if poster_temp_path and os.path.exists(poster_temp_path):\n",
        "            try:\n",
        "                os.remove(poster_temp_path)\n",
        "                # print(f\"🗑️ Poster temporário original removido: {poster_temp_path}\") # Já logado na Célula 8 se movido\n",
        "            except Exception as e:\n",
        "                # print(f\"⚠️ Não foi possível remover o poster temporário original: {e}\") # Já logado na Célula 8 se movido\n",
        "                pass # A Célula 8 lida com a limpeza do poster renomeado/movido\n",
        "\n",
        "\n",
        "# ================================================================\n",
        "# Fim da Célula 7 — Gravação, Log Centralizado e Blacklist Inteligente (AGORA USANDO ID)\n",
        "# ================================================================\n",
        "\n",
        "# Observações e recomendações:\n",
        "# - Toda manipulação de status, falha, blacklist e processamento é feita via funções do log centralizado (Célula 1 e 6), AGORA USANDO O ID.\n",
        "# - Mensagens claras e detalhadas e logging estruturado garantem rastreabilidade, CI/CD e manutenção.\n",
        "# - Pronto para execução concorrente, pipelines e auditoria centralizada no XCam."
      ],
      "metadata": {
        "id": "eJ_jrfNgKZNr"
      },
      "id": "eJ_jrfNgKZNr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Célula 8: Upload para Abyss.to, Atualização do rec.json e Poster no Google Drive — Log Centralizado, Persistência e Sincronização\n",
        "\n",
        "**Objetivo:**  \n",
        "Gerenciar de forma automatizada e robusta o pós-processamento da gravação: upload do vídeo gravado para o serviço Abyss.to, atualização e persistência dos metadados no arquivo `rec.json` do usuário diretamente no Google Drive, manipulação segura do poster associado ao vídeo, manutenção da integridade dos arquivos e limpeza consistente dos temporários.  \n",
        "Toda ação relevante é registrada no log centralizado (`xcam_master.log`) para máxima rastreabilidade, suporte a auditoria, diagnóstico rápido de falhas e compatibilidade total com execução concorrente e pipelines CI/CD.\n",
        "\n",
        "---\n",
        "\n",
        "## Estratégia técnica, fluxos e diferenciais implementados\n",
        "\n",
        "- **Upload seguro e transacional para Abyss.to:**  \n",
        "  O vídeo é enviado via POST multipart para Abyss.to, recebendo como resposta um JSON padronizado contendo status, slug (identificador único do vídeo), e URLs públicas do vídeo, iframe e poster. O slug serve como vínculo entre o vídeo, o poster e os metadados. O processo é tolerante a falhas, com tratamento de exceções e registro detalhado em caso de upload mal-sucedido ou resposta inesperada da API.\n",
        "- **Renomeação e movimentação do poster com vínculo ao slug:**  \n",
        "  O poster temporário é renomeado para `{slug}.jpg` no diretório temporário do Colab, garantindo unicidade e rastreabilidade. Em seguida, é movido para a pasta definitiva do usuário no Google Drive, permitindo sincronização, backup e fácil acesso externo. A URL do poster no `rec.json` é construída para refletir o caminho público presumido (ex: `https://db.xcam.gay/user/{username}/{slug}.jpg`).\n",
        "- **Atualização segura e incremental do rec.json:**  \n",
        "  O arquivo `rec.json` é lido e atualizado diretamente no Google Drive (sem cópias locais intermediárias), garantindo persistência e integridade dos registros históricos do usuário. Cada entrada adicionada inclui: slug, nome do arquivo, URLs públicas, poster, urlIframe, data, horário e duração formatada. Estrutura JSON validada para evitar corrupção do histórico.\n",
        "- **Registro detalhado no log centralizado:**  \n",
        "  Cada etapa crítica (upload, renomeação/movimentação de poster, atualização do rec.json, limpeza de arquivos) é registrada no log único com informações como evento, id/username, status e detalhes. Isso garante rastreabilidade completa, facilita auditoria, troubleshooting e geração de relatórios históricos.\n",
        "- **Limpeza automática e segura dos arquivos temporários:**  \n",
        "  Ao final do ciclo, o vídeo temporário e o poster remanescentes no Colab são removidos, liberando espaço e evitando acúmulo de resíduos. Falhas na limpeza são também registradas no log.\n",
        "- **Sincronização consistente com Google Drive:**  \n",
        "  Os artefatos permanentes são organizados em `/content/drive/MyDrive/XCam.Drive/user/{username}/`. A estrutura facilita backup, versionamento externo e integração com outros sistemas de armazenamento ou distribuição.\n",
        "- **Pronto para integração CI/CD, concorrência e expansão:**  \n",
        "  O fluxo é compatível com execução concorrente de múltiplos workers, pipelines automatizados e futuras integrações, pois não depende de arquivos temporários ou operações não transacionais.\n",
        "- **Segurança e redundância:**  \n",
        "  Toda persistência é feita diretamente no Drive, reduzindo riscos de perda por falhas do ambiente Colab ou interrupções inesperadas do notebook.\n",
        "\n",
        "---\n",
        "\n",
        "## Detalhes técnicos dos campos e operações\n",
        "\n",
        "- **Campos gravados no rec.json:**  \n",
        "  - `video`: slug/identificador único do vídeo no Abyss.to.\n",
        "  - `title`: nome base do arquivo de vídeo (sem extensão).\n",
        "  - `file`: nome do arquivo .mp4 original.\n",
        "  - `url`: URL pública do vídeo em Abyss.to.\n",
        "  - `poster`: URL pública do poster (presume acesso externo ao Drive ou CDN).\n",
        "  - `urlIframe`: URL do player incorporável com thumbnail.\n",
        "  - `data`, `horario`, `tempo`: metadados temporais e duração formatada.\n",
        "- **Estrutura do rec.json:**  \n",
        "  Cada usuário possui um arquivo rec.json com os campos `username`, `records` (total de vídeos) e `videos` (lista de entradas como acima).  \n",
        "  O arquivo é validado antes de cada escrita para garantir integridade.\n",
        "- **Tratamento robusto de falhas:**  \n",
        "  Qualquer falha (upload, leitura/gravação do JSON, movimentação de poster, limpeza) é capturada, logada e não impede a execução das outras etapas, reduzindo impacto no pipeline.\n",
        "- **Visibilidade e rastreamento:**  \n",
        "  O log centralizado permite identificar rapidamente uploads com falha, problemas de sincronização, arquivos que não foram limpos, e relatórios detalhados por usuário.\n",
        "\n",
        "---\n",
        "\n",
        "## Fluxo operacional detalhado\n",
        "\n",
        "1. **Upload do vídeo para Abyss.to:**  \n",
        "   O vídeo .mp4 é enviado via POST para o endpoint, recebendo slug, URL, urlIframe e status. Evento é logado.\n",
        "2. **Renomeação/movimentação do poster:**  \n",
        "   Poster temporário é renomeado para `{slug}.jpg` e transferido para o Drive. URLs públicas são calculadas e logadas.\n",
        "3. **Atualização do rec.json no Drive:**  \n",
        "   O JSON do usuário é lido/validado, nova entrada é adicionada, e o arquivo salvo de volta no Drive. Evento de sucesso ou falha é sempre registrado.\n",
        "4. **Limpeza dos arquivos temporários:**  \n",
        "   Após movimentação, vídeo e poster temporários no Colab são removidos. Falhas na limpeza são tratadas e logadas.\n",
        "5. **(Commit/push externo):**  \n",
        "   O gerenciamento de commit/push do Drive para o repositório remoto é feito por script externo, garantindo atomicidade e evitando conflitos.\n",
        "\n",
        "---\n",
        "\n",
        "## Exemplo de uso técnico\n",
        "\n",
        "```python\n",
        "upload_success, abyss_response, slug = upload_to_abyss_and_update_json(\n",
        "    filepath=arquivo_video,\n",
        "    username=\"usuario\",\n",
        "    duration_seconds=duracao,\n",
        "    poster_temp_path=caminho_poster_temp\n",
        ")\n",
        "# Após processamento em lote, execute o commit externo dos arquivos do Drive, se necessário.\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Segurança, rastreabilidade e integração\n",
        "\n",
        "- **Execução concorrente e CI/CD-ready:**  \n",
        "  Não depende de arquivos temporários após o término, e toda persistência é feita diretamente no Drive para máxima segurança.\n",
        "- **Rastreabilidade total:**  \n",
        "  Todas as etapas (upload, poster, rec.json, limpeza) são logadas detalhadamente para auditoria, reporting e troubleshooting.\n",
        "- **Design modular e resiliente:**  \n",
        "  Funções com robusto tratamento de exceções, logs claros, validação de estrutura JSON e fluxo pronto para expansão futura.\n",
        "- **Integração garantida com o pipeline XCam:**  \n",
        "  Estrutura, nomenclatura e fluxo de dados padronizados, compatíveis com as demais células e necessidades de manutenção/evolução.\n",
        "\n",
        "---\n",
        "\n",
        "## Observações e recomendações\n",
        "\n",
        "- Certifique-se de que o Google Drive está montado antes de executar esta célula.\n",
        "- O commit/push final dos arquivos no Drive deve ser feito por script externo, preferencialmente ao final do processamento em lote.\n",
        "- A URL do poster no rec.json presume que o conteúdo do Drive estará disponível publicamente via CDN, servidor web ou integração adequada.\n",
        "- Recomenda-se monitorar e analisar o log centralizado para garantir integridade do processo, detectar falhas precocemente e gerar relatórios de uso.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "YjGKDlbIKaLs"
      },
      "id": "YjGKDlbIKaLs"
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================\n",
        "# Célula 8: Upload para Abyss.to, Atualização do rec.json e Poster no Google Drive\n",
        "# ================================================================\n",
        "# Objetivo:\n",
        "# - Fazer upload do vídeo gravado para Abyss.to e registrar corretamente os metadados.\n",
        "# - Salvar gravação e poster temporariamente no Colab.\n",
        "# - Renomear poster temporário com slug (no Colab temp).\n",
        "# - LER/ESCREVER rec.json DIRETAMENTE no Google Drive.\n",
        "# - MOVER poster renomeado do Colab temp para o Google Drive.\n",
        "# - Limpar arquivos temporários locais após uso.\n",
        "# - Modular, preparado para CI/CD, concorrência e integração total ao pipeline XCam.\n",
        "# ================================================================\n",
        "\n",
        "# Caminho base no Google Drive para arquivos permanentes (rec.json, posters)\n",
        "DRIVE_USER_BASE = \"/content/drive/MyDrive/XCam.Drive/user\"\n",
        "\n",
        "def upload_to_abyss_and_update_json(\n",
        "    filepath, username, duration_seconds, poster_temp_path=None\n",
        "):\n",
        "    \"\"\"\n",
        "    Realiza upload do vídeo, atualiza rec.json do usuário (no Drive),\n",
        "    renomeia poster com slug (no Colab temp) e MOVE para o Google Drive.\n",
        "    - Salva gravação e poster temporariamente no Colab.\n",
        "    - LÊ/ESCREVE rec.json DIRETAMENTE no Drive.\n",
        "    - Renomeia poster temporário no Colab temp com o slug retornado.\n",
        "    - MOVE poster renomeado do Colab temp para o Drive.\n",
        "    - Limpa arquivos temporários locais após uso.\n",
        "    - Toda ação relevante é registrada no log centralizado via append_log().\n",
        "    \"\"\"\n",
        "    file_name = os.path.basename(filepath) # Nome do arquivo de vídeo renomeado (username_data_horario_tempo.mp4)\n",
        "    file_type = 'video/mp4'\n",
        "    print(f\"⬆️ Upload de: {file_name} para Abyss.to...\")\n",
        "\n",
        "    upload_success = False\n",
        "    abyss_response = \"Upload falhou - Sem resposta\"\n",
        "    uploaded_url = None\n",
        "    video_id = None\n",
        "    slug = None\n",
        "\n",
        "    # ---- Upload do vídeo para Abyss.to ----\n",
        "    try:\n",
        "        with open(filepath, 'rb') as f:\n",
        "            files = { 'file': (file_name, f, file_type) }\n",
        "            response = requests.post(ABYSS_UPLOAD_URL, files=files)\n",
        "            resp_json = response.json()\n",
        "            abyss_response = resp_json\n",
        "            if resp_json.get('status'):\n",
        "                upload_success = True\n",
        "                uploaded_url = resp_json.get('url') or resp_json.get('urlIframe')\n",
        "                video_id = resp_json.get('slug') or resp_json.get('video')\n",
        "                slug = video_id\n",
        "                print(f\"📤 Upload bem-sucedido. URL: {uploaded_url} | SLUG: {slug}\")\n",
        "                append_log({\n",
        "                    \"sessao\": \"upload\",\n",
        "                    \"evento\": \"upload_sucesso\",\n",
        "                    \"id\": username,\n",
        "                    \"username\": username,\n",
        "                    \"status\": \"ok\",\n",
        "                    \"detalhes\": f\"Arquivo {file_name} enviado para Abyss.to. URL: {uploaded_url}, SLUG: {slug}\"\n",
        "                })\n",
        "            else:\n",
        "                print(f\"❌ Falha no upload. Mensagem: {resp_json.get('message','')}\")\n",
        "                append_log({\n",
        "                    \"sessao\": \"upload\",\n",
        "                    \"evento\": \"upload_falhou\",\n",
        "                    \"id\": username,\n",
        "                    \"username\": username,\n",
        "                    \"status\": \"erro\",\n",
        "                    \"detalhes\": f\"Falha no upload. Mensagem: {resp_json.get('message','')}\"\n",
        "                })\n",
        "    except Exception as e:\n",
        "        abyss_response = f\"Erro no upload: {e}\"\n",
        "        print(f\"❌ Erro no upload: {e}\")\n",
        "        append_log({\n",
        "            \"sessao\": \"upload\",\n",
        "            \"evento\": \"upload_falhou\",\n",
        "            \"id\": username,\n",
        "            \"username\": username,\n",
        "            \"status\": \"erro\",\n",
        "            \"detalhes\": f\"Exceção no upload: {e}\"\n",
        "        })\n",
        "\n",
        "    poster_temp_renamed_path = None\n",
        "    drive_json_filepath = os.path.join(DRIVE_USER_BASE, username, \"rec.json\")\n",
        "    drive_user_dir = os.path.join(DRIVE_USER_BASE, username) # Pasta do usuário no Drive\n",
        "\n",
        "    if upload_success and slug:\n",
        "        # ---- Renomeia o poster temporário com o slug retornado (no diretório temporário do Colab) ----\n",
        "        # O poster_temp_path já está em TEMP_OUTPUT_FOLDER (gerado/baixado pela Célula 7)\n",
        "        if poster_temp_path and os.path.exists(poster_temp_path):\n",
        "            try:\n",
        "                # O novo nome será {slug}.jpg\n",
        "                poster_final_name = f\"{slug}.jpg\"\n",
        "                # A renomeação ocorre dentro do diretório TEMPORÁRIO do Colab\n",
        "                poster_temp_renamed_path = os.path.join(TEMP_OUTPUT_FOLDER, poster_final_name)\n",
        "                # Move (renomeia) o poster DENTRO do diretório temporário\n",
        "                shutil.move(poster_temp_path, poster_temp_renamed_path)\n",
        "                print(f\"🖼️ Poster temporário renomeado para {poster_final_name} em {TEMP_OUTPUT_FOLDER}\")\n",
        "                append_log({\n",
        "                    \"sessao\": \"poster\",\n",
        "                    \"evento\": \"poster_renomeado_temp\",\n",
        "                    \"id\": username,\n",
        "                    \"username\": username,\n",
        "                    \"status\": \"ok\",\n",
        "                    \"detalhes\": f\"Poster temporário renomeado para {poster_final_name} no Colab temp.\"\n",
        "                })\n",
        "            except Exception as e:\n",
        "                print(f\"❌ Erro ao renomear poster temporário no Colab: {e}\")\n",
        "                # Tenta limpar o poster temporário original se o renomeio falhar\n",
        "                if os.path.exists(poster_temp_path):\n",
        "                    try:\n",
        "                        os.remove(poster_temp_path)\n",
        "                    except Exception as clean_e:\n",
        "                        print(f\"⚠️ Falha ao limpar poster temporário original após erro: {clean_e}\")\n",
        "                poster_temp_renamed_path = None # Garante que não tentaremos mover um arquivo que não existe\n",
        "                append_log({\n",
        "                    \"sessao\": \"poster\",\n",
        "                    \"evento\": \"erro_renomear_poster_temp\",\n",
        "                    \"id\": username,\n",
        "                    \"username\": username,\n",
        "                    \"status\": \"erro\",\n",
        "                    \"detalhes\": f\"Erro ao renomear poster temporário no Colab: {e}\"\n",
        "                })\n",
        "        else:\n",
        "             print(f\"⚠️ Poster temporário não encontrado ou inválido para renomear com slug.\")\n",
        "             append_log({\n",
        "                \"sessao\": \"poster\",\n",
        "                \"evento\": \"poster_temp_nao_encontrado\",\n",
        "                \"id\": username,\n",
        "                \"username\": username,\n",
        "                \"status\": \"aviso\",\n",
        "                \"detalhes\": \"Poster temporário não encontrado ou inválido para renomear com slug.\"\n",
        "            })\n",
        "\n",
        "\n",
        "        # ---- Atualiza/Cria rec.json do usuário (DIRETAMENTE no Google Drive) ----\n",
        "        try:\n",
        "            # Caminho no Drive onde o rec.json deve estar/ser salvo\n",
        "            os.makedirs(drive_user_dir, exist_ok=True) # Garante que a pasta do usuário no Drive exista\n",
        "\n",
        "            file_base = file_name.replace('.mp4', '')\n",
        "            parts = file_base.split('_')\n",
        "            if len(parts) >= 4:\n",
        "                json_data = parts[-3]\n",
        "                json_horario = parts[-2]\n",
        "                json_tempo = parts[-1]\n",
        "            else:\n",
        "                now = datetime.now()\n",
        "                json_data = now.strftime(\"%d-%m-%Y\")\n",
        "                json_horario = now.strftime(\"%H-%M\")\n",
        "                json_tempo = format_seconds(duration_seconds)\n",
        "\n",
        "            # A URL do poster no rec.json aponta para onde ele estará PUBLICAMENTE disponível\n",
        "            # (presumindo que o conteúdo do Drive será servido ou sincronizado externamente)\n",
        "            poster_url_final = f\"https://db.xcam.gay/user/{username}/{slug}.jpg\" if slug else \"\"\n",
        "            url_iframe_final = f\"https://short.icu/{slug}?thumbnail={poster_url_final}\" if slug else \"\"\n",
        "\n",
        "            new_video_entry = {\n",
        "                \"video\": slug if slug else \"ID_não_retornado\",\n",
        "                \"title\": file_base,\n",
        "                \"file\": file_name, # O nome do arquivo de vídeo original é mantido como referência\n",
        "                \"url\": uploaded_url if uploaded_url else \"URL_não_retornada\",\n",
        "                \"poster\": poster_url_final, # Esta URL deve ser acessível publicamente\n",
        "                \"urlIframe\": url_iframe_final, # Esta URL deve ser acessível publicamente\n",
        "                \"data\": json_data,\n",
        "                \"horario\": json_horario,\n",
        "                \"tempo\": json_tempo\n",
        "            }\n",
        "\n",
        "            def zerar_base(username):\n",
        "                return {\n",
        "                    \"username\": username,\n",
        "                    \"records\": 0,\n",
        "                    \"videos\": []\n",
        "                }\n",
        "\n",
        "            # Carrega ou inicializa rec.json (DIRETAMENTE do Drive)\n",
        "            rec_data = zerar_base(username) # Inicializa com base zero por segurança\n",
        "            if os.path.exists(drive_json_filepath):\n",
        "                 try:\n",
        "                     with open(drive_json_filepath, 'r', encoding='utf-8') as f:\n",
        "                         loaded = json.load(f)\n",
        "                     # Valida se a estrutura carregada é razoável, senão cria uma nova\n",
        "                     valid = (\n",
        "                         isinstance(loaded, dict)\n",
        "                         and \"username\" in loaded\n",
        "                         and \"records\" in loaded\n",
        "                         and \"videos\" in loaded\n",
        "                         and isinstance(loaded[\"videos\"], list)\n",
        "                     )\n",
        "                     rec_data = loaded if valid else zerar_base(username)\n",
        "                     print(f\"📝 Carregado rec.json existente do Drive para {username}\")\n",
        "                 except Exception as read_drive_e:\n",
        "                      print(f\"⚠️ Erro ao ler rec.json existente no Drive ({drive_json_filepath}), criando novo: {read_drive_e}\")\n",
        "                      # Se der erro na leitura, rec_data já está zerada\n",
        "\n",
        "            # Adiciona novo vídeo ao histórico (no objeto carregado/novo)\n",
        "            rec_data[\"records\"] += 1\n",
        "            rec_data[\"videos\"].append(new_video_entry)\n",
        "\n",
        "            # Salva rec.json (DIRETAMENTE no Drive)\n",
        "            with open(drive_json_filepath, 'w', encoding='utf-8') as f:\n",
        "                json.dump(rec_data, f, indent=2, ensure_ascii=False)\n",
        "            print(f\"✅ rec.json para {username} atualizado DIRETAMENTE no Drive: {drive_json_filepath}\")\n",
        "\n",
        "            append_log({\n",
        "                \"sessao\": \"recjson\",\n",
        "                \"evento\": \"recjson_atualizado_drive\",\n",
        "                \"id\": username,\n",
        "                \"username\": username,\n",
        "                \"status\": \"ok\",\n",
        "                \"detalhes\": f\"rec.json atualizado diretamente no Drive em {drive_json_filepath}\"\n",
        "            })\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Erro ao atualizar rec.json no Drive: {e}\")\n",
        "            abyss_response = f\"Upload sucesso, erro no JSON do Drive: {e}\"\n",
        "            # json_temp_path = None # Não existe mais json_temp_path neste fluxo\n",
        "            append_log({\n",
        "                \"sessao\": \"recjson\",\n",
        "                \"evento\": \"erro_atualizar_recjson_drive\",\n",
        "                \"id\": username,\n",
        "                \"username\": username,\n",
        "                \"status\": \"erro\",\n",
        "                \"detalhes\": f\"Erro ao atualizar rec.json no Drive: {e}\"\n",
        "            })\n",
        "\n",
        "\n",
        "        # ---- MOVER poster renomeado (do Colab temp) para o Google Drive ----\n",
        "        if poster_temp_renamed_path and os.path.exists(poster_temp_renamed_path):\n",
        "            # O destino é a pasta do usuário no Drive\n",
        "            drive_poster_filepath = os.path.join(drive_user_dir, os.path.basename(poster_temp_renamed_path))\n",
        "            try:\n",
        "                shutil.move(poster_temp_renamed_path, drive_poster_filepath)\n",
        "                print(f\"🗂️ Poster movido para o Drive: {drive_poster_filepath}\")\n",
        "                append_log({\n",
        "                    \"sessao\": \"poster\",\n",
        "                    \"evento\": \"poster_movido_drive\",\n",
        "                    \"id\": username,\n",
        "                    \"username\": username,\n",
        "                    \"status\": \"ok\",\n",
        "                    \"detalhes\": f\"Poster movido para o Drive em {drive_poster_filepath}\"\n",
        "                })\n",
        "            except Exception as e:\n",
        "                print(f\"❌ Falha ao MOVER poster para o Drive: {e}\")\n",
        "                append_log({\n",
        "                    \"sessao\": \"poster\",\n",
        "                    \"evento\": \"erro_mover_poster_drive\",\n",
        "                    \"id\": username,\n",
        "                    \"username\": username,\n",
        "                    \"status\": \"erro\",\n",
        "                    \"detalhes\": f\"Erro ao mover poster para o Drive: {e}\"\n",
        "                })\n",
        "        else:\n",
        "             print(f\"⚠️ Poster temporário renomeado não encontrado para mover para o Drive.\")\n",
        "             append_log({\n",
        "                \"sessao\": \"poster\",\n",
        "                \"evento\": \"poster_temp_renomeado_nao_encontrado\",\n",
        "                \"id\": username,\n",
        "                \"username\": username,\n",
        "                \"status\": \"aviso\",\n",
        "                \"detalhes\": \"Poster temporário renomeado não encontrado para mover para o Drive.\"\n",
        "            })\n",
        "\n",
        "\n",
        "    # ---- Limpeza do arquivo de vídeo temporário local ----\n",
        "    # Esta limpeza já estava presente no bloco finally da gravar_stream (Célula 7),\n",
        "    # mas vamos garantir aqui também por segurança, caso a chamada venha de outro lugar.\n",
        "    # O arquivo de vídeo renomeado está em TEMP_OUTPUT_FOLDER\n",
        "    if os.path.exists(filepath): # filepath é o caminho do vídeo renomeado em TEMP_OUTPUT_FOLDER\n",
        "        try:\n",
        "            os.remove(filepath)\n",
        "            print(f\"🗑️ Arquivo de vídeo temporário local removido: {filepath}\")\n",
        "            append_log({\n",
        "                \"sessao\": \"cleanup\",\n",
        "                \"evento\": \"remover_video_temp\",\n",
        "                \"id\": username,\n",
        "                \"username\": username,\n",
        "                \"status\": \"ok\",\n",
        "                \"detalhes\": f\"Arquivo de vídeo temporário local removido: {filepath}\"\n",
        "            })\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Não foi possível remover o arquivo de vídeo temporário local: {e}\")\n",
        "            append_log({\n",
        "                \"sessao\": \"cleanup\",\n",
        "                \"evento\": \"erro_remover_video_temp\",\n",
        "                \"id\": username,\n",
        "                \"username\": username,\n",
        "                \"status\": \"erro\",\n",
        "                \"detalhes\": f\"Erro ao remover arquivo de vídeo temporário local: {e}\"\n",
        "            })\n",
        "\n",
        "    # ---- Limpeza do diretório temporário do usuário, se estiver vazio ----\n",
        "    # O diretório temporário do usuário pode não ter sido criado se o upload falhou antes.\n",
        "    # TEMP_OUTPUT_FOLDER é o diretório geral. Não vamos remover subdiretórios específicos aqui.\n",
        "    # A limpeza do diretório temp do usuário pode ser feita de forma mais robusta em outro local ou manualmente.\n",
        "    # Manteremos a limpeza apenas dos arquivos específicos manipulados.\n",
        "\n",
        "    return upload_success, abyss_response, slug\n",
        "\n",
        "# A função de commit final pendente não é mais necessária, pois o commit é gerenciado externamente.\n",
        "# def commit_push_restantes():\n",
        "#     \"\"\"\n",
        "#     Esta função não é mais necessária pois o commit/push é gerenciado externamente.\n",
        "#     \"\"\"\n",
        "#     pass # Lógica de commit/push removida\n",
        "\n",
        "# ================================================================\n",
        "# FIM DA Célula 8 — Upload, Metadados e Posters no Google Drive (com log centralizado)\n",
        "# ================================================================\n",
        "\n",
        "# Observações:\n",
        "# - A gravação e o poster inicial ficam no Colab temp.\n",
        "# - O rec.json é lido e escrito DIRETAMENTE no Drive.\n",
        "# - O poster renomeado é MOVIDO do Colab temp para o Drive.\n",
        "# - Certifique-se de que o Google Drive esteja montado antes de executar esta célula.\n",
        "# - A URL do poster no rec.json (db.xcam.gay) presume que o conteúdo do Drive será servido publicamente de alguma forma.\n",
        "# - O commit/push agora é gerenciado por um script externo que deve ler os arquivos do Drive.\n",
        "# - Toda ação relevante registrada no log centralizado para total rastreabilidade/auditoria."
      ],
      "metadata": {
        "id": "vMTiCrJ5Kp81"
      },
      "id": "vMTiCrJ5Kp81",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Célula 9: Supervisor Dinâmico — Execução Paralela, Lote Sempre Cheio, Blacklist Centralizada e Log por ID\n",
        "\n",
        "**Objetivo:**  \n",
        "Orquestrar e controlar automaticamente todo o pipeline de gravação de transmissões ao vivo, garantindo execução paralela robusta, processamento contínuo, máxima eficiência no preenchimento do lote e total segurança contra duplicidade, concorrência indevida e usuários problemáticos.  \n",
        "A célula implementa um supervisor dinâmico que mantém o lote sempre cheio, preenche vagas em tempo real com transmissões válidas, consulta e respeita a blacklist temporária centralizada (por ID), previne duplicidade de gravação consultando o log central de processamento, e integra-se a todas as rotinas críticas do pipeline XCam (gravação, upload, rec.json, poster, limpeza, commit), promovendo rastreabilidade, resiliência e escalabilidade.\n",
        "\n",
        "---\n",
        "\n",
        "## Estratégia técnica, arquitetura e diferenciais\n",
        "\n",
        "- **Execução paralela segura via multiprocessing:**  \n",
        "  Utiliza múltiplos processos (`multiprocessing.Process`) para gravação simultânea, acelerando o throughput do pipeline e melhorando o aproveitamento de recursos computacionais (CPU, I/O).\n",
        "- **Supervisor dinâmico e lote sempre cheio:**  \n",
        "  O supervisor monitora ativamente as vagas livres no lote alvo (`pool_size`) e lança novas gravações assim que houver disponibilidade, evitando períodos ociosos e maximizando a produtividade.\n",
        "- **Controle centralizado de blacklist e processamento por ID:**  \n",
        "  Antes de iniciar qualquer gravação, consulta o log centralizado para verificar se o usuário (por `id`) está em blacklist temporária (sessao=\"blacklist\", status=\"blacklisted\") ou já está em processamento ativo (sessao=\"processing\", status=\"in_progress\"), evitando duplicidade e reprocessamento indevido.\n",
        "- **Busca inteligente, seleção e escalonamento:**  \n",
        "  Utiliza funções otimizadas para buscar transmissões válidas, tanto para listas específicas de usuários quanto para busca automática. Sempre respeita blacklist, status de processamento e disponibilidade da transmissão.\n",
        "- **Worker modular e integrado:**  \n",
        "  Cada worker processa a gravação de uma transmissão (por ID), realiza upload, atualização do rec.json/poster, limpeza de arquivos temporários, e integra-se ao log central. O status de cada operação é registrado detalhadamente.\n",
        "- **Logs robustos, padronizados e detalhados:**  \n",
        "  Todas as etapas críticas (início, finalização, busca, erro, status, preenchimento de vagas) geram logs com timestamp, contexto, nível e detalhes, tanto no console quanto no log centralizado (`xcam_master.log`).  \n",
        "  Eventos são classificados por nível (INFO, WORKER, BUSCA, ERRO, STATUS, RESUMO, END) e incluem sempre o ID do usuário quando relevante.\n",
        "- **Respeito rigoroso à blacklist temporária:**  \n",
        "  Usuários que atingiram o limite de falhas são bloqueados temporariamente por ID e não são reprocessados até expiração da blacklist, otimizando recursos e evitando loops problemáticos.\n",
        "- **Design modular, extensível e pronto para CI/CD:**  \n",
        "  Código segmentado em funções (supervisor, worker, busca, log), com separação clara de responsabilidades, facilitando manutenção, reuso, testes e integração com pipelines automáticos ou ambientes colaborativos (ex: Google Colab, runners de CI).\n",
        "\n",
        "---\n",
        "\n",
        "## Fluxo operacional detalhado\n",
        "\n",
        "1. **Inicialização e configuração:**  \n",
        "   - Determina modo operacional: gravação de usuários específicos (lista) ou busca automática.\n",
        "   - Calcula tamanho do lote alvo (`pool_size`), define variáveis globais e inicializa estruturas compartilhadas (ex: results via `Manager().list()`).\n",
        "   - Loga início do supervisor.\n",
        "\n",
        "2. **Preenchimento do lote inicial:**  \n",
        "   - Busca e seleciona transmissões livres, preenchendo o lote até atingir o tamanho alvo ou esgotar opções válidas.\n",
        "   - Para cada transmissão válida (não duplicada, não em blacklist, não em processamento), marca o usuário como \"in_progress\" no log centralizado (por ID) e lança um worker dedicado.\n",
        "\n",
        "3. **Supervisão dinâmica e ciclo de preenchimento contínuo:**  \n",
        "   - Monitora, em loop, o número de processos ativos (gravações em andamento).\n",
        "   - Assim que uma gravação finaliza, imediatamente busca e lança nova transmissão para preencher a vaga, mantendo o lote sempre cheio até esgotar transmissões disponíveis.\n",
        "   - Cada ciclo de busca e preenchimento é protegido contra duplicidade por consultas ao log de blacklist/processamento (por ID).\n",
        "\n",
        "4. **Logs e controle detalhados:**  \n",
        "   - Cada ação relevante (início/fim de gravação, erros, busca, preenchimento, status periódico) é logada com timestamp, nível e detalhes no log central e no console.\n",
        "   - Resultados de cada worker são armazenados e podem ser analisados ao final do processamento.\n",
        "\n",
        "5. **Encerramento e resumo:**  \n",
        "   - Quando não há mais transmissões disponíveis e todos os processos finalizam, supervisor encerra o ciclo e registra resumo dos resultados.\n",
        "   - Commit/push dos arquivos permanentes é gerenciado externamente, promovendo atomicidade e consistência.\n",
        "\n",
        "---\n",
        "\n",
        "## Exemplo de uso técnico\n",
        "\n",
        "```python\n",
        "# Função principal para disparar o supervisor dinâmico (interativo para escolha do modo)\n",
        "main()\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Detalhes técnicos e recomendações\n",
        "\n",
        "- **Fonte de verdade centralizada:**  \n",
        "  Toda lógica de blacklist, falhas, processamento ativo e controle de duplicidade é baseada no log centralizado e no ID único do usuário, promovendo consistência, rastreabilidade e integridade em ambientes paralelos.\n",
        "- **Pronto para execução concorrente e ambientes colaborativos:**  \n",
        "  Compatível com Google Colab, runners de CI/CD, servidores multiusuário e pipelines automáticos.\n",
        "- **Diagnóstico e manutenção facilitados:**  \n",
        "  Logs detalhados, estrutura modular e documentação clara facilitam troubleshooting, evolução e integração de novos recursos.\n",
        "- **Segurança, resiliência e eficiência:**  \n",
        "  O supervisor garante que nenhum usuário problemático trave o pipeline, nenhuma transmissão seja processada duas vezes, e o lote permaneça sempre no máximo da capacidade.\n",
        "- **Pré-requisitos de execução:**  \n",
        "  Certifique-se de executar previamente as Células 1, 3, 6, 7 e 8 para garantir inicialização correta do ambiente, variáveis globais, funções de log, gravação, upload e limpeza.\n",
        "\n",
        "---\n",
        "\n",
        "## Observações finais\n",
        "\n",
        "- **Toda lógica de controle (blacklist, falhas, processamento) é feita por ID, promovendo rastreabilidade e evitando ambiguidades.**\n",
        "- **O supervisor é o núcleo do pipeline, integrando e coordenando todas as rotinas críticas do XCam.**\n",
        "- **Expansível, pronto para novos modos de busca, integração com notificações, dashboards ou novos sistemas de storage.**\n",
        "- **A arquitetura Clean facilita onboarding de novos desenvolvedores e manutenção do ciclo de vida do projeto.**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "iwgt8f8iKq4y"
      },
      "id": "iwgt8f8iKq4y"
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "# ================================================================\n",
        "# Célula 9: Supervisor Dinâmico — Execução Paralela, Lote Sempre Cheio, Blacklist e Log Centralizado (AGORA USANDO ID)\n",
        "# ================================================================\n",
        "# Objetivo:\n",
        "# - Manter o lote de gravações sempre cheio, preenchendo vagas em tempo real com máxima eficiência e segurança.\n",
        "# - Garantir que usuários problemáticos (em blacklist - por ID) não sejam tentados novamente no ciclo vigente.\n",
        "# - Prevenir duplicidade consultando log central de processamento (por ID) antes de iniciar qualquer gravação.\n",
        "# - Integrar-se com a lógica de blacklist, commit/push automático, limpeza de recursos e log robusto, TUDO BASEADO NO ID.\n",
        "# - Modularidade e clareza, pronta para integração com pipelines CI/CD, execução concorrente e ambientes colaborativos.\n",
        "# ================================================================\n",
        "\n",
        "from multiprocessing import Process, Manager # Garantir imports\n",
        "\n",
        "def log_supervisor(msg, level=\"INFO\"):\n",
        "    \"\"\"\n",
        "    Log supervisor padronizado para todas as etapas do pipeline.\n",
        "    Também registra cada evento relevante no log centralizado (sessao supervisor).\n",
        "    Pode incluir ID/username se relevante para o evento.\n",
        "    \"\"\"\n",
        "    from datetime import datetime\n",
        "    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "    print(f\"[{timestamp}] [{level}] {msg}\")\n",
        "    # Registro também no log central (sessao supervisor)\n",
        "    append_log({\n",
        "        \"sessao\": \"supervisor\",\n",
        "        \"evento\": level,\n",
        "        \"id\": \"global\", # Evento global do supervisor\n",
        "        \"username\": \"global\",\n",
        "        \"status\": \"info\" if level != \"ERRO\" else \"erro\",\n",
        "        \"detalhes\": msg\n",
        "    })\n",
        "\n",
        "# Adicionando user_id como parâmetro para o worker\n",
        "def worker(user_id, username, m3u8_url, poster_path, results):\n",
        "    \"\"\"\n",
        "    Worker dedicado: grava a stream, faz upload, atualiza rec.json/poster, integra ao log.\n",
        "    Recebe o ID do usuário e o passa para a função gravar_stream (Célula 7).\n",
        "    O processamento é rastreado via log central, e o status final é adicionado à lista de resultados.\n",
        "    \"\"\"\n",
        "    # gravar_stream agora espera user_id como primeiro parâmetro\n",
        "    log_supervisor(f\"Iniciando gravação: '{username}' (ID: {user_id}) | URL: {m3u8_url[:50]}...\", \"WORKER\") # Loga o ID\n",
        "    result = gravar_stream(user_id, username, m3u8_url, poster_url=poster_path) # Passa user_id para gravar_stream\n",
        "    log_supervisor(\n",
        "        f\"Finalizou gravação: '{username}' (ID: {user_id}) | Sucesso: {result.get('upload_success')} | \" # Loga o ID\n",
        "        f\"Arquivo: {result.get('filename')} | Abyss: {result.get('abyss_response')}\", \"WORKER\")\n",
        "    results.append(result)\n",
        "    # Registro do resultado no log central (já feito dentro de gravar_stream, mas reforça aqui)\n",
        "    # append_log({\n",
        "    #     \"sessao\": \"supervisor\",\n",
        "    #     \"evento\": \"worker_result\",\n",
        "    #     \"id\": user_id, # Usa o ID aqui\n",
        "    #     \"username\": username,\n",
        "    #     \"status\": \"ok\" if result.get(\"upload_success\") else \"erro\",\n",
        "    #     \"detalhes\": str(result)\n",
        "    # })\n",
        "\n",
        "\n",
        "# Supervisor dinâmico, agora usando ID para controle de estado\n",
        "def supervisor_dinamico(usuarios_especificos=None):\n",
        "    \"\"\"\n",
        "    Supervisor dinâmico de transmissões ao vivo:\n",
        "    - Mantém o lote de gravações sempre cheio, preenchendo vagas em tempo real.\n",
        "    - Evita duplicidade e concorrência consultando log central (sessao=\"processing\", status=\"in_progress\"), AGORA PELO ID.\n",
        "    - Respeita blacklist centralizada (pelo ID), não processando usuários bloqueados no ciclo vigente.\n",
        "    - Log detalhado e modular para diagnóstico, CI/CD e rastreabilidade.\n",
        "    \"\"\"\n",
        "\n",
        "    # Determina o tamanho do lote com base no modo operacional\n",
        "    pool_size = LIMIT_DEFAULT if not usuarios_especificos else API_SEARCH_LIMIT\n",
        "    running = []\n",
        "    results = Manager().list()\n",
        "    # Não precisamos mais do seen_usernames local, pois o log central é a fonte de verdade para o estado (is_processing, is_in_blacklist)\n",
        "    # seen_usernames = set()\n",
        "\n",
        "    log_supervisor(f\"Supervisor dinâmico iniciado | Lote alvo: {pool_size} | Modo: {'específico' if usuarios_especificos else 'automático'}\")\n",
        "\n",
        "    # A função atualizar_seen_usernames local não é mais necessária,\n",
        "    # pois is_processing e is_in_blacklist consultam o log central diretamente.\n",
        "    # def atualizar_seen_usernames():\n",
        "    #     \"\"\"\n",
        "    #     Atualiza o conjunto de usernames já processados diretamente do log central (sessao='processing').\n",
        "    #     Garante robustez em ambientes concorrentes e previne duplicidade.\n",
        "    #     \"\"\"\n",
        "    #     entries = query_logs(sessao=\"processing\", status=\"in_progress\")\n",
        "    #     seen_usernames.update([e[\"username\"] for e in entries])\n",
        "\n",
        "    def buscar_nova_transmissao():\n",
        "        \"\"\"\n",
        "        Busca uma nova transmissão livre para preencher o lote:\n",
        "        - Modo específico: busca em lista fornecida (agora retorna ID).\n",
        "        - Modo automático: busca próxima transmissão livre disponível (agora retorna ID).\n",
        "        - Sempre consulta blacklist (pelo ID) e log central (pelo ID) antes de liberar.\n",
        "        \"\"\"\n",
        "        # Não precisamos mais chamar atualizar_seen_usernames() aqui.\n",
        "        # A lógica dentro de is_in_blacklist e is_processing consulta o log central diretamente.\n",
        "\n",
        "        if usuarios_especificos:\n",
        "            # buscar_usuarios_especificos agora retorna lista com ID\n",
        "            candidatos = buscar_usuarios_especificos(usuarios_especificos)\n",
        "            for s in candidatos:\n",
        "                user_id = s[\"id\"] # Captura o ID retornado pela função de busca\n",
        "                username = s[\"username\"]\n",
        "                # Verifica se o ID está em blacklist ou processando (AGORA CONSULTANDO PELO ID)\n",
        "                if not is_in_blacklist(user_id) and not is_processing(user_id):\n",
        "                    log_supervisor(f\"Nova transmissão encontrada (específico): '{username}' (ID: {user_id})\", \"BUSCA\") # Loga o ID\n",
        "                    return s # Retorna o dicionário com id, username, src, poster_path\n",
        "                else:\n",
        "                    # Loga que o ID está sendo ignorado\n",
        "                    status_detail = \"\"\n",
        "                    if is_in_blacklist(user_id): status_detail += \"blacklist \"\n",
        "                    if is_processing(user_id): status_detail += \"processing \"\n",
        "                    log_supervisor(f\"Usuário '{username}' (ID: {user_id}) já em {status_detail.strip()}, ignorando.\", \"BUSCA\")\n",
        "            log_supervisor(\"Nenhuma transmissão específica livre encontrada (todos em blacklist/log ou offline).\", \"BUSCA\")\n",
        "            return None\n",
        "        else:\n",
        "            # Busca otimizada: tenta até 10 vezes buscar próxima transmissão livre\n",
        "            for tentativa in range(1, 11):\n",
        "                log_supervisor(f\"Buscando próxima transmissão livre: tentativa {tentativa}\", \"BUSCA\")\n",
        "                # buscar_proxima_transmissao_livre agora retorna dicionário com ID\n",
        "                stream = buscar_proxima_transmissao_livre()\n",
        "                if stream:\n",
        "                    user_id = stream[\"id\"] # Captura o ID retornado pela função de busca\n",
        "                    username = stream[\"username\"]\n",
        "                    # Verifica se o ID está em blacklist ou processando (AGORA CONSULTANDO PELO ID)\n",
        "                    if not is_in_blacklist(user_id) and not is_processing(user_id):\n",
        "                        log_supervisor(f\"Nova transmissão encontrada: '{username}' (ID: {user_id})\", \"BUSCA\") # Loga o ID\n",
        "                        return stream # Retorna o dicionário com id, username, src, poster_path\n",
        "                    else:\n",
        "                        # Loga que o ID está sendo ignorado\n",
        "                        status_detail = \"\"\n",
        "                        if is_in_blacklist(user_id): status_detail += \"blacklist \"\n",
        "                        if is_processing(user_id): status_detail += \"processing \"\n",
        "                        log_supervisor(f\"Usuário '{username}' (ID: {user_id}) já em {status_detail.strip()}, ignorando.\", \"BUSCA\")\n",
        "                else:\n",
        "                    log_supervisor(f\"buscar_proxima_transmissao_livre retornou None na tentativa {tentativa}.\", \"BUSCA\")\n",
        "\n",
        "            log_supervisor(\"Nenhuma transmissão livre encontrada após tentativas (todos em blacklist/log ou offline).\", \"BUSCA\")\n",
        "            return None\n",
        "\n",
        "    # ========== Fase 1: Preenchimento do lote inicial ==========\n",
        "    log_supervisor(f\"Preenchendo lote inicial com até {pool_size} transmissões...\", \"STARTUP\")\n",
        "    tentativas = 0\n",
        "    max_tentativas = 100 # Limita as tentativas totais para preencher o lote inicial\n",
        "    while len(running) < pool_size and tentativas < max_tentativas:\n",
        "        stream = buscar_nova_transmissao() # Retorna dicionário com id, username, src, poster_path\n",
        "        if not stream:\n",
        "            log_supervisor(\"Fim das transmissões disponíveis para preencher lote inicial.\", \"STARTUP\")\n",
        "            break # Sai do loop se não encontrar mais streams\n",
        "\n",
        "        user_id = stream[\"id\"] # Obtém o ID do dicionário retornado\n",
        "        username = stream[\"username\"]\n",
        "        m3u8_url = stream[\"src\"]\n",
        "        poster_path = stream[\"poster_path\"] # Caminho do poster temporário válido\n",
        "\n",
        "\n",
        "        # Marca no log central como em processamento para evitar duplicidade (USANDO ID)\n",
        "        mark_processing(user_id, username) # Passa user_id e username\n",
        "\n",
        "        log_supervisor(f\"Lançando processo para: '{username}' (ID: {user_id}) | {len(running)+1}/{pool_size}\", \"STARTUP\") # Loga o ID\n",
        "        # Passa o user_id para a função worker\n",
        "        p = Process(target=worker, args=(user_id, username, m3u8_url, poster_path, results))\n",
        "        running.append(p)\n",
        "        p.start()\n",
        "        tentativas += 1 # Incrementa tentativas\n",
        "\n",
        "    log_supervisor(f\"Lote inicial lançado com {len(running)} transmissões.\", \"STARTUP\")\n",
        "\n",
        "\n",
        "    # ========== Fase 2: Loop dinâmico de preenchimento contínuo ==========\n",
        "    # Monitora processos ativos e busca novas streams para manter o lote cheio\n",
        "    while True:\n",
        "        # Atualiza a lista de processos ativos\n",
        "        antes = len(running)\n",
        "        running = [p for p in running if p.is_alive()]\n",
        "        depois = len(running)\n",
        "\n",
        "        # Se algum processo finalizou\n",
        "        if antes != depois:\n",
        "            log_supervisor(f\"{antes-depois} gravações finalizaram. Vagas livres: {pool_size-len(running)}\", \"LOOP\")\n",
        "\n",
        "        vagas_livres = pool_size - len(running)\n",
        "\n",
        "        # Se houver vagas livres, busca novas streams para preencher\n",
        "        if vagas_livres > 0:\n",
        "            # Busca até o número de vagas livres, mas com limite de tentativas para não travar\n",
        "            preenchidas_nesta_rodada = 0\n",
        "            for _ in range(vagas_livres):\n",
        "                stream = buscar_nova_transmissao() # Retorna dicionário com id, username, src, poster_path\n",
        "                if not stream:\n",
        "                    # Se não encontrar mais streams disponíveis após todas as tentativas internas, sai do loop de preenchimento\n",
        "                    log_supervisor(\"Não há mais transmissões para preencher as vagas livres.\", \"LOOP\")\n",
        "                    break # Sai do loop interno de preenchimento de vagas\n",
        "\n",
        "                user_id = stream[\"id\"] # Obtém o ID do dicionário retornado\n",
        "                username = stream[\"username\"]\n",
        "                m3u8_url = stream[\"src\"]\n",
        "                poster_path = stream[\"poster_path\"] # Caminho do poster temporário válido\n",
        "\n",
        "                # Marca no log central como em processamento (USANDO ID)\n",
        "                mark_processing(user_id, username) # Passa user_id e username\n",
        "\n",
        "                log_supervisor(f\"Lançando nova gravação: '{username}' (ID: {user_id}) | Vaga preenchida {len(running)+1}/{pool_size}\", \"LOOP\") # Loga o ID\n",
        "                # Passa o user_id para a função worker\n",
        "                p = Process(target=worker, args=(user_id, username, m3u8_url, poster_path, results))\n",
        "                running.append(p)\n",
        "                p.start()\n",
        "                preenchidas_nesta_rodada += 1 # Conta quantas vagas foram preenchidas nesta rodada\n",
        "\n",
        "            if preenchidas_nesta_rodada == 0 and vagas_livres > 0 and not stream:\n",
        "                 # Condição para sair do loop principal: não há processos rodando E não há mais streams disponíveis\n",
        "                 # (a busca_nova_transmissao retornou None após várias tentativas)\n",
        "                 if not running:\n",
        "                      log_supervisor(\"Não há processos ativos e não há mais transmissões disponíveis.\", \"END\")\n",
        "                      break\n",
        "\n",
        "\n",
        "        # Se não houver processos rodando e não conseguimos preencher nenhuma vaga nesta rodada,\n",
        "        # significa que todas as transmissões disponíveis já foram processadas ou estão em blacklist/processing.\n",
        "        # A condição `if not stream:` dentro do loop de vagas + `if not running:` fora do loop de vagas\n",
        "        # já lida com isso, mas podemos adicionar uma checagem explícita.\n",
        "        # if not running and vagas_livres == pool_size and stream is None:\n",
        "        #      log_supervisor(\"Todas as transmissões possíveis já foram processadas ou estão bloqueadas.\", \"END\")\n",
        "        #      break\n",
        "\n",
        "\n",
        "        # Log de status periódico\n",
        "        log_supervisor(\n",
        "            f\"Transmissões ativas: {len(running)} | Lote alvo: {pool_size} | Buffer de resultados: {len(results)}\",\n",
        "            \"STATUS\"\n",
        "        )\n",
        "\n",
        "        # Aguarda um pouco antes de verificar novamente\n",
        "        time.sleep(5) # Aumentado o sleep para reduzir a frequência da busca quando o lote está cheio\n",
        "\n",
        "        # Condição de saída mais robusta: se não há processos rodando E a última busca não encontrou streams\n",
        "        if not running and (stream is None or (isinstance(stream, list) and len(stream) == 0)):\n",
        "             log_supervisor(\"Não há processos ativos e a última busca não encontrou transmissões.\", \"END\")\n",
        "             break\n",
        "\n",
        "\n",
        "    # ========== Fase 3: Finalização ==========\n",
        "    log_supervisor(f\"Processamento dinâmico concluído! Total de transmissões gravadas/processadas: {len(results)}\", \"RESUMO\")\n",
        "    # A chamada para commit_push_restantes() foi removida pois o commit é gerenciado externamente.\n",
        "    log_supervisor(\"Supervisor dinâmico finalizado.\", \"END\")\n",
        "\n",
        "\n",
        "# Função principal para iniciar o supervisor\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Função principal: inicia o notebook perguntando se o usuário quer gravar transmissões específicas ou automáticas.\n",
        "    Dispara o supervisor dinâmico na modalidade selecionada.\n",
        "    \"\"\"\n",
        "    # Certificar-se que as variáveis globais essenciais da Célula 1 estão carregadas\n",
        "    # Isso é feito executando a Célula 1 antes desta.\n",
        "    if 'LOG_PATH' not in globals():\n",
        "        print(\"⚠️ Variáveis globais da Célula 1 não carregadas. Execute a Célula 1 primeiro.\")\n",
        "        return # Sai se a Célula 1 não foi executada\n",
        "\n",
        "    usuarios_especificos = perguntar_transmissoes_especificas() # perguntar_transmissoes_especificas está na Célula 1\n",
        "    log_supervisor(\"Iniciando busca e gravação de streams (supervisor dinâmico)...\", \"MAIN\")\n",
        "    supervisor_dinamico(usuarios_especificos=usuarios_especificos)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Garante que as funções de log da Célula 1 estejam disponíveis\n",
        "    # Em um notebook, geralmente as células são executadas em ordem,\n",
        "    # então Célula 1 já teria definido append_log, query_logs, etc.\n",
        "    # Se rodando como script Python, precisaria importar ou definir as funções de log aqui.\n",
        "    # Para o contexto do Colab, assume-se que Célula 1 já rodou.\n",
        "\n",
        "    # Adicionando um try-except para garantir que main() seja chamada\n",
        "    # apenas se estiver em um ambiente interativo como Colab/IPython\n",
        "    try:\n",
        "        if 'google.colab' in str(get_ipython()):\n",
        "            main()\n",
        "        else:\n",
        "            print(\"Não está rodando em Colab/IPython. Execute main() manualmente se desejar.\")\n",
        "    except NameError:\n",
        "        print(\"Não está rodando em Colab/IPython. Execute main() se desejar.\")\n",
        "\n",
        "\n",
        "# ================================================================\n",
        "# FIM DA CÉLULA 9 — Supervisor Dinâmico, Lote Cheio e Blacklist Centralizados (AGORA USANDO ID)\n",
        "# ================================================================\n",
        "\n",
        "# Observações e recomendações:\n",
        "# - Toda lógica de blacklist, processamento e falhas agora se baseia no ID único do usuário no log centralizado para máxima rastreabilidade.\n",
        "# - O log central é a fonte de verdade para sincronização entre workers/processos.\n",
        "# - Modularidade, logs claros e tratamento de erro garantem manutenção e evolução seguras.\n",
        "# - Pronto para ambientes colaborativos (Colab, CI/CD, pipelines paralelos).\n",
        "# - Certifique-se de executar as Células 1, 3, 6, 7 e 8 antes desta."
      ],
      "metadata": {
        "id": "5WKQV9g_LB9M"
      },
      "id": "5WKQV9g_LB9M",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2eac76d"
      },
      "source": [
        "# Célula XX: Limpeza do Arquivo de Log Central do Google Drive\n",
        "\n",
        "**Objetivo:**\\\n",
        "Esta célula permite remover o arquivo de log central (`xcam_master.log`) do Google Drive. É uma operação útil para limpar um log corrompido que esteja causando erros (como `JSONDecodeError` ou `UnicodeDecodeError`) ou simplesmente para iniciar o registro de eventos do zero.\n",
        "\n",
        "## Principais pontos e funcionalidades\n",
        "\n",
        "- **Remoção segura:** Verifica se o arquivo de log existe antes de tentar removê-lo.\n",
        "- **Tratamento de erros:** Inclui um bloco `try-except` para capturar e reportar quaisquer problemas que possam ocorrer durante a remoção do arquivo.\n",
        "- **Feedback claro:** Imprime mensagens indicando se o arquivo foi removido com sucesso, se houve um erro ou se o arquivo não foi encontrado.\n",
        "- **Utilidade para depuração:** Essencial para resetar o estado do log quando ele se corrompe devido a falhas inesperadas de escrita ou outros problemas de sistema de arquivos.\n",
        "\n",
        "* * *\n",
        "\n",
        "## Como funciona a célula\n",
        "\n",
        "- **Define o caminho** completo para o arquivo de log central no Google Drive.\n",
        "- **Verifica** se o arquivo existe nesse local.\n",
        "- **Tenta remover** o arquivo.\n",
        "- **Imprime** o resultado da operação (sucesso, erro ou arquivo não encontrado).\n",
        "\n",
        "* * *\n",
        "\n",
        "## Exemplo de execução"
      ],
      "id": "d2eac76d"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8332447"
      },
      "source": [
        "import os\n",
        "\n",
        "log_file_drive = '/content/drive/MyDrive/XCam.Drive/logs/xcam_master.log'\n",
        "if os.path.exists(log_file_drive):\n",
        "    try:\n",
        "        os.remove(log_file_drive)\n",
        "        print(f\"Arquivo de log do Drive removido: {log_file_drive}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Erro ao remover arquivo de log do Drive: {e}\")\n",
        "else:\n",
        "    print(f\"Arquivo de log do Drive não encontrado: {log_file_drive}\")"
      ],
      "id": "c8332447",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5d23bd8d"
      },
      "source": [
        "# Célula 1: Configuração Global, Parâmetros e Log Centralizado Robusto (JSONL no Google Drive, Usando ID)\n",
        "\n",
        "**Objetivo:**\\\n",
        "Esta célula é a base do pipeline do notebook. Ela centraliza todas as configurações globais essenciais, define os caminhos importantes e, crucialmente, estabelece um sistema de log único, estruturado e robusto para registrar e gerenciar o estado de todo o processo.\n",
        "\n",
        "## Principais pontos e funcionalidades\n",
        "\n",
        "- **Configurações Centrais:** Define e propaga variáveis globais que controlam diversos aspectos do pipeline (limites de busca, duração de gravação, timeouts, etc.).\n",
        "- **Montagem do Google Drive:** Prepara o ambiente montando seu Google Drive, permitindo a persistência de dados importantes como o log central e os arquivos de usuário (`rec.json`, posters).\n",
        "- **Log Único Estruturado (JSONL):** Implementa um sistema de log centralizado em um arquivo no formato JSON Lines (`xcam_master.log`). Cada evento relevante do pipeline é registrado neste arquivo com uma estrutura definida (`sessao`, `evento`, `id`, `username`, `status`, `detalhes`).\n",
        "- **Uso do ID como Chave Primária no Log:** Garante que a lógica de controle de estado (blacklist, processamento, falhas) no log se baseie no `id` único do usuário fornecido pela API, aumentando a precisão e a robustez, mantendo o `username` para referência humana.\n",
        "- **Persistência no Google Drive:** O arquivo de log central é salvo diretamente em um diretório no seu Google Drive (`/content/drive/MyDrive/XCam.Drive/logs/`), garantindo que o histórico de execução, blacklist e falhas seja mantido entre as sessões do Colab. O diretório é criado automaticamente se não existir.\n",
        "- **Utilitários Abrangentes de Log:** Fornece um conjunto completo de funções para interagir com o log central:\n",
        "    - **`append_log`:** Adiciona novas entradas, lidando com unicidade lógica para estados críticos (como \"em processamento\" ou \"blacklisted\") atualizando entradas existentes em vez de duplicar. Inclui tratamento de erro robusto para ignorar linhas inválidas durante a leitura e garantir a escrita.\n",
        "    - **`read_logs`:** Lê todas as entradas válidas do arquivo de log, com tratamento de erro linha a linha para ignorar corrupções parciais.\n",
        "    - **`query_logs`:** Permite filtrar e buscar entradas do log com base em múltiplos critérios (sessão, ID, username, status, etc.), essencial para verificar o estado do pipeline e de usuários específicos.\n",
        "    - **`remove_logs`:** Remove entradas do log que satisfazem uma condição, útil para limpar registros expirados (como blacklist temporária vencida).\n",
        "    - **`update_log_entry`:** Permite modificar entradas existentes que correspondem a uma condição, para atualizar status ou detalhes.\n",
        "- **Tratamento de Erros na Leitura do Log:** As funções de leitura (`append_log`, `read_logs`) são resilientes a `JSONDecodeError` e `UnicodeDecodeError`, ignorando linhas inválidas com avisos em vez de travar a execução completa do notebook, embora a remoção do arquivo corrompido seja a solução ideal para a causa raiz.\n",
        "- **Função Interativa:** Inclui uma função para perguntar ao usuário se deseja processar usuários específicos no início da execução.\n",
        "\n",
        "* * *\n",
        "\n",
        "## Como funciona a célula\n",
        "\n",
        "- Monta o Google Drive.\n",
        "- Define e propaga as variáveis de configuração global via `globals().update()`.\n",
        "- Define a localização do log central no Google Drive e garante a criação do diretório necessário.\n",
        "- Define todas as funções do utilitário de log (`now_iso`, `make_id_username`, `append_log`, `read_logs`, `query_logs`, `remove_logs`, `update_log_entry`).\n",
        "- Define a função interativa `perguntar_transmissoes_especificas`.\n",
        "\n",
        "* * *\n",
        "\n",
        "## Exemplo de execução\n",
        "\n",
        "Esta célula não produz uma saída visível direta (além da montagem do Drive e da mensagem de criação do diretório de logs), mas sua execução é **obrigatória antes de qualquer outra célula** que dependa das configurações globais, caminhos ou do sistema de log centralizado."
      ],
      "id": "5d23bd8d"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "c9hve1ySGVAs"
      ],
      "cell_execution_strategy": "setup",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}