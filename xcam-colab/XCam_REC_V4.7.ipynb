{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SamuelPassamani/XCam/blob/main/xcam-colab/XCam_REC_V4.7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c9hve1ySGVAs",
      "metadata": {
        "id": "c9hve1ySGVAs"
      },
      "source": [
        "# C√©lula 1: Configura√ß√µes Auxiliares, Par√¢metros Globais e Log Centralizado\n",
        "\n",
        "**Objetivo:**  \n",
        "Esta c√©lula inicializa e centraliza todas as vari√°veis globais, par√¢metros essenciais e agora tamb√©m fornece um utilit√°rio robusto para o log √∫nico do notebook XCam.  \n",
        "Permite ajuste r√°pido e seguro do comportamento do notebook, incluindo limites de processamento, controle de grava√ß√£o, commit autom√°tico e mecanismos de resili√™ncia contra transmiss√µes problem√°ticas.\n",
        "\n",
        "## Principais pontos e melhorias implementadas\n",
        "\n",
        "- **Centraliza√ß√£o dos par√¢metros globais:**  \n",
        "  Todos os valores cr√≠ticos (limites, thresholds, caminhos) s√£o definidos e propagados como globais pelo notebook.\n",
        "- **Log √∫nico modular e estruturado (`xcam_master.log`):**  \n",
        "  Todas as opera√ß√µes relevantes (busca, grava√ß√£o, blacklist, commit, erros, etc.) agora s√£o registradas em um √∫nico arquivo JSON Lines.  \n",
        "  Cada entrada inclui sess√£o, evento, id, username, timestamps, status e detalhes.\n",
        "- **Fun√ß√µes utilit√°rias para o log:**  \n",
        "  Adi√ß√£o, busca, remo√ß√£o e atualiza√ß√£o de eventos s√£o facilitadas por fun√ß√µes modulares (CRUD), promovendo robustez, rastreabilidade e f√°cil manuten√ß√£o.\n",
        "- **Blacklist, falhas e processamento padronizados por `id`:**  \n",
        "  Toda l√≥gica de controle √© feita via identificador √∫nico, com `username` para exibi√ß√£o, garantindo unicidade e eliminando inconsist√™ncias.\n",
        "- **Fun√ß√£o interativa para sele√ß√£o de transmiss√µes espec√≠ficas:**  \n",
        "  Permite ao usu√°rio informar nomes de usu√°rios para filtrar transmiss√µes antes do processamento.\n",
        "- **Coment√°rios detalhados:**  \n",
        "  Cada etapa do c√≥digo est√° documentada para orientar ajustes, manuten√ß√£o e integra√ß√£o por toda a equipe.\n",
        "\n",
        "---\n",
        "\n",
        "## Par√¢metros globais controlados nesta c√©lula\n",
        "\n",
        "- **`LIMIT_DEFAULT`**: Quantidade m√°xima de transmiss√µes processadas em paralelo/lote.\n",
        "- **`PAGE_DEFAULT`**: P√°gina inicial para busca na API.\n",
        "- **`RECORD_SECONDS`**: Tempo m√°ximo de grava√ß√£o de cada v√≠deo (em segundos).\n",
        "- **`RECORD_SECONDS_MIN`**: Tempo m√≠nimo exigido para considerar o v√≠deo v√°lido (em segundos).\n",
        "- **`API_SEARCH_LIMIT`**: Limite de transmiss√µes retornadas ao buscar usu√°rios espec√≠ficos.\n",
        "- **`COMMIT_PUSH_THRESHOLD`**: Quantidade de transmiss√µes processadas at√© realizar commit/push autom√°tico (0 = commit imediato a cada grava√ß√£o).\n",
        "- **`LOGS_PATH`**: Caminho do arquivo √∫nico de log (JSONL).\n",
        "- **`BLACKLIST_TIMEOUT`**: Tempo de expira√ß√£o da blacklist (em segundos).\n",
        "- **`BLACKLIST_MAX_FAILURES`**: Quantidade de falhas consecutivas antes de banir temporariamente o usu√°rio.\n",
        "\n",
        "---\n",
        "\n",
        "## Estrutura do log √∫nico (`xcam_master.log`)\n",
        "\n",
        "Cada entrada segue o modelo:\n",
        "```json\n",
        "{\n",
        "  \"timestamp\": \"2025-06-06T06:15:00Z\",\n",
        "  \"sessao\": \"busca|grava√ß√£o|blacklist|commit|erro|...\",\n",
        "  \"evento\": \"...\",\n",
        "  \"id\": \"...\",         // identificador √∫nico (prim√°rio)\n",
        "  \"username\": \"...\",   // nome do usu√°rio para exibi√ß√£o\n",
        "  \"status\": \"...\",     // ok|erro|blacklisted|expirado|...\n",
        "  \"detalhes\": \"...\",   // informa√ß√µes adicionais\n",
        "}\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Fun√ß√µes utilit√°rias para o log\n",
        "\n",
        "- **`append_log(entry, logs_path=LOGS_PATH)`**: Adiciona uma nova entrada ao log central.\n",
        "- **`read_logs(logs_path=LOGS_PATH)`**: L√™ todas as entradas do log.\n",
        "- **`query_logs(...)`**: Consulta entradas do log por filtros opcionais (sess√£o, id, status, etc).\n",
        "- **`remove_logs(condition_fn, logs_path=LOGS_PATH)`**: Remove todas as entradas que satisfa√ßam a condi√ß√£o.\n",
        "- **`update_log_entry(match_fn, update_fn, logs_path=LOGS_PATH)`**: Atualiza entradas do log conforme regra.\n",
        "\n",
        "---\n",
        "\n",
        "## Exemplo de uso das fun√ß√µes (a serem aplicadas nas pr√≥ximas c√©lulas)\n",
        "\n",
        "```python\n",
        "append_log({\n",
        "    \"sessao\": \"busca\",\n",
        "    \"evento\": \"encontrado\",\n",
        "    \"id\": \"abc123\",\n",
        "    \"username\": \"Manugic_\",\n",
        "    \"status\": \"ok\",\n",
        "    \"detalhes\": \"URL v√°lida\"\n",
        "})\n",
        "\n",
        "# Consultar blacklist:\n",
        "logs_blacklist = query_logs(sessao=\"blacklist\", status=\"blacklisted\")\n",
        "\n",
        "# Remover registros expirados:\n",
        "remove_logs(lambda entry: entry[\"sessao\"] == \"processing\" and expirou(entry), logs_path=LOGS_PATH)\n",
        "\n",
        "# Atualizar status:\n",
        "update_log_entry(lambda e: e[\"id\"]==\"abc123\", lambda e: e.update({\"status\":\"ok\"}))\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Fun√ß√£o interativa\n",
        "\n",
        "Permite ao usu√°rio informar transmiss√µes espec√≠ficas a serem gravadas antes de iniciar o processamento.\n",
        "\n",
        "---\n",
        "\n",
        "## Seguran√ßa, rastreabilidade e manuten√ß√£o\n",
        "\n",
        "- Todos os par√¢metros globais s√£o definidos no in√≠cio e propagados para todo o notebook, garantindo consist√™ncia.\n",
        "- O log √∫nico fornece rastreabilidade detalhada e elimina arquivos dispersos (blacklist, falha, etc).\n",
        "- Ajuste qualquer valor diretamente nesta c√©lula para alterar o comportamento global do notebook de forma segura.\n",
        "- Coment√°rios detalhados auxiliam a compreens√£o, integra√ß√£o e manuten√ß√£o por toda a equipe.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "j5pPh353GLMD",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5pPh353GLMD",
        "outputId": "a2303e92-306f-461c-e214-84c611a44e1e"
      },
      "outputs": [],
      "source": [
        "# ================================================================\n",
        "# C√©lula 1: Configura√ß√£o Global, Par√¢metros e Utilit√°rio de Log √önico\n",
        "# ================================================================\n",
        "# Objetivo:\n",
        "# - Centralizar configura√ß√µes globais e thresholds\n",
        "# - Definir e montar caminhos do notebook\n",
        "# - Fornecer utilit√°rio robusto para LOG √öNICO MODULAR (JSONL)\n",
        "#   => Todas as c√©lulas e fun√ß√µes usar√£o este log para registrar, consultar e manipular eventos\n",
        "# - Garantir padroniza√ß√£o, rastreabilidade e f√°cil manuten√ß√£o futura\n",
        "#\n",
        "# Estrat√©gia aplicada (conforme plano):\n",
        "# - Log √∫nico estruturado (JSONL): sess√£o, evento, id, username, timestamps, status, detalhes\n",
        "# - Fun√ß√µes CRUD para log: adicionar, buscar, atualizar, remover (para blacklist, processing, falhas, auditoria)\n",
        "# - Blacklist e controles baseados em id (com username apenas para exibi√ß√£o)\n",
        "# - Par√¢metros globais facilmente edit√°veis e propagados via globals()\n",
        "# ================================================================\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# ============================\n",
        "# PAR√ÇMETROS GLOBAIS EDIT√ÅVEIS\n",
        "# ============================\n",
        "# Modifique abaixo conforme necessidade do ambiente ou processamento\n",
        "\n",
        "# Limites e thresholds principais de processamento\n",
        "LIMIT_DEFAULT = 50             # M√°ximo de transmiss√µes processadas por rodada\n",
        "PAGE_DEFAULT = 1               # P√°gina padr√£o para busca na API\n",
        "RECORD_SECONDS = 12780         # Dura√ß√£o m√°xima da grava√ß√£o (em segundos)\n",
        "RECORD_SECONDS_MIN = 660       # Dura√ß√£o m√≠nima v√°lida (em segundos)\n",
        "API_SEARCH_LIMIT = 1500        # Limite ao buscar usu√°rios espec√≠ficos\n",
        "COMMIT_PUSH_THRESHOLD = 25     # Quantidade de transmiss√µes at√© commit/push autom√°tico (0 = commit imediato)\n",
        "\n",
        "# Caminhos de arquivos principais (Google Drive)\n",
        "POSTER_TEMP_PATH = \"/content/drive/MyDrive/XCam.Drive/src/temp/posters\"\n",
        "RECORD_TEMP_PATH = \"/content/drive/MyDrive/XCam.Drive/src/temp/records\"\n",
        "LOGS_PATH = \"/content/drive/MyDrive/XCam.Drive/src/logs/xcam_master.log\"\n",
        "BLACKLIST_TIMEOUT = 15 * 60\n",
        "BLACKLIST_MAX_FAILURES = 3\n",
        "\n",
        "# Cria√ß√£o dos diret√≥rios se n√£o existirem\n",
        "import os\n",
        "import json\n",
        "for path in [POSTER_TEMP_PATH, RECORD_TEMP_PATH, os.path.dirname(LOGS_PATH)]:\n",
        "    os.makedirs(path, exist_ok=True)\n",
        "\n",
        "# ============================\n",
        "# ATUALIZA√á√ÉO GLOBAL DOS PAR√ÇMETROS\n",
        "# ============================\n",
        "# Propaga par√¢metros como globais do notebook\n",
        "globals().update({\n",
        "    'POSTER_TEMP_PATH': POSTER_TEMP_PATH,\n",
        "    'RECORD_TEMP_PATH': RECORD_TEMP_PATH,\n",
        "    'LOG_PATH': LOGS_PATH,\n",
        "    'LIMIT_DEFAULT': LIMIT_DEFAULT,\n",
        "    'PAGE_DEFAULT': PAGE_DEFAULT,\n",
        "    'RECORD_SECONDS': RECORD_SECONDS,\n",
        "    'RECORD_SECONDS_MIN': RECORD_SECONDS_MIN,\n",
        "    'API_SEARCH_LIMIT': API_SEARCH_LIMIT,\n",
        "    'COMMIT_PUSH_THRESHOLD': COMMIT_PUSH_THRESHOLD,\n",
        "    'LOGS_PATH': LOGS_PATH,\n",
        "    'BLACKLIST_TIMEOUT': BLACKLIST_TIMEOUT,\n",
        "    'BLACKLIST_MAX_FAILURES': BLACKLIST_MAX_FAILURES\n",
        "})\n",
        "\n",
        "# =============================================================================\n",
        "# UTILIT√ÅRIO DE LOG √öNICO MODULAR (JSONL)\n",
        "# -----------------------------------------------------------------------------\n",
        "# Cada entrada: {\n",
        "#   \"timestamp\": \"2025-06-06T06:15:00Z\",\n",
        "#   \"sessao\": \"busca|grava√ß√£o|blacklist|commit|erro|...\",\n",
        "#   \"evento\": \"...\",\n",
        "#   \"id\": \"...\",         # sempre o identificador prim√°rio!\n",
        "#   \"username\": \"...\",   # para exibi√ß√£o/auditoria\n",
        "#   \"status\": \"...\",     # ok|erro|blacklisted|expirado|...\n",
        "#   \"detalhes\": \"...\",   # info extra (motivo, paths, etc)\n",
        "# }\n",
        "# =============================================================================\n",
        "\n",
        "def now_iso():\n",
        "    \"\"\"Retorna timestamp UTC em formato ISO.\"\"\"\n",
        "    from datetime import datetime\n",
        "    return datetime.utcnow().isoformat() + \"Z\"\n",
        "\n",
        "def append_log(entry, logs_path=LOGS_PATH):\n",
        "    \"\"\"\n",
        "    Adiciona uma nova entrada ao log central (JSONL).\n",
        "    Campos obrigat√≥rios: sessao, evento, id, username, status.\n",
        "    \"\"\"\n",
        "    entry.setdefault(\"timestamp\", now_iso())\n",
        "    # Garante campos essenciais para rastreabilidade\n",
        "    for field in [\"sessao\", \"evento\", \"id\", \"username\", \"status\"]:\n",
        "        entry.setdefault(field, \"\")\n",
        "    with open(logs_path, \"a\", encoding=\"utf-8\") as f:\n",
        "        f.write(json.dumps(entry, ensure_ascii=False) + \"\\n\")\n",
        "\n",
        "def read_logs(logs_path=LOGS_PATH):\n",
        "    \"\"\"L√™ todas as entradas do log central.\"\"\"\n",
        "    if not os.path.exists(logs_path):\n",
        "        return []\n",
        "    with open(logs_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        return [json.loads(line) for line in f if line.strip()]\n",
        "\n",
        "def query_logs(sessao=None, id=None, username=None, evento=None, status=None, after=None, before=None, logs_path=LOGS_PATH):\n",
        "    \"\"\"\n",
        "    Consulta entradas do log por filtros opcionais.\n",
        "    - after/before: string ISO ou datetime\n",
        "    \"\"\"\n",
        "    logs = read_logs(logs_path)\n",
        "    result = []\n",
        "    for entry in logs:\n",
        "        if sessao and entry.get(\"sessao\") != sessao:\n",
        "            continue\n",
        "        if id and entry.get(\"id\") != id:\n",
        "            continue\n",
        "        if username and entry.get(\"username\") != username:\n",
        "            continue\n",
        "        if evento and entry.get(\"evento\") != evento:\n",
        "            continue\n",
        "        if status and entry.get(\"status\") != status:\n",
        "            continue\n",
        "        ts = entry.get(\"timestamp\")\n",
        "        if after:\n",
        "            after_val = after if isinstance(after, str) else after.isoformat()\n",
        "            if ts < after_val:\n",
        "                continue\n",
        "        if before:\n",
        "            before_val = before if isinstance(before, str) else before.isoformat()\n",
        "            if ts > before_val:\n",
        "                continue\n",
        "        result.append(entry)\n",
        "    return result\n",
        "\n",
        "def remove_logs(condition_fn, logs_path=LOGS_PATH):\n",
        "    \"\"\"\n",
        "    Remove do log central todas as entradas que satisfa√ßam condition_fn(entry).\n",
        "    √ötil para expurgar logs expirados, blacklists vencidas, eventos processados, etc.\n",
        "    \"\"\"\n",
        "    logs = read_logs(logs_path)\n",
        "    kept = [entry for entry in logs if not condition_fn(entry)]\n",
        "    with open(logs_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        for entry in kept:\n",
        "            f.write(json.dumps(entry, ensure_ascii=False) + \"\\n\")\n",
        "    return len(logs) - len(kept)\n",
        "\n",
        "def update_log_entry(match_fn, update_fn, logs_path=LOGS_PATH):\n",
        "    \"\"\"\n",
        "    Atualiza entradas do log central: se match_fn(entry)==True, aplica update_fn(entry).\n",
        "    Exemplo: promover status de \"pending\" para \"ok\".\n",
        "    \"\"\"\n",
        "    logs = read_logs(logs_path)\n",
        "    updated = 0\n",
        "    for entry in logs:\n",
        "        if match_fn(entry):\n",
        "            update_fn(entry)\n",
        "            updated += 1\n",
        "    with open(logs_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        for entry in logs:\n",
        "            f.write(json.dumps(entry, ensure_ascii=False) + \"\\n\")\n",
        "    return updated\n",
        "\n",
        "# Exemplos de uso (para as pr√≥ximas c√©lulas):\n",
        "# append_log({\"sessao\":\"busca\", \"evento\":\"encontrado\", \"id\":\"abc123\", \"username\":\"Manugic_\", \"status\":\"ok\", \"detalhes\":\"URL v√°lida\"})\n",
        "# logs_blacklist = query_logs(sessao=\"blacklist\", status=\"blacklisted\")\n",
        "# remove_logs(lambda entry: entry[\"sessao\"]==\"processing\" and expirou(entry), logs_path=LOGS_PATH)\n",
        "\n",
        "# =============================================================================\n",
        "# FUN√á√ÉO INTERATIVA (opcional) PARA ESCOLHA DE TRANSMISS√ïES ESPEC√çFICAS\n",
        "# =============================================================================\n",
        "def perguntar_transmissoes_especificas():\n",
        "    \"\"\"\n",
        "    Pergunta ao usu√°rio se deseja informar transmiss√µes espec√≠ficas para gravar,\n",
        "    recebendo nomes de usu√°rio separados por v√≠rgula e retornando lista limpa.\n",
        "    Retorna lista vazia caso n√£o deseje selecionar usu√°rios.\n",
        "    \"\"\"\n",
        "    resp = input('Deseja gravar alguma transmiss√£o espec√≠fica? (sim/n√£o): ').strip().lower()\n",
        "    if resp.startswith('s'):\n",
        "        usuarios = input('Informe o(s) nome(s) de usu√°rio, separados por v√≠rgula (ex: userNovo234, jovemPT): ')\n",
        "        usuarios_lista = [u.strip() for u in usuarios.split(',') if u.strip()]\n",
        "        return usuarios_lista\n",
        "    return []\n",
        "\n",
        "# =============================================================================\n",
        "# DICA DE USO EM OUTRAS C√âLULAS:\n",
        "# - Para registrar evento: append_log({...})\n",
        "# - Para consultar blacklist: query_logs(sessao=\"blacklist\", status=\"blacklisted\")\n",
        "# - Para remover registros expirados: remove_logs(lambda e: ...)\n",
        "# - Para atualizar status: update_log_entry(lambda e: ..., lambda e: ...)\n",
        "# =============================================================================\n",
        "\n",
        "# ============================\n",
        "# FIM DA C√âLULA 1\n",
        "# ============================"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "WXs0o6OPHXbi",
      "metadata": {
        "id": "WXs0o6OPHXbi"
      },
      "source": [
        "# C√©lula 2: Instala√ß√£o e Valida√ß√£o do ffmpeg\n",
        "\n",
        "**Objetivo:**  \n",
        "Esta c√©lula garante que o utilit√°rio `ffmpeg` esteja instalado e dispon√≠vel no ambiente Google Colab. O ffmpeg √© indispens√°vel para a grava√ß√£o dos v√≠deos das transmiss√µes e para o processamento de m√≠dia ao longo do pipeline do notebook XCam.\n",
        "\n",
        "## Pontos principais e melhorias implementadas\n",
        "\n",
        "- **Verifica√ß√£o pr√©-instala√ß√£o:**  \n",
        "  Antes de instalar, verifica se o ffmpeg j√° est√° dispon√≠vel no ambiente, tornando o processo idempotente e eficiente.\n",
        "- **Instala√ß√£o automatizada:**  \n",
        "  Efetua a instala√ß√£o via `apt-get` apenas se necess√°rio, reduzindo o tempo de setup em execu√ß√µes futuras.\n",
        "- **Valida√ß√£o p√≥s-instala√ß√£o:**  \n",
        "  Exibe a vers√£o instalada do ffmpeg, garantindo transpar√™ncia e rastreabilidade.\n",
        "- **Mensagens detalhadas:**  \n",
        "  O usu√°rio recebe logs informativos sobre cada etapa, facilitando o diagn√≥stico em caso de erros.\n",
        "- **Design modular:**  \n",
        "  Estrutura pronta para ser utilizada em outros ambientes (Colab, local, server) com pequenas adapta√ß√µes.\n",
        "\n",
        "---\n",
        "\n",
        "## Como funciona a c√©lula\n",
        "\n",
        "- **Verifica se o ffmpeg est√° instalado (no PATH do sistema).**\n",
        "- **Se n√£o estiver, instala automaticamente via apt-get.**\n",
        "- **Valida e exibe a vers√£o instalada ap√≥s o processo.**\n",
        "- **Em caso de falha, exibe erro detalhado e interrompe o fluxo para evitar inconsist√™ncias futuras.**\n",
        "\n",
        "---\n",
        "\n",
        "## Exemplo de uso das fun√ß√µes nesta c√©lula\n",
        "\n",
        "```python\n",
        "if not is_ffmpeg_installed():\n",
        "    install_ffmpeg()\n",
        "show_ffmpeg_version()\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Seguran√ßa, rastreabilidade e manuten√ß√£o\n",
        "\n",
        "- A c√©lula torna o setup do ambiente mais robusto, impedindo falhas silenciosas relacionadas √† aus√™ncia de ffmpeg.\n",
        "- Mensagens e valida√ß√µes ajudam a equipe a identificar rapidamente problemas de ambiente ou permiss√µes.\n",
        "- O padr√£o modular facilita a reutiliza√ß√£o do c√≥digo em diferentes notebooks ou pipelines do projeto XCam.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "vIODn0c2HiHz",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vIODn0c2HiHz",
        "outputId": "3388fb69-94fb-487e-9159-5e3693af4e4b"
      },
      "outputs": [],
      "source": [
        "# ================================================================\n",
        "# C√©lula 2: Instala√ß√£o e Valida√ß√£o do FFMPEG no Colab\n",
        "# ================================================================\n",
        "# Objetivo:\n",
        "# - Garantir que o utilit√°rio ffmpeg est√° instalado e dispon√≠vel no ambiente\n",
        "# - Validar a instala√ß√£o e exibir a vers√£o instalada\n",
        "# - Tornar a etapa idempotente, evitando instala√ß√µes desnecess√°rias\n",
        "# - Fornecer feedback claro e orienta√ß√µes em caso de erro\n",
        "#\n",
        "# Estrat√©gia aplicada:\n",
        "# - Instala√ß√£o via apt-get apenas se ffmpeg n√£o estiver dispon√≠vel\n",
        "# - Valida√ß√£o p√≥s-instala√ß√£o\n",
        "# - Logs claros e coment√°rios detalhados para rastreabilidade\n",
        "# ================================================================\n",
        "\n",
        "import subprocess\n",
        "\n",
        "def is_ffmpeg_installed():\n",
        "    \"\"\"\n",
        "    Verifica se o ffmpeg est√° instalado e dispon√≠vel no PATH do sistema.\n",
        "    Retorna True se estiver, False caso contr√°rio.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        result = subprocess.run([\"ffmpeg\", \"-version\"], capture_output=True, text=True)\n",
        "        return result.returncode == 0\n",
        "    except FileNotFoundError:\n",
        "        return False\n",
        "\n",
        "def install_ffmpeg():\n",
        "    \"\"\"\n",
        "    Instala o ffmpeg via apt-get caso n√£o esteja presente.\n",
        "    \"\"\"\n",
        "    print(\"[INFO] Instalando ffmpeg via apt-get...\")\n",
        "    # Atualiza pacotes e instala ffmpeg silenciosamente\n",
        "    !apt-get update -y > /dev/null\n",
        "    !apt-get install -y ffmpeg > /dev/null\n",
        "    print(\"[INFO] ffmpeg instalado com sucesso.\")\n",
        "\n",
        "def show_ffmpeg_version():\n",
        "    \"\"\"\n",
        "    Exibe a vers√£o instalada do ffmpeg.\n",
        "    \"\"\"\n",
        "    print(\"[INFO] Vers√£o do ffmpeg instalada:\")\n",
        "    !ffmpeg -version | head -n 2\n",
        "\n",
        "# ============================\n",
        "# EXECU√á√ÉO DA ETAPA DE SETUP\n",
        "# ============================\n",
        "\n",
        "if not is_ffmpeg_installed():\n",
        "    print(\"[WARN] ffmpeg n√£o encontrado no ambiente.\")\n",
        "    install_ffmpeg()\n",
        "    if not is_ffmpeg_installed():\n",
        "        raise RuntimeError(\"[ERRO] Falha ao instalar o ffmpeg. Verifique permiss√µes ou tente novamente.\")\n",
        "else:\n",
        "    print(\"[OK] ffmpeg j√° est√° instalado no ambiente.\")\n",
        "\n",
        "# Valida√ß√£o final e exibi√ß√£o da vers√£o\n",
        "show_ffmpeg_version()\n",
        "\n",
        "# ============================\n",
        "# FIM DA C√âLULA 2\n",
        "# ============================\n",
        "\n",
        "# Dica: ffmpeg deve estar dispon√≠vel para todas as c√©lulas subsequentes.\n",
        "# Se precisar de um caminho espec√≠fico, utilize `which ffmpeg` para obter o path absoluto."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "90qvXC0rHtWb",
      "metadata": {
        "id": "90qvXC0rHtWb"
      },
      "source": [
        "# C√©lula 3: Imports Essenciais, Utilit√°rios e Prepara√ß√£o do Ambiente\n",
        "\n",
        "**Objetivo:**  \n",
        "Importa todas as bibliotecas essenciais do Python necess√°rias para o funcionamento do notebook, incluindo m√≥dulos para requisi√ß√µes HTTP, processamento paralelo, manipula√ß√£o de datas, controle de subprocessos e exibi√ß√£o interativa.  \n",
        "Centraliza fun√ß√µes utilit√°rias robustas e padronizadas para processamento, download de poster, gera√ß√£o autom√°tica de poster com ffmpeg e exibi√ß√£o de progresso.  \n",
        "\n",
        "## Principais pontos e melhorias implementadas\n",
        "\n",
        "- **Centraliza√ß√£o de imports essenciais:**  \n",
        "  Todos os m√≥dulos fundamentais (os, requests, multiprocessing, datetime, json, time, subprocess, math, re, IPython) est√£o dispon√≠veis e prontos para uso global.\n",
        "- **Fun√ß√µes utilit√°rias padronizadas:**  \n",
        "  Fun√ß√µes para formata√ß√£o de segundos, exibi√ß√£o de progresso, download e valida√ß√£o de poster e gera√ß√£o de poster via ffmpeg foram refatoradas e documentadas, seguindo arquitetura modular e Clean Architecture.\n",
        "- **Remo√ß√£o de logs tempor√°rios dispersos:**  \n",
        "  O antigo arquivo de log de processamento tempor√°rio foi descontinuado em favor do log √∫nico centralizado definido na C√©lula 1, promovendo rastreabilidade e controle total.\n",
        "- **Robustez e clareza:**  \n",
        "  Todas as fun√ß√µes possuem tratamento de erros, mensagens amig√°veis e s√£o preparadas para uso concorrente e integra√ß√£o com as pr√≥ximas etapas do pipeline.\n",
        "- **Pronto para uso em todo o notebook:**  \n",
        "  As fun√ß√µes aqui definidas s√£o utilizadas em toda a automa√ß√£o, garantindo reuso, legibilidade e manuten√ß√£o facilitada.\n",
        "\n",
        "---\n",
        "\n",
        "## Fun√ß√µes utilit√°rias dispon√≠veis nesta c√©lula\n",
        "\n",
        "- **`format_seconds(seconds)`**: Formata um valor em segundos para string leg√≠vel (ex: \"1h23m45s\").\n",
        "- **`log_progress(username, elapsed_seconds, total_seconds)`**: Exibe o progresso da grava√ß√£o de cada transmiss√£o.\n",
        "- **`download_and_save_poster(poster_url, username, temp_folder)`**: Baixa e salva o poster da transmiss√£o a partir de uma URL remota ou retorna se for um caminho local.\n",
        "- **`generate_poster_with_ffmpeg(m3u8_url, username, temp_folder, frame_time=7, timeout=20)`**: Gera automaticamente um poster usando ffmpeg, ap√≥s validar a disponibilidade do stream.\n",
        "- **`is_poster_valid(poster_path)`**: Verifica se o arquivo de poster √© v√°lido (existe e n√£o est√° vazio).\n",
        "\n",
        "---\n",
        "\n",
        "## Exemplo de uso das fun√ß√µes\n",
        "\n",
        "```python\n",
        "# Formatar segundos em string leg√≠vel\n",
        "tempo = format_seconds(385)\n",
        "# Exibir progresso\n",
        "log_progress(\"userNovo234\", 385, 12780)\n",
        "# Download do poster\n",
        "poster_path = download_and_save_poster(url_poster, \"userNovo234\", \"/content/temp\")\n",
        "# Gera√ß√£o autom√°tica de poster via ffmpeg (se necess√°rio)\n",
        "if not is_poster_valid(poster_path):\n",
        "    poster_path = generate_poster_with_ffmpeg(m3u8_url, \"userNovo234\", \"/content/temp\")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Seguran√ßa, rastreabilidade e manuten√ß√£o\n",
        "\n",
        "- Todas as fun√ß√µes s√£o preparadas para tratamento de erros e integra√ß√£o com processos concorrentes.\n",
        "- O log tempor√°rio de processamento foi removido, garantindo que todo o rastreio e auditoria sejam feitos via log √∫nico centralizado da C√©lula 1.\n",
        "- Coment√°rios detalhados facilitam manuten√ß√£o, entendimento e evolu√ß√£o do notebook.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hOetz0nGICkz",
      "metadata": {
        "id": "hOetz0nGICkz"
      },
      "outputs": [],
      "source": [
        "# ================================================================\n",
        "# C√©lula 3: Imports Essenciais, Utilit√°rios e Prepara√ß√£o do Ambiente\n",
        "# ================================================================\n",
        "# Objetivo:\n",
        "# - Importar bibliotecas essenciais e utilit√°rios para todo o notebook\n",
        "# - Centralizar fun√ß√µes auxiliares de formata√ß√£o, download e gera√ß√£o de poster\n",
        "# - Remover depend√™ncias de logs tempor√°rios dispersos, integrando ao log √∫nico do sistema (conforme novo padr√£o)\n",
        "# - Garantir robustez, clareza e modularidade para as pr√≥ximas c√©lulas\n",
        "#\n",
        "# Estrat√©gia aplicada:\n",
        "# - Apenas os imports necess√°rios para o funcionamento do notebook\n",
        "# - Fun√ß√µes auxiliares adaptadas para Clean Architecture e integra√ß√£o com o log centralizado\n",
        "# - Fun√ß√£o de gera√ß√£o de poster com ffmpeg robusta (checagem HTTP HEAD antes de rodar)\n",
        "# - Modularidade: fun√ß√µes isoladas, prontos para reuso e testes\n",
        "# ================================================================\n",
        "\n",
        "import os\n",
        "import requests\n",
        "from multiprocessing import Manager, Process\n",
        "from datetime import datetime\n",
        "import json\n",
        "import time\n",
        "import subprocess\n",
        "import math\n",
        "import re\n",
        "import shutil\n",
        "import threading\n",
        "\n",
        "from IPython import get_ipython\n",
        "from IPython.display import display\n",
        "\n",
        "# ============================\n",
        "# UTILIT√ÅRIOS DE FORMATA√á√ÉO E PROGRESSO\n",
        "# ============================\n",
        "\n",
        "def format_seconds(seconds):\n",
        "    \"\"\"\n",
        "    Formata segundos em string leg√≠vel (e.g., 1h23m45s).\n",
        "    \"\"\"\n",
        "    total_seconds = int(seconds)\n",
        "    hours = total_seconds // 3600\n",
        "    minutes = (total_seconds % 3600) // 60\n",
        "    seconds = total_seconds % 60\n",
        "    parts = []\n",
        "    if hours > 0:\n",
        "        parts.append(f\"{hours}h\")\n",
        "    if minutes > 0 or (hours == 0 and seconds > 0):\n",
        "        parts.append(f\"{minutes}m\")\n",
        "    if seconds > 0 or total_seconds == 0:\n",
        "        parts.append(f\"{seconds}s\")\n",
        "    return \"\".join(parts) if parts else \"0s\"\n",
        "\n",
        "def log_progress(username, elapsed_seconds, total_seconds):\n",
        "    \"\"\"\n",
        "    Exibe progresso da grava√ß√£o de cada transmiss√£o em tempo real.\n",
        "    \"\"\"\n",
        "    percent = min((elapsed_seconds / total_seconds) * 100, 100)\n",
        "    tempo = format_seconds(elapsed_seconds)\n",
        "    minutos_gravados = math.floor(elapsed_seconds / 60)\n",
        "    minutos_restantes = max(0, math.ceil((total_seconds - elapsed_seconds) / 60))\n",
        "    print(f\"‚è±Ô∏è [{username}] Gravados: {minutos_gravados} min | Restantes: {minutos_restantes} min | Tempo total: {tempo} ‚Äî üìä {percent:.1f}% conclu√≠do\")\n",
        "\n",
        "# ============================\n",
        "# UTILIT√ÅRIO PARA DOWNLOAD DE POSTER\n",
        "# ============================\n",
        "\n",
        "def download_and_save_poster(poster_url, username, temp_folder=None):\n",
        "    \"\"\"\n",
        "    Baixa e salva o poster (thumbnail) a partir de uma URL HTTP/HTTPS.\n",
        "    Se for um caminho local existente, retorna esse caminho.\n",
        "    Retorna o caminho do arquivo salvo, ou None em caso de erro.\n",
        "    \"\"\"\n",
        "    if temp_folder is None:\n",
        "        temp_folder = POSTER_TEMP_PATH\n",
        "    # Uso de caminho local\n",
        "    if os.path.exists(poster_url):\n",
        "        return poster_url\n",
        "    # Download de URL HTTP/HTTPS\n",
        "    if isinstance(poster_url, str) and (poster_url.startswith(\"http://\") or poster_url.startswith(\"https://\")):\n",
        "        try:\n",
        "            response = requests.get(poster_url, timeout=15)\n",
        "            response.raise_for_status()\n",
        "            ext = os.path.splitext(poster_url)[1].lower()\n",
        "            if ext not in [\".jpg\", \".jpeg\", \".png\"]:\n",
        "                ext = \".jpg\"\n",
        "            poster_temp_path = os.path.join(temp_folder, f\"{username}_poster_temp{ext}\")\n",
        "            with open(poster_temp_path, \"wb\") as f:\n",
        "                f.write(response.content)\n",
        "            print(f\"üñºÔ∏è Poster baixado em: {poster_temp_path}\")\n",
        "            return poster_temp_path\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Erro ao baixar poster {poster_url}: {e}\")\n",
        "            return None\n",
        "    else:\n",
        "        print(f\"‚ùå poster_url inv√°lido ou n√£o encontrado: {poster_url}\")\n",
        "        return None\n",
        "\n",
        "# ============================\n",
        "# UTILIT√ÅRIO PARA GERAR POSTER COM FFMPEG\n",
        "# ============================\n",
        "\n",
        "def generate_poster_with_ffmpeg(m3u8_url, username, temp_folder=None, frame_time=7, timeout=20):\n",
        "    \"\"\"\n",
        "    Gera um poster (screenshot) usando ffmpeg a partir da URL .m3u8 da transmiss√£o.\n",
        "    Retorna o caminho do arquivo gerado ou None em caso de erro.\n",
        "    Antes de rodar o ffmpeg, faz uma checagem HTTP HEAD para saber se a URL do stream est√° ativa.\n",
        "    \"\"\"\n",
        "    if temp_folder is None:\n",
        "        temp_folder = POSTER_TEMP_PATH\n",
        "    # Checa se a URL est√° acess√≠vel antes de rodar ffmpeg\n",
        "    try:\n",
        "        head_resp = requests.head(m3u8_url, timeout=5)\n",
        "        if not head_resp.ok:\n",
        "            print(f\"‚ö†Ô∏è Stream offline ou n√£o dispon√≠vel para {username} (status {head_resp.status_code})\")\n",
        "            return None\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Erro de conex√£o ao acessar stream de {username}: {e}\")\n",
        "        return None\n",
        "\n",
        "    poster_ffmpeg_path = os.path.join(temp_folder, f\"{username}_poster_ffmpeg.jpg\")\n",
        "    command = [\n",
        "        \"ffmpeg\",\n",
        "        \"-y\",\n",
        "        \"-ss\", str(frame_time),\n",
        "        \"-i\", m3u8_url,\n",
        "        \"-vframes\", \"1\",\n",
        "        \"-q:v\", \"2\",\n",
        "        poster_ffmpeg_path\n",
        "    ]\n",
        "    try:\n",
        "        print(f\"üé¨ Gerando poster com ffmpeg para {username} no segundo {frame_time}...\")\n",
        "        result = subprocess.run(\n",
        "            command,\n",
        "            stdout=subprocess.PIPE,\n",
        "            stderr=subprocess.PIPE,\n",
        "            timeout=timeout\n",
        "        )\n",
        "        if result.returncode == 0 and os.path.exists(poster_ffmpeg_path):\n",
        "            print(f\"üñºÔ∏è Poster gerado via ffmpeg: {poster_ffmpeg_path}\")\n",
        "            return poster_ffmpeg_path\n",
        "        else:\n",
        "            print(f\"‚ùå ffmpeg n√£o conseguiu gerar poster para {username}.\\nSTDOUT:\\n{result.stdout.decode(errors='ignore')}\\nSTDERR:\\n{result.stderr.decode(errors='ignore')}\")\n",
        "            return None\n",
        "    except subprocess.TimeoutExpired:\n",
        "        print(f\"‚è∞ Tempo excedido ao tentar gerar poster para {username} via ffmpeg.\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Erro inesperado ao gerar poster via ffmpeg: {e}\")\n",
        "        return None\n",
        "\n",
        "# ============================\n",
        "# VALIDA√á√ÉO DE POSTER\n",
        "# ============================\n",
        "\n",
        "def is_poster_valid(poster_path):\n",
        "    \"\"\"\n",
        "    Verifica se o poster existe e n√£o est√° vazio.\n",
        "    \"\"\"\n",
        "    return poster_path and os.path.exists(poster_path) and os.path.getsize(poster_path) > 0\n",
        "\n",
        "# ============================\n",
        "# FIM DA C√âLULA 3\n",
        "# ============================\n",
        "\n",
        "# Observa√ß√£o:\n",
        "# - LOG_PROCESSAMENTO_PATH e logs tempor√°rios antigos N√ÉO s√£o mais necess√°rios a partir da ado√ß√£o do log √∫nico centralizado (LOGS_PATH).\n",
        "# - Todas as opera√ß√µes de logging, blacklist, falha e auditoria devem ser feitas apenas via utilit√°rio de log (C√©lula 1).\n",
        "# - Siga o padr√£o modular e Clean Architecture para m√°xima rastreabilidade e reuso."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "hpRIMtyFIY0q",
      "metadata": {
        "id": "hpRIMtyFIY0q"
      },
      "source": [
        "# C√©lula 4: Clonagem do Reposit√≥rio GitHub no Colab e Google Drive\n",
        "\n",
        "**Objetivo:**  \n",
        "Esta c√©lula garante que o reposit√≥rio do projeto XCam seja sempre clonado de forma limpa e sincronizada no ambiente local do Colab e, se dispon√≠vel, tamb√©m no Google Drive para persist√™ncia.  \n",
        "Assegura ambiente pronto, atualizado, seguro para grava√ß√µes e processamento, e prepara diret√≥rios padronizados para integra√ß√£o com o restante do pipeline.\n",
        "\n",
        "## Principais pontos e melhorias implementadas\n",
        "\n",
        "- **Clonagem idempotente e limpa:**  \n",
        "  Remove reposit√≥rios antigos antes de clonar para evitar conflitos, arquivos √≥rf√£os ou problemas de sincroniza√ß√£o.\n",
        "- **Clonagem para ambiente tempor√°rio e persistente:**  \n",
        "  O reposit√≥rio √© clonado tanto para `/content` (Colab) quanto para o Drive (`/content/drive/MyDrive/XCam.Drive`) se o Drive estiver montado.\n",
        "- **Prepara√ß√£o de diret√≥rios de grava√ß√£o e processamento:**  \n",
        "  Estrutura de diret√≥rios tempor√°rios criada automaticamente, garantindo organiza√ß√£o dos dados.\n",
        "- **Exporta√ß√£o de vari√°veis globais:**  \n",
        "  Todos os caminhos, URLs e configura√ß√µes relevantes s√£o disponibilizados via `globals().update()` para uso em todo o notebook.\n",
        "- **Mensagens e valida√ß√µes detalhadas:**  \n",
        "  Feedback informativo sobre o status de cada etapa, facilitando o diagn√≥stico e a manuten√ß√£o.\n",
        "- **Pronto para CI/CD e integra√ß√µes futuras:**  \n",
        "  Token e URLs preparados para automa√ß√µes, integra√ß√µes externas e uploads (Abyss.to, etc).\n",
        "\n",
        "---\n",
        "\n",
        "## Par√¢metros globais definidos nesta c√©lula\n",
        "\n",
        "- **`GITHUB_USER`**, **`GITHUB_REPO`**, **`GITHUB_BRANCH`**, **`GITHUB_TOKEN`**: Configura√ß√µes do reposit√≥rio e autentica√ß√£o.\n",
        "- **`repo_url`**: URL do reposit√≥rio autenticada para clone/push.\n",
        "- **`TEMP_OUTPUT_FOLDER`**: Pasta para grava√ß√µes tempor√°rias.\n",
        "- **`BASE_REPO_FOLDER`**: Localiza√ß√£o do reposit√≥rio no ambiente Colab.\n",
        "- **`DRIVE_MOUNT`**, **`DRIVE_REPO_FOLDER`**: Caminhos no Google Drive para persist√™ncia (se montado).\n",
        "- **`ABYSS_UPLOAD_URL`**: URL de upload para integra√ß√£o com sistemas externos.\n",
        "\n",
        "---\n",
        "\n",
        "## Como funciona a c√©lula\n",
        "\n",
        "- **Remove reposit√≥rios antigos e diret√≥rios tempor√°rios**, evitando res√≠duos de execu√ß√µes anteriores.\n",
        "- **Clona o reposit√≥rio do GitHub** para `/content` (Colab).\n",
        "- **Se o Google Drive estiver montado**, faz o mesmo clone no diret√≥rio persistente do Drive.\n",
        "- **Cria diret√≥rios tempor√°rios necess√°rios** para grava√ß√µes e arquivos intermedi√°rios.\n",
        "- **Exporta todas as vari√°veis configuradas** para uso global no notebook.\n",
        "- **Exibe mensagens informativas** sobre cada etapa e alerta caso o Drive n√£o esteja dispon√≠vel.\n",
        "\n",
        "---\n",
        "\n",
        "## Exemplo de uso das vari√°veis globais\n",
        "\n",
        "```python\n",
        "print(BASE_REPO_FOLDER)        # Caminho do reposit√≥rio clonado no Colab\n",
        "print(DRIVE_REPO_FOLDER)      # Caminho do reposit√≥rio no Drive (se montado)\n",
        "print(TEMP_OUTPUT_FOLDER)     # Pasta tempor√°ria para grava√ß√µes\n",
        "print(ABYSS_UPLOAD_URL)       # URL de upload para integra√ß√£o externa\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Seguran√ßa, rastreabilidade e manuten√ß√£o\n",
        "\n",
        "- Garantia de ambiente limpo a cada execu√ß√£o, evitando conflitos de arquivos e branches.\n",
        "- Persist√™ncia dos dados no Drive (se montado), evitando perda de grava√ß√µes em caso de reinicializa√ß√£o do Colab.\n",
        "- Coment√°rios detalhados e estrutura modular facilitam a manuten√ß√£o, integra√ß√£o com CI/CD e futuras expans√µes no pipeline do XCam.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Uof_0QCrIlf7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uof_0QCrIlf7",
        "outputId": "a1c4c886-dfb5-4265-f0ff-91292ac6de9d"
      },
      "outputs": [],
      "source": [
        "# ================================================================\n",
        "# C√©lula 4: Clonagem do Reposit√≥rio GitHub no Colab e no Google Drive\n",
        "# ================================================================\n",
        "# Objetivo:\n",
        "# - Garantir ambiente limpo e sincronizado para o reposit√≥rio XCam em todas as execu√ß√µes\n",
        "# - Clonar o reposit√≥rio tanto para o ambiente ef√™mero do Colab quanto para o Google Drive (persist√™ncia)\n",
        "# - Preparar diret√≥rios de trabalho para grava√ß√µes e processamento tempor√°rio\n",
        "# - Fornecer feedback claro sobre o status da opera√ß√£o\n",
        "#\n",
        "# Estrat√©gia aplicada:\n",
        "# - Remove reposit√≥rios antigos antes de clonar (evita conflitos e arquivos √≥rf√£os)\n",
        "# - Utiliza token pessoal para autentica√ß√£o segura e push futuro (CI/CD)\n",
        "# - Cria estrutura de diret√≥rios padronizada (m√≥dulos, grava√ß√µes, cache, etc.)\n",
        "# - Valida se o Drive est√° montado antes de tentar opera√ß√µes persistentes\n",
        "# - Coment√°rios detalhados para f√°cil manuten√ß√£o e evolu√ß√£o\n",
        "# ================================================================\n",
        "\n",
        "# ============================\n",
        "# CONFIGURA√á√ïES DO GITHUB\n",
        "# ============================\n",
        "GITHUB_USER = \"SamuelPassamani\"\n",
        "GITHUB_REPO = \"XCam\"\n",
        "GITHUB_BRANCH = \"main\"\n",
        "GITHUB_TOKEN = \"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\"\n",
        "\n",
        "repo_url = f\"https://{GITHUB_USER}:{GITHUB_TOKEN}@github.com/{GITHUB_USER}/{GITHUB_REPO}.git\"\n",
        "\n",
        "# ============================\n",
        "# CLONAGEM PARA O COLAB\n",
        "# ============================\n",
        "print(f\"‚è≥ Limpando ambiente e clonando '{GITHUB_REPO}' para o Colab...\")\n",
        "!rm -rf {GITHUB_REPO}\n",
        "!git clone -b {GITHUB_BRANCH} {repo_url}\n",
        "print(f\"‚úÖ Reposit√≥rio clonado em /content/{GITHUB_REPO}\")\n",
        "\n",
        "# ============================\n",
        "# ESTRUTURA DE DIRET√ìRIOS TEMPOR√ÅRIOS\n",
        "# ============================\n",
        "TEMP_OUTPUT_FOLDER = RECORD_TEMP_PATH  # agora grava√ß√µes tempor√°rias v√£o para o Drive\n",
        "os.makedirs(TEMP_OUTPUT_FOLDER, exist_ok=True)\n",
        "BASE_REPO_FOLDER = f\"/content/{GITHUB_REPO}\"\n",
        "\n",
        "# ============================\n",
        "# CLONAGEM PARA O GOOGLE DRIVE (PERSIST√äNCIA)\n",
        "# ============================\n",
        "DRIVE_MOUNT = \"/content/drive/MyDrive/XCam.Drive\"\n",
        "DRIVE_REPO_FOLDER = f\"{DRIVE_MOUNT}/{GITHUB_REPO}\"\n",
        "\n",
        "import os\n",
        "\n",
        "if os.path.exists(DRIVE_MOUNT):\n",
        "    print(f\"‚è≥ Limpando reposit√≥rio antigo no Drive (se existir)...\")\n",
        "    !rm -rf \"{DRIVE_REPO_FOLDER}\"\n",
        "    print(f\"‚è≥ Clonando '{GITHUB_REPO}' para o Drive em {DRIVE_REPO_FOLDER} ...\")\n",
        "    !git clone -b {GITHUB_BRANCH} {repo_url} \"{DRIVE_REPO_FOLDER}\"\n",
        "    print(f\"‚úÖ Reposit√≥rio tamb√©m clonado no Drive: {DRIVE_REPO_FOLDER}\")\n",
        "else:\n",
        "    print(f\"‚ö†Ô∏è Google Drive n√£o est√° montado em {DRIVE_MOUNT}.\\n‚ÑπÔ∏è Use a c√©lula de montagem antes de prosseguir para garantir persist√™ncia.\")\n",
        "\n",
        "# ============================\n",
        "# CONFIGURA√á√ÉO DE ENDPOINTS DE UPLOAD/INTEGRA√á√ÉO\n",
        "# ============================\n",
        "ABYSS_UPLOAD_URL = 'http://up.hydrax.net/0128263f78f0b426d617bb61c2a8ff43'\n",
        "globals().update({\n",
        "    'GITHUB_USER': GITHUB_USER,\n",
        "    'GITHUB_REPO': GITHUB_REPO,\n",
        "    'GITHUB_BRANCH': GITHUB_BRANCH,\n",
        "    'GITHUB_TOKEN': GITHUB_TOKEN,\n",
        "    'repo_url': repo_url,\n",
        "    'TEMP_OUTPUT_FOLDER': TEMP_OUTPUT_FOLDER,\n",
        "    'BASE_REPO_FOLDER': BASE_REPO_FOLDER,\n",
        "    'DRIVE_MOUNT': DRIVE_MOUNT,\n",
        "    'DRIVE_REPO_FOLDER': DRIVE_REPO_FOLDER,\n",
        "    'ABYSS_UPLOAD_URL': ABYSS_UPLOAD_URL\n",
        "})\n",
        "\n",
        "# ============================\n",
        "# FIM DA C√âLULA 4\n",
        "# ============================\n",
        "\n",
        "# Observa√ß√µes:\n",
        "# - Os caminhos globais s√£o exportados via globals().update() para uso em todo o notebook.\n",
        "# - Recomenda-se sempre rodar esta c√©lula ap√≥s alterar tokens ou trocar branches para garantir ambiente limpo e sincronizado.\n",
        "# - O endpoint ABYSS_UPLOAD_URL pode ser atualizado conforme integra√ß√µes futuras."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "M5iL_9BoIoj7",
      "metadata": {
        "id": "M5iL_9BoIoj7"
      },
      "source": [
        "# C√©lula 5: Commit e Push Autom√°ticos (rec.json, posters, etc.)\n",
        "\n",
        "**Objetivo:**  \n",
        "Automatiza o processo de commit e push dos arquivos modificados (ex: rec.json, posters e demais artefatos importantes) para o reposit√≥rio GitHub, garantindo rastreabilidade, atomicidade e integra√ß√£o cont√≠nua (CI/CD) do pipeline XCam.\n",
        "\n",
        "## Principais pontos e melhorias implementadas\n",
        "\n",
        "- **Fun√ß√£o robusta e modular:**  \n",
        "  A fun√ß√£o `git_commit_and_push()` aceita um caminho √∫nico (string) ou uma lista de arquivos, permitindo commit em lote e integra√ß√£o com estrat√©gias de batch commit (threshold).\n",
        "- **Configura√ß√£o automatizada de usu√°rio e e-mail do git:**  \n",
        "  Garante commits v√°lidos para rastreabilidade, auditoria e integra√ß√£o com pipelines autom√°ticos.\n",
        "- **Valida√ß√£o de caminhos e mensagens informativas:**  \n",
        "  Apenas arquivos existentes s√£o adicionados. Mensagens de sucesso, erro ou aviso detalhadas facilitam troubleshooting e manuten√ß√£o.\n",
        "- **Compat√≠vel com commit vazio:**  \n",
        "  Permite o uso do par√¢metro `--allow-empty` para garantir que o pipeline siga mesmo sem altera√ß√µes detectadas, √∫til para sincroniza√ß√£o e CI/CD.\n",
        "- **Push autenticado via token:**  \n",
        "  Utiliza o token pessoal fornecido nas vari√°veis globais para garantir push seguro e sem interven√ß√£o manual.\n",
        "- **Design pronto para integra√ß√£o com logs centralizados:**  \n",
        "  Recomenda-se registrar todas as a√ß√µes relevantes de commit/push utilizando o log √∫nico modular definido na C√©lula 1.\n",
        "\n",
        "---\n",
        "\n",
        "## Par√¢metros e vari√°veis globais utilizados\n",
        "\n",
        "- **`GITHUB_USER`**, **`GITHUB_REPO`**, **`GITHUB_TOKEN`**: Definidos nas c√©lulas anteriores para autentica√ß√£o e configura√ß√£o do reposit√≥rio.\n",
        "- **`repo_dir`**: Caminho absoluto do reposit√≥rio clonado no ambiente Colab.\n",
        "- **`file_paths`**: String ou lista de arquivos a serem commitados e enviados.\n",
        "- **`commit_message`**: Mensagem do commit, customiz√°vel conforme a opera√ß√£o realizada.\n",
        "\n",
        "---\n",
        "\n",
        "## Como funciona a fun√ß√£o principal\n",
        "\n",
        "- **Valida a exist√™ncia do reposit√≥rio local** antes de prosseguir.\n",
        "- **Aceita arquivos √∫nicos ou m√∫ltiplos** para commit (string ou lista).\n",
        "- **Adiciona apenas arquivos existentes** ao staging, com avisos para arquivos n√£o encontrados.\n",
        "- **Realiza commit (mesmo vazio) e push autenticado** para o reposit√≥rio remoto.\n",
        "- **Emite mensagens claras** de sucesso, erro ou aviso ao longo do processo.\n",
        "\n",
        "---\n",
        "\n",
        "## Exemplo de uso t√≠pico\n",
        "\n",
        "```python\n",
        "# Commit e push de um √∫nico arquivo\n",
        "git_commit_and_push(\"data/rec.json\", \"Atualiza rec.json de grava√ß√£o\")\n",
        "\n",
        "# Commit e push em lote (lista de arquivos)\n",
        "git_commit_and_push([\n",
        "    \"data/rec.json\",\n",
        "    \"posters/user1_poster.jpg\",\n",
        "    \"posters/user2_poster.jpg\"\n",
        "], \"Batch commit de m√∫ltiplos arquivos\")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Seguran√ßa, rastreabilidade e manuten√ß√£o\n",
        "\n",
        "- **Rastreabilidade garantida** por mensagens de commit claras e integra√ß√£o recomendada com o log modular (C√©lula 1).\n",
        "- **Atomicidade** em opera√ß√µes batch, evitando inconsist√™ncias de dados no reposit√≥rio.\n",
        "- **Pronto para integra√ß√£o com pipelines CI/CD**, webhooks e controles de auditoria.\n",
        "- **Mensagens e tratamento de erros detalhados** facilitam o diagn√≥stico e a evolu√ß√£o do sistema.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1aQn1G6yI6Gz",
      "metadata": {
        "id": "1aQn1G6yI6Gz"
      },
      "outputs": [],
      "source": [
        "# ================================================================\n",
        "# C√©lula 5: Commit e Push Autom√°ticos (rec.json, posters, etc.)\n",
        "# ================================================================\n",
        "# Objetivo:\n",
        "# - Automatizar o processo de commit e push dos arquivos modificados (rec.json, posters, etc.) para o reposit√≥rio GitHub\n",
        "# - Suportar tanto commit de arquivo √∫nico como em lote, permitindo estrat√©gia de batch commit baseada em thresholds\n",
        "# - Garantir rastreabilidade, atomicidade e integra√ß√£o segura (CI/CD)\n",
        "#\n",
        "# Estrat√©gia aplicada:\n",
        "# - Fun√ß√£o modular e robusta, preparada para integra√ß√£o com logs e auditoria\n",
        "# - Permite commit vazio por seguran√ßa, evitando falhas em pipelines sincronizados\n",
        "# - Mensagens e tratamento de erros detalhados para facilitar troubleshooting\n",
        "# - Utiliza√ß√£o de vari√°veis globais para caminhos, usu√°rio e token definidos nas c√©lulas anteriores\n",
        "# - Design pronto para evolu√ß√£o, reuso e integra√ß√£o com ferramentas externas (ex: webhooks, jobs, etc.)\n",
        "# ================================================================\n",
        "\n",
        "import os\n",
        "import subprocess\n",
        "\n",
        "def git_commit_and_push(file_paths, commit_message=\"Atualiza rec.json\"):\n",
        "    \"\"\"\n",
        "    Realiza git add, commit e push dos arquivos especificados.\n",
        "    - file_paths pode ser uma string (arquivo √∫nico) ou uma lista de arquivos.\n",
        "    - commit_message √© a mensagem de commit utilizada.\n",
        "\n",
        "    Estrat√©gia:\n",
        "    - Ajusta diret√≥rio para o reposit√≥rio local clonado no Colab\n",
        "    - Configura usu√°rio e e-mail do git (necess√°rios para CI/CD)\n",
        "    - Adiciona arquivos ao staging (aceita m√∫ltiplos arquivos)\n",
        "    - Realiza commit (permite commit vazio)\n",
        "    - Realiza push autenticado via token\n",
        "    \"\"\"\n",
        "    # ============================\n",
        "    # VALIDA√á√ÉO E AJUSTE DE ENTRADAS\n",
        "    # ============================\n",
        "    repo_dir = f\"/content/{GITHUB_REPO}\"\n",
        "    if not os.path.exists(repo_dir):\n",
        "        raise FileNotFoundError(f\"Reposit√≥rio '{repo_dir}' n√£o encontrado. Verifique se a c√©lula de clonagem foi executada.\")\n",
        "    os.chdir(repo_dir)\n",
        "\n",
        "    # Aceita string ou lista de arquivos\n",
        "    if isinstance(file_paths, str):\n",
        "        file_paths = [file_paths]\n",
        "    elif not isinstance(file_paths, list):\n",
        "        raise ValueError(\"file_paths deve ser uma string ou uma lista de caminhos.\")\n",
        "\n",
        "    # ============================\n",
        "    # CONFIGURA√á√ÉO DO USU√ÅRIO GIT (CI/CD)\n",
        "    # ============================\n",
        "    subprocess.run([\"git\", \"config\", \"user.email\", \"contato@aserio.work\"], check=True)\n",
        "    subprocess.run([\"git\", \"config\", \"user.name\", \"SamuelPassamani\"], check=True)\n",
        "\n",
        "    # ============================\n",
        "    # ADI√á√ÉO DOS ARQUIVOS AO STAGING\n",
        "    # ============================\n",
        "    for file_path in file_paths:\n",
        "        # Verifica se o arquivo existe antes de adicionar\n",
        "        if not os.path.exists(file_path):\n",
        "            print(f\"‚ö†Ô∏è Aviso: arquivo '{file_path}' n√£o existe e ser√° ignorado no commit.\")\n",
        "            continue\n",
        "        subprocess.run([\"git\", \"add\", file_path], check=True)\n",
        "\n",
        "    # ============================\n",
        "    # COMMIT (PERMITE COMMIT VAZIO)\n",
        "    # ============================\n",
        "    try:\n",
        "        subprocess.run(\n",
        "            [\"git\", \"commit\", \"-m\", commit_message, \"--allow-empty\"],\n",
        "            check=False  # N√£o for√ßa erro se n√£o houver mudan√ßas\n",
        "        )\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Erro ao tentar realizar commit: {e}\")\n",
        "\n",
        "    # ============================\n",
        "    # PUSH PARA O REPOSIT√ìRIO REMOTO (AUTENTICADO)\n",
        "    # ============================\n",
        "    try:\n",
        "        remote_url = f\"https://{GITHUB_USER}:{GITHUB_TOKEN}@github.com/{GITHUB_USER}/{GITHUB_REPO}.git\"\n",
        "        subprocess.run(\n",
        "            [\"git\", \"push\", remote_url],\n",
        "            check=True\n",
        "        )\n",
        "        print(f\"‚úÖ Push realizado com sucesso! ({commit_message})\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Erro ao tentar realizar push: {e}\")\n",
        "\n",
        "# ============================\n",
        "# FIM DA C√âLULA 5\n",
        "# ============================\n",
        "\n",
        "# Dicas e melhores pr√°ticas:\n",
        "# - Use commit_messages claros e informativos para facilitar a auditoria.\n",
        "# - Utilize a fun√ß√£o dentro de loops ou triggers de batch para commit em lote.\n",
        "# - Integre logs das a√ß√µes de commit/push usando o log √∫nico centralizado (C√©lula 1).\n",
        "# - Em caso de erro de autentica√ß√£o, revise o token e as permiss√µes do GitHub."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "BZ4c3Uk1I7AK",
      "metadata": {
        "id": "BZ4c3Uk1I7AK"
      },
      "source": [
        "# C√©lula 6: Busca de Transmiss√µes na API XCam, Blacklist Tempor√°ria, Fallback via liveInfo e Busca Inteligente/Unit√°ria\n",
        "\n",
        "**Objetivo:**  \n",
        "Realizar a busca das transmiss√µes ativas na API principal da XCam, mantendo o lote de transmiss√µes sempre completo at√© o `LIMIT_DEFAULT` e sem duplicidades, utilizando controle de blacklist tempor√°ria e log de transmiss√µes em processamento.  \n",
        "Inclui fun√ß√µes de busca unit√°ria/inteligente (para manter ‚Äúlote cheio‚Äù continuamente) e gerenciamento autom√°tico de poster, com gera√ß√£o via ffmpeg quando necess√°rio.\n",
        "\n",
        "## Estrat√©gia e melhorias implementadas\n",
        "\n",
        "- **Blacklist tempor√°ria e controle de falhas:**  \n",
        "  Usu√°rios problem√°ticos s√£o bloqueados temporariamente ap√≥s atingirem o limite de falhas (`BLACKLIST_MAX_FAILURES`), acelerando o processamento e evitando ciclos infinitos.\n",
        "- **Busca em lote e unit√°ria com fallback:**  \n",
        "  Consulta a API principal com limite alto para preencher o lote rapidamente. Caso necess√°rio, realiza fallback via `/liveInfo` para usu√°rios sem `src`.\n",
        "- **Controle de duplicidade e fila inteligente:**  \n",
        "  Antes de incluir qualquer transmiss√£o, verifica no log de processamento e na blacklist para evitar tentativas repetidas ou paradas em streams problem√°ticos.\n",
        "- **Poster garantido:**  \n",
        "  Se o poster estiver ausente, inv√°lido ou nulo, gera automaticamente uma imagem via ffmpeg a partir do stream, garantindo sempre um arquivo v√°lido.\n",
        "- **Efici√™ncia e paralelismo:**  \n",
        "  Todas as fun√ß√µes s√£o preparadas para processamento paralelo e integra√ß√£o total ao pipeline XCam.\n",
        "- **Compatibilidade:**  \n",
        "  Suporte total √† busca de usu√°rios espec√≠ficos, agora tamb√©m protegida pela blacklist e controle de falhas.\n",
        "- **Design modular:**  \n",
        "  Fun√ß√µes separadas para busca em lote (`get_broadcasts`), busca por usu√°rios (`buscar_usuarios_especificos`) e busca unit√°ria/primeira transmiss√£o livre (`buscar_proxima_transmissao_livre`), facilitando reuso e manuten√ß√£o.\n",
        "\n",
        "---\n",
        "\n",
        "## Como funciona cada fun√ß√£o\n",
        "\n",
        "- **get_broadcasts:**  \n",
        "  Retorna um lote de transmiss√µes v√°lidas, sempre checando blacklist, log de processamento e gerando poster se necess√°rio. Realiza fallback autom√°tico para `/liveInfo` se n√£o encontrar o src na API principal.\n",
        "- **buscar_usuarios_especificos:**  \n",
        "  Busca apenas os usu√°rios informados, respeitando sempre o controle de blacklist/falhas, e faz fallback via `/liveInfo` quando necess√°rio.\n",
        "- **buscar_proxima_transmissao_livre:**  \n",
        "  Busca rapidamente a pr√≥xima transmiss√£o livre para processamento, sempre utilizando os mesmos crit√©rios de controle, garantindo agilidade na fila e efici√™ncia m√°xima.\n",
        "\n",
        "---\n",
        "\n",
        "## Detalhes t√©cnicos e recomenda√ß√µes\n",
        "\n",
        "- **Blacklist tempor√°ria e controle de falhas:**  \n",
        "  Fun√ß√µes `register_failure`, `clear_failure`, `add_to_blacklist`, `is_in_blacklist`, `load_blacklist` e `save_blacklist` garantem rastreabilidade e bloqueio eficiente de usu√°rios problem√°ticos.\n",
        "- **Arquitetura limpa e modular:**  \n",
        "  C√≥digo preparado para integra√ß√£o futura com log √∫nico centralizado e processamento concorrente.\n",
        "- **Poster sempre v√°lido:**  \n",
        "  Fun√ß√µes utilit√°rias garantem que cada transmiss√£o s√≥ √© liberada para grava√ß√£o se houver poster v√°lido (baixado ou gerado).\n",
        "- **Tratamento de erros robusto:**  \n",
        "  Toda etapa cr√≠tica possui tratamento de exce√ß√µes e mensagens claras para facilitar manuten√ß√£o e monitoramento.\n",
        "\n",
        "---\n",
        "\n",
        "## Exemplo de uso das fun√ß√µes\n",
        "\n",
        "```python\n",
        "# Buscar lote completo de transmiss√µes v√°lidas\n",
        "streams = get_broadcasts(limit=LIMIT_DEFAULT)\n",
        "\n",
        "# Buscar apenas usu√°rios espec√≠ficos\n",
        "streams_especificos = buscar_usuarios_especificos([\"user1\", \"user2\"])\n",
        "\n",
        "# Buscar a pr√≥xima transmiss√£o livre dispon√≠vel\n",
        "proxima_stream = buscar_proxima_transmissao_livre()\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Rastreabilidade, manuten√ß√£o e integra√ß√£o\n",
        "\n",
        "- Blacklist e falhas podem ser migrados para o log centralizado para m√°xima rastreabilidade.\n",
        "- Todas as fun√ß√µes s√£o compat√≠veis com execu√ß√£o paralela e integra√ß√£o CI/CD.\n",
        "- Mensagens detalhadas e arquitetura modular facilitam manuten√ß√£o e futuras expans√µes no pipeline do XCam.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "h1jr7D0pJ7jS",
      "metadata": {
        "id": "h1jr7D0pJ7jS"
      },
      "outputs": [],
      "source": [
        "# ================================================================\n",
        "# C√©lula 6: Busca de Transmiss√µes com Blacklist Tempor√°ria e Controle de Falhas\n",
        "# ================================================================\n",
        "# Objetivo:\n",
        "# - Buscar transmiss√µes ao vivo na API XCam, considerando blacklist e controle de falhas por usu√°rio\n",
        "# - Evitar loops infinitos e tentativas repetidas em usu√°rios problem√°ticos via blacklist tempor√°ria e contador de falhas\n",
        "# - Garantir sempre poster v√°lido (via download ou ffmpeg) antes de liberar qualquer transmiss√£o para processamento\n",
        "# - Modulariza√ß√£o e robustez, pronta para integra√ß√£o com log √∫nico e arquitetura limpa\n",
        "#\n",
        "# Estrat√©gia aplicada:\n",
        "# - L√≥gica de blacklist e falhas modularizada (pronta para futura centraliza√ß√£o no log √∫nico)\n",
        "# - Consulta √† API XCam com fallback autom√°tico para liveInfo\n",
        "# - Fun√ß√µes robustas, preparadas para concorr√™ncia, reuso e integra√ß√£o cont√≠nua no pipeline XCam\n",
        "# ================================================================\n",
        "\n",
        "# ============================\n",
        "# PAR√ÇMETROS E CAMINHOS GLOBAIS (DEVEM VIR DA C√âLULA 1)\n",
        "# ============================\n",
        "# Exemplo de nomes esperados (ajuste conforme sua c√©lula 1!)\n",
        "# BLACKLIST_TIMEOUT: tempo de expira√ß√£o da blacklist (em segundos)\n",
        "# BLACKLIST_MAX_FAILURES: n√∫mero de falhas consecutivas antes de banir\n",
        "# API_SEARCH_LIMIT: limite de transmiss√µes ao buscar usu√°rios espec√≠ficos\n",
        "\n",
        "import os\n",
        "LOGS_DIR = os.path.dirname(LOGS_PATH)\n",
        "BLACKLIST_PATH = os.path.join(LOGS_DIR, \"xcam_blacklist.log\")\n",
        "FAILURE_LOGS_PATH = os.path.join(LOGS_DIR, \"xcam_failures.log\")\n",
        "LOG_PROCESSAMENTO_PATH = os.path.join(LOGS_DIR, \"xcam_processing.log\")\n",
        "\n",
        "# ============================\n",
        "# BLACKLIST TEMPOR√ÅRIA - CRUD\n",
        "# ============================\n",
        "\n",
        "def load_blacklist():\n",
        "    \"\"\"\n",
        "    Carrega a blacklist tempor√°ria (usu√°rio: timestamp).\n",
        "    Apenas mant√©m usu√°rios ainda v√°lidos pelo timeout.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(BLACKLIST_PATH):\n",
        "        return {}\n",
        "    with open(BLACKLIST_PATH, \"r\") as f:\n",
        "        now = time.time()\n",
        "        lines = [line.strip().split(\",\") for line in f if line.strip()]\n",
        "        return {user: float(ts) for user, ts in lines if now - float(ts) < BLACKLIST_TIMEOUT}\n",
        "\n",
        "def save_blacklist(blacklist):\n",
        "    \"\"\"\n",
        "    Salva o dicion√°rio da blacklist no arquivo.\n",
        "    \"\"\"\n",
        "    with open(BLACKLIST_PATH, \"w\") as f:\n",
        "        for user, ts in blacklist.items():\n",
        "            f.write(f\"{user},{ts}\\n\")\n",
        "\n",
        "def add_to_blacklist(username):\n",
        "    \"\"\"\n",
        "    Adiciona usu√°rio √† blacklist com timestamp atual.\n",
        "    \"\"\"\n",
        "    blacklist = load_blacklist()\n",
        "    blacklist[username] = time.time()\n",
        "    save_blacklist(blacklist)\n",
        "    print(f\"‚ö†Ô∏è Usu√°rio '{username}' adicionado √† blacklist tempor√°ria.\")\n",
        "\n",
        "def is_in_blacklist(username):\n",
        "    \"\"\"\n",
        "    Verifica se o usu√°rio est√° na blacklist v√°lida.\n",
        "    \"\"\"\n",
        "    blacklist = load_blacklist()\n",
        "    return username in blacklist\n",
        "\n",
        "# ============================\n",
        "# CONTROLE DE FALHAS POR USU√ÅRIO\n",
        "# ============================\n",
        "\n",
        "def load_failures():\n",
        "    \"\"\"\n",
        "    Carrega o n√∫mero de falhas por usu√°rio.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(FAILURE_LOGS_PATH):\n",
        "        return {}\n",
        "    with open(FAILURE_LOGS_PATH, \"r\") as f:\n",
        "        return {user: int(count) for user, count in (line.strip().split(\",\") for line in f if line.strip())}\n",
        "\n",
        "def save_failures(failures):\n",
        "    \"\"\"\n",
        "    Salva o contador de falhas por usu√°rio.\n",
        "    \"\"\"\n",
        "    with open(FAILURE_LOGS_PATH, \"w\") as f:\n",
        "        for user, count in failures.items():\n",
        "            f.write(f\"{user},{count}\\n\")\n",
        "\n",
        "def register_failure(username):\n",
        "    \"\"\"\n",
        "    Registra uma falha para o usu√°rio e move para blacklist se exceder o limite.\n",
        "    \"\"\"\n",
        "    failures = load_failures()\n",
        "    failures[username] = failures.get(username, 0) + 1\n",
        "    if failures[username] >= BLACKLIST_MAX_FAILURES:\n",
        "        add_to_blacklist(username)\n",
        "        failures.pop(username)  # Limpa contador ao entrar na blacklist\n",
        "    save_failures(failures)\n",
        "\n",
        "def clear_failure(username):\n",
        "    \"\"\"\n",
        "    Limpa o contador de falhas para o usu√°rio.\n",
        "    \"\"\"\n",
        "    failures = load_failures()\n",
        "    if username in failures:\n",
        "        failures.pop(username)\n",
        "        save_failures(failures)\n",
        "\n",
        "# ============================\n",
        "# BUSCA DE TRANSMISS√ïES NA API XCAM\n",
        "# ============================\n",
        "\n",
        "def get_broadcasts(limit=LIMIT_DEFAULT, page=PAGE_DEFAULT, usuarios_especificos=None, temp_folder=None):\n",
        "    \"\"\"\n",
        "    Busca transmiss√µes ao vivo, respeitando blacklist, falhas e log de processamento.\n",
        "    Garante poster v√°lido (download ou ffmpeg) e faz fallback autom√°tico.\n",
        "    \"\"\"\n",
        "    if temp_folder is None:\n",
        "        temp_folder = POSTER_TEMP_PATH\n",
        "    LOG_PROCESSAMENTO_PATH = \"/content/xcam_processing.log\"\n",
        "    transmissao_em_proc = set()\n",
        "    if os.path.exists(LOG_PROCESSAMENTO_PATH):\n",
        "        with open(LOG_PROCESSAMENTO_PATH, \"r\") as f:\n",
        "            transmissao_em_proc = set([line.strip() for line in f if line.strip()])\n",
        "\n",
        "    if usuarios_especificos:\n",
        "        api_url_main = f\"https://api.xcam.gay/?limit={API_SEARCH_LIMIT}&page=1\"\n",
        "        print(f\"üåê Acessando API principal (usu√°rios espec√≠ficos): {api_url_main}\")\n",
        "    else:\n",
        "        api_url_main = f\"https://api.xcam.gay/?limit=1500&page=1\"\n",
        "        print(f\"üåê Acessando API principal (todas transmiss√µes online): {api_url_main}\")\n",
        "\n",
        "    streams_from_main = []\n",
        "    streams_without_preview = []\n",
        "\n",
        "    try:\n",
        "        response_main = requests.get(api_url_main)\n",
        "        response_main.raise_for_status()\n",
        "        data_main = response_main.json()\n",
        "        broadcasts_data = data_main.get(\"broadcasts\")\n",
        "        if not broadcasts_data:\n",
        "            print(\"‚ö†Ô∏è Chave 'broadcasts' n√£o encontrada na resposta da API principal.\")\n",
        "            return []\n",
        "        items = broadcasts_data.get(\"items\")\n",
        "        if not isinstance(items, list):\n",
        "            print(f\"‚ö†Ô∏è Chave 'items' n√£o encontrada ou n√£o √© uma lista em 'broadcasts'.\")\n",
        "            return []\n",
        "\n",
        "        for item in items:\n",
        "            preview = item.get(\"preview\") or {}\n",
        "            src = preview.get(\"src\")\n",
        "            poster = preview.get(\"poster\")\n",
        "            username = item.get(\"username\", \"desconhecido\")\n",
        "            if username in transmissao_em_proc or is_in_blacklist(username):\n",
        "                continue\n",
        "            if usuarios_especificos and username not in usuarios_especificos:\n",
        "                continue\n",
        "            if src:\n",
        "                poster_path = None\n",
        "                try:\n",
        "                    if poster and isinstance(poster, str) and poster.strip():\n",
        "                        poster_path = download_and_save_poster(poster, username, temp_folder)\n",
        "                    if not is_poster_valid(poster_path):\n",
        "                        poster_path = generate_poster_with_ffmpeg(src, username, temp_folder)\n",
        "                    if not is_poster_valid(poster_path):\n",
        "                        register_failure(username)\n",
        "                        continue\n",
        "                    else:\n",
        "                        clear_failure(username)\n",
        "                except Exception as e:\n",
        "                    print(f\"‚ùå Falha ao gerar poster para {username}: {e}\")\n",
        "                    register_failure(username)\n",
        "                    continue\n",
        "                streams_from_main.append({\n",
        "                    \"username\": username,\n",
        "                    \"src\": src,\n",
        "                    \"poster\": poster_path\n",
        "                })\n",
        "            else:\n",
        "                streams_without_preview.append({\"username\": username})\n",
        "\n",
        "        print(f\"‚úÖ {len(streams_from_main)} transmiss√µes com URL na API principal (total consultado).\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Erro ao acessar API principal: {e}\")\n",
        "        return []\n",
        "\n",
        "    # Fallback: busca via liveInfo para streams sem URL na API principal\n",
        "    streams_from_liveinfo = []\n",
        "    if streams_without_preview:\n",
        "        print(f\"üîÅ Buscando liveInfo para {len(streams_without_preview)} streams sem URL na API principal...\")\n",
        "        for stream_info in streams_without_preview:\n",
        "            username = stream_info[\"username\"]\n",
        "            if username in transmissao_em_proc or is_in_blacklist(username):\n",
        "                continue\n",
        "            if usuarios_especificos and username not in usuarios_especificos:\n",
        "                continue\n",
        "            api_url_liveinfo = f\"https://api.xcam.gay/user/{username}/liveInfo\"\n",
        "            try:\n",
        "                response_liveinfo = requests.get(api_url_liveinfo)\n",
        "                response_liveinfo.raise_for_status()\n",
        "                data_liveinfo = response_liveinfo.json()\n",
        "                m3u8_url = data_liveinfo.get(\"cdnURL\") or data_liveinfo.get(\"edgeURL\")\n",
        "                poster_path = None\n",
        "                if m3u8_url:\n",
        "                    poster_path = generate_poster_with_ffmpeg(m3u8_url, username, temp_folder)\n",
        "                    if not is_poster_valid(poster_path):\n",
        "                        register_failure(username)\n",
        "                        continue\n",
        "                    else:\n",
        "                        clear_failure(username)\n",
        "                    streams_from_liveinfo.append({\n",
        "                        \"username\": username,\n",
        "                        \"src\": m3u8_url,\n",
        "                        \"poster\": poster_path\n",
        "                    })\n",
        "                else:\n",
        "                    print(f\"‚ö†Ô∏è liveInfo de {username} n√£o retornou cdnURL/edgeURL (usu√°rio possivelmente offline).\")\n",
        "                    register_failure(username)\n",
        "            except Exception as ex:\n",
        "                print(f\"‚ùå Erro ao buscar liveInfo para {username}: {ex}\")\n",
        "                register_failure(username)\n",
        "            time.sleep(0.5)\n",
        "\n",
        "    # Junta, evita duplicidade de usu√°rio, blacklist e respeita 'limit' FINAL\n",
        "    final_streams_list = []\n",
        "    seen_usernames = set()\n",
        "    for stream in streams_from_main + streams_from_liveinfo:\n",
        "        username = stream[\"username\"]\n",
        "        if username in seen_usernames or username in transmissao_em_proc or is_in_blacklist(username):\n",
        "            continue\n",
        "        final_streams_list.append(stream)\n",
        "        seen_usernames.add(username)\n",
        "        if len(final_streams_list) >= limit:\n",
        "            break\n",
        "\n",
        "    print(f\"üîé Selecionadas {len(final_streams_list)} streams v√°lidas ap√≥s fallback (respeitando limit={limit}).\")\n",
        "    return final_streams_list\n",
        "\n",
        "# ============================\n",
        "# BUSCA DE USU√ÅRIOS ESPEC√çFICOS (COM BLACKLIST)\n",
        "# ============================\n",
        "\n",
        "def buscar_usuarios_especificos(usuarios_lista, temp_folder=None):\n",
        "    \"\"\"\n",
        "    Busca usu√°rios espec√≠ficos via API, agora respeitando blacklist e controle de falhas.\n",
        "    \"\"\"\n",
        "    if temp_folder is None:\n",
        "        temp_folder = POSTER_TEMP_PATH\n",
        "    LOG_PROCESSAMENTO_PATH = \"/content/xcam_processing.log\"\n",
        "    transmissao_em_proc = set()\n",
        "    if os.path.exists(LOG_PROCESSAMENTO_PATH):\n",
        "        with open(LOG_PROCESSAMENTO_PATH, \"r\") as f:\n",
        "            transmissao_em_proc = set([line.strip() for line in f if line.strip()])\n",
        "\n",
        "    api_url = f\"https://api.xcam.gay/?limit={API_SEARCH_LIMIT}&page=1\"\n",
        "    print(f\"üîç Buscando usu√°rios espec√≠ficos em {api_url}\")\n",
        "    try:\n",
        "        response = requests.get(api_url)\n",
        "        response.raise_for_status()\n",
        "        data = response.json()\n",
        "        items = data.get(\"broadcasts\", {}).get(\"items\", [])\n",
        "        encontrados = []\n",
        "        sem_src = []\n",
        "        for item in items:\n",
        "            username = item.get(\"username\", \"\")\n",
        "            if username in usuarios_lista and username not in transmissao_em_proc and not is_in_blacklist(username):\n",
        "                preview = item.get(\"preview\") or {}\n",
        "                src = preview.get(\"src\")\n",
        "                poster = preview.get(\"poster\")\n",
        "                poster_path = None\n",
        "                try:\n",
        "                    if src:\n",
        "                        if poster and isinstance(poster, str) and poster.strip():\n",
        "                            poster_path = download_and_save_poster(poster, username, temp_folder)\n",
        "                        if not is_poster_valid(poster_path):\n",
        "                            poster_path = generate_poster_with_ffmpeg(src, username, temp_folder)\n",
        "                        if not is_poster_valid(poster_path):\n",
        "                            register_failure(username)\n",
        "                            continue\n",
        "                        else:\n",
        "                            clear_failure(username)\n",
        "                        encontrados.append({\n",
        "                            \"username\": username,\n",
        "                            \"src\": src,\n",
        "                            \"poster\": poster_path\n",
        "                        })\n",
        "                    else:\n",
        "                        sem_src.append(username)\n",
        "                except Exception as e:\n",
        "                    print(f\"‚ùå Falha ao gerar poster para {username}: {e}\")\n",
        "                    register_failure(username)\n",
        "        for username in sem_src:\n",
        "            if username in transmissao_em_proc or is_in_blacklist(username):\n",
        "                continue\n",
        "            api_url_liveinfo = f\"https://api.xcam.gay/user/{username}/liveInfo\"\n",
        "            try:\n",
        "                response_liveinfo = requests.get(api_url_liveinfo)\n",
        "                response_liveinfo.raise_for_status()\n",
        "                data_liveinfo = response_liveinfo.json()\n",
        "                m3u8_url = data_liveinfo.get(\"cdnURL\") or data_liveinfo.get(\"edgeURL\")\n",
        "                poster_path = None\n",
        "                if m3u8_url:\n",
        "                    poster_path = generate_poster_with_ffmpeg(m3u8_url, username, temp_folder)\n",
        "                    if not is_poster_valid(poster_path):\n",
        "                        register_failure(username)\n",
        "                        continue\n",
        "                    else:\n",
        "                        clear_failure(username)\n",
        "                    encontrados.append({\n",
        "                        \"username\": username,\n",
        "                        \"src\": m3u8_url,\n",
        "                        \"poster\": poster_path\n",
        "                    })\n",
        "                else:\n",
        "                    print(f\"‚ö†Ô∏è liveInfo de {username} n√£o retornou cdnURL/edgeURL (usu√°rio possivelmente offline).\")\n",
        "                    register_failure(username)\n",
        "            except Exception as ex:\n",
        "                print(f\"‚ùå Erro ao buscar liveInfo para {username}: {ex}\")\n",
        "                register_failure(username)\n",
        "            time.sleep(0.5)\n",
        "        print(f\"Encontrados {len(encontrados)} dos {len(usuarios_lista)} usu√°rios procurados (incluindo fallback).\")\n",
        "        return encontrados\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Erro ao buscar usu√°rios espec√≠ficos: {e}\")\n",
        "        return []\n",
        "\n",
        "# ============================\n",
        "# BUSCA DA PR√ìXIMA TRANSMISS√ÉO DISPON√çVEL (COM BLACKLIST)\n",
        "# ============================\n",
        "\n",
        "def buscar_proxima_transmissao_livre(temp_folder=None):\n",
        "    \"\"\"\n",
        "    Busca a pr√≥xima transmiss√£o ao vivo n√£o processada, com poster v√°lido e ignorando blacklist.\n",
        "    \"\"\"\n",
        "    if temp_folder is None:\n",
        "        temp_folder = POSTER_TEMP_PATH\n",
        "    LOG_PROCESSAMENTO_PATH = \"/content/xcam_processing.log\"\n",
        "    transmissao_em_proc = set()\n",
        "    if os.path.exists(LOG_PROCESSAMENTO_PATH):\n",
        "        with open(LOG_PROCESSAMENTO_PATH, \"r\") as f:\n",
        "            transmissao_em_proc = set([line.strip() for line in f if line.strip()])\n",
        "\n",
        "    api_url_main = f\"https://api.xcam.gay/?limit=1500&page=1\"\n",
        "    print(f\"üîé Buscando pr√≥xima transmiss√£o livre: {api_url_main}\")\n",
        "    try:\n",
        "        response_main = requests.get(api_url_main)\n",
        "        response_main.raise_for_status()\n",
        "        data_main = response_main.json()\n",
        "        items = data_main.get(\"broadcasts\", {}).get(\"items\", [])\n",
        "        for item in items:\n",
        "            username = item.get(\"username\", \"desconhecido\")\n",
        "            if username in transmissao_em_proc or is_in_blacklist(username):\n",
        "                continue\n",
        "            preview = item.get(\"preview\") or {}\n",
        "            src = preview.get(\"src\")\n",
        "            poster = preview.get(\"poster\")\n",
        "            try:\n",
        "                if src:\n",
        "                    poster_path = None\n",
        "                    if poster and isinstance(poster, str) and poster.strip():\n",
        "                        poster_path = download_and_save_poster(poster, username, temp_folder)\n",
        "                    if not is_poster_valid(poster_path):\n",
        "                        poster_path = generate_poster_with_ffmpeg(src, username, temp_folder)\n",
        "                    if not is_poster_valid(poster_path):\n",
        "                        register_failure(username)\n",
        "                        continue\n",
        "                    else:\n",
        "                        clear_failure(username)\n",
        "                    print(f\"üéØ Transmiss√£o livre encontrada: {username}\")\n",
        "                    return {\n",
        "                        \"username\": username,\n",
        "                        \"src\": src,\n",
        "                        \"poster\": poster_path\n",
        "                    }\n",
        "                else:\n",
        "                    api_url_liveinfo = f\"https://api.xcam.gay/user/{username}/liveInfo\"\n",
        "                    try:\n",
        "                        response_liveinfo = requests.get(api_url_liveinfo)\n",
        "                        response_liveinfo.raise_for_status()\n",
        "                        data_liveinfo = response_liveinfo.json()\n",
        "                        m3u8_url = data_liveinfo.get(\"cdnURL\") or data_liveinfo.get(\"edgeURL\")\n",
        "                        poster_path = None\n",
        "                        if m3u8_url:\n",
        "                            poster_path = generate_poster_with_ffmpeg(m3u8_url, username, temp_folder)\n",
        "                            if not is_poster_valid(poster_path):\n",
        "                                register_failure(username)\n",
        "                                continue\n",
        "                            else:\n",
        "                                clear_failure(username)\n",
        "                            print(f\"üéØ Transmiss√£o livre (pelo liveInfo) encontrada: {username}\")\n",
        "                            return {\n",
        "                                \"username\": username,\n",
        "                                \"src\": m3u8_url,\n",
        "                                \"poster\": poster_path\n",
        "                            }\n",
        "                        else:\n",
        "                            register_failure(username)\n",
        "                    except Exception as ex:\n",
        "                        print(f\"‚ùå Erro ao buscar liveInfo para {username}: {ex}\")\n",
        "                        register_failure(username)\n",
        "                    time.sleep(0.5)\n",
        "            except Exception as e:\n",
        "                print(f\"‚ùå Falha ao processar transmiss√£o {username}: {e}\")\n",
        "                register_failure(username)\n",
        "        print(\"üö´ Nenhuma transmiss√£o livre encontrada ap√≥s varrer todas online.\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Erro ao buscar transmiss√µes online: {e}\")\n",
        "        return None\n",
        "\n",
        "# ================================================================\n",
        "# FIM DA C√âLULA 6 ‚Äî BUSCA E BLACKLIST\n",
        "# ================================================================\n",
        "\n",
        "# Observa√ß√µes:\n",
        "# - Recomenda-se migrar o controle de blacklist e falhas para o log centralizado (C√©lula 1) para m√°xima rastreabilidade.\n",
        "# - Todas as fun√ß√µes est√£o preparadas para uso concorrente e integra√ß√£o com o pipeline modular do XCam.\n",
        "# - Poster gerado sempre √© validado, evitando arquivos inv√°lidos ou corrompidos.\n",
        "# - Tratamento de erro robusto e logging detalhado garantem manuten√ß√£o facilitada."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "jGFyqOUoKEF7",
      "metadata": {
        "id": "jGFyqOUoKEF7"
      },
      "source": [
        "# C√©lula 7: Grava√ß√£o da Stream, Poster Autom√°tico, Controle de Falhas, Log Seguro e Blacklist Inteligente\n",
        "\n",
        "**Objetivo:**  \n",
        "Automatizar a grava√ß√£o de transmiss√µes ao vivo com ffmpeg, garantindo robustez, rastreabilidade e integra√ß√£o com a l√≥gica de blacklist tempor√°ria e controle de falhas. A c√©lula tamb√©m assegura o gerenciamento seguro do log de transmiss√µes em processamento e a limpeza de arquivos tempor√°rios.\n",
        "\n",
        "## Estrat√©gia e melhorias implementadas\n",
        "\n",
        "- **Gerenciamento seguro de log:**  \n",
        "  O usu√°rio √© registrado no log de transmiss√µes em processamento antes da grava√ß√£o e removido dele ao final (tanto em sucesso quanto em erro), evitando duplicidade e permitindo paralelismo seguro.\n",
        "- **Poster sempre v√°lido:**  \n",
        "  O sistema tenta baixar o poster da API. Se o poster estiver ausente, inv√°lido ou nulo, gera automaticamente uma imagem via ffmpeg, assegurando que toda transmiss√£o tenha um poster associado e v√°lido.\n",
        "- **Controle de tempo m√≠nimo:**  \n",
        "  Se a grava√ß√£o resultar em v√≠deo muito curto, tanto o arquivo de v√≠deo quanto o poster s√£o descartados imediatamente, e uma falha √© registrada para o usu√°rio.\n",
        "- **Tratamento robusto de falhas:**  \n",
        "  Qualquer falha (ffmpeg, exceptions, etc.) √© registrada. Ao atingir o n√∫mero m√°ximo de falhas consecutivas (`BLACKLIST_MAX_FAILURES`), o usu√°rio entra automaticamente na blacklist tempor√°ria, evitando tentativas infinitas e desperd√≠cio de recursos.\n",
        "- **Limpeza automatizada:**  \n",
        "  Ap√≥s upload ou erro, todos os arquivos tempor√°rios (v√≠deo e poster) s√£o removidos, otimizando o uso do disco e mantendo o ambiente do Colab limpo.\n",
        "- **Reset de falhas em caso de sucesso:**  \n",
        "  Quando a grava√ß√£o √© v√°lida, o contador de falhas do usu√°rio √© limpo, evitando blacklist indevida.\n",
        "- **Coment√°rios detalhados e c√≥digo modular:**  \n",
        "  O fluxo √© completamente documentado, facilitando manuten√ß√£o, revis√£o e entendimento por toda a equipe.\n",
        "\n",
        "---\n",
        "\n",
        "## Fluxo resumido da fun√ß√£o principal\n",
        "\n",
        "1. **Registra o usu√°rio** no log de transmiss√µes em processamento.\n",
        "2. **Garante um poster v√°lido** (download ou gera√ß√£o autom√°tica).\n",
        "3. **Executa o ffmpeg** para gravar a transmiss√£o e monitora o progresso em tempo real.\n",
        "4. **Valida a grava√ß√£o**:\n",
        "   - Se falhar, registra falha e trata blacklist.\n",
        "   - Se for curta demais, descarta e registra falha.\n",
        "   - Se for v√°lida, limpa contador de falhas e prossegue normalmente.\n",
        "5. **Ap√≥s upload ou erro**, remove o usu√°rio do log e limpa arquivos tempor√°rios.\n",
        "\n",
        "---\n",
        "\n",
        "## Exemplo de uso\n",
        "\n",
        "```python\n",
        "resultado = gravar_stream(username=\"user123\", m3u8_url=\"https://cdn.xcam.gay/m3u8/...\", poster_url=\"https://api.xcam.gay/poster/...\")\n",
        "if resultado['upload_success']:\n",
        "    print(\"Grava√ß√£o e upload realizados com sucesso!\")\n",
        "else:\n",
        "    print(\"Falha na grava√ß√£o ou upload:\", resultado['abyss_response'])\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Seguran√ßa, rastreabilidade e integra√ß√£o\n",
        "\n",
        "- **Pronto para CI/CD e execu√ß√£o paralela:**  \n",
        "  Controle rigoroso de log e blacklist garante execu√ß√£o concorrente, segura e rastre√°vel por todo o pipeline XCam.\n",
        "- **Integra√ß√£o total com as fun√ß√µes globais:**  \n",
        "  Utiliza fun√ß√µes de blacklist e falha da C√©lula 6, promovendo rastreabilidade e controle centralizado.\n",
        "- **Diagn√≥stico facilitado:**  \n",
        "  Mensagens e logs detalhados em cada etapa do processo.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eJ_jrfNgKZNr",
      "metadata": {
        "id": "eJ_jrfNgKZNr"
      },
      "outputs": [],
      "source": [
        "# ================================================================\n",
        "# C√©lula 7: Grava√ß√£o Autom√°tica de Transmiss√£o, Controle de Log, Limpeza e Blacklist Inteligente\n",
        "# ================================================================\n",
        "# Objetivo:\n",
        "# - Gravar transmiss√µes ao vivo utilizando ffmpeg, com controle rigoroso de log de processamento, tratamento de falhas e integra√ß√£o com blacklist tempor√°ria.\n",
        "# - Garantir que cada transmiss√£o seja registrada no log de processamento no in√≠cio e removida ao final (sucesso ou erro), evitando duplicidade ou processamento concorrente.\n",
        "# - Registrar falhas (ffmpeg, dura√ß√£o insuficiente, poster inv√°lido), escalando usu√°rios para a blacklist tempor√°ria ao atingir o limite de tentativas, conforme regras globais (C√©lula 6).\n",
        "# - Limpar arquivos tempor√°rios ap√≥s uso.\n",
        "# - Modular e pronto para integra√ß√£o com pipelines CI/CD, execu√ß√£o concorrente e ambientes colaborativos.\n",
        "# ================================================================\n",
        "\n",
        "import os\n",
        "LOGS_DIR = os.path.dirname(LOGS_PATH)\n",
        "LOG_PROCESSAMENTO_PATH = os.path.join(LOGS_DIR, \"xcam_processing.log\")\n",
        "\n",
        "def get_video_duration(filepath):\n",
        "    \"\"\"\n",
        "    Retorna a dura√ß√£o real do arquivo mp4, em segundos, utilizando ffprobe.\n",
        "    Retorna None em caso de erro ou se o arquivo n√£o existir.\n",
        "    \"\"\"\n",
        "    import subprocess\n",
        "    import json\n",
        "    try:\n",
        "        if not os.path.exists(filepath):\n",
        "            print(f\"‚ö†Ô∏è Arquivo para ffprobe n√£o encontrado: {filepath}\")\n",
        "            return None\n",
        "        cmd = [\n",
        "            \"ffprobe\", \"-v\", \"error\",\n",
        "            \"-show_entries\", \"format=duration\",\n",
        "            \"-of\", \"json\",\n",
        "            filepath\n",
        "        ]\n",
        "        result = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
        "        info = json.loads(result.stdout)\n",
        "        duration = float(info[\"format\"][\"duration\"])\n",
        "        return int(round(duration))\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è N√£o foi poss√≠vel obter dura√ß√£o via ffprobe para {filepath}: {e}\")\n",
        "        return None\n",
        "\n",
        "def gravar_stream(username, m3u8_url, poster_url=None, poster_frame_time=7):\n",
        "    \"\"\"\n",
        "    Grava a transmiss√£o ao vivo do usu√°rio usando ffmpeg, com controle de erros, log e integra√ß√£o √† blacklist.\n",
        "    - Adiciona usu√°rio ao log de processamento no in√≠cio.\n",
        "    - Remove do log ao finalizar, independentemente do resultado (robusto via finally).\n",
        "    - Em caso de falha do ffmpeg ou grava√ß√£o muito curta, registra falha do usu√°rio.\n",
        "    - Ao atingir N falhas consecutivas, usu√°rio entra na blacklist (fun√ß√µes globais).\n",
        "    - Limpa arquivos tempor√°rios ao final.\n",
        "    - Garante poster v√°lido: baixa da poster_url, ou gera automaticamente com ffmpeg se ausente/inv√°lido.\n",
        "    - poster_frame_time: segundo do v√≠deo onde a captura do poster ser√° feita, se necess√°rio.\n",
        "    \"\"\"\n",
        "    # LOG_PROCESSAMENTO_PATH = \"/content/xcam_processing.log\"\n",
        "\n",
        "    # Adiciona a transmiss√£o ao log de transmiss√µes em processamento\n",
        "    try:\n",
        "        with open(LOG_PROCESSAMENTO_PATH, \"a\") as f:\n",
        "            f.write(f\"{username}\\n\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Erro ao registrar transmiss√£o em processamento no log: {e}\")\n",
        "\n",
        "    start_time_dt = datetime.now()\n",
        "    data_str = start_time_dt.strftime(\"%d-%m-%Y\")\n",
        "    horario_str = start_time_dt.strftime(\"%H-%M\")\n",
        "    temp_filename = f\"{username}_{start_time_dt.strftime('%Y%m%d_%H%M%S')}_temp.mp4\"\n",
        "    filepath = os.path.join(TEMP_OUTPUT_FOLDER, temp_filename)\n",
        "\n",
        "    print(f\"\\nüé¨ Iniciando grava√ß√£o de: {username} (URL: {m3u8_url}) em {filepath}\")\n",
        "\n",
        "    # Garante poster v√°lido\n",
        "    poster_temp_path = None\n",
        "    if poster_url:\n",
        "        poster_temp_path = download_and_save_poster(poster_url, username, TEMP_OUTPUT_FOLDER)\n",
        "    if not is_poster_valid(poster_temp_path) and m3u8_url:\n",
        "        poster_temp_path = generate_poster_with_ffmpeg(m3u8_url, username, TEMP_OUTPUT_FOLDER, frame_time=poster_frame_time)\n",
        "\n",
        "    ffmpeg_cmd = [\n",
        "        \"ffmpeg\", \"-i\", m3u8_url,\n",
        "        \"-t\", str(RECORD_SECONDS),\n",
        "\n",
        "        \"-c\", \"copy\", \"-y\", filepath\n",
        "    ]\n",
        "\n",
        "    start_time_process = time.time()\n",
        "    process = None\n",
        "\n",
        "    try:\n",
        "        process = subprocess.Popen(\n",
        "            ffmpeg_cmd,\n",
        "            stdout=subprocess.PIPE,\n",
        "            stderr=subprocess.STDOUT,\n",
        "            text=True,\n",
        "            bufsize=1,\n",
        "            universal_newlines=True\n",
        "        )\n",
        "\n",
        "        # Monitoramento de progresso do ffmpeg (logs em tempo real)\n",
        "        elapsed_seconds = 0\n",
        "        last_log_minute = -1\n",
        "        while True:\n",
        "            line = process.stdout.readline()\n",
        "            if not line and process.poll() is not None:\n",
        "                break\n",
        "            if \"time=\" in line:\n",
        "                try:\n",
        "                    match = re.search(r\"time=(\\d+):(\\d+):(\\d+)\", line)\n",
        "                    if match:\n",
        "                        h, m, s = map(int, match.groups())\n",
        "                        elapsed_seconds = h * 3600 + m * 60 + s\n",
        "                        if elapsed_seconds // 60 != last_log_minute:\n",
        "                            log_progress(username, elapsed_seconds, RECORD_SECONDS)\n",
        "                            last_log_minute = elapsed_seconds // 60\n",
        "                except Exception:\n",
        "                    pass\n",
        "\n",
        "        process.wait()\n",
        "        end_time_process = time.time()\n",
        "        elapsed_seconds_proc = round(end_time_process - start_time_process)\n",
        "        log_progress(username, elapsed_seconds_proc, RECORD_SECONDS)\n",
        "\n",
        "        # Se FFmpeg falhou, registra falha para o usu√°rio e retorna erro\n",
        "        if process.returncode != 0:\n",
        "            print(f\"‚ùå FFmpeg falhou para {username}. C√≥digo de sa√≠da: {process.returncode}\")\n",
        "            register_failure(username)\n",
        "            return {\n",
        "                'username': username,\n",
        "                'filename': temp_filename,\n",
        "                'filepath': filepath,\n",
        "                'upload_success': False,\n",
        "                'abyss_response': \"Grava√ß√£o FFmpeg falhou\"\n",
        "            }\n",
        "\n",
        "        # Valida√ß√£o pelo tempo real do arquivo gravado (robusta)\n",
        "        elapsed_seconds_real = get_video_duration(filepath)\n",
        "        if elapsed_seconds_real is not None:\n",
        "            print(f\"‚úÖ Dura√ß√£o real do arquivo gravado: {elapsed_seconds_real}s (ffprobe)\")\n",
        "        else:\n",
        "            print(f\"‚ö†Ô∏è N√£o foi poss√≠vel aferir dura√ß√£o real, usando a do processo: {elapsed_seconds_proc}s\")\n",
        "            elapsed_seconds_real = elapsed_seconds_proc\n",
        "\n",
        "        if elapsed_seconds_real < RECORD_SECONDS_MIN:\n",
        "            print(f\"‚è© Dura√ß√£o gravada ({elapsed_seconds_real}s) menor que o m√≠nimo ({RECORD_SECONDS_MIN}s). Arquivo descartado.\")\n",
        "            register_failure(username)\n",
        "            if os.path.exists(filepath): os.remove(filepath)\n",
        "            if poster_temp_path and os.path.exists(poster_temp_path): os.remove(poster_temp_path)\n",
        "            return {\n",
        "                'username': username,\n",
        "                'filename': temp_filename,\n",
        "                'filepath': filepath,\n",
        "                'upload_success': False,\n",
        "                'abyss_response': \"Grava√ß√£o muito curta (descartada)\"\n",
        "            }\n",
        "\n",
        "        # Sucesso: limpa falhas acumuladas do usu√°rio\n",
        "        clear_failure(username)\n",
        "        tempo_formatado = format_seconds(elapsed_seconds_real)\n",
        "        final_filename = f\"{username}_{data_str}_{horario_str}_{tempo_formatado}.mp4\"\n",
        "        final_filepath = os.path.join(TEMP_OUTPUT_FOLDER, final_filename)\n",
        "\n",
        "        try:\n",
        "            os.rename(filepath, final_filepath)\n",
        "            print(f\"‚úÖ Arquivo renomeado para: {final_filename}\")\n",
        "            filepath_for_upload = final_filepath\n",
        "            filename_for_upload = final_filename\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Erro ao renomear arquivo {temp_filename} para {final_filename}: {e}\")\n",
        "            filepath_for_upload = filepath\n",
        "            filename_for_upload = temp_filename\n",
        "\n",
        "        # Realiza upload e atualiza√ß√£o do banco de dados (json)\n",
        "        success, abyss_resp, slug = upload_to_abyss_and_update_json(\n",
        "            filepath_for_upload, username, elapsed_seconds_real,\n",
        "            poster_temp_path=poster_temp_path\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'username': username,\n",
        "            'filename': filename_for_upload,\n",
        "            'filepath': filepath_for_upload,\n",
        "            'upload_success': success,\n",
        "            'abyss_response': abyss_resp,\n",
        "            'slug': slug\n",
        "        }\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"‚ùå Erro: Comando 'ffmpeg' n√£o encontrado. Certifique-se de que foi instalado corretamente.\")\n",
        "        register_failure(username)\n",
        "        return {\n",
        "            'username': username,\n",
        "            'filename': None,\n",
        "            'filepath': None,\n",
        "            'upload_success': False,\n",
        "            'abyss_response': \"Comando FFmpeg n√£o encontrado\"\n",
        "        }\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Erro inesperado durante a execu√ß√£o do FFmpeg para {username}: {e}\")\n",
        "        register_failure(username)\n",
        "        return {\n",
        "            'username': username,\n",
        "            'filename': None,\n",
        "            'filepath': None,\n",
        "            'upload_success': False,\n",
        "            'abyss_response': f\"Erro inesperado na execu√ß√£o do FFmpeg: {e}\"\n",
        "        }\n",
        "    finally:\n",
        "        # Remo√ß√£o segura do usu√°rio do log de transmiss√µes em processamento\n",
        "        try:\n",
        "            if os.path.exists(LOG_PROCESSAMENTO_PATH):\n",
        "                with open(LOG_PROCESSAMENTO_PATH, \"r\") as f:\n",
        "                    linhas = f.readlines()\n",
        "                with open(LOG_PROCESSAMENTO_PATH, \"w\") as f:\n",
        "                    for l in linhas:\n",
        "                        if l.strip() != username:\n",
        "                            f.write(l)\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Erro ao remover transmiss√£o do log de processamento: {e}\")\n",
        "\n",
        "        # Limpeza do arquivo de v√≠deo p√≥s-upload\n",
        "        if 'filepath_for_upload' in locals() and os.path.exists(filepath_for_upload):\n",
        "            try:\n",
        "                os.remove(filepath_for_upload)\n",
        "                print(f\"üóëÔ∏è Arquivo de v√≠deo removido do Colab: {filepath_for_upload}\")\n",
        "            except Exception as e:\n",
        "                print(f\"‚ö†Ô∏è N√£o foi poss√≠vel remover o arquivo de v√≠deo tempor√°rio: {e}\")\n",
        "\n",
        "        # Limpeza do poster tempor√°rio\n",
        "        if poster_temp_path and os.path.exists(poster_temp_path):\n",
        "            try:\n",
        "                os.remove(poster_temp_path)\n",
        "                print(f\"üóëÔ∏è Poster tempor√°rio removido: {poster_temp_path}\")\n",
        "            except Exception as e:\n",
        "                print(f\"‚ö†Ô∏è N√£o foi poss√≠vel remover o poster tempor√°rio: {e}\")\n",
        "\n",
        "# ================================================================\n",
        "# Fim da C√©lula 7 ‚Äî Grava√ß√£o, Log e Blacklist Inteligente\n",
        "# ================================================================\n",
        "\n",
        "# Observa√ß√µes e recomenda√ß√µes:\n",
        "# - Use sempre as fun√ß√µes globais de blacklist/falha da C√©lula 6 para m√°xima rastreabilidade.\n",
        "# - Mensagens claras e detalhadas facilitam diagn√≥stico, CI/CD e manuten√ß√£o.\n",
        "# - Pronto para execu√ß√£o concorrente e integra√ß√£o total com pipeline modular do XCam."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "YjGKDlbIKaLs",
      "metadata": {
        "id": "YjGKDlbIKaLs"
      },
      "source": [
        "# C√©lula 8: Upload para Abyss.to, Atualiza√ß√£o do rec.json, Commit Poster e Sincroniza√ß√£o com Google Drive\n",
        "\n",
        "**Objetivo:**  \n",
        "Realizar upload do v√≠deo gravado para Abyss.to, registrar e atualizar todos os metadados relevantes no arquivo `rec.json` do usu√°rio, garantir a movimenta√ß√£o/renomea√ß√£o adequada do poster e executar o commit/push automatizado de arquivos alterados, sincronizando tamb√©m com o Google Drive.  \n",
        "O processo √© otimizado para processamento em lote: os arquivos modificados s√≥ s√£o enviados quando o n√∫mero atingir o limiar (`COMMIT_PUSH_THRESHOLD`), promovendo efici√™ncia e integridade do reposit√≥rio, mesmo em execu√ß√£o paralela.\n",
        "\n",
        "---\n",
        "\n",
        "## Estrat√©gia e melhorias implementadas\n",
        "\n",
        "- **Commit/push em lote otimizado:**  \n",
        "  Arquivos alterados s√£o acumulados em um buffer. O commit e push s√£o executados automaticamente apenas quando a quantidade de arquivos atinge o threshold configurado, reduzindo conflitos e otimizando o workflow CI/CD.\n",
        "- **Sincroniza√ß√£o autom√°tica com o Google Drive:**  \n",
        "  Sempre que `rec.json` ou poster s√£o atualizados, uma c√≥pia √© feita para o diret√≥rio correspondente do usu√°rio no Google Drive (se dispon√≠vel), garantindo redund√¢ncia, persist√™ncia e facil acesso externo aos metadados e imagens.\n",
        "- **Atomicidade e seguran√ßa em concorr√™ncia:**  \n",
        "  O acesso ao buffer de commit √© protegido por lock (`threading.Lock`), assegurando integridade mesmo em processamento paralelo ou m√∫ltiplos workers.\n",
        "- **Poster sempre correto e rastre√°vel:**  \n",
        "  O poster utilizado √© sempre movido/renomeado para o local definitivo e associado ao v√≠deo pelo nome (`slug`). O caminho √© sincronizado tanto no reposit√≥rio quanto no Drive.\n",
        "- **Atualiza√ß√£o robusta do rec.json:**  \n",
        "  O hist√≥rico do usu√°rio √© preenchido com todos os campos, incluindo poster, urlIframe, data, hor√°rio e tempo formatado. O padr√£o da estrutura JSON √© rigorosamente seguido, facilitando a integra√ß√£o, an√°lise e exporta√ß√£o dos dados.\n",
        "- **Limpeza autom√°tica de arquivos tempor√°rios:**  \n",
        "  Ap√≥s mover, copiar e commitar os arquivos, os tempor√°rios s√£o removidos, mantendo o ambiente Colab limpo e eficiente.\n",
        "\n",
        "---\n",
        "\n",
        "## Como funciona o fluxo principal\n",
        "\n",
        "1. **Faz upload do v√≠deo para Abyss.to** e recebe a confirma√ß√£o (slug, url, urlIframe).\n",
        "2. **Move/renomeia o poster** para o local definitivo no reposit√≥rio, associando ao v√≠deo pelo slug.\n",
        "3. **Atualiza ou cria `rec.json`** do usu√°rio, preenchendo todos os metadados da grava√ß√£o.\n",
        "4. **Adiciona arquivos alterados ao buffer de commit** (com lock para evitar concorr√™ncia).\n",
        "5. **Sincroniza** `rec.json` e poster no Google Drive, mantendo redund√¢ncia e facilidade de acesso.\n",
        "6. **Executa commit/push autom√°tico em lote** ao atingir o limiar definido; ao final do processamento faz o commit/push dos arquivos restantes.\n",
        "7. **Limpa arquivos tempor√°rios** garantindo efici√™ncia e organiza√ß√£o do ambiente.\n",
        "\n",
        "---\n",
        "\n",
        "## Exemplo de uso recomendado\n",
        "\n",
        "```python\n",
        "# Ap√≥s concluir o upload e gerar poster:\n",
        "upload_success, abyss_response, slug = upload_to_abyss_and_update_json(\n",
        "    filepath=arquivo_video,\n",
        "    username=\"usuario\",\n",
        "    duration_seconds=duracao,\n",
        "    poster_temp_path=caminho_poster_temp\n",
        ")\n",
        "\n",
        "# Ao final do processamento, para garantir commit dos arquivos restantes:\n",
        "commit_push_restantes()\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Seguran√ßa, rastreabilidade e integra√ß√£o\n",
        "\n",
        "- **Processo compat√≠vel com execu√ß√£o concorrente** e pipelines CI/CD.\n",
        "- **Commit/push protegido contra condi√ß√µes de corrida**, garantindo atomicidade dos dados no reposit√≥rio.\n",
        "- **Sincroniza√ß√£o Drive robusta**, ideal para ambientes colaborativos ou para garantir backup.\n",
        "- **Mensagens e logs claros** facilitam manuten√ß√£o, auditoria e diagn√≥stico r√°pido em todo o pipeline XCam.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "iwgt8f8iKq4y",
      "metadata": {
        "id": "iwgt8f8iKq4y"
      },
      "source": [
        "# C√©lula 9: Processamento Autom√°tico, Paralelismo e Supervisor Din√¢mico com Blacklist\n",
        "\n",
        "**Objetivo:**  \n",
        "Controlar e orquestrar todo o pipeline do notebook, garantindo processamento cont√≠nuo, paralelo, eficiente e seguro de transmiss√µes ao vivo. O supervisor din√¢mico mant√©m o lote sempre cheio, respeita a blacklist tempor√°ria e o log central, e integra todas as fun√ß√µes cr√≠ticas das c√©lulas anteriores, garantindo m√°xima resili√™ncia e rastreabilidade.\n",
        "\n",
        "---\n",
        "\n",
        "## Estrat√©gia e melhorias implementadas\n",
        "\n",
        "- **Paralelismo seguro e eficiente:**  \n",
        "  Utiliza m√∫ltiplos processos para gravar e processar transmiss√µes simultaneamente, otimizando o uso de recursos e acelerando o processamento em lote.\n",
        "- **Supervisor din√¢mico e lote sempre cheio:**  \n",
        "  O supervisor monitora constantemente as vagas livres no lote e preenche em tempo real com novas transmiss√µes v√°lidas, evitando ociosidade e maximizando a efici√™ncia.\n",
        "- **Controle centralizado de duplicidade:**  \n",
        "  Antes de processar qualquer transmiss√£o, consulta o log central de processamento para evitar duplicidade, mesmo em ambientes concorrentes ou paralelos.\n",
        "- **Respeito integral √† blacklist tempor√°ria:**  \n",
        "  Transmiss√µes de usu√°rios em blacklist n√£o s√£o tentadas novamente durante o ciclo vigente, economizando recursos e evitando loops problem√°ticos.\n",
        "- **Logs robustos e detalhados:**  \n",
        "  Cada etapa do processamento √© registrada com timestamp, status e contexto, facilitando auditoria, troubleshooting e acompanhamento em produ√ß√£o.\n",
        "- **Commit/push autom√°tico e seguro:**  \n",
        "  Ao final do ciclo (ou quando atingido o threshold), todos os arquivos alterados s√£o enviados ao reposit√≥rio, garantindo consist√™ncia e persist√™ncia dos dados.\n",
        "- **Design modular e Clean Architecture:**  \n",
        "  Fun√ß√µes separadas para supervis√£o, workers, busca, commit, log, etc., facilitando manuten√ß√£o, reuso e integra√ß√£o com CI/CD.\n",
        "\n",
        "---\n",
        "\n",
        "## Como funciona o fluxo principal\n",
        "\n",
        "1. **Inicializa√ß√£o:**  \n",
        "   - Determina o modo de opera√ß√£o: grava√ß√£o de usu√°rios espec√≠ficos ou busca autom√°tica.\n",
        "   - Calcula o tamanho do lote alvo (`LIMIT_DEFAULT` ou `API_SEARCH_LIMIT`).\n",
        "\n",
        "2. **Preenchimento do lote:**  \n",
        "   - Busca transmiss√µes v√°lidas (n√£o duplicadas, n√£o em blacklist) e lan√ßa workers para cada uma, registrando no log de processamento.\n",
        "   - Utiliza fun√ß√µes otimizadas de busca (`buscar_proxima_transmissao_livre` e `buscar_usuarios_especificos`), integradas √† blacklist e ao log.\n",
        "\n",
        "3. **Supervis√£o din√¢mica:**  \n",
        "   - Monitora o ciclo de vida dos workers/processos.\n",
        "   - Preenche imediatamente cada vaga livre com nova transmiss√£o dispon√≠vel, at√© esgotar as op√ß√µes v√°lidas.\n",
        "\n",
        "4. **Respeito √† blacklist:**  \n",
        "   - Antes de qualquer grava√ß√£o, verifica se o usu√°rio est√° em blacklist tempor√°ria.\n",
        "   - Usu√°rios problem√°ticos nunca s√£o tentados duas vezes no mesmo ciclo.\n",
        "\n",
        "5. **Logs detalhados:**  \n",
        "   - Todas as opera√ß√µes geram logs padronizados com n√≠vel (INFO, WORKER, BUSCA, ERRO, etc.) e timestamp.\n",
        "\n",
        "6. **Finaliza√ß√£o segura:**  \n",
        "   - Ao final do processamento, executa commit/push dos arquivos pendentes, garantindo persist√™ncia e integridade do reposit√≥rio.\n",
        "\n",
        "---\n",
        "\n",
        "## Exemplo de uso recomendado\n",
        "\n",
        "```python\n",
        "# Fun√ß√£o principal do notebook: dispara o supervisor din√¢mico\n",
        "main()\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Seguran√ßa, rastreabilidade e integra√ß√£o\n",
        "\n",
        "- **Pronto para execu√ß√£o concorrente e ambientes CI/CD.**\n",
        "- **A l√≥gica de blacklist e commit est√° totalmente integrada ao fluxo, garantindo m√°xima resili√™ncia.**\n",
        "- **Logs detalhados e arquitetura modular facilitam diagn√≥stico, manuten√ß√£o e evolu√ß√£o do pipeline XCam.**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5WKQV9g_LB9M",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5WKQV9g_LB9M",
        "outputId": "747787cc-deb6-489e-943d-3568142c87ec"
      },
      "outputs": [],
      "source": [
        "# ================================================================\n",
        "# C√©lula 9: Supervisor Din√¢mico ‚Äî Execu√ß√£o Paralela, Lote Sempre Cheio, Blacklist e Log Centralizado\n",
        "# ================================================================\n",
        "# Objetivo:\n",
        "# - Manter o lote de grava√ß√µes sempre cheio, preenchendo vagas em tempo real com m√°xima efici√™ncia e seguran√ßa.\n",
        "# - Garantir que usu√°rios problem√°ticos (em blacklist) n√£o sejam tentados novamente no ciclo vigente.\n",
        "# - Prevenir duplicidade consultando log central de processamento antes de iniciar qualquer grava√ß√£o.\n",
        "# - Integrar-se com a l√≥gica de blacklist, commit/push autom√°tico, limpeza de recursos e log robusto.\n",
        "# - Modularidade e clareza, pronta para integra√ß√£o com pipelines CI/CD, execu√ß√£o concorrente e ambientes colaborativos.\n",
        "# ================================================================\n",
        "\n",
        "import os\n",
        "\n",
        "LOGS_DIR = os.path.dirname(LOGS_PATH)\n",
        "LOG_PROCESSAMENTO_PATH = os.path.join(LOGS_DIR, \"xcam_processing.log\")\n",
        "\n",
        "def log_supervisor(msg, level=\"INFO\"):\n",
        "    \"\"\"\n",
        "    Log supervisor padronizado para todas as etapas do pipeline.\n",
        "    \"\"\"\n",
        "    from datetime import datetime\n",
        "    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "    print(f\"[{timestamp}] [{level}] {msg}\")\n",
        "\n",
        "def worker(username, m3u8_url, poster_url, results):\n",
        "    \"\"\"\n",
        "    Worker dedicado: grava a stream, faz upload, atualiza rec.json/poster, integra ao log.\n",
        "    \"\"\"\n",
        "    log_supervisor(f\"Iniciando grava√ß√£o: {username} | URL: {m3u8_url} | Poster: {poster_url}\", \"WORKER\")\n",
        "    result = gravar_stream(username, m3u8_url, poster_url)\n",
        "    log_supervisor(\n",
        "        f\"Finalizou grava√ß√£o: {username} | Sucesso: {result.get('upload_success')} | \"\n",
        "        f\"Arquivo: {result.get('filename')} | Abyss: {result.get('abyss_response')}\", \"WORKER\")\n",
        "    results.append(result)\n",
        "\n",
        "def supervisor_dinamico(usuarios_especificos=None):\n",
        "    \"\"\"\n",
        "    Supervisor din√¢mico de transmiss√µes ao vivo:\n",
        "    - Mant√©m o lote de grava√ß√µes sempre cheio, preenchendo vagas em tempo real.\n",
        "    - Evita duplicidade e concorr√™ncia consultando log central.\n",
        "    - Respeita blacklist tempor√°ria, n√£o processando usu√°rios bloqueados no ciclo vigente.\n",
        "    - Integra-se com a l√≥gica de blacklist, commit/push autom√°tico, limpeza de recursos e log robusto.\n",
        "    - Log detalhado e modular para diagn√≥stico, CI/CD e rastreabilidade.\n",
        "    \"\"\"\n",
        "\n",
        "    # Determina o tamanho do lote com base no modo operacional\n",
        "    pool_size = LIMIT_DEFAULT if not usuarios_especificos else API_SEARCH_LIMIT\n",
        "    running = []\n",
        "    results = Manager().list()\n",
        "    seen_usernames = set()\n",
        "\n",
        "    log_supervisor(f\"Supervisor din√¢mico iniciado | Lote alvo: {pool_size} | Modo: {'espec√≠fico' if usuarios_especificos else 'autom√°tico'}\")\n",
        "\n",
        "    def atualizar_seen_usernames():\n",
        "        \"\"\"\n",
        "        Atualiza o conjunto de usernames j√° processados diretamente do log central.\n",
        "        Garante robustez em ambientes concorrentes e previne duplicidade.\n",
        "        \"\"\"\n",
        "        if os.path.exists(LOG_PROCESSAMENTO_PATH):\n",
        "            with open(LOG_PROCESSAMENTO_PATH, \"r\") as f:\n",
        "                log_set = set([line.strip() for line in f if line.strip()])\n",
        "                seen_usernames.update(log_set)\n",
        "\n",
        "    def buscar_nova_transmissao():\n",
        "        \"\"\"\n",
        "        Busca uma nova transmiss√£o livre para preencher o lote:\n",
        "        - Modo espec√≠fico: busca em lista fornecida.\n",
        "        - Modo autom√°tico: busca pr√≥xima transmiss√£o livre dispon√≠vel.\n",
        "        - Sempre consulta blacklist e log central antes de lan√ßar.\n",
        "        \"\"\"\n",
        "        atualizar_seen_usernames()  # Sempre atualiza antes de buscar\n",
        "        if usuarios_especificos:\n",
        "            candidatos = buscar_usuarios_especificos(usuarios_especificos)\n",
        "            for s in candidatos:\n",
        "                username = s[\"username\"]\n",
        "                if username not in seen_usernames and not is_in_blacklist(username):\n",
        "                    log_supervisor(f\"Nova transmiss√£o encontrada (espec√≠fico): {username}\", \"BUSCA\")\n",
        "                    return s\n",
        "            log_supervisor(\"Nenhuma transmiss√£o espec√≠fica livre encontrada (todos em blacklist/log ou offline).\", \"BUSCA\")\n",
        "            return None\n",
        "        else:\n",
        "            # Busca otimizada: tenta at√© 10 vezes buscar pr√≥xima transmiss√£o livre\n",
        "            for tentativa in range(1, 11):\n",
        "                log_supervisor(f\"Buscando pr√≥xima transmiss√£o livre: tentativa {tentativa}\", \"BUSCA\")\n",
        "                stream = buscar_proxima_transmissao_livre()\n",
        "                if stream:\n",
        "                    username = stream[\"username\"]\n",
        "                    if username not in seen_usernames and not is_in_blacklist(username):\n",
        "                        log_supervisor(f\"Nova transmiss√£o encontrada: {username}\", \"BUSCA\")\n",
        "                        return stream\n",
        "                    else:\n",
        "                        log_supervisor(f\"Usu√°rio {username} j√° processado ou em blacklist, ignorando.\", \"BUSCA\")\n",
        "            log_supervisor(\"Nenhuma transmiss√£o livre encontrada ap√≥s tentativas (todos em blacklist/log ou offline).\", \"BUSCA\")\n",
        "            return None\n",
        "\n",
        "    # ========== Fase 1: Preenchimento do lote inicial ==========\n",
        "    log_supervisor(f\"Preenchendo lote inicial com at√© {pool_size} transmiss√µes...\", \"STARTUP\")\n",
        "    tentativas = 0\n",
        "    max_tentativas = 100\n",
        "    while len(running) < pool_size and tentativas < max_tentativas:\n",
        "        stream = buscar_nova_transmissao()\n",
        "        if not stream:\n",
        "            log_supervisor(\"Fim das transmiss√µes dispon√≠veis para preencher lote inicial.\", \"STARTUP\")\n",
        "            break\n",
        "        username = stream[\"username\"]\n",
        "        seen_usernames.add(username)\n",
        "        # Escreve no log imediatamente para evitar duplicidade em concorr√™ncia antes do .start()\n",
        "        with open(LOG_PROCESSAMENTO_PATH, \"a\") as f:\n",
        "            f.write(f\"{username}\\n\")\n",
        "        log_supervisor(f\"Lan√ßando processo para: {username} | {len(running)+1}/{pool_size}\", \"STARTUP\")\n",
        "        p = Process(target=worker, args=(username, stream[\"src\"], stream.get(\"poster\"), results))\n",
        "        running.append(p)\n",
        "        p.start()\n",
        "        tentativas += 1\n",
        "\n",
        "    log_supervisor(f\"Lote inicial lan√ßado com {len(running)} transmiss√µes.\", \"STARTUP\")\n",
        "\n",
        "    # ========== Fase 2: Loop din√¢mico de preenchimento cont√≠nuo ==========\n",
        "    while True:\n",
        "        antes = len(running)\n",
        "        running = [p for p in running if p.is_alive()]\n",
        "        depois = len(running)\n",
        "        if antes != depois:\n",
        "            log_supervisor(f\"{antes-depois} grava√ß√µes finalizaram. Vagas livres: {pool_size-len(running)}\", \"LOOP\")\n",
        "        vagas_livres = pool_size - len(running)\n",
        "        if vagas_livres > 0:\n",
        "            for _ in range(vagas_livres):\n",
        "                stream = buscar_nova_transmissao()\n",
        "                if not stream:\n",
        "                    log_supervisor(\"N√£o h√° mais transmiss√µes para preencher as vagas livres.\", \"LOOP\")\n",
        "                    break\n",
        "                username = stream[\"username\"]\n",
        "                seen_usernames.add(username)\n",
        "                with open(LOG_PROCESSAMENTO_PATH, \"a\") as f:\n",
        "                    f.write(f\"{username}\\n\")\n",
        "                log_supervisor(f\"Lan√ßando nova grava√ß√£o: {username} | Vaga preenchida {len(running)+1}/{pool_size}\", \"LOOP\")\n",
        "                p = Process(target=worker, args=(username, stream[\"src\"], stream.get(\"poster\"), results))\n",
        "                running.append(p)\n",
        "                p.start()\n",
        "        if not running:\n",
        "            log_supervisor(\"Todas as transmiss√µes poss√≠veis j√° foram processadas!\", \"END\")\n",
        "            break\n",
        "        log_supervisor(\n",
        "            f\"Transmiss√µes ativas: {len(running)} | Total processadas: {len(seen_usernames)} | Buffer de resultados: {len(results)}\",\n",
        "            \"STATUS\"\n",
        "        )\n",
        "        time.sleep(2)\n",
        "\n",
        "    # ========== Fase 3: Commit/push final e encerramento ==========\n",
        "    log_supervisor(f\"Processamento din√¢mico conclu√≠do! Total de transmiss√µes gravadas/processadas: {len(results)}\", \"RESUMO\")\n",
        "    try:\n",
        "        log_supervisor(\"Realizando commit/push final dos arquivos pendentes...\", \"FINALIZACAO\")\n",
        "        commit_push_restantes()\n",
        "        log_supervisor(\"Commit/push final executado com sucesso.\", \"FINALIZACAO\")\n",
        "    except Exception as e:\n",
        "        log_supervisor(f\"Falha ao tentar commit/push final dos arquivos restantes: {e}\", \"ERRO\")\n",
        "    log_supervisor(\"Supervisor din√¢mico finalizado.\", \"END\")\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Fun√ß√£o principal: inicia o notebook perguntando se o usu√°rio quer gravar transmiss√µes espec√≠ficas ou autom√°ticas.\n",
        "    Dispara o supervisor din√¢mico na modalidade selecionada.\n",
        "    \"\"\"\n",
        "    usuarios_especificos = perguntar_transmissoes_especificas()\n",
        "    log_supervisor(\"Iniciando busca e grava√ß√£o de streams (supervisor din√¢mico)...\", \"MAIN\")\n",
        "    supervisor_dinamico(usuarios_especificos=usuarios_especificos)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    try:\n",
        "        if 'google.colab' in str(get_ipython()):\n",
        "            main()\n",
        "        else:\n",
        "            print(\"Execute main() manualmente se desejar rodar fora do Colab.\")\n",
        "    except NameError:\n",
        "        print(\"N√£o est√° rodando em Colab/IPython. Execute main() se desejar.\")\n",
        "\n",
        "# ================================================================\n",
        "# FIM DA C√âLULA 9 ‚Äî Supervisor Din√¢mico, Lote Cheio e Blacklist\n",
        "# ================================================================\n",
        "\n",
        "# Observa√ß√µes e recomenda√ß√µes:\n",
        "# - Toda l√≥gica de blacklist e commit est√° integrada para m√°xima resili√™ncia e rastreabilidade.\n",
        "# - O log central de processamento √© a fonte de verdade para sincroniza√ß√£o entre workers/processos.\n",
        "# - Modularidade, logs claros e tratamento de erro garantem manuten√ß√£o e evolu√ß√£o seguras."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "cell_execution_strategy": "setup",
      "collapsed_sections": [
        "c9hve1ySGVAs"
      ],
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
