{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SamuelPassamani/XCam/blob/main/xcam-colab/XCam_REC_V4.7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c9hve1ySGVAs",
      "metadata": {
        "id": "c9hve1ySGVAs"
      },
      "source": [
        "# Célula 1: Configurações Auxiliares, Parâmetros Globais e Log Centralizado\n",
        "\n",
        "**Objetivo:**  \n",
        "Esta célula inicializa e centraliza todas as variáveis globais, parâmetros essenciais e agora também fornece um utilitário robusto para o log único do notebook XCam.  \n",
        "Permite ajuste rápido e seguro do comportamento do notebook, incluindo limites de processamento, controle de gravação, commit automático e mecanismos de resiliência contra transmissões problemáticas.\n",
        "\n",
        "## Principais pontos e melhorias implementadas\n",
        "\n",
        "- **Centralização dos parâmetros globais:**  \n",
        "  Todos os valores críticos (limites, thresholds, caminhos) são definidos e propagados como globais pelo notebook.\n",
        "- **Log único modular e estruturado (`xcam_master.log`):**  \n",
        "  Todas as operações relevantes (busca, gravação, blacklist, commit, erros, etc.) agora são registradas em um único arquivo JSON Lines.  \n",
        "  Cada entrada inclui sessão, evento, id, username, timestamps, status e detalhes.\n",
        "- **Funções utilitárias para o log:**  \n",
        "  Adição, busca, remoção e atualização de eventos são facilitadas por funções modulares (CRUD), promovendo robustez, rastreabilidade e fácil manutenção.\n",
        "- **Blacklist, falhas e processamento padronizados por `id`:**  \n",
        "  Toda lógica de controle é feita via identificador único, com `username` para exibição, garantindo unicidade e eliminando inconsistências.\n",
        "- **Função interativa para seleção de transmissões específicas:**  \n",
        "  Permite ao usuário informar nomes de usuários para filtrar transmissões antes do processamento.\n",
        "- **Comentários detalhados:**  \n",
        "  Cada etapa do código está documentada para orientar ajustes, manutenção e integração por toda a equipe.\n",
        "\n",
        "---\n",
        "\n",
        "## Parâmetros globais controlados nesta célula\n",
        "\n",
        "- **`LIMIT_DEFAULT`**: Quantidade máxima de transmissões processadas em paralelo/lote.\n",
        "- **`PAGE_DEFAULT`**: Página inicial para busca na API.\n",
        "- **`RECORD_SECONDS`**: Tempo máximo de gravação de cada vídeo (em segundos).\n",
        "- **`RECORD_SECONDS_MIN`**: Tempo mínimo exigido para considerar o vídeo válido (em segundos).\n",
        "- **`API_SEARCH_LIMIT`**: Limite de transmissões retornadas ao buscar usuários específicos.\n",
        "- **`COMMIT_PUSH_THRESHOLD`**: Quantidade de transmissões processadas até realizar commit/push automático (0 = commit imediato a cada gravação).\n",
        "- **`LOGS_PATH`**: Caminho do arquivo único de log (JSONL).\n",
        "- **`BLACKLIST_TIMEOUT`**: Tempo de expiração da blacklist (em segundos).\n",
        "- **`BLACKLIST_MAX_FAILURES`**: Quantidade de falhas consecutivas antes de banir temporariamente o usuário.\n",
        "\n",
        "---\n",
        "\n",
        "## Estrutura do log único (`xcam_master.log`)\n",
        "\n",
        "Cada entrada segue o modelo:\n",
        "```json\n",
        "{\n",
        "  \"timestamp\": \"2025-06-06T06:15:00Z\",\n",
        "  \"sessao\": \"busca|gravação|blacklist|commit|erro|...\",\n",
        "  \"evento\": \"...\",\n",
        "  \"id\": \"...\",         // identificador único (primário)\n",
        "  \"username\": \"...\",   // nome do usuário para exibição\n",
        "  \"status\": \"...\",     // ok|erro|blacklisted|expirado|...\n",
        "  \"detalhes\": \"...\",   // informações adicionais\n",
        "}\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Funções utilitárias para o log\n",
        "\n",
        "- **`append_log(entry, logs_path=LOGS_PATH)`**: Adiciona uma nova entrada ao log central.\n",
        "- **`read_logs(logs_path=LOGS_PATH)`**: Lê todas as entradas do log.\n",
        "- **`query_logs(...)`**: Consulta entradas do log por filtros opcionais (sessão, id, status, etc).\n",
        "- **`remove_logs(condition_fn, logs_path=LOGS_PATH)`**: Remove todas as entradas que satisfaçam a condição.\n",
        "- **`update_log_entry(match_fn, update_fn, logs_path=LOGS_PATH)`**: Atualiza entradas do log conforme regra.\n",
        "\n",
        "---\n",
        "\n",
        "## Exemplo de uso das funções (a serem aplicadas nas próximas células)\n",
        "\n",
        "```python\n",
        "append_log({\n",
        "    \"sessao\": \"busca\",\n",
        "    \"evento\": \"encontrado\",\n",
        "    \"id\": \"abc123\",\n",
        "    \"username\": \"Manugic_\",\n",
        "    \"status\": \"ok\",\n",
        "    \"detalhes\": \"URL válida\"\n",
        "})\n",
        "\n",
        "# Consultar blacklist:\n",
        "logs_blacklist = query_logs(sessao=\"blacklist\", status=\"blacklisted\")\n",
        "\n",
        "# Remover registros expirados:\n",
        "remove_logs(lambda entry: entry[\"sessao\"] == \"processing\" and expirou(entry), logs_path=LOGS_PATH)\n",
        "\n",
        "# Atualizar status:\n",
        "update_log_entry(lambda e: e[\"id\"]==\"abc123\", lambda e: e.update({\"status\":\"ok\"}))\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Função interativa\n",
        "\n",
        "Permite ao usuário informar transmissões específicas a serem gravadas antes de iniciar o processamento.\n",
        "\n",
        "---\n",
        "\n",
        "## Segurança, rastreabilidade e manutenção\n",
        "\n",
        "- Todos os parâmetros globais são definidos no início e propagados para todo o notebook, garantindo consistência.\n",
        "- O log único fornece rastreabilidade detalhada e elimina arquivos dispersos (blacklist, falha, etc).\n",
        "- Ajuste qualquer valor diretamente nesta célula para alterar o comportamento global do notebook de forma segura.\n",
        "- Comentários detalhados auxiliam a compreensão, integração e manutenção por toda a equipe.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "j5pPh353GLMD",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5pPh353GLMD",
        "outputId": "a2303e92-306f-461c-e214-84c611a44e1e"
      },
      "outputs": [],
      "source": [
        "# ================================================================\n",
        "# Célula 1: Configuração Global, Parâmetros e Utilitário de Log Único\n",
        "# ================================================================\n",
        "# Objetivo:\n",
        "# - Centralizar configurações globais e thresholds\n",
        "# - Definir e montar caminhos do notebook\n",
        "# - Fornecer utilitário robusto para LOG ÚNICO MODULAR (JSONL)\n",
        "#   => Todas as células e funções usarão este log para registrar, consultar e manipular eventos\n",
        "# - Garantir padronização, rastreabilidade e fácil manutenção futura\n",
        "#\n",
        "# Estratégia aplicada (conforme plano):\n",
        "# - Log único estruturado (JSONL): sessão, evento, id, username, timestamps, status, detalhes\n",
        "# - Funções CRUD para log: adicionar, buscar, atualizar, remover (para blacklist, processing, falhas, auditoria)\n",
        "# - Blacklist e controles baseados em id (com username apenas para exibição)\n",
        "# - Parâmetros globais facilmente editáveis e propagados via globals()\n",
        "# ================================================================\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# ============================\n",
        "# PARÂMETROS GLOBAIS EDITÁVEIS\n",
        "# ============================\n",
        "# Modifique abaixo conforme necessidade do ambiente ou processamento\n",
        "\n",
        "# Limites e thresholds principais de processamento\n",
        "LIMIT_DEFAULT = 50             # Máximo de transmissões processadas por rodada\n",
        "PAGE_DEFAULT = 1               # Página padrão para busca na API\n",
        "RECORD_SECONDS = 12780         # Duração máxima da gravação (em segundos)\n",
        "RECORD_SECONDS_MIN = 660       # Duração mínima válida (em segundos)\n",
        "API_SEARCH_LIMIT = 1500        # Limite ao buscar usuários específicos\n",
        "COMMIT_PUSH_THRESHOLD = 25     # Quantidade de transmissões até commit/push automático (0 = commit imediato)\n",
        "\n",
        "# Caminhos de arquivos principais (Google Drive)\n",
        "POSTER_TEMP_PATH = \"/content/drive/MyDrive/XCam.Drive/src/temp/posters\"\n",
        "RECORD_TEMP_PATH = \"/content/drive/MyDrive/XCam.Drive/src/temp/records\"\n",
        "LOGS_PATH = \"/content/drive/MyDrive/XCam.Drive/src/logs/xcam_master.log\"\n",
        "BLACKLIST_TIMEOUT = 15 * 60\n",
        "BLACKLIST_MAX_FAILURES = 3\n",
        "\n",
        "# Criação dos diretórios se não existirem\n",
        "import os\n",
        "import json\n",
        "for path in [POSTER_TEMP_PATH, RECORD_TEMP_PATH, os.path.dirname(LOGS_PATH)]:\n",
        "    os.makedirs(path, exist_ok=True)\n",
        "\n",
        "# ============================\n",
        "# ATUALIZAÇÃO GLOBAL DOS PARÂMETROS\n",
        "# ============================\n",
        "# Propaga parâmetros como globais do notebook\n",
        "globals().update({\n",
        "    'POSTER_TEMP_PATH': POSTER_TEMP_PATH,\n",
        "    'RECORD_TEMP_PATH': RECORD_TEMP_PATH,\n",
        "    'LOG_PATH': LOGS_PATH,\n",
        "    'LIMIT_DEFAULT': LIMIT_DEFAULT,\n",
        "    'PAGE_DEFAULT': PAGE_DEFAULT,\n",
        "    'RECORD_SECONDS': RECORD_SECONDS,\n",
        "    'RECORD_SECONDS_MIN': RECORD_SECONDS_MIN,\n",
        "    'API_SEARCH_LIMIT': API_SEARCH_LIMIT,\n",
        "    'COMMIT_PUSH_THRESHOLD': COMMIT_PUSH_THRESHOLD,\n",
        "    'LOGS_PATH': LOGS_PATH,\n",
        "    'BLACKLIST_TIMEOUT': BLACKLIST_TIMEOUT,\n",
        "    'BLACKLIST_MAX_FAILURES': BLACKLIST_MAX_FAILURES\n",
        "})\n",
        "\n",
        "# =============================================================================\n",
        "# UTILITÁRIO DE LOG ÚNICO MODULAR (JSONL)\n",
        "# -----------------------------------------------------------------------------\n",
        "# Cada entrada: {\n",
        "#   \"timestamp\": \"2025-06-06T06:15:00Z\",\n",
        "#   \"sessao\": \"busca|gravação|blacklist|commit|erro|...\",\n",
        "#   \"evento\": \"...\",\n",
        "#   \"id\": \"...\",         # sempre o identificador primário!\n",
        "#   \"username\": \"...\",   # para exibição/auditoria\n",
        "#   \"status\": \"...\",     # ok|erro|blacklisted|expirado|...\n",
        "#   \"detalhes\": \"...\",   # info extra (motivo, paths, etc)\n",
        "# }\n",
        "# =============================================================================\n",
        "\n",
        "def now_iso():\n",
        "    \"\"\"Retorna timestamp UTC em formato ISO.\"\"\"\n",
        "    from datetime import datetime\n",
        "    return datetime.utcnow().isoformat() + \"Z\"\n",
        "\n",
        "def append_log(entry, logs_path=LOGS_PATH):\n",
        "    \"\"\"\n",
        "    Adiciona uma nova entrada ao log central (JSONL).\n",
        "    Campos obrigatórios: sessao, evento, id, username, status.\n",
        "    \"\"\"\n",
        "    entry.setdefault(\"timestamp\", now_iso())\n",
        "    # Garante campos essenciais para rastreabilidade\n",
        "    for field in [\"sessao\", \"evento\", \"id\", \"username\", \"status\"]:\n",
        "        entry.setdefault(field, \"\")\n",
        "    with open(logs_path, \"a\", encoding=\"utf-8\") as f:\n",
        "        f.write(json.dumps(entry, ensure_ascii=False) + \"\\n\")\n",
        "\n",
        "def read_logs(logs_path=LOGS_PATH):\n",
        "    \"\"\"Lê todas as entradas do log central.\"\"\"\n",
        "    if not os.path.exists(logs_path):\n",
        "        return []\n",
        "    with open(logs_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        return [json.loads(line) for line in f if line.strip()]\n",
        "\n",
        "def query_logs(sessao=None, id=None, username=None, evento=None, status=None, after=None, before=None, logs_path=LOGS_PATH):\n",
        "    \"\"\"\n",
        "    Consulta entradas do log por filtros opcionais.\n",
        "    - after/before: string ISO ou datetime\n",
        "    \"\"\"\n",
        "    logs = read_logs(logs_path)\n",
        "    result = []\n",
        "    for entry in logs:\n",
        "        if sessao and entry.get(\"sessao\") != sessao:\n",
        "            continue\n",
        "        if id and entry.get(\"id\") != id:\n",
        "            continue\n",
        "        if username and entry.get(\"username\") != username:\n",
        "            continue\n",
        "        if evento and entry.get(\"evento\") != evento:\n",
        "            continue\n",
        "        if status and entry.get(\"status\") != status:\n",
        "            continue\n",
        "        ts = entry.get(\"timestamp\")\n",
        "        if after:\n",
        "            after_val = after if isinstance(after, str) else after.isoformat()\n",
        "            if ts < after_val:\n",
        "                continue\n",
        "        if before:\n",
        "            before_val = before if isinstance(before, str) else before.isoformat()\n",
        "            if ts > before_val:\n",
        "                continue\n",
        "        result.append(entry)\n",
        "    return result\n",
        "\n",
        "def remove_logs(condition_fn, logs_path=LOGS_PATH):\n",
        "    \"\"\"\n",
        "    Remove do log central todas as entradas que satisfaçam condition_fn(entry).\n",
        "    Útil para expurgar logs expirados, blacklists vencidas, eventos processados, etc.\n",
        "    \"\"\"\n",
        "    logs = read_logs(logs_path)\n",
        "    kept = [entry for entry in logs if not condition_fn(entry)]\n",
        "    with open(logs_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        for entry in kept:\n",
        "            f.write(json.dumps(entry, ensure_ascii=False) + \"\\n\")\n",
        "    return len(logs) - len(kept)\n",
        "\n",
        "def update_log_entry(match_fn, update_fn, logs_path=LOGS_PATH):\n",
        "    \"\"\"\n",
        "    Atualiza entradas do log central: se match_fn(entry)==True, aplica update_fn(entry).\n",
        "    Exemplo: promover status de \"pending\" para \"ok\".\n",
        "    \"\"\"\n",
        "    logs = read_logs(logs_path)\n",
        "    updated = 0\n",
        "    for entry in logs:\n",
        "        if match_fn(entry):\n",
        "            update_fn(entry)\n",
        "            updated += 1\n",
        "    with open(logs_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        for entry in logs:\n",
        "            f.write(json.dumps(entry, ensure_ascii=False) + \"\\n\")\n",
        "    return updated\n",
        "\n",
        "# Exemplos de uso (para as próximas células):\n",
        "# append_log({\"sessao\":\"busca\", \"evento\":\"encontrado\", \"id\":\"abc123\", \"username\":\"Manugic_\", \"status\":\"ok\", \"detalhes\":\"URL válida\"})\n",
        "# logs_blacklist = query_logs(sessao=\"blacklist\", status=\"blacklisted\")\n",
        "# remove_logs(lambda entry: entry[\"sessao\"]==\"processing\" and expirou(entry), logs_path=LOGS_PATH)\n",
        "\n",
        "# =============================================================================\n",
        "# FUNÇÃO INTERATIVA (opcional) PARA ESCOLHA DE TRANSMISSÕES ESPECÍFICAS\n",
        "# =============================================================================\n",
        "def perguntar_transmissoes_especificas():\n",
        "    \"\"\"\n",
        "    Pergunta ao usuário se deseja informar transmissões específicas para gravar,\n",
        "    recebendo nomes de usuário separados por vírgula e retornando lista limpa.\n",
        "    Retorna lista vazia caso não deseje selecionar usuários.\n",
        "    \"\"\"\n",
        "    resp = input('Deseja gravar alguma transmissão específica? (sim/não): ').strip().lower()\n",
        "    if resp.startswith('s'):\n",
        "        usuarios = input('Informe o(s) nome(s) de usuário, separados por vírgula (ex: userNovo234, jovemPT): ')\n",
        "        usuarios_lista = [u.strip() for u in usuarios.split(',') if u.strip()]\n",
        "        return usuarios_lista\n",
        "    return []\n",
        "\n",
        "# =============================================================================\n",
        "# DICA DE USO EM OUTRAS CÉLULAS:\n",
        "# - Para registrar evento: append_log({...})\n",
        "# - Para consultar blacklist: query_logs(sessao=\"blacklist\", status=\"blacklisted\")\n",
        "# - Para remover registros expirados: remove_logs(lambda e: ...)\n",
        "# - Para atualizar status: update_log_entry(lambda e: ..., lambda e: ...)\n",
        "# =============================================================================\n",
        "\n",
        "# ============================\n",
        "# FIM DA CÉLULA 1\n",
        "# ============================"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "WXs0o6OPHXbi",
      "metadata": {
        "id": "WXs0o6OPHXbi"
      },
      "source": [
        "# Célula 2: Instalação e Validação do ffmpeg\n",
        "\n",
        "**Objetivo:**  \n",
        "Esta célula garante que o utilitário `ffmpeg` esteja instalado e disponível no ambiente Google Colab. O ffmpeg é indispensável para a gravação dos vídeos das transmissões e para o processamento de mídia ao longo do pipeline do notebook XCam.\n",
        "\n",
        "## Pontos principais e melhorias implementadas\n",
        "\n",
        "- **Verificação pré-instalação:**  \n",
        "  Antes de instalar, verifica se o ffmpeg já está disponível no ambiente, tornando o processo idempotente e eficiente.\n",
        "- **Instalação automatizada:**  \n",
        "  Efetua a instalação via `apt-get` apenas se necessário, reduzindo o tempo de setup em execuções futuras.\n",
        "- **Validação pós-instalação:**  \n",
        "  Exibe a versão instalada do ffmpeg, garantindo transparência e rastreabilidade.\n",
        "- **Mensagens detalhadas:**  \n",
        "  O usuário recebe logs informativos sobre cada etapa, facilitando o diagnóstico em caso de erros.\n",
        "- **Design modular:**  \n",
        "  Estrutura pronta para ser utilizada em outros ambientes (Colab, local, server) com pequenas adaptações.\n",
        "\n",
        "---\n",
        "\n",
        "## Como funciona a célula\n",
        "\n",
        "- **Verifica se o ffmpeg está instalado (no PATH do sistema).**\n",
        "- **Se não estiver, instala automaticamente via apt-get.**\n",
        "- **Valida e exibe a versão instalada após o processo.**\n",
        "- **Em caso de falha, exibe erro detalhado e interrompe o fluxo para evitar inconsistências futuras.**\n",
        "\n",
        "---\n",
        "\n",
        "## Exemplo de uso das funções nesta célula\n",
        "\n",
        "```python\n",
        "if not is_ffmpeg_installed():\n",
        "    install_ffmpeg()\n",
        "show_ffmpeg_version()\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Segurança, rastreabilidade e manutenção\n",
        "\n",
        "- A célula torna o setup do ambiente mais robusto, impedindo falhas silenciosas relacionadas à ausência de ffmpeg.\n",
        "- Mensagens e validações ajudam a equipe a identificar rapidamente problemas de ambiente ou permissões.\n",
        "- O padrão modular facilita a reutilização do código em diferentes notebooks ou pipelines do projeto XCam.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "vIODn0c2HiHz",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vIODn0c2HiHz",
        "outputId": "3388fb69-94fb-487e-9159-5e3693af4e4b"
      },
      "outputs": [],
      "source": [
        "# ================================================================\n",
        "# Célula 2: Instalação e Validação do FFMPEG no Colab\n",
        "# ================================================================\n",
        "# Objetivo:\n",
        "# - Garantir que o utilitário ffmpeg está instalado e disponível no ambiente\n",
        "# - Validar a instalação e exibir a versão instalada\n",
        "# - Tornar a etapa idempotente, evitando instalações desnecessárias\n",
        "# - Fornecer feedback claro e orientações em caso de erro\n",
        "#\n",
        "# Estratégia aplicada:\n",
        "# - Instalação via apt-get apenas se ffmpeg não estiver disponível\n",
        "# - Validação pós-instalação\n",
        "# - Logs claros e comentários detalhados para rastreabilidade\n",
        "# ================================================================\n",
        "\n",
        "import subprocess\n",
        "\n",
        "def is_ffmpeg_installed():\n",
        "    \"\"\"\n",
        "    Verifica se o ffmpeg está instalado e disponível no PATH do sistema.\n",
        "    Retorna True se estiver, False caso contrário.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        result = subprocess.run([\"ffmpeg\", \"-version\"], capture_output=True, text=True)\n",
        "        return result.returncode == 0\n",
        "    except FileNotFoundError:\n",
        "        return False\n",
        "\n",
        "def install_ffmpeg():\n",
        "    \"\"\"\n",
        "    Instala o ffmpeg via apt-get caso não esteja presente.\n",
        "    \"\"\"\n",
        "    print(\"[INFO] Instalando ffmpeg via apt-get...\")\n",
        "    # Atualiza pacotes e instala ffmpeg silenciosamente\n",
        "    !apt-get update -y > /dev/null\n",
        "    !apt-get install -y ffmpeg > /dev/null\n",
        "    print(\"[INFO] ffmpeg instalado com sucesso.\")\n",
        "\n",
        "def show_ffmpeg_version():\n",
        "    \"\"\"\n",
        "    Exibe a versão instalada do ffmpeg.\n",
        "    \"\"\"\n",
        "    print(\"[INFO] Versão do ffmpeg instalada:\")\n",
        "    !ffmpeg -version | head -n 2\n",
        "\n",
        "# ============================\n",
        "# EXECUÇÃO DA ETAPA DE SETUP\n",
        "# ============================\n",
        "\n",
        "if not is_ffmpeg_installed():\n",
        "    print(\"[WARN] ffmpeg não encontrado no ambiente.\")\n",
        "    install_ffmpeg()\n",
        "    if not is_ffmpeg_installed():\n",
        "        raise RuntimeError(\"[ERRO] Falha ao instalar o ffmpeg. Verifique permissões ou tente novamente.\")\n",
        "else:\n",
        "    print(\"[OK] ffmpeg já está instalado no ambiente.\")\n",
        "\n",
        "# Validação final e exibição da versão\n",
        "show_ffmpeg_version()\n",
        "\n",
        "# ============================\n",
        "# FIM DA CÉLULA 2\n",
        "# ============================\n",
        "\n",
        "# Dica: ffmpeg deve estar disponível para todas as células subsequentes.\n",
        "# Se precisar de um caminho específico, utilize `which ffmpeg` para obter o path absoluto."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "90qvXC0rHtWb",
      "metadata": {
        "id": "90qvXC0rHtWb"
      },
      "source": [
        "# Célula 3: Imports Essenciais, Utilitários e Preparação do Ambiente\n",
        "\n",
        "**Objetivo:**  \n",
        "Importa todas as bibliotecas essenciais do Python necessárias para o funcionamento do notebook, incluindo módulos para requisições HTTP, processamento paralelo, manipulação de datas, controle de subprocessos e exibição interativa.  \n",
        "Centraliza funções utilitárias robustas e padronizadas para processamento, download de poster, geração automática de poster com ffmpeg e exibição de progresso.  \n",
        "\n",
        "## Principais pontos e melhorias implementadas\n",
        "\n",
        "- **Centralização de imports essenciais:**  \n",
        "  Todos os módulos fundamentais (os, requests, multiprocessing, datetime, json, time, subprocess, math, re, IPython) estão disponíveis e prontos para uso global.\n",
        "- **Funções utilitárias padronizadas:**  \n",
        "  Funções para formatação de segundos, exibição de progresso, download e validação de poster e geração de poster via ffmpeg foram refatoradas e documentadas, seguindo arquitetura modular e Clean Architecture.\n",
        "- **Remoção de logs temporários dispersos:**  \n",
        "  O antigo arquivo de log de processamento temporário foi descontinuado em favor do log único centralizado definido na Célula 1, promovendo rastreabilidade e controle total.\n",
        "- **Robustez e clareza:**  \n",
        "  Todas as funções possuem tratamento de erros, mensagens amigáveis e são preparadas para uso concorrente e integração com as próximas etapas do pipeline.\n",
        "- **Pronto para uso em todo o notebook:**  \n",
        "  As funções aqui definidas são utilizadas em toda a automação, garantindo reuso, legibilidade e manutenção facilitada.\n",
        "\n",
        "---\n",
        "\n",
        "## Funções utilitárias disponíveis nesta célula\n",
        "\n",
        "- **`format_seconds(seconds)`**: Formata um valor em segundos para string legível (ex: \"1h23m45s\").\n",
        "- **`log_progress(username, elapsed_seconds, total_seconds)`**: Exibe o progresso da gravação de cada transmissão.\n",
        "- **`download_and_save_poster(poster_url, username, temp_folder)`**: Baixa e salva o poster da transmissão a partir de uma URL remota ou retorna se for um caminho local.\n",
        "- **`generate_poster_with_ffmpeg(m3u8_url, username, temp_folder, frame_time=7, timeout=20)`**: Gera automaticamente um poster usando ffmpeg, após validar a disponibilidade do stream.\n",
        "- **`is_poster_valid(poster_path)`**: Verifica se o arquivo de poster é válido (existe e não está vazio).\n",
        "\n",
        "---\n",
        "\n",
        "## Exemplo de uso das funções\n",
        "\n",
        "```python\n",
        "# Formatar segundos em string legível\n",
        "tempo = format_seconds(385)\n",
        "# Exibir progresso\n",
        "log_progress(\"userNovo234\", 385, 12780)\n",
        "# Download do poster\n",
        "poster_path = download_and_save_poster(url_poster, \"userNovo234\", \"/content/temp\")\n",
        "# Geração automática de poster via ffmpeg (se necessário)\n",
        "if not is_poster_valid(poster_path):\n",
        "    poster_path = generate_poster_with_ffmpeg(m3u8_url, \"userNovo234\", \"/content/temp\")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Segurança, rastreabilidade e manutenção\n",
        "\n",
        "- Todas as funções são preparadas para tratamento de erros e integração com processos concorrentes.\n",
        "- O log temporário de processamento foi removido, garantindo que todo o rastreio e auditoria sejam feitos via log único centralizado da Célula 1.\n",
        "- Comentários detalhados facilitam manutenção, entendimento e evolução do notebook.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hOetz0nGICkz",
      "metadata": {
        "id": "hOetz0nGICkz"
      },
      "outputs": [],
      "source": [
        "# ================================================================\n",
        "# Célula 3: Imports Essenciais, Utilitários e Preparação do Ambiente\n",
        "# ================================================================\n",
        "# Objetivo:\n",
        "# - Importar bibliotecas essenciais e utilitários para todo o notebook\n",
        "# - Centralizar funções auxiliares de formatação, download e geração de poster\n",
        "# - Remover dependências de logs temporários dispersos, integrando ao log único do sistema (conforme novo padrão)\n",
        "# - Garantir robustez, clareza e modularidade para as próximas células\n",
        "#\n",
        "# Estratégia aplicada:\n",
        "# - Apenas os imports necessários para o funcionamento do notebook\n",
        "# - Funções auxiliares adaptadas para Clean Architecture e integração com o log centralizado\n",
        "# - Função de geração de poster com ffmpeg robusta (checagem HTTP HEAD antes de rodar)\n",
        "# - Modularidade: funções isoladas, prontos para reuso e testes\n",
        "# ================================================================\n",
        "\n",
        "import os\n",
        "import requests\n",
        "from multiprocessing import Manager, Process\n",
        "from datetime import datetime\n",
        "import json\n",
        "import time\n",
        "import subprocess\n",
        "import math\n",
        "import re\n",
        "import shutil\n",
        "import threading\n",
        "\n",
        "from IPython import get_ipython\n",
        "from IPython.display import display\n",
        "\n",
        "# ============================\n",
        "# UTILITÁRIOS DE FORMATAÇÃO E PROGRESSO\n",
        "# ============================\n",
        "\n",
        "def format_seconds(seconds):\n",
        "    \"\"\"\n",
        "    Formata segundos em string legível (e.g., 1h23m45s).\n",
        "    \"\"\"\n",
        "    total_seconds = int(seconds)\n",
        "    hours = total_seconds // 3600\n",
        "    minutes = (total_seconds % 3600) // 60\n",
        "    seconds = total_seconds % 60\n",
        "    parts = []\n",
        "    if hours > 0:\n",
        "        parts.append(f\"{hours}h\")\n",
        "    if minutes > 0 or (hours == 0 and seconds > 0):\n",
        "        parts.append(f\"{minutes}m\")\n",
        "    if seconds > 0 or total_seconds == 0:\n",
        "        parts.append(f\"{seconds}s\")\n",
        "    return \"\".join(parts) if parts else \"0s\"\n",
        "\n",
        "def log_progress(username, elapsed_seconds, total_seconds):\n",
        "    \"\"\"\n",
        "    Exibe progresso da gravação de cada transmissão em tempo real.\n",
        "    \"\"\"\n",
        "    percent = min((elapsed_seconds / total_seconds) * 100, 100)\n",
        "    tempo = format_seconds(elapsed_seconds)\n",
        "    minutos_gravados = math.floor(elapsed_seconds / 60)\n",
        "    minutos_restantes = max(0, math.ceil((total_seconds - elapsed_seconds) / 60))\n",
        "    print(f\"⏱️ [{username}] Gravados: {minutos_gravados} min | Restantes: {minutos_restantes} min | Tempo total: {tempo} — 📊 {percent:.1f}% concluído\")\n",
        "\n",
        "# ============================\n",
        "# UTILITÁRIO PARA DOWNLOAD DE POSTER\n",
        "# ============================\n",
        "\n",
        "def download_and_save_poster(poster_url, username, temp_folder=None):\n",
        "    \"\"\"\n",
        "    Baixa e salva o poster (thumbnail) a partir de uma URL HTTP/HTTPS.\n",
        "    Se for um caminho local existente, retorna esse caminho.\n",
        "    Retorna o caminho do arquivo salvo, ou None em caso de erro.\n",
        "    \"\"\"\n",
        "    if temp_folder is None:\n",
        "        temp_folder = POSTER_TEMP_PATH\n",
        "    # Uso de caminho local\n",
        "    if os.path.exists(poster_url):\n",
        "        return poster_url\n",
        "    # Download de URL HTTP/HTTPS\n",
        "    if isinstance(poster_url, str) and (poster_url.startswith(\"http://\") or poster_url.startswith(\"https://\")):\n",
        "        try:\n",
        "            response = requests.get(poster_url, timeout=15)\n",
        "            response.raise_for_status()\n",
        "            ext = os.path.splitext(poster_url)[1].lower()\n",
        "            if ext not in [\".jpg\", \".jpeg\", \".png\"]:\n",
        "                ext = \".jpg\"\n",
        "            poster_temp_path = os.path.join(temp_folder, f\"{username}_poster_temp{ext}\")\n",
        "            with open(poster_temp_path, \"wb\") as f:\n",
        "                f.write(response.content)\n",
        "            print(f\"🖼️ Poster baixado em: {poster_temp_path}\")\n",
        "            return poster_temp_path\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Erro ao baixar poster {poster_url}: {e}\")\n",
        "            return None\n",
        "    else:\n",
        "        print(f\"❌ poster_url inválido ou não encontrado: {poster_url}\")\n",
        "        return None\n",
        "\n",
        "# ============================\n",
        "# UTILITÁRIO PARA GERAR POSTER COM FFMPEG\n",
        "# ============================\n",
        "\n",
        "def generate_poster_with_ffmpeg(m3u8_url, username, temp_folder=None, frame_time=7, timeout=20):\n",
        "    \"\"\"\n",
        "    Gera um poster (screenshot) usando ffmpeg a partir da URL .m3u8 da transmissão.\n",
        "    Retorna o caminho do arquivo gerado ou None em caso de erro.\n",
        "    Antes de rodar o ffmpeg, faz uma checagem HTTP HEAD para saber se a URL do stream está ativa.\n",
        "    \"\"\"\n",
        "    if temp_folder is None:\n",
        "        temp_folder = POSTER_TEMP_PATH\n",
        "    # Checa se a URL está acessível antes de rodar ffmpeg\n",
        "    try:\n",
        "        head_resp = requests.head(m3u8_url, timeout=5)\n",
        "        if not head_resp.ok:\n",
        "            print(f\"⚠️ Stream offline ou não disponível para {username} (status {head_resp.status_code})\")\n",
        "            return None\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ Erro de conexão ao acessar stream de {username}: {e}\")\n",
        "        return None\n",
        "\n",
        "    poster_ffmpeg_path = os.path.join(temp_folder, f\"{username}_poster_ffmpeg.jpg\")\n",
        "    command = [\n",
        "        \"ffmpeg\",\n",
        "        \"-y\",\n",
        "        \"-ss\", str(frame_time),\n",
        "        \"-i\", m3u8_url,\n",
        "        \"-vframes\", \"1\",\n",
        "        \"-q:v\", \"2\",\n",
        "        poster_ffmpeg_path\n",
        "    ]\n",
        "    try:\n",
        "        print(f\"🎬 Gerando poster com ffmpeg para {username} no segundo {frame_time}...\")\n",
        "        result = subprocess.run(\n",
        "            command,\n",
        "            stdout=subprocess.PIPE,\n",
        "            stderr=subprocess.PIPE,\n",
        "            timeout=timeout\n",
        "        )\n",
        "        if result.returncode == 0 and os.path.exists(poster_ffmpeg_path):\n",
        "            print(f\"🖼️ Poster gerado via ffmpeg: {poster_ffmpeg_path}\")\n",
        "            return poster_ffmpeg_path\n",
        "        else:\n",
        "            print(f\"❌ ffmpeg não conseguiu gerar poster para {username}.\\nSTDOUT:\\n{result.stdout.decode(errors='ignore')}\\nSTDERR:\\n{result.stderr.decode(errors='ignore')}\")\n",
        "            return None\n",
        "    except subprocess.TimeoutExpired:\n",
        "        print(f\"⏰ Tempo excedido ao tentar gerar poster para {username} via ffmpeg.\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Erro inesperado ao gerar poster via ffmpeg: {e}\")\n",
        "        return None\n",
        "\n",
        "# ============================\n",
        "# VALIDAÇÃO DE POSTER\n",
        "# ============================\n",
        "\n",
        "def is_poster_valid(poster_path):\n",
        "    \"\"\"\n",
        "    Verifica se o poster existe e não está vazio.\n",
        "    \"\"\"\n",
        "    return poster_path and os.path.exists(poster_path) and os.path.getsize(poster_path) > 0\n",
        "\n",
        "# ============================\n",
        "# FIM DA CÉLULA 3\n",
        "# ============================\n",
        "\n",
        "# Observação:\n",
        "# - LOG_PROCESSAMENTO_PATH e logs temporários antigos NÃO são mais necessários a partir da adoção do log único centralizado (LOGS_PATH).\n",
        "# - Todas as operações de logging, blacklist, falha e auditoria devem ser feitas apenas via utilitário de log (Célula 1).\n",
        "# - Siga o padrão modular e Clean Architecture para máxima rastreabilidade e reuso."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "hpRIMtyFIY0q",
      "metadata": {
        "id": "hpRIMtyFIY0q"
      },
      "source": [
        "# Célula 4: Clonagem do Repositório GitHub no Colab e Google Drive\n",
        "\n",
        "**Objetivo:**  \n",
        "Esta célula garante que o repositório do projeto XCam seja sempre clonado de forma limpa e sincronizada no ambiente local do Colab e, se disponível, também no Google Drive para persistência.  \n",
        "Assegura ambiente pronto, atualizado, seguro para gravações e processamento, e prepara diretórios padronizados para integração com o restante do pipeline.\n",
        "\n",
        "## Principais pontos e melhorias implementadas\n",
        "\n",
        "- **Clonagem idempotente e limpa:**  \n",
        "  Remove repositórios antigos antes de clonar para evitar conflitos, arquivos órfãos ou problemas de sincronização.\n",
        "- **Clonagem para ambiente temporário e persistente:**  \n",
        "  O repositório é clonado tanto para `/content` (Colab) quanto para o Drive (`/content/drive/MyDrive/XCam.Drive`) se o Drive estiver montado.\n",
        "- **Preparação de diretórios de gravação e processamento:**  \n",
        "  Estrutura de diretórios temporários criada automaticamente, garantindo organização dos dados.\n",
        "- **Exportação de variáveis globais:**  \n",
        "  Todos os caminhos, URLs e configurações relevantes são disponibilizados via `globals().update()` para uso em todo o notebook.\n",
        "- **Mensagens e validações detalhadas:**  \n",
        "  Feedback informativo sobre o status de cada etapa, facilitando o diagnóstico e a manutenção.\n",
        "- **Pronto para CI/CD e integrações futuras:**  \n",
        "  Token e URLs preparados para automações, integrações externas e uploads (Abyss.to, etc).\n",
        "\n",
        "---\n",
        "\n",
        "## Parâmetros globais definidos nesta célula\n",
        "\n",
        "- **`GITHUB_USER`**, **`GITHUB_REPO`**, **`GITHUB_BRANCH`**, **`GITHUB_TOKEN`**: Configurações do repositório e autenticação.\n",
        "- **`repo_url`**: URL do repositório autenticada para clone/push.\n",
        "- **`TEMP_OUTPUT_FOLDER`**: Pasta para gravações temporárias.\n",
        "- **`BASE_REPO_FOLDER`**: Localização do repositório no ambiente Colab.\n",
        "- **`DRIVE_MOUNT`**, **`DRIVE_REPO_FOLDER`**: Caminhos no Google Drive para persistência (se montado).\n",
        "- **`ABYSS_UPLOAD_URL`**: URL de upload para integração com sistemas externos.\n",
        "\n",
        "---\n",
        "\n",
        "## Como funciona a célula\n",
        "\n",
        "- **Remove repositórios antigos e diretórios temporários**, evitando resíduos de execuções anteriores.\n",
        "- **Clona o repositório do GitHub** para `/content` (Colab).\n",
        "- **Se o Google Drive estiver montado**, faz o mesmo clone no diretório persistente do Drive.\n",
        "- **Cria diretórios temporários necessários** para gravações e arquivos intermediários.\n",
        "- **Exporta todas as variáveis configuradas** para uso global no notebook.\n",
        "- **Exibe mensagens informativas** sobre cada etapa e alerta caso o Drive não esteja disponível.\n",
        "\n",
        "---\n",
        "\n",
        "## Exemplo de uso das variáveis globais\n",
        "\n",
        "```python\n",
        "print(BASE_REPO_FOLDER)        # Caminho do repositório clonado no Colab\n",
        "print(DRIVE_REPO_FOLDER)      # Caminho do repositório no Drive (se montado)\n",
        "print(TEMP_OUTPUT_FOLDER)     # Pasta temporária para gravações\n",
        "print(ABYSS_UPLOAD_URL)       # URL de upload para integração externa\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Segurança, rastreabilidade e manutenção\n",
        "\n",
        "- Garantia de ambiente limpo a cada execução, evitando conflitos de arquivos e branches.\n",
        "- Persistência dos dados no Drive (se montado), evitando perda de gravações em caso de reinicialização do Colab.\n",
        "- Comentários detalhados e estrutura modular facilitam a manutenção, integração com CI/CD e futuras expansões no pipeline do XCam.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Uof_0QCrIlf7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uof_0QCrIlf7",
        "outputId": "a1c4c886-dfb5-4265-f0ff-91292ac6de9d"
      },
      "outputs": [],
      "source": [
        "# ================================================================\n",
        "# Célula 4: Clonagem do Repositório GitHub no Colab e no Google Drive\n",
        "# ================================================================\n",
        "# Objetivo:\n",
        "# - Garantir ambiente limpo e sincronizado para o repositório XCam em todas as execuções\n",
        "# - Clonar o repositório tanto para o ambiente efêmero do Colab quanto para o Google Drive (persistência)\n",
        "# - Preparar diretórios de trabalho para gravações e processamento temporário\n",
        "# - Fornecer feedback claro sobre o status da operação\n",
        "#\n",
        "# Estratégia aplicada:\n",
        "# - Remove repositórios antigos antes de clonar (evita conflitos e arquivos órfãos)\n",
        "# - Utiliza token pessoal para autenticação segura e push futuro (CI/CD)\n",
        "# - Cria estrutura de diretórios padronizada (módulos, gravações, cache, etc.)\n",
        "# - Valida se o Drive está montado antes de tentar operações persistentes\n",
        "# - Comentários detalhados para fácil manutenção e evolução\n",
        "# ================================================================\n",
        "\n",
        "# ============================\n",
        "# CONFIGURAÇÕES DO GITHUB\n",
        "# ============================\n",
        "GITHUB_USER = \"SamuelPassamani\"\n",
        "GITHUB_REPO = \"XCam\"\n",
        "GITHUB_BRANCH = \"main\"\n",
        "GITHUB_TOKEN = \"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\"\n",
        "\n",
        "repo_url = f\"https://{GITHUB_USER}:{GITHUB_TOKEN}@github.com/{GITHUB_USER}/{GITHUB_REPO}.git\"\n",
        "\n",
        "# ============================\n",
        "# CLONAGEM PARA O COLAB\n",
        "# ============================\n",
        "print(f\"⏳ Limpando ambiente e clonando '{GITHUB_REPO}' para o Colab...\")\n",
        "!rm -rf {GITHUB_REPO}\n",
        "!git clone -b {GITHUB_BRANCH} {repo_url}\n",
        "print(f\"✅ Repositório clonado em /content/{GITHUB_REPO}\")\n",
        "\n",
        "# ============================\n",
        "# ESTRUTURA DE DIRETÓRIOS TEMPORÁRIOS\n",
        "# ============================\n",
        "TEMP_OUTPUT_FOLDER = RECORD_TEMP_PATH  # agora gravações temporárias vão para o Drive\n",
        "os.makedirs(TEMP_OUTPUT_FOLDER, exist_ok=True)\n",
        "BASE_REPO_FOLDER = f\"/content/{GITHUB_REPO}\"\n",
        "\n",
        "# ============================\n",
        "# CLONAGEM PARA O GOOGLE DRIVE (PERSISTÊNCIA)\n",
        "# ============================\n",
        "DRIVE_MOUNT = \"/content/drive/MyDrive/XCam.Drive\"\n",
        "DRIVE_REPO_FOLDER = f\"{DRIVE_MOUNT}/{GITHUB_REPO}\"\n",
        "\n",
        "import os\n",
        "\n",
        "if os.path.exists(DRIVE_MOUNT):\n",
        "    print(f\"⏳ Limpando repositório antigo no Drive (se existir)...\")\n",
        "    !rm -rf \"{DRIVE_REPO_FOLDER}\"\n",
        "    print(f\"⏳ Clonando '{GITHUB_REPO}' para o Drive em {DRIVE_REPO_FOLDER} ...\")\n",
        "    !git clone -b {GITHUB_BRANCH} {repo_url} \"{DRIVE_REPO_FOLDER}\"\n",
        "    print(f\"✅ Repositório também clonado no Drive: {DRIVE_REPO_FOLDER}\")\n",
        "else:\n",
        "    print(f\"⚠️ Google Drive não está montado em {DRIVE_MOUNT}.\\nℹ️ Use a célula de montagem antes de prosseguir para garantir persistência.\")\n",
        "\n",
        "# ============================\n",
        "# CONFIGURAÇÃO DE ENDPOINTS DE UPLOAD/INTEGRAÇÃO\n",
        "# ============================\n",
        "ABYSS_UPLOAD_URL = 'http://up.hydrax.net/0128263f78f0b426d617bb61c2a8ff43'\n",
        "globals().update({\n",
        "    'GITHUB_USER': GITHUB_USER,\n",
        "    'GITHUB_REPO': GITHUB_REPO,\n",
        "    'GITHUB_BRANCH': GITHUB_BRANCH,\n",
        "    'GITHUB_TOKEN': GITHUB_TOKEN,\n",
        "    'repo_url': repo_url,\n",
        "    'TEMP_OUTPUT_FOLDER': TEMP_OUTPUT_FOLDER,\n",
        "    'BASE_REPO_FOLDER': BASE_REPO_FOLDER,\n",
        "    'DRIVE_MOUNT': DRIVE_MOUNT,\n",
        "    'DRIVE_REPO_FOLDER': DRIVE_REPO_FOLDER,\n",
        "    'ABYSS_UPLOAD_URL': ABYSS_UPLOAD_URL\n",
        "})\n",
        "\n",
        "# ============================\n",
        "# FIM DA CÉLULA 4\n",
        "# ============================\n",
        "\n",
        "# Observações:\n",
        "# - Os caminhos globais são exportados via globals().update() para uso em todo o notebook.\n",
        "# - Recomenda-se sempre rodar esta célula após alterar tokens ou trocar branches para garantir ambiente limpo e sincronizado.\n",
        "# - O endpoint ABYSS_UPLOAD_URL pode ser atualizado conforme integrações futuras."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "M5iL_9BoIoj7",
      "metadata": {
        "id": "M5iL_9BoIoj7"
      },
      "source": [
        "# Célula 5: Commit e Push Automáticos (rec.json, posters, etc.)\n",
        "\n",
        "**Objetivo:**  \n",
        "Automatiza o processo de commit e push dos arquivos modificados (ex: rec.json, posters e demais artefatos importantes) para o repositório GitHub, garantindo rastreabilidade, atomicidade e integração contínua (CI/CD) do pipeline XCam.\n",
        "\n",
        "## Principais pontos e melhorias implementadas\n",
        "\n",
        "- **Função robusta e modular:**  \n",
        "  A função `git_commit_and_push()` aceita um caminho único (string) ou uma lista de arquivos, permitindo commit em lote e integração com estratégias de batch commit (threshold).\n",
        "- **Configuração automatizada de usuário e e-mail do git:**  \n",
        "  Garante commits válidos para rastreabilidade, auditoria e integração com pipelines automáticos.\n",
        "- **Validação de caminhos e mensagens informativas:**  \n",
        "  Apenas arquivos existentes são adicionados. Mensagens de sucesso, erro ou aviso detalhadas facilitam troubleshooting e manutenção.\n",
        "- **Compatível com commit vazio:**  \n",
        "  Permite o uso do parâmetro `--allow-empty` para garantir que o pipeline siga mesmo sem alterações detectadas, útil para sincronização e CI/CD.\n",
        "- **Push autenticado via token:**  \n",
        "  Utiliza o token pessoal fornecido nas variáveis globais para garantir push seguro e sem intervenção manual.\n",
        "- **Design pronto para integração com logs centralizados:**  \n",
        "  Recomenda-se registrar todas as ações relevantes de commit/push utilizando o log único modular definido na Célula 1.\n",
        "\n",
        "---\n",
        "\n",
        "## Parâmetros e variáveis globais utilizados\n",
        "\n",
        "- **`GITHUB_USER`**, **`GITHUB_REPO`**, **`GITHUB_TOKEN`**: Definidos nas células anteriores para autenticação e configuração do repositório.\n",
        "- **`repo_dir`**: Caminho absoluto do repositório clonado no ambiente Colab.\n",
        "- **`file_paths`**: String ou lista de arquivos a serem commitados e enviados.\n",
        "- **`commit_message`**: Mensagem do commit, customizável conforme a operação realizada.\n",
        "\n",
        "---\n",
        "\n",
        "## Como funciona a função principal\n",
        "\n",
        "- **Valida a existência do repositório local** antes de prosseguir.\n",
        "- **Aceita arquivos únicos ou múltiplos** para commit (string ou lista).\n",
        "- **Adiciona apenas arquivos existentes** ao staging, com avisos para arquivos não encontrados.\n",
        "- **Realiza commit (mesmo vazio) e push autenticado** para o repositório remoto.\n",
        "- **Emite mensagens claras** de sucesso, erro ou aviso ao longo do processo.\n",
        "\n",
        "---\n",
        "\n",
        "## Exemplo de uso típico\n",
        "\n",
        "```python\n",
        "# Commit e push de um único arquivo\n",
        "git_commit_and_push(\"data/rec.json\", \"Atualiza rec.json de gravação\")\n",
        "\n",
        "# Commit e push em lote (lista de arquivos)\n",
        "git_commit_and_push([\n",
        "    \"data/rec.json\",\n",
        "    \"posters/user1_poster.jpg\",\n",
        "    \"posters/user2_poster.jpg\"\n",
        "], \"Batch commit de múltiplos arquivos\")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Segurança, rastreabilidade e manutenção\n",
        "\n",
        "- **Rastreabilidade garantida** por mensagens de commit claras e integração recomendada com o log modular (Célula 1).\n",
        "- **Atomicidade** em operações batch, evitando inconsistências de dados no repositório.\n",
        "- **Pronto para integração com pipelines CI/CD**, webhooks e controles de auditoria.\n",
        "- **Mensagens e tratamento de erros detalhados** facilitam o diagnóstico e a evolução do sistema.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1aQn1G6yI6Gz",
      "metadata": {
        "id": "1aQn1G6yI6Gz"
      },
      "outputs": [],
      "source": [
        "# ================================================================\n",
        "# Célula 5: Commit e Push Automáticos (rec.json, posters, etc.)\n",
        "# ================================================================\n",
        "# Objetivo:\n",
        "# - Automatizar o processo de commit e push dos arquivos modificados (rec.json, posters, etc.) para o repositório GitHub\n",
        "# - Suportar tanto commit de arquivo único como em lote, permitindo estratégia de batch commit baseada em thresholds\n",
        "# - Garantir rastreabilidade, atomicidade e integração segura (CI/CD)\n",
        "#\n",
        "# Estratégia aplicada:\n",
        "# - Função modular e robusta, preparada para integração com logs e auditoria\n",
        "# - Permite commit vazio por segurança, evitando falhas em pipelines sincronizados\n",
        "# - Mensagens e tratamento de erros detalhados para facilitar troubleshooting\n",
        "# - Utilização de variáveis globais para caminhos, usuário e token definidos nas células anteriores\n",
        "# - Design pronto para evolução, reuso e integração com ferramentas externas (ex: webhooks, jobs, etc.)\n",
        "# ================================================================\n",
        "\n",
        "import os\n",
        "import subprocess\n",
        "\n",
        "def git_commit_and_push(file_paths, commit_message=\"Atualiza rec.json\"):\n",
        "    \"\"\"\n",
        "    Realiza git add, commit e push dos arquivos especificados.\n",
        "    - file_paths pode ser uma string (arquivo único) ou uma lista de arquivos.\n",
        "    - commit_message é a mensagem de commit utilizada.\n",
        "\n",
        "    Estratégia:\n",
        "    - Ajusta diretório para o repositório local clonado no Colab\n",
        "    - Configura usuário e e-mail do git (necessários para CI/CD)\n",
        "    - Adiciona arquivos ao staging (aceita múltiplos arquivos)\n",
        "    - Realiza commit (permite commit vazio)\n",
        "    - Realiza push autenticado via token\n",
        "    \"\"\"\n",
        "    # ============================\n",
        "    # VALIDAÇÃO E AJUSTE DE ENTRADAS\n",
        "    # ============================\n",
        "    repo_dir = f\"/content/{GITHUB_REPO}\"\n",
        "    if not os.path.exists(repo_dir):\n",
        "        raise FileNotFoundError(f\"Repositório '{repo_dir}' não encontrado. Verifique se a célula de clonagem foi executada.\")\n",
        "    os.chdir(repo_dir)\n",
        "\n",
        "    # Aceita string ou lista de arquivos\n",
        "    if isinstance(file_paths, str):\n",
        "        file_paths = [file_paths]\n",
        "    elif not isinstance(file_paths, list):\n",
        "        raise ValueError(\"file_paths deve ser uma string ou uma lista de caminhos.\")\n",
        "\n",
        "    # ============================\n",
        "    # CONFIGURAÇÃO DO USUÁRIO GIT (CI/CD)\n",
        "    # ============================\n",
        "    subprocess.run([\"git\", \"config\", \"user.email\", \"contato@aserio.work\"], check=True)\n",
        "    subprocess.run([\"git\", \"config\", \"user.name\", \"SamuelPassamani\"], check=True)\n",
        "\n",
        "    # ============================\n",
        "    # ADIÇÃO DOS ARQUIVOS AO STAGING\n",
        "    # ============================\n",
        "    for file_path in file_paths:\n",
        "        # Verifica se o arquivo existe antes de adicionar\n",
        "        if not os.path.exists(file_path):\n",
        "            print(f\"⚠️ Aviso: arquivo '{file_path}' não existe e será ignorado no commit.\")\n",
        "            continue\n",
        "        subprocess.run([\"git\", \"add\", file_path], check=True)\n",
        "\n",
        "    # ============================\n",
        "    # COMMIT (PERMITE COMMIT VAZIO)\n",
        "    # ============================\n",
        "    try:\n",
        "        subprocess.run(\n",
        "            [\"git\", \"commit\", \"-m\", commit_message, \"--allow-empty\"],\n",
        "            check=False  # Não força erro se não houver mudanças\n",
        "        )\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Erro ao tentar realizar commit: {e}\")\n",
        "\n",
        "    # ============================\n",
        "    # PUSH PARA O REPOSITÓRIO REMOTO (AUTENTICADO)\n",
        "    # ============================\n",
        "    try:\n",
        "        remote_url = f\"https://{GITHUB_USER}:{GITHUB_TOKEN}@github.com/{GITHUB_USER}/{GITHUB_REPO}.git\"\n",
        "        subprocess.run(\n",
        "            [\"git\", \"push\", remote_url],\n",
        "            check=True\n",
        "        )\n",
        "        print(f\"✅ Push realizado com sucesso! ({commit_message})\")\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Erro ao tentar realizar push: {e}\")\n",
        "\n",
        "# ============================\n",
        "# FIM DA CÉLULA 5\n",
        "# ============================\n",
        "\n",
        "# Dicas e melhores práticas:\n",
        "# - Use commit_messages claros e informativos para facilitar a auditoria.\n",
        "# - Utilize a função dentro de loops ou triggers de batch para commit em lote.\n",
        "# - Integre logs das ações de commit/push usando o log único centralizado (Célula 1).\n",
        "# - Em caso de erro de autenticação, revise o token e as permissões do GitHub."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "BZ4c3Uk1I7AK",
      "metadata": {
        "id": "BZ4c3Uk1I7AK"
      },
      "source": [
        "# Célula 6: Busca de Transmissões na API XCam, Blacklist Temporária, Fallback via liveInfo e Busca Inteligente/Unitária\n",
        "\n",
        "**Objetivo:**  \n",
        "Realizar a busca das transmissões ativas na API principal da XCam, mantendo o lote de transmissões sempre completo até o `LIMIT_DEFAULT` e sem duplicidades, utilizando controle de blacklist temporária e log de transmissões em processamento.  \n",
        "Inclui funções de busca unitária/inteligente (para manter “lote cheio” continuamente) e gerenciamento automático de poster, com geração via ffmpeg quando necessário.\n",
        "\n",
        "## Estratégia e melhorias implementadas\n",
        "\n",
        "- **Blacklist temporária e controle de falhas:**  \n",
        "  Usuários problemáticos são bloqueados temporariamente após atingirem o limite de falhas (`BLACKLIST_MAX_FAILURES`), acelerando o processamento e evitando ciclos infinitos.\n",
        "- **Busca em lote e unitária com fallback:**  \n",
        "  Consulta a API principal com limite alto para preencher o lote rapidamente. Caso necessário, realiza fallback via `/liveInfo` para usuários sem `src`.\n",
        "- **Controle de duplicidade e fila inteligente:**  \n",
        "  Antes de incluir qualquer transmissão, verifica no log de processamento e na blacklist para evitar tentativas repetidas ou paradas em streams problemáticos.\n",
        "- **Poster garantido:**  \n",
        "  Se o poster estiver ausente, inválido ou nulo, gera automaticamente uma imagem via ffmpeg a partir do stream, garantindo sempre um arquivo válido.\n",
        "- **Eficiência e paralelismo:**  \n",
        "  Todas as funções são preparadas para processamento paralelo e integração total ao pipeline XCam.\n",
        "- **Compatibilidade:**  \n",
        "  Suporte total à busca de usuários específicos, agora também protegida pela blacklist e controle de falhas.\n",
        "- **Design modular:**  \n",
        "  Funções separadas para busca em lote (`get_broadcasts`), busca por usuários (`buscar_usuarios_especificos`) e busca unitária/primeira transmissão livre (`buscar_proxima_transmissao_livre`), facilitando reuso e manutenção.\n",
        "\n",
        "---\n",
        "\n",
        "## Como funciona cada função\n",
        "\n",
        "- **get_broadcasts:**  \n",
        "  Retorna um lote de transmissões válidas, sempre checando blacklist, log de processamento e gerando poster se necessário. Realiza fallback automático para `/liveInfo` se não encontrar o src na API principal.\n",
        "- **buscar_usuarios_especificos:**  \n",
        "  Busca apenas os usuários informados, respeitando sempre o controle de blacklist/falhas, e faz fallback via `/liveInfo` quando necessário.\n",
        "- **buscar_proxima_transmissao_livre:**  \n",
        "  Busca rapidamente a próxima transmissão livre para processamento, sempre utilizando os mesmos critérios de controle, garantindo agilidade na fila e eficiência máxima.\n",
        "\n",
        "---\n",
        "\n",
        "## Detalhes técnicos e recomendações\n",
        "\n",
        "- **Blacklist temporária e controle de falhas:**  \n",
        "  Funções `register_failure`, `clear_failure`, `add_to_blacklist`, `is_in_blacklist`, `load_blacklist` e `save_blacklist` garantem rastreabilidade e bloqueio eficiente de usuários problemáticos.\n",
        "- **Arquitetura limpa e modular:**  \n",
        "  Código preparado para integração futura com log único centralizado e processamento concorrente.\n",
        "- **Poster sempre válido:**  \n",
        "  Funções utilitárias garantem que cada transmissão só é liberada para gravação se houver poster válido (baixado ou gerado).\n",
        "- **Tratamento de erros robusto:**  \n",
        "  Toda etapa crítica possui tratamento de exceções e mensagens claras para facilitar manutenção e monitoramento.\n",
        "\n",
        "---\n",
        "\n",
        "## Exemplo de uso das funções\n",
        "\n",
        "```python\n",
        "# Buscar lote completo de transmissões válidas\n",
        "streams = get_broadcasts(limit=LIMIT_DEFAULT)\n",
        "\n",
        "# Buscar apenas usuários específicos\n",
        "streams_especificos = buscar_usuarios_especificos([\"user1\", \"user2\"])\n",
        "\n",
        "# Buscar a próxima transmissão livre disponível\n",
        "proxima_stream = buscar_proxima_transmissao_livre()\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Rastreabilidade, manutenção e integração\n",
        "\n",
        "- Blacklist e falhas podem ser migrados para o log centralizado para máxima rastreabilidade.\n",
        "- Todas as funções são compatíveis com execução paralela e integração CI/CD.\n",
        "- Mensagens detalhadas e arquitetura modular facilitam manutenção e futuras expansões no pipeline do XCam.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "h1jr7D0pJ7jS",
      "metadata": {
        "id": "h1jr7D0pJ7jS"
      },
      "outputs": [],
      "source": [
        "# ================================================================\n",
        "# Célula 6: Busca de Transmissões com Blacklist Temporária e Controle de Falhas\n",
        "# ================================================================\n",
        "# Objetivo:\n",
        "# - Buscar transmissões ao vivo na API XCam, considerando blacklist e controle de falhas por usuário\n",
        "# - Evitar loops infinitos e tentativas repetidas em usuários problemáticos via blacklist temporária e contador de falhas\n",
        "# - Garantir sempre poster válido (via download ou ffmpeg) antes de liberar qualquer transmissão para processamento\n",
        "# - Modularização e robustez, pronta para integração com log único e arquitetura limpa\n",
        "#\n",
        "# Estratégia aplicada:\n",
        "# - Lógica de blacklist e falhas modularizada (pronta para futura centralização no log único)\n",
        "# - Consulta à API XCam com fallback automático para liveInfo\n",
        "# - Funções robustas, preparadas para concorrência, reuso e integração contínua no pipeline XCam\n",
        "# ================================================================\n",
        "\n",
        "# ============================\n",
        "# PARÂMETROS E CAMINHOS GLOBAIS (DEVEM VIR DA CÉLULA 1)\n",
        "# ============================\n",
        "# Exemplo de nomes esperados (ajuste conforme sua célula 1!)\n",
        "# BLACKLIST_TIMEOUT: tempo de expiração da blacklist (em segundos)\n",
        "# BLACKLIST_MAX_FAILURES: número de falhas consecutivas antes de banir\n",
        "# API_SEARCH_LIMIT: limite de transmissões ao buscar usuários específicos\n",
        "\n",
        "import os\n",
        "LOGS_DIR = os.path.dirname(LOGS_PATH)\n",
        "BLACKLIST_PATH = os.path.join(LOGS_DIR, \"xcam_blacklist.log\")\n",
        "FAILURE_LOGS_PATH = os.path.join(LOGS_DIR, \"xcam_failures.log\")\n",
        "LOG_PROCESSAMENTO_PATH = os.path.join(LOGS_DIR, \"xcam_processing.log\")\n",
        "\n",
        "# ============================\n",
        "# BLACKLIST TEMPORÁRIA - CRUD\n",
        "# ============================\n",
        "\n",
        "def load_blacklist():\n",
        "    \"\"\"\n",
        "    Carrega a blacklist temporária (usuário: timestamp).\n",
        "    Apenas mantém usuários ainda válidos pelo timeout.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(BLACKLIST_PATH):\n",
        "        return {}\n",
        "    with open(BLACKLIST_PATH, \"r\") as f:\n",
        "        now = time.time()\n",
        "        lines = [line.strip().split(\",\") for line in f if line.strip()]\n",
        "        return {user: float(ts) for user, ts in lines if now - float(ts) < BLACKLIST_TIMEOUT}\n",
        "\n",
        "def save_blacklist(blacklist):\n",
        "    \"\"\"\n",
        "    Salva o dicionário da blacklist no arquivo.\n",
        "    \"\"\"\n",
        "    with open(BLACKLIST_PATH, \"w\") as f:\n",
        "        for user, ts in blacklist.items():\n",
        "            f.write(f\"{user},{ts}\\n\")\n",
        "\n",
        "def add_to_blacklist(username):\n",
        "    \"\"\"\n",
        "    Adiciona usuário à blacklist com timestamp atual.\n",
        "    \"\"\"\n",
        "    blacklist = load_blacklist()\n",
        "    blacklist[username] = time.time()\n",
        "    save_blacklist(blacklist)\n",
        "    print(f\"⚠️ Usuário '{username}' adicionado à blacklist temporária.\")\n",
        "\n",
        "def is_in_blacklist(username):\n",
        "    \"\"\"\n",
        "    Verifica se o usuário está na blacklist válida.\n",
        "    \"\"\"\n",
        "    blacklist = load_blacklist()\n",
        "    return username in blacklist\n",
        "\n",
        "# ============================\n",
        "# CONTROLE DE FALHAS POR USUÁRIO\n",
        "# ============================\n",
        "\n",
        "def load_failures():\n",
        "    \"\"\"\n",
        "    Carrega o número de falhas por usuário.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(FAILURE_LOGS_PATH):\n",
        "        return {}\n",
        "    with open(FAILURE_LOGS_PATH, \"r\") as f:\n",
        "        return {user: int(count) for user, count in (line.strip().split(\",\") for line in f if line.strip())}\n",
        "\n",
        "def save_failures(failures):\n",
        "    \"\"\"\n",
        "    Salva o contador de falhas por usuário.\n",
        "    \"\"\"\n",
        "    with open(FAILURE_LOGS_PATH, \"w\") as f:\n",
        "        for user, count in failures.items():\n",
        "            f.write(f\"{user},{count}\\n\")\n",
        "\n",
        "def register_failure(username):\n",
        "    \"\"\"\n",
        "    Registra uma falha para o usuário e move para blacklist se exceder o limite.\n",
        "    \"\"\"\n",
        "    failures = load_failures()\n",
        "    failures[username] = failures.get(username, 0) + 1\n",
        "    if failures[username] >= BLACKLIST_MAX_FAILURES:\n",
        "        add_to_blacklist(username)\n",
        "        failures.pop(username)  # Limpa contador ao entrar na blacklist\n",
        "    save_failures(failures)\n",
        "\n",
        "def clear_failure(username):\n",
        "    \"\"\"\n",
        "    Limpa o contador de falhas para o usuário.\n",
        "    \"\"\"\n",
        "    failures = load_failures()\n",
        "    if username in failures:\n",
        "        failures.pop(username)\n",
        "        save_failures(failures)\n",
        "\n",
        "# ============================\n",
        "# BUSCA DE TRANSMISSÕES NA API XCAM\n",
        "# ============================\n",
        "\n",
        "def get_broadcasts(limit=LIMIT_DEFAULT, page=PAGE_DEFAULT, usuarios_especificos=None, temp_folder=None):\n",
        "    \"\"\"\n",
        "    Busca transmissões ao vivo, respeitando blacklist, falhas e log de processamento.\n",
        "    Garante poster válido (download ou ffmpeg) e faz fallback automático.\n",
        "    \"\"\"\n",
        "    if temp_folder is None:\n",
        "        temp_folder = POSTER_TEMP_PATH\n",
        "    LOG_PROCESSAMENTO_PATH = \"/content/xcam_processing.log\"\n",
        "    transmissao_em_proc = set()\n",
        "    if os.path.exists(LOG_PROCESSAMENTO_PATH):\n",
        "        with open(LOG_PROCESSAMENTO_PATH, \"r\") as f:\n",
        "            transmissao_em_proc = set([line.strip() for line in f if line.strip()])\n",
        "\n",
        "    if usuarios_especificos:\n",
        "        api_url_main = f\"https://api.xcam.gay/?limit={API_SEARCH_LIMIT}&page=1\"\n",
        "        print(f\"🌐 Acessando API principal (usuários específicos): {api_url_main}\")\n",
        "    else:\n",
        "        api_url_main = f\"https://api.xcam.gay/?limit=1500&page=1\"\n",
        "        print(f\"🌐 Acessando API principal (todas transmissões online): {api_url_main}\")\n",
        "\n",
        "    streams_from_main = []\n",
        "    streams_without_preview = []\n",
        "\n",
        "    try:\n",
        "        response_main = requests.get(api_url_main)\n",
        "        response_main.raise_for_status()\n",
        "        data_main = response_main.json()\n",
        "        broadcasts_data = data_main.get(\"broadcasts\")\n",
        "        if not broadcasts_data:\n",
        "            print(\"⚠️ Chave 'broadcasts' não encontrada na resposta da API principal.\")\n",
        "            return []\n",
        "        items = broadcasts_data.get(\"items\")\n",
        "        if not isinstance(items, list):\n",
        "            print(f\"⚠️ Chave 'items' não encontrada ou não é uma lista em 'broadcasts'.\")\n",
        "            return []\n",
        "\n",
        "        for item in items:\n",
        "            preview = item.get(\"preview\") or {}\n",
        "            src = preview.get(\"src\")\n",
        "            poster = preview.get(\"poster\")\n",
        "            username = item.get(\"username\", \"desconhecido\")\n",
        "            if username in transmissao_em_proc or is_in_blacklist(username):\n",
        "                continue\n",
        "            if usuarios_especificos and username not in usuarios_especificos:\n",
        "                continue\n",
        "            if src:\n",
        "                poster_path = None\n",
        "                try:\n",
        "                    if poster and isinstance(poster, str) and poster.strip():\n",
        "                        poster_path = download_and_save_poster(poster, username, temp_folder)\n",
        "                    if not is_poster_valid(poster_path):\n",
        "                        poster_path = generate_poster_with_ffmpeg(src, username, temp_folder)\n",
        "                    if not is_poster_valid(poster_path):\n",
        "                        register_failure(username)\n",
        "                        continue\n",
        "                    else:\n",
        "                        clear_failure(username)\n",
        "                except Exception as e:\n",
        "                    print(f\"❌ Falha ao gerar poster para {username}: {e}\")\n",
        "                    register_failure(username)\n",
        "                    continue\n",
        "                streams_from_main.append({\n",
        "                    \"username\": username,\n",
        "                    \"src\": src,\n",
        "                    \"poster\": poster_path\n",
        "                })\n",
        "            else:\n",
        "                streams_without_preview.append({\"username\": username})\n",
        "\n",
        "        print(f\"✅ {len(streams_from_main)} transmissões com URL na API principal (total consultado).\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Erro ao acessar API principal: {e}\")\n",
        "        return []\n",
        "\n",
        "    # Fallback: busca via liveInfo para streams sem URL na API principal\n",
        "    streams_from_liveinfo = []\n",
        "    if streams_without_preview:\n",
        "        print(f\"🔁 Buscando liveInfo para {len(streams_without_preview)} streams sem URL na API principal...\")\n",
        "        for stream_info in streams_without_preview:\n",
        "            username = stream_info[\"username\"]\n",
        "            if username in transmissao_em_proc or is_in_blacklist(username):\n",
        "                continue\n",
        "            if usuarios_especificos and username not in usuarios_especificos:\n",
        "                continue\n",
        "            api_url_liveinfo = f\"https://api.xcam.gay/user/{username}/liveInfo\"\n",
        "            try:\n",
        "                response_liveinfo = requests.get(api_url_liveinfo)\n",
        "                response_liveinfo.raise_for_status()\n",
        "                data_liveinfo = response_liveinfo.json()\n",
        "                m3u8_url = data_liveinfo.get(\"cdnURL\") or data_liveinfo.get(\"edgeURL\")\n",
        "                poster_path = None\n",
        "                if m3u8_url:\n",
        "                    poster_path = generate_poster_with_ffmpeg(m3u8_url, username, temp_folder)\n",
        "                    if not is_poster_valid(poster_path):\n",
        "                        register_failure(username)\n",
        "                        continue\n",
        "                    else:\n",
        "                        clear_failure(username)\n",
        "                    streams_from_liveinfo.append({\n",
        "                        \"username\": username,\n",
        "                        \"src\": m3u8_url,\n",
        "                        \"poster\": poster_path\n",
        "                    })\n",
        "                else:\n",
        "                    print(f\"⚠️ liveInfo de {username} não retornou cdnURL/edgeURL (usuário possivelmente offline).\")\n",
        "                    register_failure(username)\n",
        "            except Exception as ex:\n",
        "                print(f\"❌ Erro ao buscar liveInfo para {username}: {ex}\")\n",
        "                register_failure(username)\n",
        "            time.sleep(0.5)\n",
        "\n",
        "    # Junta, evita duplicidade de usuário, blacklist e respeita 'limit' FINAL\n",
        "    final_streams_list = []\n",
        "    seen_usernames = set()\n",
        "    for stream in streams_from_main + streams_from_liveinfo:\n",
        "        username = stream[\"username\"]\n",
        "        if username in seen_usernames or username in transmissao_em_proc or is_in_blacklist(username):\n",
        "            continue\n",
        "        final_streams_list.append(stream)\n",
        "        seen_usernames.add(username)\n",
        "        if len(final_streams_list) >= limit:\n",
        "            break\n",
        "\n",
        "    print(f\"🔎 Selecionadas {len(final_streams_list)} streams válidas após fallback (respeitando limit={limit}).\")\n",
        "    return final_streams_list\n",
        "\n",
        "# ============================\n",
        "# BUSCA DE USUÁRIOS ESPECÍFICOS (COM BLACKLIST)\n",
        "# ============================\n",
        "\n",
        "def buscar_usuarios_especificos(usuarios_lista, temp_folder=None):\n",
        "    \"\"\"\n",
        "    Busca usuários específicos via API, agora respeitando blacklist e controle de falhas.\n",
        "    \"\"\"\n",
        "    if temp_folder is None:\n",
        "        temp_folder = POSTER_TEMP_PATH\n",
        "    LOG_PROCESSAMENTO_PATH = \"/content/xcam_processing.log\"\n",
        "    transmissao_em_proc = set()\n",
        "    if os.path.exists(LOG_PROCESSAMENTO_PATH):\n",
        "        with open(LOG_PROCESSAMENTO_PATH, \"r\") as f:\n",
        "            transmissao_em_proc = set([line.strip() for line in f if line.strip()])\n",
        "\n",
        "    api_url = f\"https://api.xcam.gay/?limit={API_SEARCH_LIMIT}&page=1\"\n",
        "    print(f\"🔍 Buscando usuários específicos em {api_url}\")\n",
        "    try:\n",
        "        response = requests.get(api_url)\n",
        "        response.raise_for_status()\n",
        "        data = response.json()\n",
        "        items = data.get(\"broadcasts\", {}).get(\"items\", [])\n",
        "        encontrados = []\n",
        "        sem_src = []\n",
        "        for item in items:\n",
        "            username = item.get(\"username\", \"\")\n",
        "            if username in usuarios_lista and username not in transmissao_em_proc and not is_in_blacklist(username):\n",
        "                preview = item.get(\"preview\") or {}\n",
        "                src = preview.get(\"src\")\n",
        "                poster = preview.get(\"poster\")\n",
        "                poster_path = None\n",
        "                try:\n",
        "                    if src:\n",
        "                        if poster and isinstance(poster, str) and poster.strip():\n",
        "                            poster_path = download_and_save_poster(poster, username, temp_folder)\n",
        "                        if not is_poster_valid(poster_path):\n",
        "                            poster_path = generate_poster_with_ffmpeg(src, username, temp_folder)\n",
        "                        if not is_poster_valid(poster_path):\n",
        "                            register_failure(username)\n",
        "                            continue\n",
        "                        else:\n",
        "                            clear_failure(username)\n",
        "                        encontrados.append({\n",
        "                            \"username\": username,\n",
        "                            \"src\": src,\n",
        "                            \"poster\": poster_path\n",
        "                        })\n",
        "                    else:\n",
        "                        sem_src.append(username)\n",
        "                except Exception as e:\n",
        "                    print(f\"❌ Falha ao gerar poster para {username}: {e}\")\n",
        "                    register_failure(username)\n",
        "        for username in sem_src:\n",
        "            if username in transmissao_em_proc or is_in_blacklist(username):\n",
        "                continue\n",
        "            api_url_liveinfo = f\"https://api.xcam.gay/user/{username}/liveInfo\"\n",
        "            try:\n",
        "                response_liveinfo = requests.get(api_url_liveinfo)\n",
        "                response_liveinfo.raise_for_status()\n",
        "                data_liveinfo = response_liveinfo.json()\n",
        "                m3u8_url = data_liveinfo.get(\"cdnURL\") or data_liveinfo.get(\"edgeURL\")\n",
        "                poster_path = None\n",
        "                if m3u8_url:\n",
        "                    poster_path = generate_poster_with_ffmpeg(m3u8_url, username, temp_folder)\n",
        "                    if not is_poster_valid(poster_path):\n",
        "                        register_failure(username)\n",
        "                        continue\n",
        "                    else:\n",
        "                        clear_failure(username)\n",
        "                    encontrados.append({\n",
        "                        \"username\": username,\n",
        "                        \"src\": m3u8_url,\n",
        "                        \"poster\": poster_path\n",
        "                    })\n",
        "                else:\n",
        "                    print(f\"⚠️ liveInfo de {username} não retornou cdnURL/edgeURL (usuário possivelmente offline).\")\n",
        "                    register_failure(username)\n",
        "            except Exception as ex:\n",
        "                print(f\"❌ Erro ao buscar liveInfo para {username}: {ex}\")\n",
        "                register_failure(username)\n",
        "            time.sleep(0.5)\n",
        "        print(f\"Encontrados {len(encontrados)} dos {len(usuarios_lista)} usuários procurados (incluindo fallback).\")\n",
        "        return encontrados\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Erro ao buscar usuários específicos: {e}\")\n",
        "        return []\n",
        "\n",
        "# ============================\n",
        "# BUSCA DA PRÓXIMA TRANSMISSÃO DISPONÍVEL (COM BLACKLIST)\n",
        "# ============================\n",
        "\n",
        "def buscar_proxima_transmissao_livre(temp_folder=None):\n",
        "    \"\"\"\n",
        "    Busca a próxima transmissão ao vivo não processada, com poster válido e ignorando blacklist.\n",
        "    \"\"\"\n",
        "    if temp_folder is None:\n",
        "        temp_folder = POSTER_TEMP_PATH\n",
        "    LOG_PROCESSAMENTO_PATH = \"/content/xcam_processing.log\"\n",
        "    transmissao_em_proc = set()\n",
        "    if os.path.exists(LOG_PROCESSAMENTO_PATH):\n",
        "        with open(LOG_PROCESSAMENTO_PATH, \"r\") as f:\n",
        "            transmissao_em_proc = set([line.strip() for line in f if line.strip()])\n",
        "\n",
        "    api_url_main = f\"https://api.xcam.gay/?limit=1500&page=1\"\n",
        "    print(f\"🔎 Buscando próxima transmissão livre: {api_url_main}\")\n",
        "    try:\n",
        "        response_main = requests.get(api_url_main)\n",
        "        response_main.raise_for_status()\n",
        "        data_main = response_main.json()\n",
        "        items = data_main.get(\"broadcasts\", {}).get(\"items\", [])\n",
        "        for item in items:\n",
        "            username = item.get(\"username\", \"desconhecido\")\n",
        "            if username in transmissao_em_proc or is_in_blacklist(username):\n",
        "                continue\n",
        "            preview = item.get(\"preview\") or {}\n",
        "            src = preview.get(\"src\")\n",
        "            poster = preview.get(\"poster\")\n",
        "            try:\n",
        "                if src:\n",
        "                    poster_path = None\n",
        "                    if poster and isinstance(poster, str) and poster.strip():\n",
        "                        poster_path = download_and_save_poster(poster, username, temp_folder)\n",
        "                    if not is_poster_valid(poster_path):\n",
        "                        poster_path = generate_poster_with_ffmpeg(src, username, temp_folder)\n",
        "                    if not is_poster_valid(poster_path):\n",
        "                        register_failure(username)\n",
        "                        continue\n",
        "                    else:\n",
        "                        clear_failure(username)\n",
        "                    print(f\"🎯 Transmissão livre encontrada: {username}\")\n",
        "                    return {\n",
        "                        \"username\": username,\n",
        "                        \"src\": src,\n",
        "                        \"poster\": poster_path\n",
        "                    }\n",
        "                else:\n",
        "                    api_url_liveinfo = f\"https://api.xcam.gay/user/{username}/liveInfo\"\n",
        "                    try:\n",
        "                        response_liveinfo = requests.get(api_url_liveinfo)\n",
        "                        response_liveinfo.raise_for_status()\n",
        "                        data_liveinfo = response_liveinfo.json()\n",
        "                        m3u8_url = data_liveinfo.get(\"cdnURL\") or data_liveinfo.get(\"edgeURL\")\n",
        "                        poster_path = None\n",
        "                        if m3u8_url:\n",
        "                            poster_path = generate_poster_with_ffmpeg(m3u8_url, username, temp_folder)\n",
        "                            if not is_poster_valid(poster_path):\n",
        "                                register_failure(username)\n",
        "                                continue\n",
        "                            else:\n",
        "                                clear_failure(username)\n",
        "                            print(f\"🎯 Transmissão livre (pelo liveInfo) encontrada: {username}\")\n",
        "                            return {\n",
        "                                \"username\": username,\n",
        "                                \"src\": m3u8_url,\n",
        "                                \"poster\": poster_path\n",
        "                            }\n",
        "                        else:\n",
        "                            register_failure(username)\n",
        "                    except Exception as ex:\n",
        "                        print(f\"❌ Erro ao buscar liveInfo para {username}: {ex}\")\n",
        "                        register_failure(username)\n",
        "                    time.sleep(0.5)\n",
        "            except Exception as e:\n",
        "                print(f\"❌ Falha ao processar transmissão {username}: {e}\")\n",
        "                register_failure(username)\n",
        "        print(\"🚫 Nenhuma transmissão livre encontrada após varrer todas online.\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Erro ao buscar transmissões online: {e}\")\n",
        "        return None\n",
        "\n",
        "# ================================================================\n",
        "# FIM DA CÉLULA 6 — BUSCA E BLACKLIST\n",
        "# ================================================================\n",
        "\n",
        "# Observações:\n",
        "# - Recomenda-se migrar o controle de blacklist e falhas para o log centralizado (Célula 1) para máxima rastreabilidade.\n",
        "# - Todas as funções estão preparadas para uso concorrente e integração com o pipeline modular do XCam.\n",
        "# - Poster gerado sempre é validado, evitando arquivos inválidos ou corrompidos.\n",
        "# - Tratamento de erro robusto e logging detalhado garantem manutenção facilitada."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "jGFyqOUoKEF7",
      "metadata": {
        "id": "jGFyqOUoKEF7"
      },
      "source": [
        "# Célula 7: Gravação da Stream, Poster Automático, Controle de Falhas, Log Seguro e Blacklist Inteligente\n",
        "\n",
        "**Objetivo:**  \n",
        "Automatizar a gravação de transmissões ao vivo com ffmpeg, garantindo robustez, rastreabilidade e integração com a lógica de blacklist temporária e controle de falhas. A célula também assegura o gerenciamento seguro do log de transmissões em processamento e a limpeza de arquivos temporários.\n",
        "\n",
        "## Estratégia e melhorias implementadas\n",
        "\n",
        "- **Gerenciamento seguro de log:**  \n",
        "  O usuário é registrado no log de transmissões em processamento antes da gravação e removido dele ao final (tanto em sucesso quanto em erro), evitando duplicidade e permitindo paralelismo seguro.\n",
        "- **Poster sempre válido:**  \n",
        "  O sistema tenta baixar o poster da API. Se o poster estiver ausente, inválido ou nulo, gera automaticamente uma imagem via ffmpeg, assegurando que toda transmissão tenha um poster associado e válido.\n",
        "- **Controle de tempo mínimo:**  \n",
        "  Se a gravação resultar em vídeo muito curto, tanto o arquivo de vídeo quanto o poster são descartados imediatamente, e uma falha é registrada para o usuário.\n",
        "- **Tratamento robusto de falhas:**  \n",
        "  Qualquer falha (ffmpeg, exceptions, etc.) é registrada. Ao atingir o número máximo de falhas consecutivas (`BLACKLIST_MAX_FAILURES`), o usuário entra automaticamente na blacklist temporária, evitando tentativas infinitas e desperdício de recursos.\n",
        "- **Limpeza automatizada:**  \n",
        "  Após upload ou erro, todos os arquivos temporários (vídeo e poster) são removidos, otimizando o uso do disco e mantendo o ambiente do Colab limpo.\n",
        "- **Reset de falhas em caso de sucesso:**  \n",
        "  Quando a gravação é válida, o contador de falhas do usuário é limpo, evitando blacklist indevida.\n",
        "- **Comentários detalhados e código modular:**  \n",
        "  O fluxo é completamente documentado, facilitando manutenção, revisão e entendimento por toda a equipe.\n",
        "\n",
        "---\n",
        "\n",
        "## Fluxo resumido da função principal\n",
        "\n",
        "1. **Registra o usuário** no log de transmissões em processamento.\n",
        "2. **Garante um poster válido** (download ou geração automática).\n",
        "3. **Executa o ffmpeg** para gravar a transmissão e monitora o progresso em tempo real.\n",
        "4. **Valida a gravação**:\n",
        "   - Se falhar, registra falha e trata blacklist.\n",
        "   - Se for curta demais, descarta e registra falha.\n",
        "   - Se for válida, limpa contador de falhas e prossegue normalmente.\n",
        "5. **Após upload ou erro**, remove o usuário do log e limpa arquivos temporários.\n",
        "\n",
        "---\n",
        "\n",
        "## Exemplo de uso\n",
        "\n",
        "```python\n",
        "resultado = gravar_stream(username=\"user123\", m3u8_url=\"https://cdn.xcam.gay/m3u8/...\", poster_url=\"https://api.xcam.gay/poster/...\")\n",
        "if resultado['upload_success']:\n",
        "    print(\"Gravação e upload realizados com sucesso!\")\n",
        "else:\n",
        "    print(\"Falha na gravação ou upload:\", resultado['abyss_response'])\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Segurança, rastreabilidade e integração\n",
        "\n",
        "- **Pronto para CI/CD e execução paralela:**  \n",
        "  Controle rigoroso de log e blacklist garante execução concorrente, segura e rastreável por todo o pipeline XCam.\n",
        "- **Integração total com as funções globais:**  \n",
        "  Utiliza funções de blacklist e falha da Célula 6, promovendo rastreabilidade e controle centralizado.\n",
        "- **Diagnóstico facilitado:**  \n",
        "  Mensagens e logs detalhados em cada etapa do processo.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eJ_jrfNgKZNr",
      "metadata": {
        "id": "eJ_jrfNgKZNr"
      },
      "outputs": [],
      "source": [
        "# ================================================================\n",
        "# Célula 7: Gravação Automática de Transmissão, Controle de Log, Limpeza e Blacklist Inteligente\n",
        "# ================================================================\n",
        "# Objetivo:\n",
        "# - Gravar transmissões ao vivo utilizando ffmpeg, com controle rigoroso de log de processamento, tratamento de falhas e integração com blacklist temporária.\n",
        "# - Garantir que cada transmissão seja registrada no log de processamento no início e removida ao final (sucesso ou erro), evitando duplicidade ou processamento concorrente.\n",
        "# - Registrar falhas (ffmpeg, duração insuficiente, poster inválido), escalando usuários para a blacklist temporária ao atingir o limite de tentativas, conforme regras globais (Célula 6).\n",
        "# - Limpar arquivos temporários após uso.\n",
        "# - Modular e pronto para integração com pipelines CI/CD, execução concorrente e ambientes colaborativos.\n",
        "# ================================================================\n",
        "\n",
        "import os\n",
        "LOGS_DIR = os.path.dirname(LOGS_PATH)\n",
        "LOG_PROCESSAMENTO_PATH = os.path.join(LOGS_DIR, \"xcam_processing.log\")\n",
        "\n",
        "def get_video_duration(filepath):\n",
        "    \"\"\"\n",
        "    Retorna a duração real do arquivo mp4, em segundos, utilizando ffprobe.\n",
        "    Retorna None em caso de erro ou se o arquivo não existir.\n",
        "    \"\"\"\n",
        "    import subprocess\n",
        "    import json\n",
        "    try:\n",
        "        if not os.path.exists(filepath):\n",
        "            print(f\"⚠️ Arquivo para ffprobe não encontrado: {filepath}\")\n",
        "            return None\n",
        "        cmd = [\n",
        "            \"ffprobe\", \"-v\", \"error\",\n",
        "            \"-show_entries\", \"format=duration\",\n",
        "            \"-of\", \"json\",\n",
        "            filepath\n",
        "        ]\n",
        "        result = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
        "        info = json.loads(result.stdout)\n",
        "        duration = float(info[\"format\"][\"duration\"])\n",
        "        return int(round(duration))\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ Não foi possível obter duração via ffprobe para {filepath}: {e}\")\n",
        "        return None\n",
        "\n",
        "def gravar_stream(username, m3u8_url, poster_url=None, poster_frame_time=7):\n",
        "    \"\"\"\n",
        "    Grava a transmissão ao vivo do usuário usando ffmpeg, com controle de erros, log e integração à blacklist.\n",
        "    - Adiciona usuário ao log de processamento no início.\n",
        "    - Remove do log ao finalizar, independentemente do resultado (robusto via finally).\n",
        "    - Em caso de falha do ffmpeg ou gravação muito curta, registra falha do usuário.\n",
        "    - Ao atingir N falhas consecutivas, usuário entra na blacklist (funções globais).\n",
        "    - Limpa arquivos temporários ao final.\n",
        "    - Garante poster válido: baixa da poster_url, ou gera automaticamente com ffmpeg se ausente/inválido.\n",
        "    - poster_frame_time: segundo do vídeo onde a captura do poster será feita, se necessário.\n",
        "    \"\"\"\n",
        "    # LOG_PROCESSAMENTO_PATH = \"/content/xcam_processing.log\"\n",
        "\n",
        "    # Adiciona a transmissão ao log de transmissões em processamento\n",
        "    try:\n",
        "        with open(LOG_PROCESSAMENTO_PATH, \"a\") as f:\n",
        "            f.write(f\"{username}\\n\")\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Erro ao registrar transmissão em processamento no log: {e}\")\n",
        "\n",
        "    start_time_dt = datetime.now()\n",
        "    data_str = start_time_dt.strftime(\"%d-%m-%Y\")\n",
        "    horario_str = start_time_dt.strftime(\"%H-%M\")\n",
        "    temp_filename = f\"{username}_{start_time_dt.strftime('%Y%m%d_%H%M%S')}_temp.mp4\"\n",
        "    filepath = os.path.join(TEMP_OUTPUT_FOLDER, temp_filename)\n",
        "\n",
        "    print(f\"\\n🎬 Iniciando gravação de: {username} (URL: {m3u8_url}) em {filepath}\")\n",
        "\n",
        "    # Garante poster válido\n",
        "    poster_temp_path = None\n",
        "    if poster_url:\n",
        "        poster_temp_path = download_and_save_poster(poster_url, username, TEMP_OUTPUT_FOLDER)\n",
        "    if not is_poster_valid(poster_temp_path) and m3u8_url:\n",
        "        poster_temp_path = generate_poster_with_ffmpeg(m3u8_url, username, TEMP_OUTPUT_FOLDER, frame_time=poster_frame_time)\n",
        "\n",
        "    ffmpeg_cmd = [\n",
        "        \"ffmpeg\", \"-i\", m3u8_url,\n",
        "        \"-t\", str(RECORD_SECONDS),\n",
        "\n",
        "        \"-c\", \"copy\", \"-y\", filepath\n",
        "    ]\n",
        "\n",
        "    start_time_process = time.time()\n",
        "    process = None\n",
        "\n",
        "    try:\n",
        "        process = subprocess.Popen(\n",
        "            ffmpeg_cmd,\n",
        "            stdout=subprocess.PIPE,\n",
        "            stderr=subprocess.STDOUT,\n",
        "            text=True,\n",
        "            bufsize=1,\n",
        "            universal_newlines=True\n",
        "        )\n",
        "\n",
        "        # Monitoramento de progresso do ffmpeg (logs em tempo real)\n",
        "        elapsed_seconds = 0\n",
        "        last_log_minute = -1\n",
        "        while True:\n",
        "            line = process.stdout.readline()\n",
        "            if not line and process.poll() is not None:\n",
        "                break\n",
        "            if \"time=\" in line:\n",
        "                try:\n",
        "                    match = re.search(r\"time=(\\d+):(\\d+):(\\d+)\", line)\n",
        "                    if match:\n",
        "                        h, m, s = map(int, match.groups())\n",
        "                        elapsed_seconds = h * 3600 + m * 60 + s\n",
        "                        if elapsed_seconds // 60 != last_log_minute:\n",
        "                            log_progress(username, elapsed_seconds, RECORD_SECONDS)\n",
        "                            last_log_minute = elapsed_seconds // 60\n",
        "                except Exception:\n",
        "                    pass\n",
        "\n",
        "        process.wait()\n",
        "        end_time_process = time.time()\n",
        "        elapsed_seconds_proc = round(end_time_process - start_time_process)\n",
        "        log_progress(username, elapsed_seconds_proc, RECORD_SECONDS)\n",
        "\n",
        "        # Se FFmpeg falhou, registra falha para o usuário e retorna erro\n",
        "        if process.returncode != 0:\n",
        "            print(f\"❌ FFmpeg falhou para {username}. Código de saída: {process.returncode}\")\n",
        "            register_failure(username)\n",
        "            return {\n",
        "                'username': username,\n",
        "                'filename': temp_filename,\n",
        "                'filepath': filepath,\n",
        "                'upload_success': False,\n",
        "                'abyss_response': \"Gravação FFmpeg falhou\"\n",
        "            }\n",
        "\n",
        "        # Validação pelo tempo real do arquivo gravado (robusta)\n",
        "        elapsed_seconds_real = get_video_duration(filepath)\n",
        "        if elapsed_seconds_real is not None:\n",
        "            print(f\"✅ Duração real do arquivo gravado: {elapsed_seconds_real}s (ffprobe)\")\n",
        "        else:\n",
        "            print(f\"⚠️ Não foi possível aferir duração real, usando a do processo: {elapsed_seconds_proc}s\")\n",
        "            elapsed_seconds_real = elapsed_seconds_proc\n",
        "\n",
        "        if elapsed_seconds_real < RECORD_SECONDS_MIN:\n",
        "            print(f\"⏩ Duração gravada ({elapsed_seconds_real}s) menor que o mínimo ({RECORD_SECONDS_MIN}s). Arquivo descartado.\")\n",
        "            register_failure(username)\n",
        "            if os.path.exists(filepath): os.remove(filepath)\n",
        "            if poster_temp_path and os.path.exists(poster_temp_path): os.remove(poster_temp_path)\n",
        "            return {\n",
        "                'username': username,\n",
        "                'filename': temp_filename,\n",
        "                'filepath': filepath,\n",
        "                'upload_success': False,\n",
        "                'abyss_response': \"Gravação muito curta (descartada)\"\n",
        "            }\n",
        "\n",
        "        # Sucesso: limpa falhas acumuladas do usuário\n",
        "        clear_failure(username)\n",
        "        tempo_formatado = format_seconds(elapsed_seconds_real)\n",
        "        final_filename = f\"{username}_{data_str}_{horario_str}_{tempo_formatado}.mp4\"\n",
        "        final_filepath = os.path.join(TEMP_OUTPUT_FOLDER, final_filename)\n",
        "\n",
        "        try:\n",
        "            os.rename(filepath, final_filepath)\n",
        "            print(f\"✅ Arquivo renomeado para: {final_filename}\")\n",
        "            filepath_for_upload = final_filepath\n",
        "            filename_for_upload = final_filename\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Erro ao renomear arquivo {temp_filename} para {final_filename}: {e}\")\n",
        "            filepath_for_upload = filepath\n",
        "            filename_for_upload = temp_filename\n",
        "\n",
        "        # Realiza upload e atualização do banco de dados (json)\n",
        "        success, abyss_resp, slug = upload_to_abyss_and_update_json(\n",
        "            filepath_for_upload, username, elapsed_seconds_real,\n",
        "            poster_temp_path=poster_temp_path\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'username': username,\n",
        "            'filename': filename_for_upload,\n",
        "            'filepath': filepath_for_upload,\n",
        "            'upload_success': success,\n",
        "            'abyss_response': abyss_resp,\n",
        "            'slug': slug\n",
        "        }\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"❌ Erro: Comando 'ffmpeg' não encontrado. Certifique-se de que foi instalado corretamente.\")\n",
        "        register_failure(username)\n",
        "        return {\n",
        "            'username': username,\n",
        "            'filename': None,\n",
        "            'filepath': None,\n",
        "            'upload_success': False,\n",
        "            'abyss_response': \"Comando FFmpeg não encontrado\"\n",
        "        }\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Erro inesperado durante a execução do FFmpeg para {username}: {e}\")\n",
        "        register_failure(username)\n",
        "        return {\n",
        "            'username': username,\n",
        "            'filename': None,\n",
        "            'filepath': None,\n",
        "            'upload_success': False,\n",
        "            'abyss_response': f\"Erro inesperado na execução do FFmpeg: {e}\"\n",
        "        }\n",
        "    finally:\n",
        "        # Remoção segura do usuário do log de transmissões em processamento\n",
        "        try:\n",
        "            if os.path.exists(LOG_PROCESSAMENTO_PATH):\n",
        "                with open(LOG_PROCESSAMENTO_PATH, \"r\") as f:\n",
        "                    linhas = f.readlines()\n",
        "                with open(LOG_PROCESSAMENTO_PATH, \"w\") as f:\n",
        "                    for l in linhas:\n",
        "                        if l.strip() != username:\n",
        "                            f.write(l)\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Erro ao remover transmissão do log de processamento: {e}\")\n",
        "\n",
        "        # Limpeza do arquivo de vídeo pós-upload\n",
        "        if 'filepath_for_upload' in locals() and os.path.exists(filepath_for_upload):\n",
        "            try:\n",
        "                os.remove(filepath_for_upload)\n",
        "                print(f\"🗑️ Arquivo de vídeo removido do Colab: {filepath_for_upload}\")\n",
        "            except Exception as e:\n",
        "                print(f\"⚠️ Não foi possível remover o arquivo de vídeo temporário: {e}\")\n",
        "\n",
        "        # Limpeza do poster temporário\n",
        "        if poster_temp_path and os.path.exists(poster_temp_path):\n",
        "            try:\n",
        "                os.remove(poster_temp_path)\n",
        "                print(f\"🗑️ Poster temporário removido: {poster_temp_path}\")\n",
        "            except Exception as e:\n",
        "                print(f\"⚠️ Não foi possível remover o poster temporário: {e}\")\n",
        "\n",
        "# ================================================================\n",
        "# Fim da Célula 7 — Gravação, Log e Blacklist Inteligente\n",
        "# ================================================================\n",
        "\n",
        "# Observações e recomendações:\n",
        "# - Use sempre as funções globais de blacklist/falha da Célula 6 para máxima rastreabilidade.\n",
        "# - Mensagens claras e detalhadas facilitam diagnóstico, CI/CD e manutenção.\n",
        "# - Pronto para execução concorrente e integração total com pipeline modular do XCam."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "YjGKDlbIKaLs",
      "metadata": {
        "id": "YjGKDlbIKaLs"
      },
      "source": [
        "# Célula 8: Upload para Abyss.to, Atualização do rec.json, Commit Poster e Sincronização com Google Drive\n",
        "\n",
        "**Objetivo:**  \n",
        "Realizar upload do vídeo gravado para Abyss.to, registrar e atualizar todos os metadados relevantes no arquivo `rec.json` do usuário, garantir a movimentação/renomeação adequada do poster e executar o commit/push automatizado de arquivos alterados, sincronizando também com o Google Drive.  \n",
        "O processo é otimizado para processamento em lote: os arquivos modificados só são enviados quando o número atingir o limiar (`COMMIT_PUSH_THRESHOLD`), promovendo eficiência e integridade do repositório, mesmo em execução paralela.\n",
        "\n",
        "---\n",
        "\n",
        "## Estratégia e melhorias implementadas\n",
        "\n",
        "- **Commit/push em lote otimizado:**  \n",
        "  Arquivos alterados são acumulados em um buffer. O commit e push são executados automaticamente apenas quando a quantidade de arquivos atinge o threshold configurado, reduzindo conflitos e otimizando o workflow CI/CD.\n",
        "- **Sincronização automática com o Google Drive:**  \n",
        "  Sempre que `rec.json` ou poster são atualizados, uma cópia é feita para o diretório correspondente do usuário no Google Drive (se disponível), garantindo redundância, persistência e facil acesso externo aos metadados e imagens.\n",
        "- **Atomicidade e segurança em concorrência:**  \n",
        "  O acesso ao buffer de commit é protegido por lock (`threading.Lock`), assegurando integridade mesmo em processamento paralelo ou múltiplos workers.\n",
        "- **Poster sempre correto e rastreável:**  \n",
        "  O poster utilizado é sempre movido/renomeado para o local definitivo e associado ao vídeo pelo nome (`slug`). O caminho é sincronizado tanto no repositório quanto no Drive.\n",
        "- **Atualização robusta do rec.json:**  \n",
        "  O histórico do usuário é preenchido com todos os campos, incluindo poster, urlIframe, data, horário e tempo formatado. O padrão da estrutura JSON é rigorosamente seguido, facilitando a integração, análise e exportação dos dados.\n",
        "- **Limpeza automática de arquivos temporários:**  \n",
        "  Após mover, copiar e commitar os arquivos, os temporários são removidos, mantendo o ambiente Colab limpo e eficiente.\n",
        "\n",
        "---\n",
        "\n",
        "## Como funciona o fluxo principal\n",
        "\n",
        "1. **Faz upload do vídeo para Abyss.to** e recebe a confirmação (slug, url, urlIframe).\n",
        "2. **Move/renomeia o poster** para o local definitivo no repositório, associando ao vídeo pelo slug.\n",
        "3. **Atualiza ou cria `rec.json`** do usuário, preenchendo todos os metadados da gravação.\n",
        "4. **Adiciona arquivos alterados ao buffer de commit** (com lock para evitar concorrência).\n",
        "5. **Sincroniza** `rec.json` e poster no Google Drive, mantendo redundância e facilidade de acesso.\n",
        "6. **Executa commit/push automático em lote** ao atingir o limiar definido; ao final do processamento faz o commit/push dos arquivos restantes.\n",
        "7. **Limpa arquivos temporários** garantindo eficiência e organização do ambiente.\n",
        "\n",
        "---\n",
        "\n",
        "## Exemplo de uso recomendado\n",
        "\n",
        "```python\n",
        "# Após concluir o upload e gerar poster:\n",
        "upload_success, abyss_response, slug = upload_to_abyss_and_update_json(\n",
        "    filepath=arquivo_video,\n",
        "    username=\"usuario\",\n",
        "    duration_seconds=duracao,\n",
        "    poster_temp_path=caminho_poster_temp\n",
        ")\n",
        "\n",
        "# Ao final do processamento, para garantir commit dos arquivos restantes:\n",
        "commit_push_restantes()\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Segurança, rastreabilidade e integração\n",
        "\n",
        "- **Processo compatível com execução concorrente** e pipelines CI/CD.\n",
        "- **Commit/push protegido contra condições de corrida**, garantindo atomicidade dos dados no repositório.\n",
        "- **Sincronização Drive robusta**, ideal para ambientes colaborativos ou para garantir backup.\n",
        "- **Mensagens e logs claros** facilitam manutenção, auditoria e diagnóstico rápido em todo o pipeline XCam.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "iwgt8f8iKq4y",
      "metadata": {
        "id": "iwgt8f8iKq4y"
      },
      "source": [
        "# Célula 9: Processamento Automático, Paralelismo e Supervisor Dinâmico com Blacklist\n",
        "\n",
        "**Objetivo:**  \n",
        "Controlar e orquestrar todo o pipeline do notebook, garantindo processamento contínuo, paralelo, eficiente e seguro de transmissões ao vivo. O supervisor dinâmico mantém o lote sempre cheio, respeita a blacklist temporária e o log central, e integra todas as funções críticas das células anteriores, garantindo máxima resiliência e rastreabilidade.\n",
        "\n",
        "---\n",
        "\n",
        "## Estratégia e melhorias implementadas\n",
        "\n",
        "- **Paralelismo seguro e eficiente:**  \n",
        "  Utiliza múltiplos processos para gravar e processar transmissões simultaneamente, otimizando o uso de recursos e acelerando o processamento em lote.\n",
        "- **Supervisor dinâmico e lote sempre cheio:**  \n",
        "  O supervisor monitora constantemente as vagas livres no lote e preenche em tempo real com novas transmissões válidas, evitando ociosidade e maximizando a eficiência.\n",
        "- **Controle centralizado de duplicidade:**  \n",
        "  Antes de processar qualquer transmissão, consulta o log central de processamento para evitar duplicidade, mesmo em ambientes concorrentes ou paralelos.\n",
        "- **Respeito integral à blacklist temporária:**  \n",
        "  Transmissões de usuários em blacklist não são tentadas novamente durante o ciclo vigente, economizando recursos e evitando loops problemáticos.\n",
        "- **Logs robustos e detalhados:**  \n",
        "  Cada etapa do processamento é registrada com timestamp, status e contexto, facilitando auditoria, troubleshooting e acompanhamento em produção.\n",
        "- **Commit/push automático e seguro:**  \n",
        "  Ao final do ciclo (ou quando atingido o threshold), todos os arquivos alterados são enviados ao repositório, garantindo consistência e persistência dos dados.\n",
        "- **Design modular e Clean Architecture:**  \n",
        "  Funções separadas para supervisão, workers, busca, commit, log, etc., facilitando manutenção, reuso e integração com CI/CD.\n",
        "\n",
        "---\n",
        "\n",
        "## Como funciona o fluxo principal\n",
        "\n",
        "1. **Inicialização:**  \n",
        "   - Determina o modo de operação: gravação de usuários específicos ou busca automática.\n",
        "   - Calcula o tamanho do lote alvo (`LIMIT_DEFAULT` ou `API_SEARCH_LIMIT`).\n",
        "\n",
        "2. **Preenchimento do lote:**  \n",
        "   - Busca transmissões válidas (não duplicadas, não em blacklist) e lança workers para cada uma, registrando no log de processamento.\n",
        "   - Utiliza funções otimizadas de busca (`buscar_proxima_transmissao_livre` e `buscar_usuarios_especificos`), integradas à blacklist e ao log.\n",
        "\n",
        "3. **Supervisão dinâmica:**  \n",
        "   - Monitora o ciclo de vida dos workers/processos.\n",
        "   - Preenche imediatamente cada vaga livre com nova transmissão disponível, até esgotar as opções válidas.\n",
        "\n",
        "4. **Respeito à blacklist:**  \n",
        "   - Antes de qualquer gravação, verifica se o usuário está em blacklist temporária.\n",
        "   - Usuários problemáticos nunca são tentados duas vezes no mesmo ciclo.\n",
        "\n",
        "5. **Logs detalhados:**  \n",
        "   - Todas as operações geram logs padronizados com nível (INFO, WORKER, BUSCA, ERRO, etc.) e timestamp.\n",
        "\n",
        "6. **Finalização segura:**  \n",
        "   - Ao final do processamento, executa commit/push dos arquivos pendentes, garantindo persistência e integridade do repositório.\n",
        "\n",
        "---\n",
        "\n",
        "## Exemplo de uso recomendado\n",
        "\n",
        "```python\n",
        "# Função principal do notebook: dispara o supervisor dinâmico\n",
        "main()\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Segurança, rastreabilidade e integração\n",
        "\n",
        "- **Pronto para execução concorrente e ambientes CI/CD.**\n",
        "- **A lógica de blacklist e commit está totalmente integrada ao fluxo, garantindo máxima resiliência.**\n",
        "- **Logs detalhados e arquitetura modular facilitam diagnóstico, manutenção e evolução do pipeline XCam.**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5WKQV9g_LB9M",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5WKQV9g_LB9M",
        "outputId": "747787cc-deb6-489e-943d-3568142c87ec"
      },
      "outputs": [],
      "source": [
        "# ================================================================\n",
        "# Célula 9: Supervisor Dinâmico — Execução Paralela, Lote Sempre Cheio, Blacklist e Log Centralizado\n",
        "# ================================================================\n",
        "# Objetivo:\n",
        "# - Manter o lote de gravações sempre cheio, preenchendo vagas em tempo real com máxima eficiência e segurança.\n",
        "# - Garantir que usuários problemáticos (em blacklist) não sejam tentados novamente no ciclo vigente.\n",
        "# - Prevenir duplicidade consultando log central de processamento antes de iniciar qualquer gravação.\n",
        "# - Integrar-se com a lógica de blacklist, commit/push automático, limpeza de recursos e log robusto.\n",
        "# - Modularidade e clareza, pronta para integração com pipelines CI/CD, execução concorrente e ambientes colaborativos.\n",
        "# ================================================================\n",
        "\n",
        "import os\n",
        "\n",
        "LOGS_DIR = os.path.dirname(LOGS_PATH)\n",
        "LOG_PROCESSAMENTO_PATH = os.path.join(LOGS_DIR, \"xcam_processing.log\")\n",
        "\n",
        "def log_supervisor(msg, level=\"INFO\"):\n",
        "    \"\"\"\n",
        "    Log supervisor padronizado para todas as etapas do pipeline.\n",
        "    \"\"\"\n",
        "    from datetime import datetime\n",
        "    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "    print(f\"[{timestamp}] [{level}] {msg}\")\n",
        "\n",
        "def worker(username, m3u8_url, poster_url, results):\n",
        "    \"\"\"\n",
        "    Worker dedicado: grava a stream, faz upload, atualiza rec.json/poster, integra ao log.\n",
        "    \"\"\"\n",
        "    log_supervisor(f\"Iniciando gravação: {username} | URL: {m3u8_url} | Poster: {poster_url}\", \"WORKER\")\n",
        "    result = gravar_stream(username, m3u8_url, poster_url)\n",
        "    log_supervisor(\n",
        "        f\"Finalizou gravação: {username} | Sucesso: {result.get('upload_success')} | \"\n",
        "        f\"Arquivo: {result.get('filename')} | Abyss: {result.get('abyss_response')}\", \"WORKER\")\n",
        "    results.append(result)\n",
        "\n",
        "def supervisor_dinamico(usuarios_especificos=None):\n",
        "    \"\"\"\n",
        "    Supervisor dinâmico de transmissões ao vivo:\n",
        "    - Mantém o lote de gravações sempre cheio, preenchendo vagas em tempo real.\n",
        "    - Evita duplicidade e concorrência consultando log central.\n",
        "    - Respeita blacklist temporária, não processando usuários bloqueados no ciclo vigente.\n",
        "    - Integra-se com a lógica de blacklist, commit/push automático, limpeza de recursos e log robusto.\n",
        "    - Log detalhado e modular para diagnóstico, CI/CD e rastreabilidade.\n",
        "    \"\"\"\n",
        "\n",
        "    # Determina o tamanho do lote com base no modo operacional\n",
        "    pool_size = LIMIT_DEFAULT if not usuarios_especificos else API_SEARCH_LIMIT\n",
        "    running = []\n",
        "    results = Manager().list()\n",
        "    seen_usernames = set()\n",
        "\n",
        "    log_supervisor(f\"Supervisor dinâmico iniciado | Lote alvo: {pool_size} | Modo: {'específico' if usuarios_especificos else 'automático'}\")\n",
        "\n",
        "    def atualizar_seen_usernames():\n",
        "        \"\"\"\n",
        "        Atualiza o conjunto de usernames já processados diretamente do log central.\n",
        "        Garante robustez em ambientes concorrentes e previne duplicidade.\n",
        "        \"\"\"\n",
        "        if os.path.exists(LOG_PROCESSAMENTO_PATH):\n",
        "            with open(LOG_PROCESSAMENTO_PATH, \"r\") as f:\n",
        "                log_set = set([line.strip() for line in f if line.strip()])\n",
        "                seen_usernames.update(log_set)\n",
        "\n",
        "    def buscar_nova_transmissao():\n",
        "        \"\"\"\n",
        "        Busca uma nova transmissão livre para preencher o lote:\n",
        "        - Modo específico: busca em lista fornecida.\n",
        "        - Modo automático: busca próxima transmissão livre disponível.\n",
        "        - Sempre consulta blacklist e log central antes de lançar.\n",
        "        \"\"\"\n",
        "        atualizar_seen_usernames()  # Sempre atualiza antes de buscar\n",
        "        if usuarios_especificos:\n",
        "            candidatos = buscar_usuarios_especificos(usuarios_especificos)\n",
        "            for s in candidatos:\n",
        "                username = s[\"username\"]\n",
        "                if username not in seen_usernames and not is_in_blacklist(username):\n",
        "                    log_supervisor(f\"Nova transmissão encontrada (específico): {username}\", \"BUSCA\")\n",
        "                    return s\n",
        "            log_supervisor(\"Nenhuma transmissão específica livre encontrada (todos em blacklist/log ou offline).\", \"BUSCA\")\n",
        "            return None\n",
        "        else:\n",
        "            # Busca otimizada: tenta até 10 vezes buscar próxima transmissão livre\n",
        "            for tentativa in range(1, 11):\n",
        "                log_supervisor(f\"Buscando próxima transmissão livre: tentativa {tentativa}\", \"BUSCA\")\n",
        "                stream = buscar_proxima_transmissao_livre()\n",
        "                if stream:\n",
        "                    username = stream[\"username\"]\n",
        "                    if username not in seen_usernames and not is_in_blacklist(username):\n",
        "                        log_supervisor(f\"Nova transmissão encontrada: {username}\", \"BUSCA\")\n",
        "                        return stream\n",
        "                    else:\n",
        "                        log_supervisor(f\"Usuário {username} já processado ou em blacklist, ignorando.\", \"BUSCA\")\n",
        "            log_supervisor(\"Nenhuma transmissão livre encontrada após tentativas (todos em blacklist/log ou offline).\", \"BUSCA\")\n",
        "            return None\n",
        "\n",
        "    # ========== Fase 1: Preenchimento do lote inicial ==========\n",
        "    log_supervisor(f\"Preenchendo lote inicial com até {pool_size} transmissões...\", \"STARTUP\")\n",
        "    tentativas = 0\n",
        "    max_tentativas = 100\n",
        "    while len(running) < pool_size and tentativas < max_tentativas:\n",
        "        stream = buscar_nova_transmissao()\n",
        "        if not stream:\n",
        "            log_supervisor(\"Fim das transmissões disponíveis para preencher lote inicial.\", \"STARTUP\")\n",
        "            break\n",
        "        username = stream[\"username\"]\n",
        "        seen_usernames.add(username)\n",
        "        # Escreve no log imediatamente para evitar duplicidade em concorrência antes do .start()\n",
        "        with open(LOG_PROCESSAMENTO_PATH, \"a\") as f:\n",
        "            f.write(f\"{username}\\n\")\n",
        "        log_supervisor(f\"Lançando processo para: {username} | {len(running)+1}/{pool_size}\", \"STARTUP\")\n",
        "        p = Process(target=worker, args=(username, stream[\"src\"], stream.get(\"poster\"), results))\n",
        "        running.append(p)\n",
        "        p.start()\n",
        "        tentativas += 1\n",
        "\n",
        "    log_supervisor(f\"Lote inicial lançado com {len(running)} transmissões.\", \"STARTUP\")\n",
        "\n",
        "    # ========== Fase 2: Loop dinâmico de preenchimento contínuo ==========\n",
        "    while True:\n",
        "        antes = len(running)\n",
        "        running = [p for p in running if p.is_alive()]\n",
        "        depois = len(running)\n",
        "        if antes != depois:\n",
        "            log_supervisor(f\"{antes-depois} gravações finalizaram. Vagas livres: {pool_size-len(running)}\", \"LOOP\")\n",
        "        vagas_livres = pool_size - len(running)\n",
        "        if vagas_livres > 0:\n",
        "            for _ in range(vagas_livres):\n",
        "                stream = buscar_nova_transmissao()\n",
        "                if not stream:\n",
        "                    log_supervisor(\"Não há mais transmissões para preencher as vagas livres.\", \"LOOP\")\n",
        "                    break\n",
        "                username = stream[\"username\"]\n",
        "                seen_usernames.add(username)\n",
        "                with open(LOG_PROCESSAMENTO_PATH, \"a\") as f:\n",
        "                    f.write(f\"{username}\\n\")\n",
        "                log_supervisor(f\"Lançando nova gravação: {username} | Vaga preenchida {len(running)+1}/{pool_size}\", \"LOOP\")\n",
        "                p = Process(target=worker, args=(username, stream[\"src\"], stream.get(\"poster\"), results))\n",
        "                running.append(p)\n",
        "                p.start()\n",
        "        if not running:\n",
        "            log_supervisor(\"Todas as transmissões possíveis já foram processadas!\", \"END\")\n",
        "            break\n",
        "        log_supervisor(\n",
        "            f\"Transmissões ativas: {len(running)} | Total processadas: {len(seen_usernames)} | Buffer de resultados: {len(results)}\",\n",
        "            \"STATUS\"\n",
        "        )\n",
        "        time.sleep(2)\n",
        "\n",
        "    # ========== Fase 3: Commit/push final e encerramento ==========\n",
        "    log_supervisor(f\"Processamento dinâmico concluído! Total de transmissões gravadas/processadas: {len(results)}\", \"RESUMO\")\n",
        "    try:\n",
        "        log_supervisor(\"Realizando commit/push final dos arquivos pendentes...\", \"FINALIZACAO\")\n",
        "        commit_push_restantes()\n",
        "        log_supervisor(\"Commit/push final executado com sucesso.\", \"FINALIZACAO\")\n",
        "    except Exception as e:\n",
        "        log_supervisor(f\"Falha ao tentar commit/push final dos arquivos restantes: {e}\", \"ERRO\")\n",
        "    log_supervisor(\"Supervisor dinâmico finalizado.\", \"END\")\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Função principal: inicia o notebook perguntando se o usuário quer gravar transmissões específicas ou automáticas.\n",
        "    Dispara o supervisor dinâmico na modalidade selecionada.\n",
        "    \"\"\"\n",
        "    usuarios_especificos = perguntar_transmissoes_especificas()\n",
        "    log_supervisor(\"Iniciando busca e gravação de streams (supervisor dinâmico)...\", \"MAIN\")\n",
        "    supervisor_dinamico(usuarios_especificos=usuarios_especificos)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    try:\n",
        "        if 'google.colab' in str(get_ipython()):\n",
        "            main()\n",
        "        else:\n",
        "            print(\"Execute main() manualmente se desejar rodar fora do Colab.\")\n",
        "    except NameError:\n",
        "        print(\"Não está rodando em Colab/IPython. Execute main() se desejar.\")\n",
        "\n",
        "# ================================================================\n",
        "# FIM DA CÉLULA 9 — Supervisor Dinâmico, Lote Cheio e Blacklist\n",
        "# ================================================================\n",
        "\n",
        "# Observações e recomendações:\n",
        "# - Toda lógica de blacklist e commit está integrada para máxima resiliência e rastreabilidade.\n",
        "# - O log central de processamento é a fonte de verdade para sincronização entre workers/processos.\n",
        "# - Modularidade, logs claros e tratamento de erro garantem manutenção e evolução seguras."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "cell_execution_strategy": "setup",
      "collapsed_sections": [
        "c9hve1ySGVAs"
      ],
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
