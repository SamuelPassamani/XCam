{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SamuelPassamani/XCam/blob/main/xcam-colab/XCam_REC_V2.7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# C√©lula 1: Configura√ß√µes Auxiliares e Par√¢metros Gerais\n",
        "\n",
        "**Objetivo:**\n",
        "Esta c√©lula inicializa vari√°veis globais para ajuste r√°pido do comportamento do notebook, como:\n",
        "\n",
        "*   Quantidade de transmiss√µes por p√°gina (LIMIT_DEFAULT)\n",
        "*   P√°gina inicial a ser buscada (PAGE_DEFAULT)\n",
        "*   Tempo m√°ximo de grava√ß√£o de cada v√≠deo (RECORD_SECONDS)\n",
        "*   Tempo m√≠nimo exigido para considerar o v√≠deo v√°lido (RECORD_SECONDS_MIN)\n",
        "*   Limite de busca ao procurar usu√°rios espec√≠ficos (API_SEARCH_LIMIT)\n",
        "*   **Novo:** Quantidade de transmiss√µes processadas at√© realizar commit/push (COMMIT_PUSH_THRESHOLD)\n",
        "\n",
        "**Interatividade:**\n",
        "Inclui a fun√ß√£o perguntar_transmissoes_especificas() que pergunta ao usu√°rio se deseja gravar transmiss√µes de usu√°rios espec√≠ficos. Caso sim, solicita os nomes e retorna uma lista.\n",
        "\n",
        "**Como funciona:**\n",
        "Antes do processamento, voc√™ pode ajustar facilmente qualquer par√¢metro. O notebook perguntar√° se voc√™ quer gravar transmiss√µes de usu√°rios espec√≠ficos e, se quiser, pedir√° os nomes (ex: \"userNovo234, jovemPT\")"
      ],
      "metadata": {
        "id": "c9hve1ySGVAs"
      },
      "id": "c9hve1ySGVAs"
    },
    {
      "cell_type": "code",
      "source": [
        "# C√©lula 1: Configura√ß√µes Auxiliares e Par√¢metros Gerais\n",
        "# ------------------------------------------------------\n",
        "# Ajuste facilmente os principais par√¢metros do sistema e escolha se deseja gravar transmiss√µes espec√≠ficas.\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "\n",
        "# Par√¢metros globais edit√°veis\n",
        "LIMIT_DEFAULT = 5            # Quantidade padr√£o de transmiss√µes por p√°gina\n",
        "PAGE_DEFAULT = 1              # P√°gina inicial\n",
        "RECORD_SECONDS = 420         # Tempo m√°ximo de grava√ß√£o por v√≠deo (segundos)\n",
        "RECORD_SECONDS_MIN = 300      # Tempo m√≠nimo de grava√ß√£o exigido para upload (segundos)\n",
        "API_SEARCH_LIMIT = 1000       # Limite m√°ximo para busca de usu√°rios espec√≠ficos\n",
        "COMMIT_PUSH_THRESHOLD = 10   # Apenas faz commit/push ap√≥s processar/gravar 10 transmiss√µes\n",
        "\n",
        "globals().update({\n",
        "    'LIMIT_DEFAULT': LIMIT_DEFAULT,\n",
        "    'PAGE_DEFAULT': PAGE_DEFAULT,\n",
        "    'RECORD_SECONDS': RECORD_SECONDS,\n",
        "    'RECORD_SECONDS_MIN': RECORD_SECONDS_MIN,\n",
        "    'API_SEARCH_LIMIT': API_SEARCH_LIMIT,\n",
        "    'COMMIT_PUSH_THRESHOLD': COMMIT_PUSH_THRESHOLD\n",
        "})\n",
        "\n",
        "def perguntar_transmissoes_especificas():\n",
        "    resp = input('Deseja gravar alguma transmiss√£o espec√≠fica? (sim/n√£o): ').strip().lower()\n",
        "    if resp.startswith('s'):\n",
        "        usuarios = input('Informe o(s) nome(s) de usu√°rio, separados por v√≠rgula (ex: userNovo234, jovemPT): ')\n",
        "        usuarios_lista = [u.strip() for u in usuarios.split(',') if u.strip()]\n",
        "        return usuarios_lista\n",
        "    return []"
      ],
      "metadata": {
        "id": "j5pPh353GLMD"
      },
      "id": "j5pPh353GLMD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# C√©lula 2: Instala√ß√£o do ffmpeg\n",
        "\n",
        "**Objetivo:**\n",
        "Garante que o ffmpeg esteja instalado no ambiente do Google Colab. O ffmpeg √© fundamental para gravar os v√≠deos das transmiss√µes.\n",
        "\n",
        "**Como funciona:**\n",
        "Executa comandos de instala√ß√£o do ffmpeg, necess√°rios para o funcionamento correto das pr√≥ximas etapas."
      ],
      "metadata": {
        "id": "WXs0o6OPHXbi"
      },
      "id": "WXs0o6OPHXbi"
    },
    {
      "cell_type": "code",
      "source": [
        "# C√©lula 2: Instala√ß√£o do ffmpeg\n",
        "# ------------------------------\n",
        "# Garante que o ffmpeg est√° instalado no ambiente Colab.\n",
        "\n",
        "!apt-get update -y\n",
        "!apt-get install -y ffmpeg"
      ],
      "metadata": {
        "id": "vIODn0c2HiHz"
      },
      "id": "vIODn0c2HiHz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# C√©lula 3: Imports Essenciais e Fun√ß√µes Utilit√°rias\n",
        "\n",
        "**Objetivo:**\n",
        "Importa todas as bibliotecas do Python necess√°rias (como requests, multiprocessing, datetime, etc.) e define fun√ß√µes utilit√°rias para:\n",
        "\n",
        "*   Formatar o tempo de grava√ß√£o (`format_seconds`)\n",
        "*   Exibir logs de progresso (`log_progress`)\n",
        "*   Baixar e salvar a imagem de poster de cada transmiss√£o (`download_and_save_poster`)\n",
        "*   Gerar poster automaticamente com o ffmpeg a partir da transmiss√£o ao vivo caso o poster esteja ausente ou inv√°lido (`generate_poster_with_ffmpeg`)\n",
        "*   Validar se o poster √© v√°lido (`is_poster_valid`)\n",
        "*   Garantir a cria√ß√£o do arquivo de log tempor√°rio para controlar transmiss√µes atualmente em processamento\n",
        "\n",
        "**Como funciona:**\n",
        "Essas fun√ß√µes s√£o usadas em v√°rias partes do notebook para manipular tempos, apresentar informa√ß√µes mais amig√°veis, garantir que os posters das transmiss√µes estejam sempre presentes (baixando da API ou gerando com ffmpeg se necess√°rio) e manter o controle das transmiss√µes em processamento por meio do arquivo de log tempor√°rio."
      ],
      "metadata": {
        "id": "90qvXC0rHtWb"
      },
      "id": "90qvXC0rHtWb"
    },
    {
      "cell_type": "code",
      "source": [
        "# C√©lula 3: Imports essenciais e utilit√°rios\n",
        "# ------------------------------------------\n",
        "# Importa√ß√£o de bibliotecas e fun√ß√µes auxiliares de formata√ß√£o e download.\n",
        "# Tamb√©m garante a cria√ß√£o do arquivo de log tempor√°rio para controle de transmiss√µes em processamento.\n",
        "# ADI√á√ÉO: Fun√ß√£o para gerar poster com ffmpeg caso n√£o haja poster v√°lido na API.\n",
        "# CORRE√á√ÉO: Antes de rodar ffmpeg, testa se a URL do stream est√° acess√≠vel (HEAD).\n",
        "# Se n√£o estiver, retorna None e faz o tratamento do erro de stream offline.\n",
        "\n",
        "import os\n",
        "import requests\n",
        "import multiprocessing\n",
        "from datetime import datetime\n",
        "import json\n",
        "import time\n",
        "import subprocess\n",
        "import math\n",
        "import re\n",
        "\n",
        "from IPython import get_ipython\n",
        "from IPython.display import display\n",
        "\n",
        "# Caminho do arquivo de log tempor√°rio\n",
        "LOG_PROCESSAMENTO_PATH = \"/content/xcam_processing.log\"\n",
        "\n",
        "# Garante que o arquivo de log tempor√°rio exista ao iniciar o notebook\n",
        "if not os.path.exists(LOG_PROCESSAMENTO_PATH):\n",
        "    with open(LOG_PROCESSAMENTO_PATH, \"w\") as f:\n",
        "        f.write(\"\")  # Cria arquivo vazio\n",
        "\n",
        "def format_seconds(seconds):\n",
        "    total_seconds = int(seconds)\n",
        "    hours = total_seconds // 3600\n",
        "    minutes = (total_seconds % 3600) // 60\n",
        "    seconds = total_seconds % 60\n",
        "    parts = []\n",
        "    if hours > 0: parts.append(f\"{hours}h\")\n",
        "    if minutes > 0 or (hours == 0 and seconds > 0): parts.append(f\"{minutes}m\")\n",
        "    if seconds > 0 or total_seconds == 0: parts.append(f\"{seconds}s\")\n",
        "    return \"\".join(parts) if parts else \"0s\"\n",
        "\n",
        "def log_progress(username, elapsed_seconds, total_seconds):\n",
        "    percent = min((elapsed_seconds / total_seconds) * 100, 100)\n",
        "    tempo = format_seconds(elapsed_seconds)\n",
        "    minutos_gravados = math.floor(elapsed_seconds / 60)\n",
        "    minutos_restantes = max(0, math.ceil((total_seconds - elapsed_seconds) / 60))\n",
        "    print(f\"‚è±Ô∏è [{username}] Gravados: {minutos_gravados} min | Restantes: {minutos_restantes} min | Tempo total: {tempo} ‚Äî üìä {percent:.1f}% conclu√≠do\")\n",
        "\n",
        "def download_and_save_poster(poster_url, username, temp_folder):\n",
        "    \"\"\"\n",
        "    Baixa e salva o poster a partir de uma URL HTTP/HTTPS.\n",
        "    Ou, se receber um caminho local existente, apenas retorna esse caminho.\n",
        "    Retorna o caminho do arquivo salvo, ou None em caso de erro.\n",
        "    \"\"\"\n",
        "    # Se for um caminho local j√° existente, apenas retorna\n",
        "    if os.path.exists(poster_url):\n",
        "        return poster_url\n",
        "    # Se for uma URL HTTP/HTTPS, faz o download normalmente\n",
        "    if isinstance(poster_url, str) and (poster_url.startswith(\"http://\") or poster_url.startswith(\"https://\")):\n",
        "        try:\n",
        "            response = requests.get(poster_url, timeout=15)\n",
        "            response.raise_for_status()\n",
        "            ext = os.path.splitext(poster_url)[1].lower()\n",
        "            if ext not in [\".jpg\", \".jpeg\", \".png\"]:\n",
        "                ext = \".jpg\"\n",
        "            poster_temp_path = os.path.join(temp_folder, f\"{username}_poster_temp{ext}\")\n",
        "            with open(poster_temp_path, \"wb\") as f:\n",
        "                f.write(response.content)\n",
        "            print(f\"üñºÔ∏è Poster baixado em: {poster_temp_path}\")\n",
        "            return poster_temp_path\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Erro ao baixar poster {poster_url}: {e}\")\n",
        "            return None\n",
        "    else:\n",
        "        print(f\"‚ùå poster_url inv√°lido ou n√£o encontrado: {poster_url}\")\n",
        "        return None\n",
        "\n",
        "def generate_poster_with_ffmpeg(m3u8_url, username, temp_folder, frame_time=7, timeout=20):\n",
        "    \"\"\"\n",
        "    Gera um poster (screenshot) usando ffmpeg a partir da URL .m3u8 da transmiss√£o.\n",
        "    Retorna o caminho do arquivo gerado ou None em caso de erro.\n",
        "    frame_time: segundo do v√≠deo em que o poster ser√° capturado (padr√£o: 7s para evitar frame preto).\n",
        "    Antes de rodar o ffmpeg, faz uma checagem HTTP HEAD para saber se a URL do stream est√° ativa.\n",
        "    \"\"\"\n",
        "    # Checa se a URL est√° acess√≠vel antes de rodar ffmpeg\n",
        "    try:\n",
        "        head_resp = requests.head(m3u8_url, timeout=5)\n",
        "        if not head_resp.ok:\n",
        "            print(f\"‚ö†Ô∏è Stream offline ou n√£o dispon√≠vel para {username} (status {head_resp.status_code})\")\n",
        "            return None\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Erro de conex√£o ao acessar stream de {username}: {e}\")\n",
        "        return None\n",
        "\n",
        "    poster_ffmpeg_path = os.path.join(temp_folder, f\"{username}_poster_ffmpeg.jpg\")\n",
        "    # Comando ffmpeg: captura 1 frame ap√≥s frame_time segundos de v√≠deo\n",
        "    command = [\n",
        "        \"ffmpeg\",\n",
        "        \"-y\",  # sobrescreve arquivo se j√° existir\n",
        "        \"-ss\", str(frame_time),  # avan√ßa para frame_time segundos antes de capturar\n",
        "        \"-i\", m3u8_url,\n",
        "        \"-vframes\", \"1\",\n",
        "        \"-q:v\", \"2\",  # qualidade alta\n",
        "        poster_ffmpeg_path\n",
        "    ]\n",
        "    try:\n",
        "        print(f\"üé¨ Gerando poster com ffmpeg para {username} no segundo {frame_time}...\")\n",
        "        # subprocess.run com timeout para evitar travamento caso a URL esteja offline/inv√°lida\n",
        "        result = subprocess.run(\n",
        "            command,\n",
        "            stdout=subprocess.PIPE,\n",
        "            stderr=subprocess.PIPE,\n",
        "            timeout=timeout\n",
        "        )\n",
        "        if result.returncode == 0 and os.path.exists(poster_ffmpeg_path):\n",
        "            print(f\"üñºÔ∏è Poster gerado via ffmpeg: {poster_ffmpeg_path}\")\n",
        "            return poster_ffmpeg_path\n",
        "        else:\n",
        "            print(f\"‚ùå ffmpeg n√£o conseguiu gerar poster para {username}. Sa√≠da: {result.stderr.decode(errors='ignore')}\")\n",
        "            return None\n",
        "    except subprocess.TimeoutExpired:\n",
        "        print(f\"‚è∞ Tempo excedido ao tentar gerar poster para {username} via ffmpeg.\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Erro inesperado ao gerar poster via ffmpeg: {e}\")\n",
        "        return None\n",
        "\n",
        "def is_poster_valid(poster_path):\n",
        "    \"\"\"\n",
        "    Verifica se o poster existe e n√£o est√° vazio.\n",
        "    \"\"\"\n",
        "    return poster_path and os.path.exists(poster_path) and os.path.getsize(poster_path) > 0"
      ],
      "metadata": {
        "id": "hOetz0nGICkz"
      },
      "id": "hOetz0nGICkz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# C√©lula 4: Clonagem do Reposit√≥rio GitHub para o Colab\n",
        "\n",
        "**Objetivo:**\n",
        "Clona o reposit√≥rio do GitHub para o ambiente local do Colab, garantindo que o ambiente sempre esteja atualizado e pronto para armazenar os arquivos gerados.\n",
        "\n",
        "**Como funciona:**\n",
        "Remove qualquer reposit√≥rio anterior para evitar conflitos, clona o novo, prepara pastas tempor√°rias e define a URL de upload para o Abyss.to."
      ],
      "metadata": {
        "id": "hpRIMtyFIY0q"
      },
      "id": "hpRIMtyFIY0q"
    },
    {
      "cell_type": "code",
      "source": [
        "# C√©lula 4: Clonagem do reposit√≥rio GitHub para o Colab e para o Drive\n",
        "# --------------------------------------------------------------------\n",
        "# Clona o reposit√≥rio para o ambiente Colab E tamb√©m para o Google Drive (se montado),\n",
        "# garantindo ambiente limpo, persist√™ncia e sincroniza√ß√£o para futuras execu√ß√µes.\n",
        "\n",
        "GITHUB_USER = \"SamuelPassamani\"\n",
        "GITHUB_REPO = \"XCam\"\n",
        "GITHUB_BRANCH = \"main\"\n",
        "GITHUB_TOKEN = \"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\"\n",
        "\n",
        "repo_url = f\"https://{GITHUB_USER}:{GITHUB_TOKEN}@github.com/{GITHUB_USER}/{GITHUB_REPO}.git\"\n",
        "\n",
        "# Clona para o ambiente Colab\n",
        "!rm -rf {GITHUB_REPO}\n",
        "!git clone -b {GITHUB_BRANCH} {repo_url}\n",
        "\n",
        "# Caminhos locais\n",
        "TEMP_OUTPUT_FOLDER = \"/content/temp_recordings\"\n",
        "os.makedirs(TEMP_OUTPUT_FOLDER, exist_ok=True)\n",
        "BASE_REPO_FOLDER = f\"/content/{GITHUB_REPO}\"\n",
        "\n",
        "# Caminho para o Drive (se montado)\n",
        "DRIVE_MOUNT = \"/content/drive/MyDrive\"\n",
        "DRIVE_REPO_FOLDER = f\"{DRIVE_MOUNT}/{GITHUB_REPO}\"\n",
        "\n",
        "# Clona tamb√©m para o Drive, se estiver montado\n",
        "import os\n",
        "if os.path.exists(DRIVE_MOUNT):\n",
        "    # Remove reposit√≥rio antigo no Drive (se existir), depois clona\n",
        "    !rm -rf \"{DRIVE_REPO_FOLDER}\"\n",
        "    !git clone -b {GITHUB_BRANCH} {repo_url} \"{DRIVE_REPO_FOLDER}\"\n",
        "    print(f\"‚úÖ Reposit√≥rio tamb√©m clonado no Drive: {DRIVE_REPO_FOLDER}\")\n",
        "else:\n",
        "    print(f\"‚ö†Ô∏è Google Drive n√£o est√° montado em {DRIVE_MOUNT}.\")\n",
        "\n",
        "ABYSS_UPLOAD_URL = 'http://up.hydrax.net/0128263f78f0b426d617bb61c2a8ff43'"
      ],
      "metadata": {
        "id": "Uof_0QCrIlf7"
      },
      "id": "Uof_0QCrIlf7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# C√©lula 5: Commit e Push Autom√°ticos (rec.json e poster)\n",
        "\n",
        "---\n",
        "\n",
        "**Objetivo:**\n",
        "Define a fun√ß√£o git_commit_and_push() para garantir que apenas arquivos importantes (JSON de grava√ß√£o e posters de imagem) sejam adicionados, commitados e enviados ao reposit√≥rio.\n",
        "\n",
        "**Como funciona:**\n",
        "Configura o git, adiciona o arquivo desejado, faz commit e push para o reposit√≥rio remoto."
      ],
      "metadata": {
        "id": "M5iL_9BoIoj7"
      },
      "id": "M5iL_9BoIoj7"
    },
    {
      "cell_type": "code",
      "source": [
        "# C√©lula 5: Commit e Push autom√°ticos (rec.json e poster)\n",
        "# -------------------------------------------------------\n",
        "# Esta fun√ß√£o agora aceita tanto um caminho √∫nico (str) quanto uma lista de caminhos (list) para realizar commit e push.\n",
        "# O comportamento original para um √∫nico arquivo √© preservado, mas agora √© poss√≠vel realizar commit em lote,\n",
        "# conforme necess√°rio para a estrat√©gia de batch commit com threshold.\n",
        "\n",
        "def git_commit_and_push(file_paths, commit_message=\"Atualiza rec.json\"):\n",
        "    \"\"\"\n",
        "    Realiza git add, commit e push dos arquivos especificados.\n",
        "    - file_paths pode ser uma string (arquivo √∫nico) ou uma lista de arquivos.\n",
        "    - commit_message √© a mensagem de commit utilizada.\n",
        "    \"\"\"\n",
        "    repo_dir = f\"/content/{GITHUB_REPO}\"\n",
        "    os.chdir(repo_dir)\n",
        "    subprocess.run([\"git\", \"config\", \"user.email\", \"contato@aserio.work\"])\n",
        "    subprocess.run([\"git\", \"config\", \"user.name\", \"SamuelPassamani\"])\n",
        "\n",
        "    # Permite tanto um arquivo √∫nico quanto uma lista de arquivos\n",
        "    if isinstance(file_paths, str):\n",
        "        file_paths = [file_paths]\n",
        "\n",
        "    # Adiciona cada arquivo ao staging do git\n",
        "    for file_path in file_paths:\n",
        "        subprocess.run([\"git\", \"add\", file_path])\n",
        "\n",
        "    # Realiza o commit (permite commit vazio por seguran√ßa)\n",
        "    subprocess.run([\"git\", \"commit\", \"-m\", commit_message, \"--allow-empty\"], check=False)\n",
        "\n",
        "    # Push para o reposit√≥rio remoto usando autentica√ß√£o via token\n",
        "    subprocess.run([\n",
        "        \"git\", \"push\", f\"https://{GITHUB_USER}:{GITHUB_TOKEN}@github.com/{GITHUB_USER}/{GITHUB_REPO}.git\"\n",
        "    ])"
      ],
      "metadata": {
        "id": "1aQn1G6yI6Gz"
      },
      "id": "1aQn1G6yI6Gz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# C√©lula 6: Busca de Transmiss√µes na API XCam, com Fallback via liveInfo\n",
        "\n",
        "**Objetivo:**\n",
        "Busca as transmiss√µes ativas na API principal da XCam. Se alguma transmiss√£o n√£o retornar o link da stream (src), faz um fallback via a API /liveInfo do usu√°rio para tentar obter o link direto.  \n",
        "Agora, al√©m de garantir que o lote retornado esteja sempre completo at√© LIMIT_DEFAULT, evitar duplicidade consultando o log de transmiss√µes em processamento e controlar a unicidade das transmiss√µes processadas, tamb√©m assegura que cada transmiss√£o tenha um poster v√°lido:  \n",
        "Se o poster n√£o estiver presente, for nulo ou inv√°lido, o notebook gera automaticamente uma imagem de poster usando o ffmpeg a partir da URL da transmiss√£o ao vivo (.m3u8).\n",
        "\n",
        "**Como funciona:**\n",
        "\n",
        "*   Para cada transmiss√£o encontrada, retorna um dicion√°rio com username, src (endere√ßo do stream) e poster (imagem local gerada ou baixada).\n",
        "*   Se for solicitado buscar usu√°rios espec√≠ficos, s√≥ retorna esses.\n",
        "*   Caso algum usu√°rio n√£o tenha src na API principal, faz nova chamada √† API liveInfo para tentar encontrar o link da transmiss√£o.\n",
        "*   Caso o poster esteja ausente, vazio, nulo ou inv√°lido (tanto na API principal quanto na liveInfo), o notebook gera e salva automaticamente uma imagem de poster via ffmpeg no momento do processamento.\n",
        "*   Antes de adicionar uma transmiss√£o ao lote, verifica se ela j√° est√° em processamento (consultando o log tempor√°rio) e se n√£o h√° duplicidade na sele√ß√£o.\n",
        "*   O lote final respeita sempre o LIMIT_DEFAULT de transmiss√µes v√°lidas, preenchendo com fallback se necess√°rio."
      ],
      "metadata": {
        "id": "BZ4c3Uk1I7AK"
      },
      "id": "BZ4c3Uk1I7AK"
    },
    {
      "cell_type": "code",
      "source": [
        "# C√©lula 6: Busca de transmiss√µes na API XCam, com fallback via liveInfo\n",
        "# ----------------------------------------------------------------------\n",
        "# Ajuste: O par√¢metro 'limit' agora √© sempre respeitado, sem multiplica√ß√£o nem excesso.\n",
        "# O corte do n√∫mero de transmiss√µes v√°lidas ocorre ao final, garantindo que nunca ultrapassa 'limit'.\n",
        "# N√£o altera nenhuma outra l√≥gica al√©m do solicitado.\n",
        "\n",
        "def get_broadcasts(limit=LIMIT_DEFAULT, page=PAGE_DEFAULT, usuarios_especificos=None, temp_folder=\"/content\"):\n",
        "    \"\"\"\n",
        "    Busca transmiss√µes ao vivo via API principal da XCam.\n",
        "    Se usuarios_especificos for fornecido (lista), retorna apenas essas transmiss√µes.\n",
        "    Faz fallback via liveInfo para transmiss√µes sem src.\n",
        "    Garante poster v√°lido: se ausente, gera com ffmpeg a partir do src/m3u8.\n",
        "    Mant√©m o lote at√© LIMIT_DEFAULT, evita duplicidade e checa log de transmiss√µes em processamento.\n",
        "    \"\"\"\n",
        "    # Caminho do arquivo de log tempor√°rio\n",
        "    LOG_PROCESSAMENTO_PATH = \"/content/xcam_processing.log\"\n",
        "\n",
        "    # Carrega transmiss√µes j√° em processamento para evitar duplicidade\n",
        "    transmissao_em_proc = set()\n",
        "    if os.path.exists(LOG_PROCESSAMENTO_PATH):\n",
        "        with open(LOG_PROCESSAMENTO_PATH, \"r\") as f:\n",
        "            transmissao_em_proc = set([line.strip() for line in f if line.strip()])\n",
        "\n",
        "    # Busca principal de transmiss√µes\n",
        "    # AJUSTE: Sempre usa 'limit' diretamente, sem multiplica√ß√£o\n",
        "    api_url_main = f\"https://api.xcam.gay/?limit={API_SEARCH_LIMIT if usuarios_especificos else limit}&page={page}\"\n",
        "    print(f\"üåê Acessando API principal: {api_url_main}\")\n",
        "\n",
        "    streams_from_main = []\n",
        "    streams_without_preview = []\n",
        "\n",
        "    try:\n",
        "        response_main = requests.get(api_url_main)\n",
        "        response_main.raise_for_status()\n",
        "        data_main = response_main.json()\n",
        "        broadcasts_data = data_main.get(\"broadcasts\")\n",
        "        if not broadcasts_data:\n",
        "            print(\"‚ö†Ô∏è Chave 'broadcasts' n√£o encontrada na resposta da API principal.\")\n",
        "            return []\n",
        "        items = broadcasts_data.get(\"items\")\n",
        "        if not isinstance(items, list):\n",
        "            print(f\"‚ö†Ô∏è Chave 'items' n√£o encontrada ou n√£o √© uma lista em 'broadcasts'.\")\n",
        "            return []\n",
        "\n",
        "        # Percorre todas as transmiss√µes retornadas pela API principal\n",
        "        for item in items:\n",
        "            preview = item.get(\"preview\") or {}\n",
        "            src = preview.get(\"src\")\n",
        "            poster = preview.get(\"poster\")\n",
        "            username = item.get(\"username\", \"desconhecido\")\n",
        "            # Evita duplicidade: s√≥ adiciona se n√£o estiver em processamento\n",
        "            if username in transmissao_em_proc:\n",
        "                continue\n",
        "            if src:\n",
        "                if (not usuarios_especificos) or (username in usuarios_especificos):\n",
        "                    # Garante poster v√°lido: se ausente, gera com ffmpeg\n",
        "                    poster_path = None\n",
        "                    if poster and isinstance(poster, str) and poster.strip():\n",
        "                        poster_path = download_and_save_poster(poster, username, temp_folder)\n",
        "                    if not is_poster_valid(poster_path):\n",
        "                        poster_path = generate_poster_with_ffmpeg(src, username, temp_folder)\n",
        "                    streams_from_main.append({\n",
        "                        \"username\": username,\n",
        "                        \"src\": src,\n",
        "                        \"poster\": poster_path\n",
        "                    })\n",
        "            else:\n",
        "                # Caso n√£o tenha src, adiciona para tentar fallback via liveInfo\n",
        "                if (not usuarios_especificos) or (username in usuarios_especificos):\n",
        "                    streams_without_preview.append({\"username\": username})\n",
        "\n",
        "        print(f\"‚úÖ {len(streams_from_main)} transmiss√µes com URL na API principal (p√°gina {page}).\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Erro ao acessar API principal: {e}\")\n",
        "        return []\n",
        "\n",
        "    # Fallback: busca via liveInfo para streams sem URL na API principal\n",
        "    streams_from_liveinfo = []\n",
        "    if streams_without_preview:\n",
        "        print(f\"üîÅ Buscando liveInfo para {len(streams_without_preview)} streams sem URL na API principal...\")\n",
        "        for stream_info in streams_without_preview:\n",
        "            username = stream_info[\"username\"]\n",
        "            if username in transmissao_em_proc:\n",
        "                continue\n",
        "            api_url_liveinfo = f\"https://api.xcam.gay/user/{username}/liveInfo\"\n",
        "            try:\n",
        "                response_liveinfo = requests.get(api_url_liveinfo)\n",
        "                response_liveinfo.raise_for_status()\n",
        "                data_liveinfo = response_liveinfo.json()\n",
        "                m3u8_url = data_liveinfo.get(\"cdnURL\") or data_liveinfo.get(\"edgeURL\")\n",
        "                # liveInfo n√£o retorna poster\n",
        "                poster_path = None\n",
        "                if m3u8_url:\n",
        "                    # Gera poster via ffmpeg pois liveInfo n√£o retorna poster\n",
        "                    poster_path = generate_poster_with_ffmpeg(m3u8_url, username, temp_folder)\n",
        "                    streams_from_liveinfo.append({\n",
        "                        \"username\": username,\n",
        "                        \"src\": m3u8_url,\n",
        "                        \"poster\": poster_path\n",
        "                    })\n",
        "                else:\n",
        "                    # Log detalhado para f√°cil debug de casos sem m3u8_url\n",
        "                    print(f\"‚ö†Ô∏è liveInfo de {username} n√£o retornou cdnURL/edgeURL (usu√°rio possivelmente offline).\")\n",
        "            except Exception as ex:\n",
        "                print(f\"‚ùå Erro ao buscar liveInfo para {username}: {ex}\")\n",
        "            time.sleep(0.5)\n",
        "\n",
        "    # Junta, evita duplicidade de usu√°rio e respeita 'limit' FINAL\n",
        "    final_streams_list = []\n",
        "    seen_usernames = set()\n",
        "    for stream in streams_from_main + streams_from_liveinfo:\n",
        "        username = stream[\"username\"]\n",
        "        if username in seen_usernames or username in transmissao_em_proc:\n",
        "            continue\n",
        "        final_streams_list.append(stream)\n",
        "        seen_usernames.add(username)\n",
        "        if len(final_streams_list) >= limit:\n",
        "            break\n",
        "\n",
        "    print(f\"üîé P√°gina {page}: {len(final_streams_list)} streams v√°lidas ap√≥s fallback (respeitando limit={limit}).\")\n",
        "    return final_streams_list\n",
        "\n",
        "def buscar_usuarios_especificos(usuarios_lista, temp_folder=\"/content\"):\n",
        "    \"\"\"\n",
        "    Busca usu√°rios espec√≠ficos via API, utilizando um limit alto.\n",
        "    Fallback via liveInfo para usu√°rios sem src.\n",
        "    Garante poster v√°lido: se ausente, gera com ffmpeg a partir do src/m3u8.\n",
        "    Considera log de transmiss√µes em processamento para evitar duplicidade.\n",
        "    \"\"\"\n",
        "    LOG_PROCESSAMENTO_PATH = \"/content/xcam_processing.log\"\n",
        "    transmissao_em_proc = set()\n",
        "    if os.path.exists(LOG_PROCESSAMENTO_PATH):\n",
        "        with open(LOG_PROCESSAMENTO_PATH, \"r\") as f:\n",
        "            transmissao_em_proc = set([line.strip() for line in f if line.strip()])\n",
        "\n",
        "    api_url = f\"https://api.xcam.gay/?limit={API_SEARCH_LIMIT}&page=1\"\n",
        "    print(f\"üîç Buscando usu√°rios espec√≠ficos em {api_url}\")\n",
        "    try:\n",
        "        response = requests.get(api_url)\n",
        "        response.raise_for_status()\n",
        "        data = response.json()\n",
        "        items = data.get(\"broadcasts\", {}).get(\"items\", [])\n",
        "        encontrados = []\n",
        "        sem_src = []\n",
        "        for item in items:\n",
        "            username = item.get(\"username\", \"\")\n",
        "            if username in usuarios_lista and username not in transmissao_em_proc:\n",
        "                preview = item.get(\"preview\") or {}\n",
        "                src = preview.get(\"src\")\n",
        "                poster = preview.get(\"poster\")\n",
        "                poster_path = None\n",
        "                if src:\n",
        "                    if poster and isinstance(poster, str) and poster.strip():\n",
        "                        poster_path = download_and_save_poster(poster, username, temp_folder)\n",
        "                    if not is_poster_valid(poster_path):\n",
        "                        poster_path = generate_poster_with_ffmpeg(src, username, temp_folder)\n",
        "                    encontrados.append({\n",
        "                        \"username\": username,\n",
        "                        \"src\": src,\n",
        "                        \"poster\": poster_path\n",
        "                    })\n",
        "                else:\n",
        "                    # Se n√£o encontrou src, registra para fallback via liveInfo\n",
        "                    sem_src.append(username)\n",
        "        # Fallback via liveInfo\n",
        "        for username in sem_src:\n",
        "            if username in transmissao_em_proc:\n",
        "                continue\n",
        "            api_url_liveinfo = f\"https://api.xcam.gay/user/{username}/liveInfo\"\n",
        "            try:\n",
        "                response_liveinfo = requests.get(api_url_liveinfo)\n",
        "                response_liveinfo.raise_for_status()\n",
        "                data_liveinfo = response_liveinfo.json()\n",
        "                m3u8_url = data_liveinfo.get(\"cdnURL\") or data_liveinfo.get(\"edgeURL\")\n",
        "                poster_path = None\n",
        "                if m3u8_url:\n",
        "                    poster_path = generate_poster_with_ffmpeg(m3u8_url, username, temp_folder)\n",
        "                    encontrados.append({\n",
        "                        \"username\": username,\n",
        "                        \"src\": m3u8_url,\n",
        "                        \"poster\": poster_path\n",
        "                    })\n",
        "                else:\n",
        "                    print(f\"‚ö†Ô∏è liveInfo de {username} n√£o retornou cdnURL/edgeURL (usu√°rio possivelmente offline).\")\n",
        "            except Exception as ex:\n",
        "                print(f\"‚ùå Erro ao buscar liveInfo para {username}: {ex}\")\n",
        "            time.sleep(0.5)\n",
        "        print(f\"Encontrados {len(encontrados)} dos {len(usuarios_lista)} usu√°rios procurados (incluindo fallback).\")\n",
        "        return encontrados\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Erro ao buscar usu√°rios espec√≠ficos: {e}\")\n",
        "        return []"
      ],
      "metadata": {
        "id": "h1jr7D0pJ7jS"
      },
      "id": "h1jr7D0pJ7jS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# C√©lula 7: Grava√ß√£o da Stream, Download/Gera√ß√£o do Poster e Controle de Tempo M√≠nimo\n",
        "\n",
        "**Objetivo:**\n",
        "Grava a transmiss√£o ao vivo do usu√°rio usando ffmpeg. Durante a grava√ß√£o, baixa o poster da transmiss√£o e, caso ele esteja ausente, inv√°lido ou n√£o possa ser baixado, gera automaticamente uma imagem de poster utilizando ffmpeg a partir da pr√≥pria stream. Ao final, verifica se o tempo de grava√ß√£o atingiu o m√≠nimo desejado para ser considerado v√°lido.  \n",
        "Agora, tamb√©m atualiza o log de transmiss√µes em processamento ao iniciar e finalizar a grava√ß√£o, garantindo o controle e a unicidade das transmiss√µes processadas.\n",
        "\n",
        "**Como funciona:**\n",
        "\n",
        "*  Se o v√≠deo gravado for muito curto, descarta imediatamente o v√≠deo e o poster.\n",
        "*  Se for suficiente, renomeia o v√≠deo, faz upload, renomeia o poster e chama a fun√ß√£o de atualiza√ß√£o de JSON.\n",
        "*  Antes de iniciar a grava√ß√£o, registra o usu√°rio no log de transmiss√µes em processamento; ao finalizar (com sucesso ou erro), remove o usu√°rio desse log para liberar espa√ßo para novas transmiss√µes.\n",
        "*  Garante que sempre haver√° um poster v√°lido para cada transmiss√£o, baixando da API quando poss√≠vel ou gerando automaticamente com ffmpeg caso necess√°rio."
      ],
      "metadata": {
        "id": "jGFyqOUoKEF7"
      },
      "id": "jGFyqOUoKEF7"
    },
    {
      "cell_type": "code",
      "source": [
        "# C√©lula 7: Grava√ß√£o de stream, download/gera√ß√£o do poster e controle de tempo m√≠nimo\n",
        "# -----------------------------------------------------------------------------------\n",
        "# Ajuste: Calcula a dura√ß√£o real do arquivo gravado usando ffprobe ap√≥s finalizar o ffmpeg,\n",
        "# garantindo que a valida√ß√£o de dura√ß√£o m√≠nima e a formata√ß√£o do nome usem o tempo real do arquivo,\n",
        "# n√£o o tempo do processo Python (que pode ser impreciso, finalizando antes).\n",
        "# N√£o altera nenhuma outra l√≥gica al√©m do solicitado.\n",
        "\n",
        "def get_video_duration(filepath):\n",
        "    \"\"\"\n",
        "    Utiliza ffprobe para obter a dura√ß√£o real do arquivo mp4, em segundos.\n",
        "    Retorna None em caso de erro.\n",
        "    \"\"\"\n",
        "    import subprocess\n",
        "    import json\n",
        "    try:\n",
        "        cmd = [\n",
        "            \"ffprobe\", \"-v\", \"error\",\n",
        "            \"-show_entries\", \"format=duration\",\n",
        "            \"-of\", \"json\",\n",
        "            filepath\n",
        "        ]\n",
        "        result = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
        "        info = json.loads(result.stdout)\n",
        "        duration = float(info[\"format\"][\"duration\"])\n",
        "        return int(round(duration))\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è N√£o foi poss√≠vel obter dura√ß√£o via ffprobe: {e}\")\n",
        "        return None\n",
        "\n",
        "def gravar_stream(username, m3u8_url, poster_url=None, poster_frame_time=7):\n",
        "    \"\"\"\n",
        "    Grava a transmiss√£o ao vivo do usu√°rio usando ffmpeg.\n",
        "    Garante poster v√°lido: baixa da poster_url, ou gera automaticamente com ffmpeg se ausente/inv√°lido.\n",
        "    Controla o tempo m√≠nimo de grava√ß√£o e gerencia o log de transmiss√µes em processamento.\n",
        "    poster_frame_time: tempo (em segundos) do v√≠deo onde a captura do poster ser√° feita, se gerado via ffmpeg.\n",
        "    \"\"\"\n",
        "    # Caminho do arquivo de log tempor√°rio\n",
        "    LOG_PROCESSAMENTO_PATH = \"/content/xcam_processing.log\"\n",
        "\n",
        "    # ----> Adiciona a transmiss√£o ao log de transmiss√µes em processamento\n",
        "    try:\n",
        "        with open(LOG_PROCESSAMENTO_PATH, \"a\") as f:\n",
        "            f.write(f\"{username}\\n\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Erro ao registrar transmiss√£o em processamento no log: {e}\")\n",
        "\n",
        "    start_time_dt = datetime.now()\n",
        "    data_str = start_time_dt.strftime(\"%d-%m-%Y\")\n",
        "    horario_str = start_time_dt.strftime(\"%H-%M\")\n",
        "    temp_filename = f\"{username}_{start_time_dt.strftime('%Y%m%d_%H%M%S')}_temp.mp4\"\n",
        "    filepath = os.path.join(TEMP_OUTPUT_FOLDER, temp_filename)\n",
        "\n",
        "    print(f\"\\nüé¨ Iniciando grava√ß√£o de: {username} (URL: {m3u8_url}) em {filepath}\")\n",
        "\n",
        "    # Garantia de poster v√°lido:\n",
        "    poster_temp_path = None\n",
        "    if poster_url:\n",
        "        poster_temp_path = download_and_save_poster(poster_url, username, TEMP_OUTPUT_FOLDER)\n",
        "    # Se n√£o conseguiu baixar ou poster √© inv√°lido, gera via ffmpeg (caso src v√°lido dispon√≠vel)\n",
        "    if not is_poster_valid(poster_temp_path) and m3u8_url:\n",
        "        # ATEN√á√ÉO: A fun√ß√£o usada aqui √© a da C√©lula 3, que suporta timeout e tratamento robusto.\n",
        "        poster_temp_path = generate_poster_with_ffmpeg(\n",
        "            m3u8_url, username, TEMP_OUTPUT_FOLDER, frame_time=poster_frame_time\n",
        "        )\n",
        "\n",
        "    ffmpeg_cmd = [\"ffmpeg\", \"-i\", m3u8_url, \"-t\", str(RECORD_SECONDS), \"-c\", \"copy\", \"-y\", filepath]\n",
        "\n",
        "    start_time_process = time.time()\n",
        "    process = None\n",
        "\n",
        "    try:\n",
        "        process = subprocess.Popen(\n",
        "            ffmpeg_cmd,\n",
        "            stdout=subprocess.PIPE,\n",
        "            stderr=subprocess.STDOUT,\n",
        "            text=True,\n",
        "            bufsize=1,\n",
        "            universal_newlines=True\n",
        "        )\n",
        "        # Monitora o andamento do ffmpeg em tempo real (mantido para logs)\n",
        "        elapsed_seconds = 0\n",
        "        last_log_minute = -1\n",
        "        while True:\n",
        "            line = process.stdout.readline()\n",
        "            if not line and process.poll() is not None:\n",
        "                break\n",
        "            if \"time=\" in line:\n",
        "                try:\n",
        "                    match = re.search(r\"time=(\\d+):(\\d+):(\\d+)\", line)\n",
        "                    if match:\n",
        "                        h, m, s = map(int, match.groups())\n",
        "                        elapsed_seconds = h * 3600 + m * 60 + s\n",
        "                        if elapsed_seconds // 60 != last_log_minute:\n",
        "                            log_progress(username, elapsed_seconds, RECORD_SECONDS)\n",
        "                            last_log_minute = elapsed_seconds // 60\n",
        "                except Exception:\n",
        "                    pass\n",
        "\n",
        "        process.wait()\n",
        "        end_time_process = time.time()\n",
        "        # Dura√ß√£o pelo processo Python (para log apenas)\n",
        "        elapsed_seconds_proc = round(end_time_process - start_time_process)\n",
        "        log_progress(username, elapsed_seconds_proc, RECORD_SECONDS)\n",
        "\n",
        "        if process.returncode != 0:\n",
        "            print(f\"‚ùå FFmpeg falhou para {username}. C√≥digo de sa√≠da: {process.returncode}\")\n",
        "            return {\n",
        "                'username': username,\n",
        "                'filename': temp_filename,\n",
        "                'filepath': filepath,\n",
        "                'upload_success': False,\n",
        "                'abyss_response': \"Grava√ß√£o FFmpeg falhou\"\n",
        "            }\n",
        "        else:\n",
        "            # ATEN√á√ÉO: Usa ffprobe para obter a dura√ß√£o real do arquivo gravado!\n",
        "            elapsed_seconds_real = get_video_duration(filepath)\n",
        "            if elapsed_seconds_real is not None:\n",
        "                print(f\"‚úÖ Dura√ß√£o real do arquivo gravado: {elapsed_seconds_real}s (ffprobe)\")\n",
        "            else:\n",
        "                print(f\"‚ö†Ô∏è N√£o foi poss√≠vel aferir dura√ß√£o real, usando a do processo: {elapsed_seconds_proc}s\")\n",
        "                elapsed_seconds_real = elapsed_seconds_proc\n",
        "\n",
        "            # Valida√ß√£o pelo tempo real do arquivo!\n",
        "            if elapsed_seconds_real < RECORD_SECONDS_MIN:\n",
        "                print(f\"‚è© Dura√ß√£o gravada ({elapsed_seconds_real}s) menor que o m√≠nimo ({RECORD_SECONDS_MIN}s). Arquivo descartado.\")\n",
        "                if os.path.exists(filepath): os.remove(filepath)\n",
        "                if poster_temp_path and os.path.exists(poster_temp_path): os.remove(poster_temp_path)\n",
        "                return {\n",
        "                    'username': username,\n",
        "                    'filename': temp_filename,\n",
        "                    'filepath': filepath,\n",
        "                    'upload_success': False,\n",
        "                    'abyss_response': \"Grava√ß√£o muito curta (descartada)\"\n",
        "                }\n",
        "\n",
        "            tempo_formatado = format_seconds(elapsed_seconds_real)\n",
        "            final_filename = f\"{username}_{data_str}_{horario_str}_{tempo_formatado}.mp4\"\n",
        "            final_filepath = os.path.join(TEMP_OUTPUT_FOLDER, final_filename)\n",
        "\n",
        "            try:\n",
        "                os.rename(filepath, final_filepath)\n",
        "                print(f\"‚úÖ Arquivo renomeado para: {final_filename}\")\n",
        "                filepath_for_upload = final_filepath\n",
        "                filename_for_upload = final_filename\n",
        "            except Exception as e:\n",
        "                print(f\"‚ùå Erro ao renomear arquivo {temp_filename} para {final_filename}: {e}\")\n",
        "                filepath_for_upload = filepath\n",
        "                filename_for_upload = temp_filename\n",
        "\n",
        "            success, abyss_resp, slug = upload_to_abyss_and_update_json(\n",
        "                filepath_for_upload, username, elapsed_seconds_real,\n",
        "                poster_temp_path=poster_temp_path\n",
        "            )\n",
        "\n",
        "            return {\n",
        "                'username': username,\n",
        "                'filename': filename_for_upload,\n",
        "                'filepath': filepath_for_upload,\n",
        "                'upload_success': success,\n",
        "                'abyss_response': abyss_resp,\n",
        "                'slug': slug\n",
        "            }\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"‚ùå Erro: Comando 'ffmpeg' n√£o encontrado. Certifique-se de que foi instalado corretamente.\")\n",
        "        return {\n",
        "            'username': username,\n",
        "            'filename': None,\n",
        "            'filepath': None,\n",
        "            'upload_success': False,\n",
        "            'abyss_response': \"Comando FFmpeg n√£o encontrado\"\n",
        "        }\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Erro inesperado durante a execu√ß√£o do FFmpeg para {username}: {e}\")\n",
        "        return {\n",
        "            'username': username,\n",
        "            'filename': None,\n",
        "            'filepath': None,\n",
        "            'upload_success': False,\n",
        "            'abyss_response': f\"Erro inesperado na execu√ß√£o do FFmpeg: {e}\"\n",
        "        }\n",
        "    finally:\n",
        "        # ----> Remove a transmiss√£o do log de transmiss√µes em processamento\n",
        "        try:\n",
        "            if os.path.exists(LOG_PROCESSAMENTO_PATH):\n",
        "                with open(LOG_PROCESSAMENTO_PATH, \"r\") as f:\n",
        "                    linhas = f.readlines()\n",
        "                with open(LOG_PROCESSAMENTO_PATH, \"w\") as f:\n",
        "                    for l in linhas:\n",
        "                        if l.strip() != username:\n",
        "                            f.write(l)\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Erro ao remover transmiss√£o do log de processamento: {e}\")\n",
        "\n",
        "        # Limpa o arquivo de v√≠deo tempor√°rio ap√≥s upload (para n√£o ocupar espa√ßo no Colab)\n",
        "        if 'filepath_for_upload' in locals() and os.path.exists(filepath_for_upload):\n",
        "            try:\n",
        "                os.remove(filepath_for_upload)\n",
        "                print(f\"üóëÔ∏è Arquivo de v√≠deo removido do Colab: {filepath_for_upload}\")\n",
        "            except Exception as e:\n",
        "                print(f\"‚ö†Ô∏è N√£o foi poss√≠vel remover o arquivo de v√≠deo tempor√°rio: {e}\")"
      ],
      "metadata": {
        "id": "eJ_jrfNgKZNr"
      },
      "id": "eJ_jrfNgKZNr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# C√©lula 8: Upload para Abyss.to, Atualiza√ß√£o do rec.json, Commit do Poster\n",
        "\n",
        "**Objetivo:**\n",
        "Faz upload do v√≠deo para o Abyss.to. Se bem-sucedido, renomeia/move o poster para a pasta correta do reposit√≥rio, atualiza/cria o arquivo rec.json do usu√°rio com todos os metadados (incluindo poster e urlIframe) e faz commit/push dos arquivos.  \n",
        "Agora, os commits e pushs s√£o feitos em lote, apenas quando a quantidade de arquivos alterados atinge o valor definido por COMMIT_PUSH_THRESHOLD, otimizando o fluxo de trabalho e reduzindo opera√ß√µes desnecess√°rias. Tamb√©m garante que o poster utilizado (baixado ou gerado via ffmpeg) √© corretamente movido e registrado.\n",
        "\n",
        "**Como funciona:**\n",
        "\n",
        "*   Preenche todos os campos do JSON conforme seu padr√£o, incluindo poster e urlIframe.\n",
        "*   Garante que apenas v√≠deos v√°lidos sejam registrados e compartilha os links corretos.\n",
        "*   Move/renomeia o arquivo do poster utilizado para o local definitivo, sempre associando ao v√≠deo pelo slug no nome do arquivo.\n",
        "*   Ao inv√©s de commitar/pushar a cada altera√ß√£o, acumula os arquivos modificados e s√≥ realiza o commit/push ao atingir o threshold definido. No final do processamento, realiza commit/push dos arquivos restantes, se houver.\n",
        "*   Remove arquivos tempor√°rios de poster ap√≥s mover para o destino final, mantendo o ambiente limpo."
      ],
      "metadata": {
        "id": "YjGKDlbIKaLs"
      },
      "id": "YjGKDlbIKaLs"
    },
    {
      "cell_type": "code",
      "source": [
        "# C√©lula 8: Upload para Abyss.to, atualiza√ß√£o do rec.json, commit do poster (com threshold)\n",
        "# -----------------------------------------------------------------------------------------\n",
        "# Esta c√©lula √© respons√°vel por:\n",
        "# - Fazer upload do v√≠deo gravado para o servi√ßo Abyss.to\n",
        "# - Atualizar e registrar os metadados no arquivo rec.json do usu√°rio\n",
        "# - Mover/renomear o poster (imagem) para o local correto, sempre usando o novo poster (seja baixado ou gerado via ffmpeg)\n",
        "# - Acumular arquivos para commit/push e executar o envio ao atingir o threshold de altera√ß√µes\n",
        "# - Fazer a limpeza de arquivos tempor√°rios ap√≥s o uso\n",
        "\n",
        "def upload_to_abyss_and_update_json(\n",
        "    filepath, username, duration_seconds, poster_temp_path=None,\n",
        "    commit_buffer=None, commit_threshold=None\n",
        "):\n",
        "    \"\"\"\n",
        "    Faz upload do v√≠deo, atualiza o rec.json e move o poster.\n",
        "    Acumula arquivos para commit/push e s√≥ executa quando atingir o threshold.\n",
        "    \"\"\"\n",
        "    file_name = os.path.basename(filepath)\n",
        "    file_type = 'video/mp4'\n",
        "    print(f\"‚¨ÜÔ∏è Upload de: {file_name} para Abyss.to...\")\n",
        "\n",
        "    upload_success = False\n",
        "    abyss_response = \"Upload falhou - Sem resposta\"\n",
        "    uploaded_url = None\n",
        "    video_id = None\n",
        "    slug = None\n",
        "\n",
        "    # Inicializa buffers se n√£o enviados\n",
        "    if commit_buffer is None:\n",
        "        # Buffer de arquivos aguardando commit/push (persistente entre execu√ß√µes)\n",
        "        if not hasattr(upload_to_abyss_and_update_json, 'commit_buffer'):\n",
        "            upload_to_abyss_and_update_json.commit_buffer = []\n",
        "        commit_buffer = upload_to_abyss_and_update_json.commit_buffer\n",
        "\n",
        "    if commit_threshold is None:\n",
        "        # Threshold global configurado\n",
        "        global COMMIT_PUSH_THRESHOLD\n",
        "        commit_threshold = COMMIT_PUSH_THRESHOLD if 'COMMIT_PUSH_THRESHOLD' in globals() else 100\n",
        "\n",
        "    # ---- Upload do v√≠deo para Abyss.to ----\n",
        "    try:\n",
        "        with open(filepath, 'rb') as f:\n",
        "            files = { 'file': (file_name, f, file_type) }\n",
        "            response = requests.post(ABYSS_UPLOAD_URL, files=files)\n",
        "            resp_json = response.json()\n",
        "            abyss_response = resp_json\n",
        "            if resp_json.get('status'):\n",
        "                upload_success = True\n",
        "                uploaded_url = resp_json.get('url') or resp_json.get('urlIframe')\n",
        "                video_id = resp_json.get('slug') or resp_json.get('video')\n",
        "                slug = video_id\n",
        "                print(f\"üì§ Upload bem-sucedido. URL: {uploaded_url} | SLUG: {slug}\")\n",
        "            else:\n",
        "                print(f\"‚ùå Falha no upload. Mensagem: {resp_json.get('message','')}\")\n",
        "    except Exception as e:\n",
        "        abyss_response = f\"Erro no upload: {e}\"\n",
        "        print(f\"‚ùå Erro no upload: {e}\")\n",
        "\n",
        "    poster_final_relpath = None\n",
        "    # ---- Move/renomeia o poster (imagem) para o local correto do usu√°rio ----\n",
        "    if upload_success and poster_temp_path and slug:\n",
        "        try:\n",
        "            user_folder = os.path.join(BASE_REPO_FOLDER, \"xcam-db\", \"user\", username)\n",
        "            os.makedirs(user_folder, exist_ok=True)\n",
        "            poster_final_name = f\"{slug}.jpg\"\n",
        "            poster_final_path = os.path.join(user_folder, poster_final_name)\n",
        "            os.rename(poster_temp_path, poster_final_path)\n",
        "            poster_final_relpath = os.path.relpath(poster_final_path, BASE_REPO_FOLDER)\n",
        "            print(f\"üñºÔ∏è Poster movido para {poster_final_path}\")\n",
        "            # Adiciona poster ao buffer de commit\n",
        "            if poster_final_relpath not in commit_buffer:\n",
        "                commit_buffer.append(poster_final_relpath)\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Erro ao mover/renomear poster: {e}\")\n",
        "\n",
        "    # ---- Atualiza/Cria rec.json do usu√°rio com os dados do v√≠deo ----\n",
        "    if upload_success:\n",
        "        try:\n",
        "            user_folder = os.path.join(BASE_REPO_FOLDER, \"xcam-db\", \"user\", username)\n",
        "            os.makedirs(user_folder, exist_ok=True)\n",
        "            json_filepath = os.path.join(user_folder, \"rec.json\")\n",
        "\n",
        "            file_base = file_name.replace('.mp4', '')\n",
        "            parts = file_base.split('_')\n",
        "            if len(parts) >= 4:\n",
        "                json_data = parts[-3]\n",
        "                json_horario = parts[-2]\n",
        "                json_tempo = parts[-1]\n",
        "            else:\n",
        "                now = datetime.now()\n",
        "                json_data = now.strftime(\"%d-%m-%Y\")\n",
        "                json_horario = now.strftime(\"%H-%M\")\n",
        "                json_tempo = format_seconds(duration_seconds)\n",
        "\n",
        "            poster_url = f\"https://db.xcam.gay/user/{username}/{slug}.jpg\" if slug else \"\"\n",
        "            url_iframe = f\"https://short.icu/{slug}?thumbnail={poster_url}\" if slug else \"\"\n",
        "\n",
        "            new_video_entry = {\n",
        "                \"video\": slug if slug else \"ID_n√£o_retornado\",\n",
        "                \"title\": file_base,\n",
        "                \"file\": file_name,\n",
        "                \"url\": uploaded_url if uploaded_url else \"URL_n√£o_retornada\",\n",
        "                \"poster\": poster_url,\n",
        "                \"urlIframe\": url_iframe,\n",
        "                \"data\": json_data,\n",
        "                \"horario\": json_horario,\n",
        "                \"tempo\": json_tempo\n",
        "            }\n",
        "\n",
        "            def zerar_base(username):\n",
        "                return {\n",
        "                    \"username\": username,\n",
        "                    \"records\": 0,\n",
        "                    \"videos\": []\n",
        "                }\n",
        "\n",
        "            # Carrega ou inicializa rec.json\n",
        "            if not os.path.exists(json_filepath):\n",
        "                rec_data = zerar_base(username)\n",
        "            else:\n",
        "                try:\n",
        "                    with open(json_filepath, 'r', encoding='utf-8') as f:\n",
        "                        loaded = json.load(f)\n",
        "                    valid = (\n",
        "                        isinstance(loaded, dict)\n",
        "                        and \"username\" in loaded\n",
        "                        and \"records\" in loaded\n",
        "                        and \"videos\" in loaded\n",
        "                        and isinstance(loaded[\"videos\"], list)\n",
        "                    )\n",
        "                    rec_data = loaded if valid else zerar_base(username)\n",
        "                except Exception:\n",
        "                    rec_data = zerar_base(username)\n",
        "\n",
        "            # Adiciona novo v√≠deo ao hist√≥rico\n",
        "            rec_data[\"records\"] += 1\n",
        "            rec_data[\"videos\"].append(new_video_entry)\n",
        "            with open(json_filepath, 'w', encoding='utf-8') as f:\n",
        "                json.dump(rec_data, f, indent=2, ensure_ascii=False)\n",
        "            print(f\"‚úÖ rec.json para {username} atualizado em {json_filepath}\")\n",
        "\n",
        "            rel_json_path = os.path.relpath(json_filepath, BASE_REPO_FOLDER)\n",
        "            # Adiciona rec.json ao buffer de commit\n",
        "            if rel_json_path not in commit_buffer:\n",
        "                commit_buffer.append(rel_json_path)\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Erro ao atualizar rec.json: {e}\")\n",
        "            abyss_response = f\"Upload sucesso, erro no JSON: {e}\"\n",
        "\n",
        "    # ---- Commit/push autom√°tico ao atingir threshold ----\n",
        "    if len(commit_buffer) >= commit_threshold:\n",
        "        print(f\"üöÄ Commit/push autom√°tico: {len(commit_buffer)} arquivos (threshold: {commit_threshold})\")\n",
        "        try:\n",
        "            git_commit_and_push(commit_buffer, commit_message=\"Atualiza arquivos em lote (threshold autom√°tico)\")\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Falha no commit/push em lote: {e}\")\n",
        "        commit_buffer.clear()\n",
        "\n",
        "    # ---- Limpeza do arquivo de poster tempor√°rio, se sobrou ----\n",
        "    if poster_temp_path and os.path.exists(poster_temp_path):\n",
        "        try:\n",
        "            os.remove(poster_temp_path)\n",
        "            print(f\"üóëÔ∏è Poster tempor√°rio removido: {poster_temp_path}\")\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è N√£o foi poss√≠vel remover o poster tempor√°rio: {e}\")\n",
        "\n",
        "    return upload_success, abyss_response, slug\n",
        "\n",
        "# Fun√ß√£o auxiliar para garantir commit/push dos arquivos restantes ao final do processamento\n",
        "def commit_push_restantes():\n",
        "    \"\"\"\n",
        "    Realiza commit/push final de todos os arquivos pendentes no buffer.\n",
        "    \"\"\"\n",
        "    buffer = getattr(upload_to_abyss_and_update_json, 'commit_buffer', None)\n",
        "    if buffer and len(buffer) > 0:\n",
        "        print(f\"üöÄ Commit/push final de {len(buffer)} arquivos restantes\")\n",
        "        try:\n",
        "            git_commit_and_push(buffer, commit_message=\"Atualiza arquivos finais (commit final)\")\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Falha no commit/push final em lote: {e}\")\n",
        "        buffer.clear()"
      ],
      "metadata": {
        "id": "vMTiCrJ5Kp81"
      },
      "id": "vMTiCrJ5Kp81",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# C√©lula 9: Processamento Autom√°tico (Paralelo e Interativo)\n",
        "\n",
        "**Objetivo:**\n",
        "Controla todo o fluxo do notebook, processando as transmiss√µes em paralelo (mais de uma ao mesmo tempo) para efici√™ncia. Utiliza as fun√ß√µes anteriores para buscar, gravar, processar, fazer upload e registrar os v√≠deos.  \n",
        "Agora, tamb√©m garante que o lote de transmiss√µes seja sempre preenchido at√© o LIMIT_DEFAULT, controla a unicidade das transmiss√µes em processamento e faz o gerenciamento autom√°tico das p√°ginas.\n",
        "\n",
        "**Como funciona:**\n",
        "\n",
        "*   Se o usu√°rio informou nomes espec√≠ficos, busca/grava apenas esses.\n",
        "*   Caso contr√°rio, processa normalmente por p√°ginas, sempre mantendo o lote cheio at√© LIMIT_DEFAULT e pulando transmiss√µes j√° em processamento.\n",
        "*   Mant√©m o loop at√© n√£o encontrar mais transmiss√µes dispon√≠veis para processar.\n",
        "*   Exibe logs amig√°veis e controla a espera entre p√°ginas.\n",
        "*   Faz o controle das p√°ginas e da unicidade das transmiss√µes processadas, evitando duplicidade e otimizando o uso do processamento paralelo."
      ],
      "metadata": {
        "id": "iwgt8f8iKq4y"
      },
      "id": "iwgt8f8iKq4y"
    },
    {
      "cell_type": "code",
      "source": [
        "# C√©lula 9: Processamento autom√°tico (paralelo e interativo) das transmiss√µes\n",
        "# ----------------------------------------------------------------------------\n",
        "# Esta c√©lula gerencia o fluxo principal do notebook de grava√ß√£o:\n",
        "# - Busca transmiss√µes dispon√≠veis (com controle de lote e duplicidade)\n",
        "# - Processa as grava√ß√µes em paralelo usando multiprocessing\n",
        "# - Garante unicidade e sincroniza√ß√£o com o log de transmiss√µes em processamento\n",
        "# - Lida tanto com busca autom√°tica quanto com sele√ß√£o de usu√°rios espec√≠ficos\n",
        "\n",
        "def process_page(page=PAGE_DEFAULT, limit=LIMIT_DEFAULT, usuarios_especificos=None):\n",
        "    \"\"\"\n",
        "    Processa uma p√°gina de transmiss√µes:\n",
        "    - Busca transmiss√µes dispon√≠veis, sempre tentando manter o lote cheio at√© LIMIT_DEFAULT.\n",
        "    - Garante que n√£o haja duplicidade (controle pelo log de transmiss√µes em processamento).\n",
        "    - Inicia o processamento paralelo das transmiss√µes.\n",
        "    \"\"\"\n",
        "    print(f\"\\nüìÑ Processando p√°gina {page}\\n\")\n",
        "    streams = []\n",
        "    if usuarios_especificos:\n",
        "        # Busca apenas transmiss√µes dos usu√°rios solicitados\n",
        "        streams = buscar_usuarios_especificos(usuarios_especificos)\n",
        "        # Garante que n√£o ultrapasse o limit solicitado\n",
        "        streams = streams[:limit]\n",
        "    else:\n",
        "        # Busca autom√°tica: tenta preencher o lote completo, mesmo que precise avan√ßar p√°ginas\n",
        "        tentative_page = page\n",
        "        streams = []\n",
        "        seen_usernames = set()\n",
        "        LOG_PROCESSAMENTO_PATH = \"/content/xcam_processing.log\"\n",
        "        # Carrega transmiss√µes j√° em processamento para evitar duplicidade\n",
        "        transmissao_em_proc = set()\n",
        "        if os.path.exists(LOG_PROCESSAMENTO_PATH):\n",
        "            with open(LOG_PROCESSAMENTO_PATH, \"r\") as f:\n",
        "                transmissao_em_proc = set([line.strip() for line in f if line.strip()])\n",
        "        max_tentativas = 10  # Evita loops infinitos\n",
        "        tentativas = 0\n",
        "        while len(streams) < limit and tentativas < max_tentativas:\n",
        "            curr_streams = get_broadcasts(limit=limit, page=tentative_page)\n",
        "            # Adiciona apenas streams novas e n√£o em processamento\n",
        "            for s in curr_streams:\n",
        "                username = s[\"username\"]\n",
        "                if username not in seen_usernames and username not in transmissao_em_proc:\n",
        "                    streams.append(s)\n",
        "                    seen_usernames.add(username)\n",
        "                    if len(streams) >= limit:\n",
        "                        break\n",
        "            # Avan√ßa para a pr√≥xima p√°gina se necess√°rio\n",
        "            tentative_page += 1\n",
        "            if tentative_page > 10:\n",
        "                tentative_page = 1\n",
        "            tentativas += 1\n",
        "        # Garante que n√£o retorna mais que o limite\n",
        "        streams = streams[:limit]\n",
        "\n",
        "    if not streams:\n",
        "        print(f\"\\nüö´ Nenhuma stream encontrada na p√°gina {page}.\")\n",
        "        return False\n",
        "\n",
        "    jobs = []\n",
        "    results = multiprocessing.Manager().list()\n",
        "\n",
        "    # Worker para gravar cada stream; roda em processo separado\n",
        "    def worker(username, m3u8_url, poster_url, results):\n",
        "        # Chama a fun√ß√£o principal de grava√ß√£o (lida com poster local ou gerado)\n",
        "        result = gravar_stream(username, m3u8_url, poster_url)\n",
        "        results.append(result)\n",
        "\n",
        "    print(f\"üöÄ Gravando {len(streams)} streams em paralelo...\")\n",
        "    for stream in streams:\n",
        "        username = stream[\"username\"]\n",
        "        m3u8_url = stream[\"src\"]\n",
        "        poster_url = stream.get(\"poster\")\n",
        "        # Cada transmiss√£o √© processada em paralelo (multiprocessing)\n",
        "        p = multiprocessing.Process(target=worker, args=(username, m3u8_url, poster_url, results))\n",
        "        jobs.append(p)\n",
        "        p.start()\n",
        "\n",
        "    # Aguarda o t√©rmino de todas as grava√ß√µes em paralelo\n",
        "    for job in jobs:\n",
        "        job.join()\n",
        "\n",
        "    print(f\"\\nüèÅ Todas as grava√ß√µes da p√°gina {page} conclu√≠das.\")\n",
        "\n",
        "    return True if streams else False\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Loop principal:\n",
        "    - Pergunta se deseja processar transmiss√µes espec√≠ficas ou buscar automaticamente.\n",
        "    - Mant√©m o lote sempre cheio at√© LIMIT_DEFAULT, avan√ßando p√°gina conforme necess√°rio e evitando duplicidade.\n",
        "    - Garante o controle das p√°ginas e a unicidade das transmiss√µes processadas.\n",
        "    \"\"\"\n",
        "    usuarios_especificos = perguntar_transmissoes_especificas()\n",
        "    page = PAGE_DEFAULT\n",
        "    limit = LIMIT_DEFAULT if not usuarios_especificos else API_SEARCH_LIMIT\n",
        "\n",
        "    print(\"ü§ñ Iniciando busca e grava√ß√£o de streams...\")\n",
        "    while True:\n",
        "        ok = process_page(page=page, limit=limit, usuarios_especificos=usuarios_especificos)\n",
        "        if not ok:\n",
        "            print(\"\\nEncerrando processo por falta de streams.\")\n",
        "            break\n",
        "        if not usuarios_especificos:\n",
        "            page += 1\n",
        "            if page > 10:\n",
        "                page = 1\n",
        "            print(f\"\\nAguardando 5 segundos antes de processar a pr√≥xima p√°gina...\")\n",
        "            time.sleep(5)\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    print(\"\\n‚ú® Processo principal finalizado.\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    try:\n",
        "        # Detecta se est√° rodando em ambiente Colab para execu√ß√£o autom√°tica\n",
        "        if 'google.colab' in str(get_ipython()):\n",
        "            main()\n",
        "        else:\n",
        "            print(\"Execute main() manualmente se desejar rodar fora do Colab.\")\n",
        "    except NameError:\n",
        "        print(\"N√£o est√° rodando em Colab/IPython. Execute main() se desejar.\")"
      ],
      "metadata": {
        "id": "5WKQV9g_LB9M"
      },
      "id": "5WKQV9g_LB9M",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# C√©lula extra: Commit final de pend√™ncias\n",
        "def commit_final_pendencias():\n",
        "    commit_buffer = getattr(upload_to_abyss_and_update_json, 'commit_buffer', [])\n",
        "    if commit_buffer:\n",
        "        print(f\"üîî Realizando commit/push final de {len(commit_buffer)} pend√™ncias...\")\n",
        "        git_commit_and_push(commit_buffer, commit_message=\"Commit final de pend√™ncias\")\n",
        "        commit_buffer.clear()\n",
        "    else:\n",
        "        print(\"‚úÖ Sem pend√™ncias para commit final.\")\n",
        "\n",
        "# Execute isto ao final do processamento\n",
        "# commit_final_pendencias()"
      ],
      "metadata": {
        "id": "eXVBhXjsAuAY"
      },
      "id": "eXVBhXjsAuAY",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "c9hve1ySGVAs"
      ],
      "cell_execution_strategy": "setup",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}