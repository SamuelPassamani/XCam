{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SamuelPassamani/XCam/blob/main/xcam-colab/XCam_REC_V4.3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# C√©lula 1: Configura√ß√µes Auxiliares, Par√¢metros Globais e Log Centralizado\n",
        "\n",
        "**Objetivo:**  \n",
        "Esta c√©lula inicializa e centraliza todas as vari√°veis globais, par√¢metros essenciais e agora tamb√©m fornece um utilit√°rio robusto para o log √∫nico do notebook XCam.  \n",
        "Permite ajuste r√°pido e seguro do comportamento do notebook, incluindo limites de processamento, controle de grava√ß√£o, commit autom√°tico e mecanismos de resili√™ncia contra transmiss√µes problem√°ticas.\n",
        "\n",
        "## Principais pontos e melhorias implementadas\n",
        "\n",
        "- **Centraliza√ß√£o dos par√¢metros globais:**  \n",
        "  Todos os valores cr√≠ticos (limites, thresholds, caminhos) s√£o definidos e propagados como globais pelo notebook.\n",
        "- **Log √∫nico modular e estruturado (`xcam_master.log`):**  \n",
        "  Todas as opera√ß√µes relevantes (busca, grava√ß√£o, blacklist, commit, erros, etc.) agora s√£o registradas em um √∫nico arquivo JSON Lines.  \n",
        "  Cada entrada inclui sess√£o, evento, id, username, id_username, timestamps, status e detalhes.\n",
        "- **Fun√ß√µes utilit√°rias para o log:**  \n",
        "  Adi√ß√£o, busca, remo√ß√£o e atualiza√ß√£o de eventos s√£o facilitadas por fun√ß√µes modulares (CRUD), promovendo robustez, rastreabilidade e f√°cil manuten√ß√£o.\n",
        "- **Blacklist, falhas e processamento padronizados por `id`:**  \n",
        "  Toda l√≥gica de controle √© feita via identificador √∫nico (`id`) e refer√™ncia `{id}:{username}` (`id_username`), garantindo unicidade e eliminando inconsist√™ncias.\n",
        "- **Uso consistente do campo `sessao`:**  \n",
        "  Todos os registros s√£o organizados por sess√µes l√≥gicas, facilitando filtros, relat√≥rios e auditoria.\n",
        "- **Fun√ß√£o interativa para sele√ß√£o de transmiss√µes espec√≠ficas:**  \n",
        "  Permite ao usu√°rio informar nomes de usu√°rios para filtrar transmiss√µes antes do processamento.\n",
        "- **Coment√°rios detalhados:**  \n",
        "  Cada etapa do c√≥digo est√° documentada para orientar ajustes, manuten√ß√£o e integra√ß√£o por toda a equipe.\n",
        "\n",
        "---\n",
        "\n",
        "## Par√¢metros globais controlados nesta c√©lula\n",
        "\n",
        "- **`LIMIT_DEFAULT`**: Quantidade m√°xima de transmiss√µes processadas em paralelo/lote.\n",
        "- **`PAGE_DEFAULT`**: P√°gina inicial para busca na API.\n",
        "- **`RECORD_SECONDS`**: Tempo m√°ximo de grava√ß√£o de cada v√≠deo (em segundos).\n",
        "- **`RECORD_SECONDS_MIN`**: Tempo m√≠nimo exigido para considerar o v√≠deo v√°lido (em segundos).\n",
        "- **`API_SEARCH_LIMIT`**: Limite de transmiss√µes retornadas ao buscar usu√°rios espec√≠ficos.\n",
        "- **`COMMIT_PUSH_THRESHOLD`**: Quantidade de transmiss√µes processadas at√© realizar commit/push autom√°tico (0 = commit imediato a cada grava√ß√£o).\n",
        "- **`LOG_PATH`**: Caminho do arquivo √∫nico de log (JSONL).\n",
        "- **`BLACKLIST_TIMEOUT`**: Tempo de expira√ß√£o da blacklist (em segundos).\n",
        "- **`BLACKLIST_MAX_FAILURES`**: Quantidade de falhas consecutivas antes de banir temporariamente o usu√°rio.\n",
        "\n",
        "---\n",
        "\n",
        "## Estrutura do log √∫nico (`xcam_master.log`)\n",
        "\n",
        "Cada entrada segue o modelo:\n",
        "```json\n",
        "{\n",
        "  \"timestamp\": \"2025-06-06T06:15:00Z\",\n",
        "  \"sessao\": \"busca|grava√ß√£o|blacklist|processing|failure|success|commit|erro|...\",\n",
        "  \"evento\": \"...\",\n",
        "  \"id\": \"...\",           // identificador √∫nico (prim√°rio)\n",
        "  \"username\": \"...\",     // nome do usu√°rio para exibi√ß√£o\n",
        "  \"id_username\": \"...\",  // refer√™ncia padr√£o \"{id}:{username}\" para consultas e auditoria\n",
        "  \"status\": \"...\",       // ok|erro|blacklisted|expirado|...\n",
        "  \"detalhes\": \"...\",     // informa√ß√µes adicionais (motivo, paths, etc)\n",
        "}\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Fun√ß√µes utilit√°rias para o log\n",
        "\n",
        "- **`append_log(entry, log_path=LOG_PATH)`**: Adiciona uma nova entrada ao log central (gera campo `id_username` automaticamente).\n",
        "- **`read_logs(log_path=LOG_PATH)`**: L√™ todas as entradas do log.\n",
        "- **`query_logs(...)`**: Consulta entradas do log por filtros opcionais (sess√£o, id, id_username, status, etc).\n",
        "- **`remove_logs(condition_fn, log_path=LOG_PATH)`**: Remove todas as entradas que satisfa√ßam a condi√ß√£o.\n",
        "- **`update_log_entry(match_fn, update_fn, log_path=LOG_PATH)`**: Atualiza entradas do log conforme regra.\n",
        "\n",
        "---\n",
        "\n",
        "## Exemplo de uso das fun√ß√µes (a serem aplicadas nas pr√≥ximas c√©lulas)\n",
        "\n",
        "```python\n",
        "append_log({\n",
        "    \"sessao\": \"processing\",\n",
        "    \"evento\": \"iniciado\",\n",
        "    \"id\": \"abc123\",\n",
        "    \"username\": \"Manugic_\",\n",
        "    \"status\": \"ok\",\n",
        "    \"detalhes\": \"URL v√°lida\"\n",
        "})\n",
        "\n",
        "# Consultar blacklist:\n",
        "logs_blacklist = query_logs(sessao=\"blacklist\", status=\"blacklisted\")\n",
        "\n",
        "# Remover registros expirados:\n",
        "remove_logs(lambda entry: entry[\"sessao\"] == \"processing\" and expirou(entry), log_path=LOG_PATH)\n",
        "\n",
        "# Atualizar status:\n",
        "update_log_entry(lambda e: e[\"id\"]==\"abc123\" and e[\"sessao\"]==\"processing\", lambda e: e.update({\"status\":\"ok\"}))\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Fun√ß√£o interativa\n",
        "\n",
        "Permite ao usu√°rio informar transmiss√µes espec√≠ficas a serem gravadas antes de iniciar o processamento.\n",
        "\n",
        "---\n",
        "\n",
        "## Seguran√ßa, rastreabilidade e manuten√ß√£o\n",
        "\n",
        "- Todos os par√¢metros globais s√£o definidos no in√≠cio e propagados para todo o notebook, garantindo consist√™ncia.\n",
        "- O log √∫nico fornece rastreabilidade detalhada e elimina arquivos dispersos (blacklist, falha, etc).\n",
        "- Uso do padr√£o `{id}:{username}` para refer√™ncia e auditoria.\n",
        "- Ajuste qualquer valor diretamente nesta c√©lula para alterar o comportamento global do notebook de forma segura.\n",
        "- Coment√°rios detalhados auxiliam a compreens√£o, integra√ß√£o e manuten√ß√£o por toda a equipe.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "c9hve1ySGVAs"
      },
      "id": "c9hve1ySGVAs"
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================\n",
        "# C√©lula 1: Configura√ß√£o Global, Par√¢metros e Log √önico Estruturado\n",
        "# ================================================================\n",
        "# Objetivo:\n",
        "# - Centralizar configura√ß√µes globais e thresholds\n",
        "# - Definir e montar caminhos do notebook\n",
        "# - Fornecer utilit√°rio robusto para LOG √öNICO MODULAR (JSONL)\n",
        "#   => Todas as c√©lulas e fun√ß√µes usar√£o este log para registrar, consultar e manipular eventos\n",
        "# - Garantir padroniza√ß√£o, rastreabilidade, unicidade e f√°cil manuten√ß√£o futura\n",
        "#\n",
        "# Estrat√©gia:\n",
        "# - Log √∫nico estruturado (JSONL): sess√£o, evento, id, username, id_username, timestamps, status, detalhes\n",
        "# - Fun√ß√µes CRUD para log: adicionar, buscar, atualizar, remover (para blacklist, processing, falhas, auditoria)\n",
        "# - Blacklist e controles baseados em id (com username apenas para exibi√ß√£o)\n",
        "# - Par√¢metros globais facilmente edit√°veis e propagados via globals()\n",
        "# - Uso consistente de \"sessao\" para diferenciar tipos de registros\n",
        "# ================================================================\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "import json\n",
        "\n",
        "# ============================\n",
        "# PAR√ÇMETROS GLOBAIS EDIT√ÅVEIS\n",
        "# ============================\n",
        "# Modifique abaixo conforme necessidade do ambiente ou processamento\n",
        "\n",
        "# Limites e thresholds principais de processamento\n",
        "LIMIT_DEFAULT = 100             # M√°ximo de transmiss√µes processadas por rodada\n",
        "PAGE_DEFAULT = 1               # P√°gina padr√£o para busca na API\n",
        "RECORD_SECONDS = 12780         # Dura√ß√£o m√°xima da grava√ß√£o (em segundos)\n",
        "RECORD_SECONDS_MIN = 420       # Dura√ß√£o m√≠nima v√°lida (em segundos)\n",
        "API_SEARCH_LIMIT = 3333        # Limite ao buscar usu√°rios espec√≠ficos\n",
        "# COMMIT_PUSH_THRESHOLD removido pois o commit/push √© gerenciado externamente\n",
        "\n",
        "# Caminhos de arquivos principais\n",
        "BASE_PATH = '/content' # Mantido para refer√™ncia, mas LOG_PATH vai para o Drive\n",
        "DRIVE_BASE_LOG_PATH = '/content/drive/MyDrive/XCam.Drive/logs' # Novo caminho base para logs no Drive\n",
        "LOG_PATH = f\"{DRIVE_BASE_LOG_PATH}/xcam_master.log\"          # Arquivo √∫nico de log central MOVIDO PARA O DRIVE\n",
        "BLACKLIST_TIMEOUT = 15 * 60                        # Blacklist: tempo de expira√ß√£o (segundos)\n",
        "BLACKLIST_MAX_FAILURES = 3                         # Blacklist: falhas para banimento tempor√°rio\n",
        "\n",
        "# Garante que o diret√≥rio de logs no Drive exista\n",
        "os.makedirs(DRIVE_BASE_LOG_PATH, exist_ok=True)\n",
        "print(f\"Diret√≥rio de logs no Drive garantido: {DRIVE_BASE_LOG_PATH}\")\n",
        "\n",
        "\n",
        "# ============================\n",
        "# ATUALIZA√á√ÉO GLOBAL DOS PAR√ÇMETROS\n",
        "# ============================\n",
        "# Propaga par√¢metros como globais do notebook\n",
        "globals().update({\n",
        "    'LIMIT_DEFAULT': LIMIT_DEFAULT,\n",
        "    'PAGE_DEFAULT': PAGE_DEFAULT,\n",
        "    'RECORD_SECONDS': RECORD_SECONDS,\n",
        "    'RECORD_SECONDS_MIN': RECORD_SECONDS_MIN,\n",
        "    'API_SEARCH_LIMIT': API_SEARCH_LIMIT,\n",
        "    'LOG_PATH': LOG_PATH, # Atualizado para o caminho do Drive\n",
        "    'BLACKLIST_TIMEOUT': BLACKLIST_TIMEOUT,\n",
        "    'BLACKLIST_MAX_FAILURES': BLACKLIST_MAX_FAILURES\n",
        "})\n",
        "\n",
        "# =============================================================================\n",
        "# UTILIT√ÅRIO DE LOG √öNICO MODULAR (JSONL) ‚Äî Clean Architecture\n",
        "# -----------------------------------------------------------------------------\n",
        "# Cada entrada: {\n",
        "#   \"timestamp\": \"2025-06-06T06:15:00Z\",\n",
        "#   \"sessao\": \"busca|grava√ß√£o|blacklist|processing|failure|commit|erro|...\",\n",
        "#   \"evento\": \"...\",\n",
        "#   \"id\": \"...\",               # identificador prim√°rio (ex: id da transmiss√£o)\n",
        "#   \"username\": \"...\",         # apenas refer√™ncia humana\n",
        "#   \"id_username\": \"...\",      # padr√£o \"{id}:{username}\" para f√°cil leitura/humano\n",
        "#   \"status\": \"...\",           # ok|erro|blacklisted|expirado|...\n",
        "#   \"detalhes\": \"...\",         # informa√ß√µes adicionais/motivo/paths\n",
        "# }\n",
        "# =============================================================================\n",
        "\n",
        "from datetime import datetime\n",
        "\n",
        "def now_iso():\n",
        "    \"\"\"Retorna timestamp UTC em formato ISO.\"\"\"\n",
        "    return datetime.utcnow().isoformat() + \"Z\"\n",
        "\n",
        "def make_id_username(id, username):\n",
        "    \"\"\"Gera o identificador de refer√™ncia padr√£o para logs: '{id}:{username}'.\"\"\"\n",
        "    return f\"{id}:{username}\"\n",
        "\n",
        "def append_log(entry, log_path=LOG_PATH):\n",
        "    \"\"\"\n",
        "    Adiciona uma nova entrada ao log central (JSONL).\n",
        "    Campos obrigat√≥rios: sessao, evento, id, username, status.\n",
        "    - 'id' DEVE ser chave prim√°ria (√∫nico por transmiss√£o/processo).\n",
        "    - 'username' √© apenas refer√™ncia humana.\n",
        "    - 'id_username' sempre gerado para facilitar auditoria/consulta.\n",
        "    - 'sessao' obrigat√≥rio e padronizado para facilitar filtros e consultas.\n",
        "    \"\"\"\n",
        "    entry.setdefault(\"timestamp\", now_iso())\n",
        "    for field in [\"sessao\", \"evento\", \"id\", \"username\", \"status\"]:\n",
        "        entry.setdefault(field, \"\")\n",
        "    # Padr√£o de refer√™ncia √∫nico e f√°cil busca\n",
        "    entry[\"id_username\"] = make_id_username(entry[\"id\"], entry[\"username\"])\n",
        "    # Evitar duplicidade de id+sessao+evento (unicidade l√≥gica)\n",
        "    logs = []\n",
        "    # Verifica se o arquivo existe ANTES de tentar ler\n",
        "    if os.path.exists(log_path):\n",
        "        try:\n",
        "            with open(log_path, \"r\", encoding=\"utf-8\") as f:\n",
        "                # L√™ linha por linha e tenta parsear JSON. Ignora linhas inv√°lidas com aviso.\n",
        "                for line in f:\n",
        "                    line = line.strip()\n",
        "                    if line:\n",
        "                        try:\n",
        "                            logs.append(json.loads(line))\n",
        "                        except json.JSONDecodeError as e:\n",
        "                            print(f\"‚ö†Ô∏è Aviso: Linha inv√°lida no log '{log_path}', ignorada: {line} - Erro: {e}\")\n",
        "        except Exception as e:\n",
        "             print(f\"‚ùå Erro inesperado ao ler log '{log_path}', inicializando lista vazia: {e}\")\n",
        "             logs = []\n",
        "\n",
        "\n",
        "    # Checa unicidade apenas para eventos que n√£o podem ser duplicados (ex: processing, blacklist, etc)\n",
        "    if entry[\"sessao\"] in {\"processing\", \"blacklist\", \"failure\", \"success\"}:\n",
        "        key = (entry[\"id\"], entry[\"sessao\"], entry[\"evento\"])\n",
        "        # Encontra o √≠ndice da entrada existente, se houver\n",
        "        existing_index = next((i for i, e in enumerate(logs) if (e.get(\"id\"), e.get(\"sessao\"), e.get(\"evento\")) == key), -1)\n",
        "\n",
        "        if existing_index != -1:\n",
        "            # Atualiza o registro existente ao inv√©s de duplicar\n",
        "            logs[existing_index].update(entry)\n",
        "            # Escreve o arquivo completo de volta (substitui)\n",
        "            try:\n",
        "                with open(log_path, \"w\", encoding=\"utf-8\") as f:\n",
        "                    for l in logs:\n",
        "                        f.write(json.dumps(l, ensure_ascii=False) + \"\\n\")\n",
        "                return # Retorna ap√≥s atualizar\n",
        "            except Exception as e:\n",
        "                print(f\"‚ùå Erro ao reescrever log '{log_path}' ap√≥s atualiza√ß√£o: {e}\")\n",
        "                # Em caso de erro ao reescrever, tenta apenas append abaixo como fallback?\n",
        "                # Ou seria melhor parar? Por seguran√ßa, vamos tentar append (pode gerar duplicidade tempor√°ria)\n",
        "                pass # Continua para o append abaixo em caso de erro ao reescrever\n",
        "\n",
        "    # Se n√£o existe ou se houve erro ao reescrever, apenas append a nova entrada\n",
        "    try:\n",
        "        with open(log_path, \"a\", encoding=\"utf-8\") as f:\n",
        "            f.write(json.dumps(entry, ensure_ascii=False) + \"\\n\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Erro ao adicionar entrada ao log '{log_path}': {e}\")\n",
        "\n",
        "\n",
        "def read_logs(log_path=LOG_PATH):\n",
        "    \"\"\"L√™ todas as entradas do log central.\"\"\"\n",
        "    if not os.path.exists(log_path):\n",
        "        return []\n",
        "    logs = []\n",
        "    try:\n",
        "        with open(log_path, \"r\", encoding=\"utf-8\") as f:\n",
        "            for line in f:\n",
        "                line = line.strip()\n",
        "                if line:\n",
        "                    try:\n",
        "                        logs.append(json.loads(line))\n",
        "                    except json.JSONDecodeError as e:\n",
        "                         print(f\"‚ö†Ô∏è Aviso: Linha inv√°lida no log '{log_path}', ignorada: {line} - Erro: {e}\")\n",
        "    except Exception as e:\n",
        "         print(f\"‚ùå Erro inesperado ao ler log '{log_path}': {e}\")\n",
        "         return []\n",
        "    return logs\n",
        "\n",
        "\n",
        "def query_logs(sessao=None, id=None, username=None, id_username=None, evento=None, status=None, after=None, before=None, log_path=LOG_PATH):\n",
        "    \"\"\"\n",
        "    Consulta entradas do log por filtros opcionais.\n",
        "    Filtros dispon√≠veis: sessao, id, username, id_username, evento, status, after, before.\n",
        "    - after/before: string ISO ou datetime\n",
        "    \"\"\"\n",
        "    logs = read_logs(log_path)\n",
        "    result = []\n",
        "    for entry in logs:\n",
        "        if sessao and entry.get(\"sessao\") != sessao:\n",
        "            continue\n",
        "        if id and entry.get(\"id\") != id:\n",
        "            continue\n",
        "        if username and entry.get(\"username\") != username:\n",
        "            continue\n",
        "        if id_username and entry.get(\"id_username\") != id_username:\n",
        "            continue\n",
        "        if evento and entry.get(\"evento\") != evento:\n",
        "            continue\n",
        "        if status and entry.get(\"status\") != status:\n",
        "            continue\n",
        "        ts = entry.get(\"timestamp\")\n",
        "        if after:\n",
        "            after_val = after if isinstance(after, str) else after.isoformat()\n",
        "            if ts < after_val:\n",
        "                continue\n",
        "        if before:\n",
        "            before_val = before if isinstance(before, str) else before.isoformat()\n",
        "            if ts > before_val:\n",
        "                continue\n",
        "        result.append(entry)\n",
        "    return result\n",
        "\n",
        "def remove_logs(condition_fn, log_path=LOG_PATH):\n",
        "    \"\"\"\n",
        "    Remove do log central todas as entradas que satisfa√ßam condition_fn(entry).\n",
        "    √ötil para expurgar logs expirados, blacklists vencidas, eventos processados, etc.\n",
        "    \"\"\"\n",
        "    logs = read_logs(log_path)\n",
        "    kept = [entry for entry in logs if not condition_fn(entry)]\n",
        "    # S√≥ reescreve se houve remo√ß√£o ou se o arquivo existia e agora est√° vazio\n",
        "    if len(kept) < len(logs) or (len(logs) > 0 and len(kept) == 0):\n",
        "        try:\n",
        "            with open(log_path, \"w\", encoding=\"utf-8\") as f:\n",
        "                for entry in kept:\n",
        "                    f.write(json.dumps(entry, ensure_ascii=False) + \"\\n\")\n",
        "            print(f\"‚úÖ {len(logs) - len(kept)} entradas removidas do log '{log_path}'.\")\n",
        "            return len(logs) - len(kept)\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Erro ao reescrever log '{log_path}' ap√≥s remo√ß√£o: {e}\")\n",
        "            return 0 # N√£o podemos confirmar quantas foram removidas no arquivo\n",
        "    else:\n",
        "         print(f\"‚ÑπÔ∏è Nenhuma entrada satisfez a condi√ß√£o de remo√ß√£o no log '{log_path}'.\")\n",
        "         return 0\n",
        "\n",
        "\n",
        "def update_log_entry(match_fn, update_fn, log_path=LOG_PATH):\n",
        "    \"\"\"\n",
        "    Atualiza entradas do log central: se match_fn(entry)==True, aplica update_fn(entry).\n",
        "    Exemplo: promover status de \"pending\" para \"ok\".\n",
        "    \"\"\"\n",
        "    logs = read_logs(log_path)\n",
        "    updated = 0\n",
        "    # Cria uma c√≥pia para iterar enquanto modifica a original (ou uma nova lista)\n",
        "    new_logs = []\n",
        "    made_changes = False\n",
        "    for entry in logs:\n",
        "        # Cria uma c√≥pia da entrada para modificar, se necess√°rio\n",
        "        entry_copy = entry.copy()\n",
        "        if match_fn(entry_copy):\n",
        "            update_fn(entry_copy)\n",
        "            updated += 1\n",
        "            made_changes = True\n",
        "        new_logs.append(entry_copy)\n",
        "\n",
        "    if made_changes:\n",
        "        try:\n",
        "            with open(log_path, \"w\", encoding=\"utf-8\") as f:\n",
        "                for entry in new_logs:\n",
        "                    f.write(json.dumps(entry, ensure_ascii=False) + \"\\n\")\n",
        "            print(f\"‚úÖ {updated} entradas atualizadas no log '{log_path}'.\")\n",
        "        except Exception as e:\n",
        "             print(f\"‚ùå Erro ao reescrever log '{log_path}' ap√≥s atualiza√ß√£o: {e}\")\n",
        "\n",
        "    return updated\n",
        "\n",
        "# Exemplos de uso (para as pr√≥ximas c√©lulas):\n",
        "# append_log({\"sessao\":\"processing\", \"evento\":\"iniciado\", \"id\":\"123456\", \"username\":\"Manugic_\", \"status\":\"ok\", \"detalhes\":\"URL v√°lida\"})\n",
        "# logs_blacklist = query_logs(sessao=\"blacklist\", status=\"blacklisted\")\n",
        "# remove_logs(lambda entry: entry[\"sessao\"]==\"processing\" and expirou(entry), log_path=LOG_PATH)\n",
        "# update_log_entry(lambda e: e[\"id\"]==\"123456\" and e[\"sessao\"]==\"processing\", lambda e: e.update({\"status\":\"ok\"}))\n",
        "\n",
        "# =============================================================================\n",
        "# FUN√á√ÉO INTERATIVA (opcional) PARA ESCOLHA DE TRANSMISS√ïES ESPEC√çFICAS\n",
        "# =============================================================================\n",
        "def perguntar_transmissoes_especificas():\n",
        "    \"\"\"\n",
        "    Pergunta ao usu√°rio se deseja informar transmiss√µes espec√≠ficas para gravar,\n",
        "    recebendo nomes de usu√°rio separados por v√≠rgula e retornando lista limpa.\n",
        "    Retorna lista vazia caso n√£o deseje selecionar usu√°rios.\n",
        "    \"\"\"\n",
        "    resp = input('Deseja gravar alguma transmiss√£o espec√≠fica? (sim/n√£o): ').strip().lower()\n",
        "    if resp.startswith('s'):\n",
        "        usuarios = input('Informe o(s) nome(s) de usu√°rio, separados por v√≠rgula (ex: userNovo234, jovemPT): ')\n",
        "        usuarios_lista = [u.strip() for u in usuarios.split(',') if u.strip()]\n",
        "        return usuarios_lista\n",
        "    return []\n",
        "\n",
        "# =============================================================================\n",
        "# DICAS DE USO EM OUTRAS C√âLULAS:\n",
        "# - Para registrar evento: append_log({...})\n",
        "# - Para consultar blacklist: query_logs(sessao=\"blacklist\", status=\"blacklisted\")\n",
        "# - Para remover registros expirados: remove_logs(lambda e: ...)\n",
        "# - Para atualizar status: update_log_entry(lambda e: ..., lambda e: ...)\n",
        "# - Sempre use o id como chave prim√°ria e id_username para refer√™ncia em relat√≥rios/auditoria\n",
        "# =============================================================================\n",
        "\n",
        "# ============================\n",
        "# FIM DA C√âLULA 1\n",
        "# ============================"
      ],
      "metadata": {
        "id": "j5pPh353GLMD"
      },
      "id": "j5pPh353GLMD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# C√©lula 2: Instala√ß√£o e Valida√ß√£o do ffmpeg\n",
        "\n",
        "**Objetivo:**  \n",
        "Esta c√©lula garante que o utilit√°rio `ffmpeg` esteja instalado e dispon√≠vel no ambiente Google Colab. O ffmpeg √© indispens√°vel para a grava√ß√£o dos v√≠deos das transmiss√µes e para o processamento de m√≠dia ao longo do pipeline do notebook XCam.\n",
        "\n",
        "## Pontos principais e melhorias implementadas\n",
        "\n",
        "- **Verifica√ß√£o pr√©-instala√ß√£o:**  \n",
        "  Antes de instalar, verifica se o ffmpeg j√° est√° dispon√≠vel no ambiente, tornando o processo idempotente e eficiente.\n",
        "- **Instala√ß√£o automatizada:**  \n",
        "  Efetua a instala√ß√£o via `apt-get` apenas se necess√°rio, reduzindo o tempo de setup em execu√ß√µes futuras.\n",
        "- **Valida√ß√£o p√≥s-instala√ß√£o:**  \n",
        "  Exibe a vers√£o instalada do ffmpeg, garantindo transpar√™ncia e rastreabilidade.\n",
        "- **Mensagens detalhadas:**  \n",
        "  O usu√°rio recebe logs informativos sobre cada etapa, facilitando o diagn√≥stico em caso de erros.\n",
        "- **Design modular:**  \n",
        "  Estrutura pronta para ser utilizada em outros ambientes (Colab, local, server) com pequenas adapta√ß√µes.\n",
        "\n",
        "---\n",
        "\n",
        "## Como funciona a c√©lula\n",
        "\n",
        "- **Verifica se o ffmpeg est√° instalado (no PATH do sistema).**\n",
        "- **Se n√£o estiver, instala automaticamente via apt-get.**\n",
        "- **Valida e exibe a vers√£o instalada ap√≥s o processo.**\n",
        "- **Em caso de falha, exibe erro detalhado e interrompe o fluxo para evitar inconsist√™ncias futuras.**\n",
        "\n",
        "---\n",
        "\n",
        "## Exemplo de uso das fun√ß√µes nesta c√©lula\n",
        "\n",
        "```python\n",
        "if not is_ffmpeg_installed():\n",
        "    install_ffmpeg()\n",
        "show_ffmpeg_version()\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Seguran√ßa, rastreabilidade e manuten√ß√£o\n",
        "\n",
        "- A c√©lula torna o setup do ambiente mais robusto, impedindo falhas silenciosas relacionadas √† aus√™ncia de ffmpeg.\n",
        "- Mensagens e valida√ß√µes ajudam a equipe a identificar rapidamente problemas de ambiente ou permiss√µes.\n",
        "- O padr√£o modular facilita a reutiliza√ß√£o do c√≥digo em diferentes notebooks ou pipelines do projeto XCam.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "WXs0o6OPHXbi"
      },
      "id": "WXs0o6OPHXbi"
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================\n",
        "# C√©lula 2: Instala√ß√£o e Valida√ß√£o do FFMPEG no Colab e Linux\n",
        "# ================================================================\n",
        "# Objetivo:\n",
        "# - Garantir que o utilit√°rio ffmpeg est√° instalado e dispon√≠vel no ambiente (Colab ou Linux)\n",
        "# - Validar a instala√ß√£o e exibir a vers√£o instalada para rastreabilidade\n",
        "# - Tornar a etapa idempotente, evitando instala√ß√µes desnecess√°rias (safe to rerun)\n",
        "# - Fornecer feedback detalhado e logs a cada etapa para diagn√≥stico r√°pido\n",
        "#\n",
        "# Estrat√©gia aplicada:\n",
        "# - Checa se ffmpeg est√° dispon√≠vel no PATH do sistema\n",
        "# - Caso n√£o esteja, instala automaticamente via apt-get (compat√≠vel Colab/Linux)\n",
        "# - Valida a instala√ß√£o e exibe a vers√£o instalada\n",
        "# - Modularidade e robustez para uso em pipelines, CI/CD e ambientes colaborativos\n",
        "# ================================================================\n",
        "\n",
        "import subprocess   # Importa√ß√£o obrigat√≥ria para checagem e instala√ß√£o do ffmpeg\n",
        "import sys\n",
        "\n",
        "def is_ffmpeg_installed():\n",
        "    \"\"\"\n",
        "    Verifica se o ffmpeg est√° instalado e dispon√≠vel no PATH do sistema.\n",
        "    Retorna True se estiver, False caso contr√°rio.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        result = subprocess.run([\"ffmpeg\", \"-version\"], capture_output=True, text=True)\n",
        "        return result.returncode == 0\n",
        "    except Exception:\n",
        "        return False\n",
        "\n",
        "def install_ffmpeg():\n",
        "    \"\"\"\n",
        "    Instala o ffmpeg via apt-get caso n√£o esteja presente.\n",
        "    Somente para sistemas baseados em Debian/Ubuntu (inclui Google Colab).\n",
        "    \"\"\"\n",
        "    print(\"[INFO] Iniciando instala√ß√£o do ffmpeg via apt-get...\")\n",
        "    try:\n",
        "        # Atualiza pacotes e instala ffmpeg de forma silenciosa para logs limpos\n",
        "        subprocess.run(\"apt-get update -y\", shell=True, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "        subprocess.run(\"apt-get install -y ffmpeg\", shell=True, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "        print(\"[INFO] ffmpeg instalado com sucesso.\")\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"[ERRO] Falha ao instalar ffmpeg via apt-get: {e}\")\n",
        "        print(\"üî¥ Tente rodar manualmente ou verifique permiss√µes/root.\")\n",
        "        raise\n",
        "\n",
        "def show_ffmpeg_version():\n",
        "    \"\"\"\n",
        "    Exibe a vers√£o instalada do ffmpeg, se dispon√≠vel.\n",
        "    Mostra as duas primeiras linhas para rastreabilidade.\n",
        "    \"\"\"\n",
        "    print(\"[INFO] Vers√£o do ffmpeg instalada:\")\n",
        "    try:\n",
        "        result = subprocess.run([\"ffmpeg\", \"-version\"], capture_output=True, text=True)\n",
        "        if result.returncode == 0:\n",
        "            linhas = result.stdout.strip().split('\\n')\n",
        "            for l in linhas[:2]:\n",
        "                print(l)\n",
        "        else:\n",
        "            print(\"[ERRO] ffmpeg instalado, mas n√£o foi poss√≠vel obter a vers√£o.\")\n",
        "    except Exception as e:\n",
        "        print(f\"[ERRO] N√£o foi poss√≠vel exibir a vers√£o do ffmpeg: {e}\")\n",
        "\n",
        "# ================================================================\n",
        "# EXECU√á√ÉO DA ETAPA DE SETUP ‚Äî Sempre idempotente e segura\n",
        "# ================================================================\n",
        "\n",
        "if not is_ffmpeg_installed():\n",
        "    print(\"[WARN] ffmpeg n√£o encontrado no ambiente.\")\n",
        "    try:\n",
        "        install_ffmpeg()\n",
        "    except Exception:\n",
        "        raise RuntimeError(\"[ERRO] Falha ao instalar o ffmpeg. Verifique permiss√µes ou tente novamente.\")\n",
        "    if not is_ffmpeg_installed():\n",
        "        # √öltima checagem ap√≥s instala√ß√£o\n",
        "        raise RuntimeError(\"[ERRO] Falha ao instalar o ffmpeg. Verifique permiss√µes, root ou tente novamente.\")\n",
        "    else:\n",
        "        print(\"[OK] ffmpeg instalado e pronto para uso.\")\n",
        "else:\n",
        "    print(\"[OK] ffmpeg j√° est√° instalado no ambiente.\")\n",
        "\n",
        "show_ffmpeg_version()\n",
        "\n",
        "# ================================================================\n",
        "# FIM DA C√âLULA 2 ‚Äî Instala√ß√£o e Valida√ß√£o do ffmpeg\n",
        "# ================================================================\n",
        "#\n",
        "# Observa√ß√µes t√©cnicas:\n",
        "# - ffmpeg deve estar dispon√≠vel para todas as etapas do pipeline XCam.\n",
        "# - Para obter o caminho absoluto: subprocess.run(['which', 'ffmpeg'], capture_output=True, text=True).stdout.strip()\n",
        "# - C√©lula idempotente: pode ser executada m√∫ltiplas vezes sem efeitos colaterais.\n",
        "# - Pronta para uso em pipelines, scripts automatizados e ambientes colaborativos."
      ],
      "metadata": {
        "id": "vIODn0c2HiHz"
      },
      "id": "vIODn0c2HiHz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# C√©lula 3: Imports Essenciais, Utilit√°rios e Prepara√ß√£o do Ambiente\n",
        "\n",
        "**Objetivo:**  \n",
        "Importa todas as bibliotecas essenciais do Python necess√°rias para o funcionamento do notebook, incluindo m√≥dulos para requisi√ß√µes HTTP, processamento paralelo, manipula√ß√£o de datas, controle de subprocessos e exibi√ß√£o interativa.  \n",
        "Centraliza fun√ß√µes utilit√°rias robustas e padronizadas para processamento, download de poster, gera√ß√£o autom√°tica de poster com ffmpeg e exibi√ß√£o de progresso, totalmente integradas ao log √∫nico centralizado definido na C√©lula 1.\n",
        "\n",
        "## Principais pontos e melhorias implementadas\n",
        "\n",
        "- **Centraliza√ß√£o de imports essenciais:**  \n",
        "  Todos os m√≥dulos fundamentais (os, requests, multiprocessing, datetime, json, time, subprocess, math, re, IPython) est√£o dispon√≠veis e prontos para uso global.\n",
        "- **Fun√ß√µes utilit√°rias padronizadas:**  \n",
        "  Fun√ß√µes para formata√ß√£o de segundos, exibi√ß√£o de progresso, download e valida√ß√£o de poster, gera√ß√£o de poster via ffmpeg (com fallback e m√∫ltiplas tentativas) e integra√ß√£o direta ao log centralizado, seguindo Clean Architecture.\n",
        "- **Remo√ß√£o de logs tempor√°rios dispersos:**  \n",
        "  Toda rastreabilidade de eventos (incluindo processamento, blacklist, falhas e auditoria) agora √© feita apenas pelo log √∫nico centralizado (LOG_PATH), eliminando arquivos dispersos como LOG_PROCESSAMENTO_PATH, BLACKLIST_PATH ou FAILURE_LOG_PATH.\n",
        "- **Robustez, clareza e modularidade:**  \n",
        "  As fun√ß√µes possuem tratamento de erros, s√£o preparadas para uso concorrente, possuem fallback inteligente (poster placeholder) e integra√ß√£o autom√°tica com o pipeline e o log centralizado.\n",
        "- **Pronto para uso em todo o notebook:**  \n",
        "  Todas as fun√ß√µes aqui definidas s√£o utilizadas em toda a automa√ß√£o, promovendo reuso, legibilidade e manuten√ß√£o facilitada em pipelines concorrentes ou distribu√≠dos.\n",
        "\n",
        "---\n",
        "\n",
        "## Fun√ß√µes utilit√°rias dispon√≠veis nesta c√©lula\n",
        "\n",
        "- **`format_seconds(seconds)`**: Formata um valor em segundos para string leg√≠vel (ex: \"1h23m45s\").\n",
        "- **`log_progress(username, elapsed_seconds, total_seconds)`**: Exibe o progresso da grava√ß√£o de cada transmiss√£o.\n",
        "- **`download_and_save_poster(poster_url, username, temp_folder)`**: Baixa e salva o poster da transmiss√£o a partir de uma URL remota ou retorna se for um caminho local.\n",
        "- **`generate_poster_with_ffmpeg(m3u8_url, username, temp_folder, tries=(7,1,15,30), timeout=30)`**: Gera automaticamente um poster usando ffmpeg, tentando m√∫ltiplos pontos e, em caso de falha, gera um placeholder e registra o erro no log centralizado.\n",
        "- **`is_poster_valid(poster_path)`**: Verifica se o arquivo de poster √© v√°lido (existe e n√£o est√° vazio).\n",
        "\n",
        "---\n",
        "\n",
        "## Exemplo de uso das fun√ß√µes\n",
        "\n",
        "```python\n",
        "# Formatar segundos em string leg√≠vel\n",
        "tempo = format_seconds(385)\n",
        "\n",
        "# Exibir progresso\n",
        "log_progress(\"userNovo234\", 385, 12780)\n",
        "\n",
        "# Download do poster\n",
        "poster_path = download_and_save_poster(url_poster, \"userNovo234\", \"/content/temp\")\n",
        "\n",
        "# Gera√ß√£o autom√°tica de poster via ffmpeg (com fallback e registro no log)\n",
        "if not is_poster_valid(poster_path):\n",
        "    poster_path = generate_poster_with_ffmpeg(m3u8_url, \"userNovo234\", \"/content/temp\")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Seguran√ßa, rastreabilidade e manuten√ß√£o\n",
        "\n",
        "- Todas as fun√ß√µes s√£o preparadas para tratamento de erros, integra√ß√£o com processos concorrentes e fallback inteligente.\n",
        "- O log tempor√°rio de processamento foi removido, garantindo que todo o rastreio e auditoria sejam feitos via log √∫nico centralizado da C√©lula 1.\n",
        "- Fun√ß√µes de gera√ß√£o de poster integram fallback (placeholder) e registro detalhado de falhas no log central.\n",
        "- Coment√°rios detalhados facilitam manuten√ß√£o, entendimento e evolu√ß√£o do notebook para toda a equipe.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "90qvXC0rHtWb"
      },
      "id": "90qvXC0rHtWb"
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================\n",
        "# C√©lula 3: Imports Essenciais, Utilit√°rios e Prepara√ß√£o do Ambiente\n",
        "# ================================================================\n",
        "# Objetivo:\n",
        "# - Importar bibliotecas essenciais para todo o notebook\n",
        "# - Centralizar fun√ß√µes auxiliares de formata√ß√£o, download e gera√ß√£o de poster\n",
        "# - Remover depend√™ncias de logs tempor√°rios dispersos, integrando ao log √∫nico do sistema (LOG_PATH)\n",
        "# - Garantir robustez, clareza e modularidade para as pr√≥ximas c√©lulas\n",
        "#\n",
        "# Estrat√©gia aplicada:\n",
        "# - Apenas os imports necess√°rios para o funcionamento do notebook\n",
        "# - Fun√ß√µes auxiliares adaptadas para Clean Architecture e integra√ß√£o com o log centralizado (C√©lula 1)\n",
        "# - Fun√ß√£o de gera√ß√£o de poster com ffmpeg robusta, com m√∫ltiplas tentativas e fallback\n",
        "# - Modularidade: fun√ß√µes isoladas, reus√°veis, prontas para testes e integra√ß√£o\n",
        "# ================================================================\n",
        "\n",
        "import os\n",
        "import requests\n",
        "from multiprocessing import Manager, Process\n",
        "from datetime import datetime\n",
        "import json\n",
        "import time\n",
        "import subprocess\n",
        "import math\n",
        "import re\n",
        "import shutil\n",
        "import threading\n",
        "\n",
        "from IPython import get_ipython\n",
        "from IPython.display import display\n",
        "\n",
        "# ============================\n",
        "# UTILIT√ÅRIOS DE FORMATA√á√ÉO E PROGRESSO\n",
        "# ============================\n",
        "\n",
        "def format_seconds(seconds):\n",
        "    \"\"\"\n",
        "    Formata segundos em string leg√≠vel (e.g., 1h23m45s).\n",
        "    \"\"\"\n",
        "    total_seconds = int(seconds)\n",
        "    hours = total_seconds // 3600\n",
        "    minutes = (total_seconds % 3600) // 60\n",
        "    seconds = total_seconds % 60\n",
        "    parts = []\n",
        "    if hours > 0:\n",
        "        parts.append(f\"{hours}h\")\n",
        "    if minutes > 0 or (hours == 0 and seconds > 0):\n",
        "        parts.append(f\"{minutes}m\")\n",
        "    if seconds > 0 or total_seconds == 0:\n",
        "        parts.append(f\"{seconds}s\")\n",
        "    return \"\".join(parts) if parts else \"0s\"\n",
        "\n",
        "def log_progress(username, elapsed_seconds, total_seconds):\n",
        "    \"\"\"\n",
        "    Exibe progresso da grava√ß√£o de cada transmiss√£o em tempo real.\n",
        "    \"\"\"\n",
        "    percent = min((elapsed_seconds / total_seconds) * 100, 100)\n",
        "    tempo = format_seconds(elapsed_seconds)\n",
        "    minutos_gravados = math.floor(elapsed_seconds / 60)\n",
        "    minutos_restantes = max(0, math.ceil((total_seconds - elapsed_seconds) / 60))\n",
        "    print(f\"‚è±Ô∏è [{username}] Gravados: {minutos_gravados} min | Restantes: {minutos_restantes} min | Tempo total: {tempo} ‚Äî üìä {percent:.1f}% conclu√≠do\")\n",
        "\n",
        "# ============================\n",
        "# UTILIT√ÅRIO PARA DOWNLOAD DE POSTER\n",
        "# ============================\n",
        "\n",
        "def download_and_save_poster(poster_url, username, temp_folder):\n",
        "    \"\"\"\n",
        "    Baixa e salva o poster (thumbnail) a partir de uma URL HTTP/HTTPS.\n",
        "    Se for um caminho local existente, retorna esse caminho.\n",
        "    Retorna o caminho do arquivo salvo, ou None em caso de erro.\n",
        "    \"\"\"\n",
        "    # Se for um caminho local v√°lido, retorna diretamente\n",
        "    if os.path.exists(poster_url):\n",
        "        return poster_url\n",
        "    # Download de URL HTTP/HTTPS\n",
        "    if isinstance(poster_url, str) and (poster_url.startswith(\"http://\") or poster_url.startswith(\"https://\")):\n",
        "        try:\n",
        "            response = requests.get(poster_url, timeout=15)\n",
        "            response.raise_for_status()\n",
        "            ext = os.path.splitext(poster_url)[1].lower()\n",
        "            if ext not in [\".jpg\", \".jpeg\", \".png\"]:\n",
        "                ext = \".jpg\"\n",
        "            poster_temp_path = os.path.join(temp_folder, f\"{username}_poster_temp{ext}\")\n",
        "            with open(poster_temp_path, \"wb\") as f:\n",
        "                f.write(response.content)\n",
        "            print(f\"üñºÔ∏è Poster baixado em: {poster_temp_path}\")\n",
        "            return poster_temp_path\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Erro ao baixar poster {poster_url}: {e}\")\n",
        "            return None\n",
        "    else:\n",
        "        print(f\"‚ùå poster_url inv√°lido ou n√£o encontrado: {poster_url}\")\n",
        "        return None\n",
        "\n",
        "# ============================\n",
        "# UTILIT√ÅRIO PARA GERAR POSTER COM FFMPEG (com fallback e log central)\n",
        "# ============================\n",
        "\n",
        "def generate_poster_with_ffmpeg(m3u8_url, username, temp_folder, tries=(3, 1, 7, 15, 30), timeout=30):\n",
        "    \"\"\"\n",
        "    Gera um poster (screenshot) usando ffmpeg a partir da URL .m3u8 da transmiss√£o.\n",
        "    Tenta m√∫ltiplos pontos no v√≠deo caso haja erro (robustez).\n",
        "    Integra ao log centralizado via append_log em caso de falha.\n",
        "    Retorna o caminho do arquivo gerado ou None em caso de erro.\n",
        "    \"\"\"\n",
        "    from IPython.display import clear_output\n",
        "    import requests # Garantir requests est√° importado aqui\n",
        "\n",
        "    # --- Checa se a URL est√° acess√≠vel antes de rodar ffmpeg ---\n",
        "    try:\n",
        "        # Usar um timeout curto para a checagem inicial\n",
        "        head_resp = requests.head(m3u8_url, timeout=5)\n",
        "        if not head_resp.ok:\n",
        "            msg = f\"Stream offline ou n√£o dispon√≠vel para {username} (status {head_resp.status_code})\"\n",
        "            print(f\"‚ö†Ô∏è {msg}\")\n",
        "            # Registrar falha de conex√£o no log central\n",
        "            if \"register_failure\" in globals():\n",
        "                 register_failure(username, msg)\n",
        "            return None # Retorna None imediatamente se a stream n√£o estiver acess√≠vel\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        msg = f\"Erro de conex√£o ao acessar stream de {username}: {e}\"\n",
        "        print(f\"‚ùå {msg}\")\n",
        "        # Registrar falha de conex√£o no log central\n",
        "        if \"register_failure\" in globals():\n",
        "             register_failure(username, msg)\n",
        "        return None # Retorna None imediatamente em caso de erro de conex√£o\n",
        "    except Exception as e:\n",
        "        msg = f\"Erro inesperado na checagem de stream para {username}: {e}\"\n",
        "        print(f\"‚ùå {msg}\")\n",
        "        # Registrar falha gen√©rica na checagem\n",
        "        if \"register_failure\" in globals():\n",
        "             register_failure(username, msg)\n",
        "        return None # Retorna None em caso de qualquer outra exce√ß√£o na checagem\n",
        "\n",
        "\n",
        "    # --- Tenta gerar poster com ffmpeg (se a checagem inicial passou) ---\n",
        "    for frame_time in tries:\n",
        "        poster_ffmpeg_path = os.path.join(temp_folder, f\"{username}_poster_ffmpeg_{frame_time}.jpg\")\n",
        "        command = [\n",
        "            \"ffmpeg\",\n",
        "            \"-y\",\n",
        "            \"-analyzeduration\", \"10M\",\n",
        "            \"-probesize\", \"50M\",\n",
        "            \"-ss\", str(frame_time),\n",
        "            \"-i\", m3u8_url,\n",
        "            \"-vframes\", \"1\",\n",
        "            \"-q:v\", \"2\",\n",
        "            poster_ffmpeg_path\n",
        "        ]\n",
        "        try:\n",
        "            print(f\"üé¨ Tentando gerar poster para {username} com ffmpeg no segundo {frame_time}...\")\n",
        "            result = subprocess.run(\n",
        "                command,\n",
        "                stdout=subprocess.PIPE,\n",
        "                stderr=subprocess.PIPE,\n",
        "                timeout=timeout\n",
        "            )\n",
        "            if result.returncode == 0 and os.path.exists(poster_ffmpeg_path) and os.path.getsize(poster_ffmpeg_path) > 0:\n",
        "                print(f\"üñºÔ∏è Poster gerado via ffmpeg: {poster_ffmpeg_path}\")\n",
        "                # Limpa falhas relacionadas a poster/ffmpeg se a gera√ß√£o for bem-sucedida\n",
        "                if \"clear_failure\" in globals():\n",
        "                    clear_failure(username)\n",
        "                return poster_ffmpeg_path\n",
        "            else:\n",
        "                msg = f\"ffmpeg n√£o conseguiu gerar poster para {username} no segundo {frame_time}. C√≥digo: {result.returncode}\"\n",
        "                print(f\"‚ùå {msg}\\nSTDOUT:\\n{result.stdout.decode(errors='ignore')}\\nSTDERR:\\n{result.stderr.decode(errors='ignore')}\")\n",
        "                # Registrar falha espec√≠fica de ffmpeg no log central\n",
        "                if \"append_log\" in globals():\n",
        "                    append_log({\n",
        "                        \"sessao\": \"poster\",\n",
        "                        \"evento\": \"erro_ffmpeg_frame\",\n",
        "                        \"id\": username,\n",
        "                        \"username\": username,\n",
        "                        \"status\": \"erro\",\n",
        "                        \"detalhes\": f\"{msg} | stdout: {result.stdout.decode(errors='ignore')[:200]} | stderr: {result.stderr.decode(errors='ignore')[:200]}\"\n",
        "                    })\n",
        "\n",
        "        except subprocess.TimeoutExpired:\n",
        "            msg = f\"Tempo excedido ao tentar gerar poster para {username} via ffmpeg (segundo {frame_time}).\"\n",
        "            print(f\"‚è∞ {msg}\")\n",
        "            # Registrar timeout de ffmpeg no log central\n",
        "            if \"append_log\" in globals():\n",
        "                append_log({\n",
        "                    \"sessao\": \"poster\",\n",
        "                    \"evento\": \"timeout_ffmpeg\",\n",
        "                    \"id\": username,\n",
        "                    \"username\": username,\n",
        "                    \"status\": \"erro\",\n",
        "                    \"detalhes\": msg\n",
        "                })\n",
        "        except Exception as e:\n",
        "            msg = f\"Erro inesperado ao rodar ffmpeg para poster ({username}, segundo {frame_time}): {e}\"\n",
        "            print(f\"‚ùå {msg}\")\n",
        "            # Registrar exce√ß√£o de ffmpeg no log central\n",
        "            if \"append_log\" in globals():\n",
        "                append_log({\n",
        "                    \"sessao\": \"poster\",\n",
        "                    \"evento\": \"excecao_ffmpeg\",\n",
        "                    \"id\": username,\n",
        "                    \"username\": username,\n",
        "                    \"status\": \"erro\",\n",
        "                    \"detalhes\": msg\n",
        "                })\n",
        "\n",
        "\n",
        "    # --- Fallback: gera um poster placeholder se todas as tentativas falharem ---\n",
        "    placeholder_path = os.path.join(temp_folder, f\"{username}_placeholder.jpg\")\n",
        "    try:\n",
        "        from PIL import Image, ImageDraw\n",
        "        img = Image.new('RGB', (640, 360), color=(80, 80, 80))\n",
        "        d = ImageDraw.Draw(img)\n",
        "        d.text((10, 150), f\"Poster indispon√≠vel\\n{username}\", fill=(255, 255, 255))\n",
        "        img.save(placeholder_path)\n",
        "        print(f\"‚ö†Ô∏è Poster placeholder gerado para {username}: {placeholder_path}\")\n",
        "        # Registrar gera√ß√£o de placeholder no log central\n",
        "        if \"append_log\" in globals():\n",
        "             append_log({\n",
        "                 \"sessao\": \"poster\",\n",
        "                 \"evento\": \"placeholder_gerado\",\n",
        "                 \"id\": username,\n",
        "                 \"username\": username,\n",
        "                 \"status\": \"aviso\",\n",
        "                 \"detalhes\": f\"Poster placeholder gerado ap√≥s falha no ffmpeg.\"\n",
        "             })\n",
        "        return placeholder_path\n",
        "    except Exception as e:\n",
        "        msg = f\"Erro ao gerar placeholder para {username}: {e}\"\n",
        "        print(f\"‚ùå {msg}\")\n",
        "        # Registrar falha na gera√ß√£o de placeholder no log central\n",
        "        if \"append_log\" in globals():\n",
        "             append_log({\n",
        "                 \"sessao\": \"poster\",\n",
        "                 \"evento\": \"erro_placeholder\",\n",
        "                 \"id\": username,\n",
        "                 \"username\": username,\n",
        "                 \"status\": \"erro\",\n",
        "                 \"detalhes\": msg\n",
        "             })\n",
        "        return None\n",
        "\n",
        "# ============================\n",
        "# VALIDA√á√ÉO DE POSTER\n",
        "# ============================\n",
        "\n",
        "def is_poster_valid(poster_path):\n",
        "    \"\"\"\n",
        "    Verifica se o poster existe e n√£o est√° vazio.\n",
        "    \"\"\"\n",
        "    return poster_path and os.path.exists(poster_path) and os.path.getsize(poster_path) > 0\n",
        "\n",
        "# ============================\n",
        "# FIM DA C√âLULA 3\n",
        "# ============================\n",
        "\n",
        "# Observa√ß√µes:\n",
        "# - Todas as fun√ß√µes de logging, blacklist, falha e auditoria devem ser feitas via utilit√°rio de log centralizado (C√©lula 1).\n",
        "# - LOG_PROCESSAMENTO_PATH, BLACKLIST_PATH, FAILURE_LOG_PATH e outros logs dispersos n√£o devem mais ser usados.\n",
        "# - O pipeline est√° pronto para Clean Architecture, m√°xima rastreabilidade e integra√ß√£o.\n",
        "# - Fun√ß√µes aqui s√£o modulares, reus√°veis e preparadas para tratamento de exce√ß√µes e logging detalhado."
      ],
      "metadata": {
        "id": "hOetz0nGICkz"
      },
      "id": "hOetz0nGICkz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# C√©lula 4: Clonagem do Reposit√≥rio GitHub no Colab e Google Drive\n",
        "\n",
        "**Objetivo:**  \n",
        "Esta c√©lula garante que o reposit√≥rio do projeto XCam seja sempre clonado de forma limpa e sincronizada no ambiente local do Colab e, se dispon√≠vel, tamb√©m no Google Drive para persist√™ncia.  \n",
        "Assegura ambiente pronto, atualizado, seguro para grava√ß√µes e processamento, e prepara diret√≥rios padronizados para integra√ß√£o com o restante do pipeline.\n",
        "\n",
        "## Principais pontos e melhorias implementadas\n",
        "\n",
        "- **Clonagem idempotente e limpa:**  \n",
        "  Remove reposit√≥rios antigos antes de clonar para evitar conflitos, arquivos √≥rf√£os ou problemas de sincroniza√ß√£o.\n",
        "- **Clonagem para ambiente tempor√°rio e persistente:**  \n",
        "  O reposit√≥rio √© clonado tanto para `/content` (Colab) quanto para o Drive (`/content/drive/MyDrive/XCam.Drive`) se o Drive estiver montado.\n",
        "- **Prepara√ß√£o de diret√≥rios de grava√ß√£o e processamento:**  \n",
        "  Estrutura de diret√≥rios tempor√°rios criada automaticamente, garantindo organiza√ß√£o dos dados.\n",
        "- **Exporta√ß√£o de vari√°veis globais:**  \n",
        "  Todos os caminhos, URLs e configura√ß√µes relevantes s√£o disponibilizados via `globals().update()` para uso em todo o notebook.\n",
        "- **Mensagens e valida√ß√µes detalhadas:**  \n",
        "  Feedback informativo sobre o status de cada etapa, facilitando o diagn√≥stico e a manuten√ß√£o.\n",
        "- **Pronto para CI/CD e integra√ß√µes futuras:**  \n",
        "  Token e URLs preparados para automa√ß√µes, integra√ß√µes externas e uploads (Abyss.to, etc).\n",
        "\n",
        "---\n",
        "\n",
        "## Par√¢metros globais definidos nesta c√©lula\n",
        "\n",
        "- **`GITHUB_USER`**, **`GITHUB_REPO`**, **`GITHUB_BRANCH`**, **`GITHUB_TOKEN`**: Configura√ß√µes do reposit√≥rio e autentica√ß√£o.\n",
        "- **`repo_url`**: URL do reposit√≥rio autenticada para clone/push.\n",
        "- **`TEMP_OUTPUT_FOLDER`**: Pasta para grava√ß√µes tempor√°rias.\n",
        "- **`BASE_REPO_FOLDER`**: Localiza√ß√£o do reposit√≥rio no ambiente Colab.\n",
        "- **`DRIVE_MOUNT`**, **`DRIVE_REPO_FOLDER`**: Caminhos no Google Drive para persist√™ncia (se montado).\n",
        "- **`ABYSS_UPLOAD_URL`**: URL de upload para integra√ß√£o com sistemas externos.\n",
        "\n",
        "---\n",
        "\n",
        "## Como funciona a c√©lula\n",
        "\n",
        "- **Remove reposit√≥rios antigos e diret√≥rios tempor√°rios**, evitando res√≠duos de execu√ß√µes anteriores.\n",
        "- **Clona o reposit√≥rio do GitHub** para `/content` (Colab).\n",
        "- **Se o Google Drive estiver montado**, faz o mesmo clone no diret√≥rio persistente do Drive.\n",
        "- **Cria diret√≥rios tempor√°rios necess√°rios** para grava√ß√µes e arquivos intermedi√°rios.\n",
        "- **Exporta todas as vari√°veis configuradas** para uso global no notebook.\n",
        "- **Exibe mensagens informativas** sobre cada etapa e alerta caso o Drive n√£o esteja dispon√≠vel.\n",
        "\n",
        "---\n",
        "\n",
        "## Exemplo de uso das vari√°veis globais\n",
        "\n",
        "```python\n",
        "print(BASE_REPO_FOLDER)        # Caminho do reposit√≥rio clonado no Colab\n",
        "print(DRIVE_REPO_FOLDER)      # Caminho do reposit√≥rio no Drive (se montado)\n",
        "print(TEMP_OUTPUT_FOLDER)     # Pasta tempor√°ria para grava√ß√µes\n",
        "print(ABYSS_UPLOAD_URL)       # URL de upload para integra√ß√£o externa\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Seguran√ßa, rastreabilidade e manuten√ß√£o\n",
        "\n",
        "- Garantia de ambiente limpo a cada execu√ß√£o, evitando conflitos de arquivos e branches.\n",
        "- Persist√™ncia dos dados no Drive (se montado), evitando perda de grava√ß√µes em caso de reinicializa√ß√£o do Colab.\n",
        "- Coment√°rios detalhados e estrutura modular facilitam a manuten√ß√£o, integra√ß√£o com CI/CD e futuras expans√µes no pipeline do XCam.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "hpRIMtyFIY0q"
      },
      "id": "hpRIMtyFIY0q"
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================\n",
        "# C√©lula 4: Clonagem do Reposit√≥rio GitHub no Colab e no Google Drive\n",
        "# ================================================================\n",
        "# Objetivo:\n",
        "# - Garantir ambiente limpo e sincronizado para o reposit√≥rio XCam em todas as execu√ß√µes\n",
        "# - Clonar o reposit√≥rio tanto para o ambiente ef√™mero do Colab quanto para o Google Drive (persist√™ncia)\n",
        "# - Preparar diret√≥rios de trabalho para grava√ß√µes e processamento tempor√°rio\n",
        "# - Fornecer feedback claro sobre o status da opera√ß√£o\n",
        "#\n",
        "# Estrat√©gia aplicada:\n",
        "# - Remove reposit√≥rios antigos antes de clonar (evita conflitos e arquivos √≥rf√£os)\n",
        "# - Utiliza token pessoal para autentica√ß√£o segura e push futuro (CI/CD)\n",
        "# - Cria estrutura de diret√≥rios padronizada (m√≥dulos, grava√ß√µes, cache, etc.)\n",
        "# - Valida se o Drive est√° montado antes de tentar opera√ß√µes persistentes\n",
        "# - Coment√°rios detalhados para f√°cil manuten√ß√£o e evolu√ß√£o\n",
        "# ================================================================\n",
        "\n",
        "# ============================\n",
        "# CONFIGURA√á√ïES DO GITHUB\n",
        "# ============================\n",
        "GITHUB_USER = \"SamuelPassamani\"\n",
        "GITHUB_REPO = \"XCam\"\n",
        "GITHUB_BRANCH = \"main\"\n",
        "GITHUB_TOKEN = \"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\"\n",
        "\n",
        "repo_url = f\"https://{GITHUB_USER}:{GITHUB_TOKEN}@github.com/{GITHUB_USER}/{GITHUB_REPO}.git\"\n",
        "\n",
        "# ============================\n",
        "# CLONAGEM PARA O COLAB\n",
        "# ============================\n",
        "print(f\"‚è≥ Limpando ambiente e clonando '{GITHUB_REPO}' para o Colab...\")\n",
        "!rm -rf {GITHUB_REPO}\n",
        "!git clone -b {GITHUB_BRANCH} {repo_url}\n",
        "print(f\"‚úÖ Reposit√≥rio clonado em /content/{GITHUB_REPO}\")\n",
        "\n",
        "# ============================\n",
        "# ESTRUTURA DE DIRET√ìRIOS TEMPOR√ÅRIOS\n",
        "# ============================\n",
        "TEMP_OUTPUT_FOLDER = \"/content/temp_recordings\"  # Para grava√ß√µes tempor√°rias\n",
        "os.makedirs(TEMP_OUTPUT_FOLDER, exist_ok=True)\n",
        "BASE_REPO_FOLDER = f\"/content/{GITHUB_REPO}\"\n",
        "\n",
        "# ============================\n",
        "# CLONAGEM PARA O GOOGLE DRIVE (PERSIST√äNCIA)\n",
        "# ============================\n",
        "DRIVE_MOUNT = \"/content/drive/MyDrive/XCam.Drive\"\n",
        "DRIVE_REPO_FOLDER = f\"{DRIVE_MOUNT}/{GITHUB_REPO}\"\n",
        "\n",
        "if os.path.exists(DRIVE_MOUNT):\n",
        "    print(f\"‚è≥ Limpando reposit√≥rio antigo no Drive (se existir)...\")\n",
        "    !rm -rf \"{DRIVE_REPO_FOLDER}\"\n",
        "    print(f\"‚è≥ Clonando '{GITHUB_REPO}' para o Drive em {DRIVE_REPO_FOLDER} ...\")\n",
        "    !git clone -b {GITHUB_BRANCH} {repo_url} \"{DRIVE_REPO_FOLDER}\"\n",
        "    print(f\"‚úÖ Reposit√≥rio tamb√©m clonado no Drive: {DRIVE_REPO_FOLDER}\")\n",
        "else:\n",
        "    print(f\"‚ö†Ô∏è Google Drive n√£o est√° montado em {DRIVE_MOUNT}.\\n‚ÑπÔ∏è Use a c√©lula de montagem antes de prosseguir para garantir persist√™ncia.\")\n",
        "\n",
        "# ============================\n",
        "# CONFIGURA√á√ÉO DE ENDPOINTS DE UPLOAD/INTEGRA√á√ÉO\n",
        "# ============================\n",
        "ABYSS_UPLOAD_URL = 'http://up.hydrax.net/0128263f78f0b426d617bb61c2a8ff43'\n",
        "globals().update({\n",
        "    'GITHUB_USER': GITHUB_USER,\n",
        "    'GITHUB_REPO': GITHUB_REPO,\n",
        "    'GITHUB_BRANCH': GITHUB_BRANCH,\n",
        "    'GITHUB_TOKEN': GITHUB_TOKEN,\n",
        "    'repo_url': repo_url,\n",
        "    'TEMP_OUTPUT_FOLDER': TEMP_OUTPUT_FOLDER,\n",
        "    'BASE_REPO_FOLDER': BASE_REPO_FOLDER,\n",
        "    'DRIVE_MOUNT': DRIVE_MOUNT,\n",
        "    'DRIVE_REPO_FOLDER': DRIVE_REPO_FOLDER,\n",
        "    'ABYSS_UPLOAD_URL': ABYSS_UPLOAD_URL\n",
        "})\n",
        "\n",
        "# ============================\n",
        "# FIM DA C√âLULA 4\n",
        "# ============================\n",
        "\n",
        "# Observa√ß√µes:\n",
        "# - Os caminhos globais s√£o exportados via globals().update() para uso em todo o notebook.\n",
        "# - Recomenda-se sempre rodar esta c√©lula ap√≥s alterar tokens ou trocar branches para garantir ambiente limpo e sincronizado.\n",
        "# - O endpoint ABYSS_UPLOAD_URL pode ser atualizado conforme integra√ß√µes futuras."
      ],
      "metadata": {
        "id": "Uof_0QCrIlf7"
      },
      "id": "Uof_0QCrIlf7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# C√©lula 5: Commit e Push Autom√°ticos (rec.json, posters, etc.)\n",
        "\n",
        "**Objetivo:**  \n",
        "Automatiza o processo de commit e push dos arquivos modificados (ex: rec.json, posters e demais artefatos importantes) para o reposit√≥rio GitHub, garantindo rastreabilidade, atomicidade e integra√ß√£o cont√≠nua (CI/CD) do pipeline XCam.\n",
        "\n",
        "## Principais pontos e melhorias implementadas\n",
        "\n",
        "- **Fun√ß√£o robusta e modular:**  \n",
        "  A fun√ß√£o `git_commit_and_push()` aceita um caminho √∫nico (string) ou uma lista de arquivos, permitindo commit em lote e integra√ß√£o com estrat√©gias de batch commit (threshold).\n",
        "- **Configura√ß√£o automatizada de usu√°rio e e-mail do git:**  \n",
        "  Garante commits v√°lidos para rastreabilidade, auditoria e integra√ß√£o com pipelines autom√°ticos.\n",
        "- **Valida√ß√£o de caminhos e mensagens informativas:**  \n",
        "  Apenas arquivos existentes s√£o adicionados. Mensagens de sucesso, erro ou aviso detalhadas facilitam troubleshooting e manuten√ß√£o.\n",
        "- **Compat√≠vel com commit vazio:**  \n",
        "  Permite o uso do par√¢metro `--allow-empty` para garantir que o pipeline siga mesmo sem altera√ß√µes detectadas, √∫til para sincroniza√ß√£o e CI/CD.\n",
        "- **Push autenticado via token:**  \n",
        "  Utiliza o token pessoal fornecido nas vari√°veis globais para garantir push seguro e sem interven√ß√£o manual.\n",
        "- **Design pronto para integra√ß√£o com logs centralizados:**  \n",
        "  Recomenda-se registrar todas as a√ß√µes relevantes de commit/push utilizando o log √∫nico modular definido na C√©lula 1.\n",
        "\n",
        "---\n",
        "\n",
        "## Par√¢metros e vari√°veis globais utilizados\n",
        "\n",
        "- **`GITHUB_USER`**, **`GITHUB_REPO`**, **`GITHUB_TOKEN`**: Definidos nas c√©lulas anteriores para autentica√ß√£o e configura√ß√£o do reposit√≥rio.\n",
        "- **`repo_dir`**: Caminho absoluto do reposit√≥rio clonado no ambiente Colab.\n",
        "- **`file_paths`**: String ou lista de arquivos a serem commitados e enviados.\n",
        "- **`commit_message`**: Mensagem do commit, customiz√°vel conforme a opera√ß√£o realizada.\n",
        "\n",
        "---\n",
        "\n",
        "## Como funciona a fun√ß√£o principal\n",
        "\n",
        "- **Valida a exist√™ncia do reposit√≥rio local** antes de prosseguir.\n",
        "- **Aceita arquivos √∫nicos ou m√∫ltiplos** para commit (string ou lista).\n",
        "- **Adiciona apenas arquivos existentes** ao staging, com avisos para arquivos n√£o encontrados.\n",
        "- **Realiza commit (mesmo vazio) e push autenticado** para o reposit√≥rio remoto.\n",
        "- **Emite mensagens claras** de sucesso, erro ou aviso ao longo do processo.\n",
        "\n",
        "---\n",
        "\n",
        "## Exemplo de uso t√≠pico\n",
        "\n",
        "```python\n",
        "# Commit e push de um √∫nico arquivo\n",
        "git_commit_and_push(\"data/rec.json\", \"Atualiza rec.json de grava√ß√£o\")\n",
        "\n",
        "# Commit e push em lote (lista de arquivos)\n",
        "git_commit_and_push([\n",
        "    \"data/rec.json\",\n",
        "    \"posters/user1_poster.jpg\",\n",
        "    \"posters/user2_poster.jpg\"\n",
        "], \"Batch commit de m√∫ltiplos arquivos\")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Seguran√ßa, rastreabilidade e manuten√ß√£o\n",
        "\n",
        "- **Rastreabilidade garantida** por mensagens de commit claras e integra√ß√£o recomendada com o log modular (C√©lula 1).\n",
        "- **Atomicidade** em opera√ß√µes batch, evitando inconsist√™ncias de dados no reposit√≥rio.\n",
        "- **Pronto para integra√ß√£o com pipelines CI/CD**, webhooks e controles de auditoria.\n",
        "- **Mensagens e tratamento de erros detalhados** facilitam o diagn√≥stico e a evolu√ß√£o do sistema.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "M5iL_9BoIoj7"
      },
      "id": "M5iL_9BoIoj7"
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================\n",
        "# C√©lula 5: Commit e Push Autom√°ticos (rec.json, posters, etc.)\n",
        "# ================================================================\n",
        "# Objetivo:\n",
        "# - Automatizar o processo de commit e push dos arquivos modificados (rec.json, posters, etc.) para o reposit√≥rio GitHub\n",
        "# - Suportar tanto commit de arquivo √∫nico como em lote, permitindo estrat√©gia de batch commit baseada em thresholds\n",
        "# - Garantir rastreabilidade, atomicidade e integra√ß√£o segura (CI/CD)\n",
        "#\n",
        "# Estrat√©gia aplicada:\n",
        "# - Fun√ß√£o modular e robusta, preparada para integra√ß√£o com logs e auditoria\n",
        "# - Permite commit vazio por seguran√ßa, evitando falhas em pipelines sincronizados\n",
        "# - Mensagens e tratamento de erros detalhados para facilitar troubleshooting\n",
        "# - Utiliza√ß√£o de vari√°veis globais para caminhos, usu√°rio e token definidos nas c√©lulas anteriores\n",
        "# - Design pronto para evolu√ß√£o, reuso e integra√ß√£o com ferramentas externas (ex: webhooks, jobs, etc.)\n",
        "# ================================================================\n",
        "\n",
        "# A l√≥gica de commit e push agora √© gerenciada por um script externo.\n",
        "# Esta c√©lula foi mantida para refer√™ncia, mas a fun√ß√£o git_commit_and_push\n",
        "# foi removida pois n√£o ser√° mais executada internamente.\n",
        "\n",
        "# def git_commit_and_push(file_paths, commit_message=\"Atualiza rec.json\"):\n",
        "#     \"\"\"\n",
        "#     Realiza git add, commit e push dos arquivos especificados.\n",
        "#     - file_paths pode ser uma string (arquivo √∫nico) ou uma lista de arquivos.\n",
        "#     - commit_message √© a mensagem de commit utilizada.\n",
        "\n",
        "#     Estrat√©gia:\n",
        "#     - Ajusta diret√≥rio para o reposit√≥rio local clonado no Colab\n",
        "#     - Configura usu√°rio e e-mail do git (necess√°rios para CI/CD)\n",
        "#     - Adiciona arquivos ao staging (aceita m√∫ltiplos arquivos)\n",
        "#     - Realiza commit (permite commit vazio)\n",
        "#     - Realiza push autenticado via token\n",
        "#     \"\"\"\n",
        "#     # ============================\n",
        "#     # VALIDA√á√ÉO E AJUSTE DE ENTRADAS\n",
        "#     # ============================\n",
        "#     repo_dir = f\"/content/{GITHUB_REPO}\"\n",
        "#     if not os.path.exists(repo_dir):\n",
        "#         raise FileNotFoundError(f\"Reposit√≥rio '{repo_dir}' n√£o encontrado. Verifique se a c√©lula de clonagem foi executada.\")\n",
        "#     os.chdir(repo_dir)\n",
        "\n",
        "#     # Aceita string ou lista de arquivos\n",
        "#     if isinstance(file_paths, str):\n",
        "#         file_paths = [file_paths]\n",
        "#     elif not isinstance(file_paths, list):\n",
        "#         raise ValueError(\"file_paths deve ser uma string ou uma lista de caminhos.\")\n",
        "\n",
        "#     # ============================\n",
        "#     # CONFIGURA√á√ÉO DO USU√ÅRIO GIT (CI/CD)\n",
        "#     # ============================\n",
        "#     subprocess.run([\"git\", \"config\", \"user.email\", \"contato@aserio.work\"], check=True)\n",
        "#     subprocess.run([\"git\", \"config\", \"user.name\", \"SamuelPassamani\"], check=True)\n",
        "\n",
        "#     # ============================\n",
        "#     # ADI√á√ÉO DOS ARQUIVOS AO STAGING\n",
        "#     # ============================\n",
        "#     for file_path in file_paths:\n",
        "#         # Verifica se o arquivo existe antes de adicionar\n",
        "#         if not os.path.exists(file_path):\n",
        "#             print(f\"‚ö†Ô∏è Aviso: arquivo '{file_path}' n√£o existe e ser√° ignorado no commit.\")\n",
        "#             continue\n",
        "#         subprocess.run([\"git\", \"add\", file_path], check=True)\n",
        "\n",
        "#     # ============================\n",
        "#     # COMMIT (PERMITE COMMIT VAZIO)\n",
        "#     # ============================\n",
        "#     try:\n",
        "#         subprocess.run(\n",
        "#             [\"git\", \"commit\", \"-m\", commit_message, \"--allow-empty\"],\n",
        "#             check=False  # N√£o for√ßa erro se n√£o houver mudan√ßas\n",
        "#         )\n",
        "#     except Exception as e:\n",
        "#         print(f\"‚ùå Erro ao tentar realizar commit: {e}\")\n",
        "\n",
        "#     # ============================\n",
        "#     # PUSH PARA O REPOSIT√ìRIO REMOTO (AUTENTICADO)\n",
        "#     # ============================\n",
        "#     try:\n",
        "#         remote_url = f\"https://{GITHUB_USER}:{GITHUB_TOKEN}@github.com/{GITHUB_USER}/{GITHUB_REPO}.git\"\n",
        "#         subprocess.run(\n",
        "#             [\"git\", \"push\", remote_url],\n",
        "#             check=True\n",
        "#         )\n",
        "#         print(f\"‚úÖ Push realizado com sucesso! ({commit_message})\")\n",
        "#     except Exception as e:\n",
        "#         print(f\"‚ùå Erro ao tentar realizar push: {e}\")\n",
        "\n",
        "# ============================\n",
        "# FIM DA C√âLULA 5\n",
        "# ============================\n",
        "\n",
        "# Dicas e melhores pr√°ticas:\n",
        "# - A l√≥gica de commit e push agora √© gerenciada por um script externo.\n",
        "# - Certifique-se de que seu script externo gerencie corretamente o commit e push\n",
        "#   dos arquivos alterados (como o rec.json e os posters).\n",
        "# - Monitore os logs do seu script externo para verificar o status dos commits e pushes."
      ],
      "metadata": {
        "id": "1aQn1G6yI6Gz"
      },
      "id": "1aQn1G6yI6Gz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# C√©lula 6: Busca de Transmiss√µes na API XCam, Blacklist Tempor√°ria, Fallback via liveInfo e Busca Inteligente/Unit√°ria ‚Äî Centraliza√ß√£o no Log √önico\n",
        "\n",
        "**Objetivo:**  \n",
        "Realizar a busca das transmiss√µes ativas na API principal da XCam, mantendo o lote de transmiss√µes sempre completo at√© o `LIMIT_DEFAULT` e sem duplicidades, utilizando agora o controle de blacklist tempor√°ria, falhas e transmiss√µes em processamento **totalmente centralizados no log √∫nico** (`xcam_master.log`).  \n",
        "Inclui fun√ß√µes de busca unit√°ria/inteligente (para manter ‚Äúlote cheio‚Äù continuamente), gerenciamento autom√°tico de poster com gera√ß√£o via ffmpeg e rastreabilidade m√°xima para auditoria e manuten√ß√£o.\n",
        "\n",
        "## Estrat√©gia e melhorias implementadas\n",
        "\n",
        "- **Blacklist e controle de falhas centralizados:**  \n",
        "  Usu√°rios problem√°ticos s√£o bloqueados temporariamente ap√≥s atingirem o limite de falhas (`BLACKLIST_MAX_FAILURES`), com todos os eventos registrados via sess√µes (`sessao`) no log √∫nico.  \n",
        "  N√£o h√° mais leitura ou escrita em arquivos dispersos de blacklist/falha ‚Äî toda consulta e registro √© feita por fun√ß√µes do log central (`append_log`, `query_logs`, `remove_logs`).\n",
        "- **Busca em lote e unit√°ria com fallback:**  \n",
        "  Consulta a API principal com limite alto para preencher o lote rapidamente; fallback autom√°tico via `/liveInfo` para usu√°rios sem `src`.\n",
        "- **Controle de duplicidade e fila inteligente:**  \n",
        "  Antes de incluir qualquer transmiss√£o, verifica no log central se j√° est√° em processamento (`sessao=\"processing\"`), al√©m de checar blacklist, evitando tentativas repetidas ou travamento em streams problem√°ticos.\n",
        "- **Poster garantido:**  \n",
        "  Se o poster estiver ausente, inv√°lido ou nulo, gera automaticamente uma imagem via ffmpeg a partir do stream, garantindo sempre um arquivo v√°lido para cada transmiss√£o.\n",
        "- **Efici√™ncia, paralelismo e rastreabilidade:**  \n",
        "  Fun√ß√µes preparadas para execu√ß√£o concorrente e integra√ß√£o CI/CD, com toda a rastreabilidade poss√≠vel (inclusive limpeza autom√°tica de eventos expirados).\n",
        "- **Compatibilidade com busca de usu√°rios espec√≠ficos:**  \n",
        "  Busca protegida por blacklist/falhas, fallback via `/liveInfo` e controle de processamento j√° em lote.\n",
        "- **Design modular e Clean Architecture:**  \n",
        "  Fun√ß√µes separadas para busca em lote (`get_broadcasts`), busca por usu√°rios (`buscar_usuarios_especificos`) e busca unit√°ria/primeira transmiss√£o livre (`buscar_proxima_transmissao_livre`), todas com integra√ß√£o nativa ao log centralizado.\n",
        "\n",
        "---\n",
        "\n",
        "## Como funciona cada fun√ß√£o\n",
        "\n",
        "- **get_broadcasts:**  \n",
        "  Retorna um lote de transmiss√µes v√°lidas, sempre checando blacklist, log de processamento e gerando poster se necess√°rio. Realiza fallback autom√°tico para `/liveInfo` se n√£o encontrar o src na API principal. Todos os eventos de falha, blacklist ou sucesso s√£o registrados no log √∫nico.\n",
        "- **buscar_usuarios_especificos:**  \n",
        "  Busca apenas os usu√°rios informados, respeitando sempre o controle centralizado de blacklist/falhas, com fallback via `/liveInfo` quando necess√°rio.\n",
        "- **buscar_proxima_transmissao_livre:**  \n",
        "  Busca rapidamente a pr√≥xima transmiss√£o livre para processamento, sempre utilizando os mesmos crit√©rios de controle, garantindo agilidade na fila e efici√™ncia m√°xima ‚Äî tudo com rastreabilidade total no log.\n",
        "\n",
        "---\n",
        "\n",
        "## Detalhes t√©cnicos e recomenda√ß√µes\n",
        "\n",
        "- **Blacklist e falhas totalmente centralizados:**  \n",
        "  Fun√ß√µes `register_failure`, `clear_failure`, `add_to_blacklist`, `is_in_blacklist`, `get_failures` operam exclusivamente sobre o log √∫nico, eliminando arquivos auxiliares e promovendo rastreabilidade, auditoria e manuten√ß√£o facilitada.\n",
        "- **Arquitetura limpa e modular:**  \n",
        "  C√≥digo 100% integrado ao log centralizado, pronto para execu√ß√£o concorrente, CI/CD e manuten√ß√£o.\n",
        "- **Poster sempre v√°lido:**  \n",
        "  Fun√ß√µes utilit√°rias garantem que cada transmiss√£o s√≥ √© liberada para grava√ß√£o se houver poster v√°lido (baixado ou gerado).\n",
        "- **Tratamento de erros robusto e logging autom√°tico:**  \n",
        "  Toda etapa cr√≠tica possui tratamento de exce√ß√µes, registro detalhado de eventos e mensagens claras para facilitar monitoramento e evolu√ß√£o.\n",
        "- **Limpeza autom√°tica de eventos expirados:**  \n",
        "  Sempre que uma blacklist ou falha expira, o log √© automaticamente limpo, garantindo performance e precis√£o.\n",
        "\n",
        "---\n",
        "\n",
        "## Exemplo de uso das fun√ß√µes\n",
        "\n",
        "```python\n",
        "# Buscar lote completo de transmiss√µes v√°lidas (integrado ao log central)\n",
        "streams = get_broadcasts(limit=LIMIT_DEFAULT)\n",
        "\n",
        "# Buscar apenas usu√°rios espec√≠ficos (com prote√ß√£o centralizada)\n",
        "streams_especificos = buscar_usuarios_especificos([\"user1\", \"user2\"])\n",
        "\n",
        "# Buscar a pr√≥xima transmiss√£o livre dispon√≠vel (total rastreabilidade)\n",
        "proxima_stream = buscar_proxima_transmissao_livre()\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Rastreabilidade, manuten√ß√£o e integra√ß√£o\n",
        "\n",
        "- **Toda blacklist, falha, evento de processamento e sucesso √© registrado no log √∫nico centralizado (`xcam_master.log`).**\n",
        "- **Fun√ß√µes compat√≠veis com execu√ß√£o paralela, CI/CD e auditoria.**\n",
        "- **Mensagens detalhadas e arquitetura modular facilitam manuten√ß√£o, entendimento e futuras expans√µes no pipeline XCam.**\n",
        "- **Elimina√ß√£o completa de arquivos dispersos como BLACKLIST_PATH, FAILURE_LOG_PATH ou xcam_processing.log.**\n",
        "- **Uso consistente dos campos `sessao`, `id`, `username`, `status`, `detalhes` e timestamps ISO, conforme padr√£o global do notebook.**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "BZ4c3Uk1I7AK"
      },
      "id": "BZ4c3Uk1I7AK"
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================\n",
        "# C√©lula 6: Busca de Transmiss√µes com Blacklist Tempor√°ria e Controle de Falhas Centralizados\n",
        "# ================================================================\n",
        "# Objetivo:\n",
        "# - Buscar transmiss√µes ao vivo na API XCam, considerando blacklist e controle de falhas por usu√°rio, ambos centralizados no log √∫nico (xcam_master.log)\n",
        "# - Evitar loops infinitos e tentativas repetidas em usu√°rios problem√°ticos via sess√µes de blacklist/falha no log √∫nico\n",
        "# - Garantir sempre poster v√°lido (via download ou ffmpeg) antes de liberar qualquer transmiss√£o para processamento\n",
        "# - Modulariza√ß√£o robusta, integra√ß√£o total com log √∫nico, sem leitura/escrita direta em arquivos dispersos\n",
        "# - CAPTURAR E USAR O \"id\" √öNICO DO USU√ÅRIO DA API PARA CONTROLE NO LOG\n",
        "#\n",
        "# Estrat√©gia aplicada:\n",
        "# - Toda a l√≥gica de blacklist e falhas opera via fun√ß√µes utilit√°rias do log centralizado (C√©lula 1), AGORA USANDO O 'id'\n",
        "# - Sess√µes do log: \"blacklist\" (usu√°rios banidos temporariamente), \"failure\" (falhas por usu√°rio), \"processing\" (transmiss√£o em processamento)\n",
        "# - Cada evento registrado no log cont√©m: sessao, evento, id (AGORA ID √öNICO DA API), username, status, detalhes, timestamp\n",
        "# - N√£o existe mais uso de arquivos como BLACKLIST_PATH, FAILURE_LOG_PATH ou LOG_PROCESSAMENTO_PATH\n",
        "# ================================================================\n",
        "\n",
        "# ============================\n",
        "# FUN√á√ïES DE BLACKLIST E FALHAS CENTRALIZADAS NO LOG (AGORA BASEADO EM ID)\n",
        "# ============================\n",
        "\n",
        "# As fun√ß√µes abaixo usar√£o o 'id' do usu√°rio como chave prim√°ria para consultar/manipular o log central.\n",
        "\n",
        "def is_in_blacklist(user_id, now=None):\n",
        "    \"\"\"\n",
        "    Verifica se o usu√°rio (pelo ID) est√° atualmente na blacklist (sessao='blacklist' e status='blacklisted' e n√£o expirado).\n",
        "    Remove automaticamente entradas expiradas.\n",
        "    \"\"\"\n",
        "    now = now or time.time()\n",
        "    # Busca todos eventos atuais de blacklist desse ID de usu√°rio\n",
        "    entries = query_logs(sessao=\"blacklist\", id=user_id, status=\"blacklisted\")\n",
        "    for entry in entries:\n",
        "        ts_log = entry.get(\"timestamp\")\n",
        "        # timestamp ISO para epoch\n",
        "        try:\n",
        "            ts_epoch = datetime.fromisoformat(ts_log.replace(\"Z\", \"+00:00\")).timestamp() if ts_log else 0\n",
        "        except ValueError: # Tratar poss√≠veis erros de formato ISO\n",
        "            ts_epoch = 0\n",
        "            print(f\"‚ö†Ô∏è Aviso: Formato de timestamp inv√°lido no log para entrada blacklist (id: {user_id}): {ts_log}\")\n",
        "\n",
        "        # Verifica expira√ß√£o\n",
        "        if now - ts_epoch < BLACKLIST_TIMEOUT:\n",
        "            return True\n",
        "        else:\n",
        "            # Remove entrada expirada (usando id e timestamp para garantir unicidade na remo√ß√£o)\n",
        "            removed_count = remove_logs(lambda e: e.get(\"sessao\") == \"blacklist\" and e.get(\"id\") == user_id and e.get(\"timestamp\") == ts_log)\n",
        "            # print(f\"‚ÑπÔ∏è Removidas {removed_count} entradas de blacklist expiradas para ID {user_id}\") # O remove_logs j√° loga\n",
        "    return False\n",
        "\n",
        "def add_to_blacklist(user_id, username):\n",
        "    \"\"\"\n",
        "    Adiciona usu√°rio (pelo ID) √† blacklist tempor√°ria via log central.\n",
        "    Registra tamb√©m o username para refer√™ncia.\n",
        "    \"\"\"\n",
        "    # Primeiro, limpa entradas antigas de blacklist para este ID (garante que s√≥ haja uma ativa)\n",
        "    remove_logs(lambda e: e.get(\"sessao\") == \"blacklist\" and e.get(\"id\") == user_id)\n",
        "\n",
        "    entry = {\n",
        "        \"sessao\": \"blacklist\",\n",
        "        \"evento\": \"add_blacklist\",\n",
        "        \"id\": user_id,\n",
        "        \"username\": username, # Mant√©m username para refer√™ncia\n",
        "        \"status\": \"blacklisted\",\n",
        "        \"detalhes\": f\"Banido temporariamente por atingir o limite de falhas ({BLACKLIST_MAX_FAILURES})\"\n",
        "    }\n",
        "    append_log(entry)\n",
        "    print(f\"‚ö†Ô∏è Usu√°rio '{username}' (ID: {user_id}) adicionado √† blacklist tempor√°ria (registrado no log centralizado).\")\n",
        "\n",
        "def get_failures(user_id):\n",
        "    \"\"\"\n",
        "    Conta o n√∫mero de falhas registradas para o usu√°rio (pelo ID) (sessao='failure' e status='erro' n√£o expiradas).\n",
        "    \"\"\"\n",
        "    # Busca falhas nos √∫ltimos BLACKLIST_TIMEOUT segundos (expira junto com blacklist)\n",
        "    now = time.time()\n",
        "    entries = query_logs(sessao=\"failure\", id=user_id, status=\"erro\")\n",
        "    valid_failures = []\n",
        "    for entry in entries:\n",
        "        ts_log = entry.get(\"timestamp\")\n",
        "        try:\n",
        "            ts_epoch = datetime.fromisoformat(ts_log.replace(\"Z\", \"+00:00\")).timestamp() if ts_log else 0\n",
        "        except ValueError: # Tratar poss√≠veis erros de formato ISO\n",
        "            ts_epoch = 0\n",
        "            print(f\"‚ö†Ô∏è Aviso: Formato de timestamp inv√°lido no log para entrada failure (id: {user_id}): {ts_log}\")\n",
        "\n",
        "        if now - ts_epoch < BLACKLIST_TIMEOUT:\n",
        "            valid_failures.append(entry)\n",
        "        else:\n",
        "            # Remove entrada expirada (usando id e timestamp para garantir unicidade na remo√ß√£o)\n",
        "            removed_count = remove_logs(lambda e: e.get(\"sessao\") == \"failure\" and e.get(\"id\") == user_id and e.get(\"timestamp\") == ts_log)\n",
        "            # print(f\"‚ÑπÔ∏è Removidas {removed_count} entradas de falha expiradas para ID {user_id}\") # O remove_logs j√° loga\n",
        "    return len(valid_failures)\n",
        "\n",
        "def register_failure(user_id, username, details=\"\"):\n",
        "    \"\"\"\n",
        "    Registra uma falha para o usu√°rio (pelo ID). Move para blacklist se exceder o limite.\n",
        "    Registra tamb√©m o username para refer√™ncia.\n",
        "    \"\"\"\n",
        "    # Limpa falhas antigas expiradas antes de adicionar uma nova para este ID\n",
        "    now = time.time()\n",
        "    remove_logs(lambda e: e.get(\"sessao\") == \"failure\" and e.get(\"id\") == user_id and (datetime.fromisoformat(e.get(\"timestamp\",\"\").replace(\"Z\", \"+00:00\")).timestamp() if e.get(\"timestamp\") else 0) < now - BLACKLIST_TIMEOUT)\n",
        "\n",
        "    append_log({\n",
        "        \"sessao\": \"failure\",\n",
        "        \"evento\": \"registrar_falha\",\n",
        "        \"id\": user_id,\n",
        "        \"username\": username, # Mant√©m username para refer√™ncia\n",
        "        \"status\": \"erro\",\n",
        "        \"detalhes\": details\n",
        "    })\n",
        "    failures = get_failures(user_id)\n",
        "    print(f\"‚ùå Falha registrada para '{username}' (ID: {user_id}). Total de falhas recentes: {failures}/{BLACKLIST_MAX_FAILURES}\")\n",
        "\n",
        "    if failures >= BLACKLIST_MAX_FAILURES:\n",
        "        add_to_blacklist(user_id, username)\n",
        "        # Limpa falhas ap√≥s blacklisting para este ID\n",
        "        remove_logs(lambda e: e.get(\"sessao\") == \"failure\" and e.get(\"id\") == user_id)\n",
        "        print(f\"‚úÖ Falhas limpas para ID {user_id} ap√≥s blacklisting.\")\n",
        "\n",
        "\n",
        "def clear_failure(user_id):\n",
        "    \"\"\"\n",
        "    Limpa todas as falhas registradas para o usu√°rio (pelo ID).\n",
        "    \"\"\"\n",
        "    removed = remove_logs(lambda e: e.get(\"sessao\") == \"failure\" and e.get(\"id\") == user_id)\n",
        "    if removed > 0:\n",
        "        # Podemos adicionar um log de sucesso de limpeza aqui, se necess√°rio\n",
        "        # append_log({\"sessao\": \"failure\", \"evento\": \"limpar_falhas\", \"id\": user_id, \"status\": \"ok\", \"detalhes\": f\"{removed} falhas limpas\"})\n",
        "        print(f\"‚úÖ {removed} falhas limpas para ID {user_id}.\")\n",
        "    # else:\n",
        "    #     print(f\"‚ÑπÔ∏è Nenhuma falha encontrada para limpar para ID {user_id}.\") # remove_logs j√° loga se nada foi removido\n",
        "\n",
        "\n",
        "def is_processing(user_id):\n",
        "    \"\"\"\n",
        "    Verifica se o usu√°rio (pelo ID) est√° marcado como em processamento ativo.\n",
        "    \"\"\"\n",
        "    # Procura por entrada de processamento 'in_progress' para este ID\n",
        "    entries = query_logs(sessao=\"processing\", id=user_id, status=\"in_progress\")\n",
        "    return len(entries) > 0\n",
        "\n",
        "def mark_processing(user_id, username):\n",
        "    \"\"\"\n",
        "    Marca o usu√°rio/transmiss√£o (pelo ID) como em processamento ativo via log central.\n",
        "    Registra tamb√©m o username para refer√™ncia.\n",
        "    \"\"\"\n",
        "    # Remove entradas antigas de processamento para este ID antes de adicionar a nova (garante unicidade)\n",
        "    remove_logs(lambda e: e.get(\"sessao\") == \"processing\" and e.get(\"id\") == user_id)\n",
        "\n",
        "    append_log({\n",
        "        \"sessao\": \"processing\",\n",
        "        \"evento\": \"iniciar\",\n",
        "        \"id\": user_id,\n",
        "        \"username\": username, # Mant√©m username para refer√™ncia\n",
        "        \"status\": \"in_progress\",\n",
        "        \"detalhes\": \"\"\n",
        "    })\n",
        "    # print(f\"‚ÑπÔ∏è Usu√°rio '{username}' (ID: {user_id}) marcado como 'in_progress' no log.\")\n",
        "\n",
        "\n",
        "def unmark_processing(user_id):\n",
        "    \"\"\"\n",
        "    Remove marca√ß√£o de processamento ativo para o usu√°rio (pelo ID).\n",
        "    \"\"\"\n",
        "    # Remove entradas de processamento 'in_progress' para este ID\n",
        "    removed = remove_logs(lambda e: e.get(\"sessao\") == \"processing\" and e.get(\"id\") == user_id and e.get(\"status\") == \"in_progress\")\n",
        "    # if removed > 0:\n",
        "    #     print(f\"‚ÑπÔ∏è Marca√ß√£o 'in_progress' removida para ID {user_id}.\")\n",
        "    # else:\n",
        "    #      print(f\"‚ÑπÔ∏è Nenhuma marca√ß√£o 'in_progress' encontrada para remover para ID {user_id}.\") # remove_logs j√° loga se nada foi removido\n",
        "\n",
        "\n",
        "# ============================\n",
        "# BUSCA DE TRANSMISS√ïES NA API XCAM (AGORA CAPTURANDO O ID E USANDO NO CONTROLE)\n",
        "# ============================\n",
        "\n",
        "def get_broadcasts(limit=LIMIT_DEFAULT, page=PAGE_DEFAULT, usuarios_especificos=None, temp_folder=\"/content\"):\n",
        "    \"\"\"\n",
        "    Busca transmiss√µes ao vivo, respeitando blacklist (por ID), falhas (por ID) e log de processamento (por ID) via log centralizado.\n",
        "    Garante poster v√°lido (download ou ffmpeg) e faz fallback autom√°tico.\n",
        "    RETORNA LISTA DE DICION√ÅRIOS INCLUINDO O 'id' DA API.\n",
        "    \"\"\"\n",
        "    # Coleta IDs de usu√°rios atualmente em processamento ou blacklist\n",
        "    ids_em_proc_ou_blacklist = {e[\"id\"] for e in query_logs(sessao=\"processing\", status=\"in_progress\")} | \\\n",
        "                               {e[\"id\"] for e in query_logs(sessao=\"blacklist\", status=\"blacklisted\")}\n",
        "\n",
        "\n",
        "    if usuarios_especificos:\n",
        "        # Note: Buscar por username espec√≠fico na API e depois filtrar por ID no log √© necess√°rio\n",
        "        # A API principal n√£o parece permitir busca por lista de IDs diretamente\n",
        "        api_url_main = f\"https://api.xcam.gay/?limit={API_SEARCH_LIMIT}&page=1\" # Ainda busca um lote grande para encontrar espec√≠ficos\n",
        "        print(f\"üåê Acessando API principal (buscando usu√°rios espec√≠ficos) em: {api_url_main}\")\n",
        "    else:\n",
        "        # Busca um lote grande para ter mais chances de encontrar usu√°rios dispon√≠veis\n",
        "        api_url_main = f\"https://api.xcam.gay/?limit=3333\"\n",
        "        print(f\"üåê Acessando API principal (buscando todas transmiss√µes online) em: {api_url_main}\")\n",
        "\n",
        "    streams_candidates = [] # streams que tem src ou que precisam de liveInfo\n",
        "    streams_without_preview = [] # streams sem src na API principal\n",
        "\n",
        "    try:\n",
        "        response_main = requests.get(api_url_main)\n",
        "        response_main.raise_for_status()\n",
        "        data_main = response_main.json()\n",
        "        broadcasts_data = data_main.get(\"broadcasts\")\n",
        "        if not broadcasts_data:\n",
        "            print(\"‚ö†Ô∏è Chave 'broadcasts' n√£o encontrada na resposta da API principal.\")\n",
        "            return []\n",
        "        items = broadcasts_data.get(\"items\")\n",
        "        if not isinstance(items, list):\n",
        "            print(f\"‚ö†Ô∏è Chave 'items' n√£o encontrada ou n√£o √© uma lista em 'broadcasts'.\")\n",
        "            return []\n",
        "\n",
        "        print(f\"API principal retornou {len(items)} transmiss√µes.\")\n",
        "\n",
        "        for item in items:\n",
        "            # ** CAPTURA O ID AQUI **\n",
        "            user_id = str(item.get(\"id\")) # Garante que o ID seja string\n",
        "            username = item.get(\"username\", \"desconhecido\")\n",
        "            preview = item.get(\"preview\") or {}\n",
        "            src = preview.get(\"src\")\n",
        "            poster = preview.get(\"poster\")\n",
        "\n",
        "            # Ignora se j√° est√° em processamento ou blacklist (AGORA VERIFICA PELO ID)\n",
        "            if user_id in ids_em_proc_ou_blacklist:\n",
        "                # print(f\"‚ÑπÔ∏è Usu√°rio '{username}' (ID: {user_id}) j√° processado/em blacklist/processing, ignorando.\")\n",
        "                continue\n",
        "\n",
        "            # Ignora se est√° buscando espec√≠ficos e este usu√°rio/ID n√£o est√° na lista\n",
        "            if usuarios_especificos and username not in usuarios_especificos: # Continua filtrando por username se especificado\n",
        "                 # Poder√≠amos tamb√©m adicionar uma lista de IDs espec√≠ficos, se a API permitisse buscar por ID.\n",
        "                continue\n",
        "\n",
        "            stream_info = {\n",
        "                 \"id\": user_id, # Inclui o ID\n",
        "                 \"username\": username,\n",
        "                 \"src\": src,\n",
        "                 \"poster\": poster # Isso pode ser URL ou None\n",
        "            }\n",
        "\n",
        "            if src:\n",
        "                streams_candidates.append(stream_info) # Adiciona streams com src para processar/validar poster\n",
        "            else:\n",
        "                 streams_without_preview.append(stream_info) # Adiciona streams sem src para tentar liveInfo\n",
        "\n",
        "        print(f\"‚úÖ {len(streams_candidates)} transmiss√µes com URL na API principal, {len(streams_without_preview)} sem URL.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Erro ao acessar API principal: {e}\")\n",
        "        # Registrar erro de busca no log\n",
        "        if \"append_log\" in globals():\n",
        "             append_log({\n",
        "                 \"sessao\": \"busca\",\n",
        "                 \"evento\": \"erro_api_principal\",\n",
        "                 \"id\": \"global\", # Erro global de API\n",
        "                 \"username\": \"global\",\n",
        "                 \"status\": \"erro\",\n",
        "                 \"detalhes\": f\"Erro ao acessar API principal: {e}\"\n",
        "             })\n",
        "        return [] # Retorna vazio em caso de erro na API principal\n",
        "\n",
        "    # Fallback: busca via liveInfo para streams sem URL na API principal\n",
        "    streams_from_liveinfo = []\n",
        "    if streams_without_preview:\n",
        "        print(f\"üîÅ Buscando liveInfo para {len(streams_without_preview)} streams sem URL na API principal...\")\n",
        "        for stream_info in streams_without_preview:\n",
        "            user_id = stream_info[\"id\"] # Usa o ID capturado\n",
        "            username = stream_info[\"username\"]\n",
        "\n",
        "            # Verifica novamente se entrou em proc/blacklist enquanto process√°vamos a lista\n",
        "            if user_id in ids_em_proc_ou_blacklist:\n",
        "                 # print(f\"‚ÑπÔ∏è Usu√°rio '{username}' (ID: {user_id}) j√° processado/em blacklist/processing durante fallback, ignorando.\")\n",
        "                 continue\n",
        "\n",
        "            api_url_liveinfo = f\"https://api.xcam.gay/user/{username}/liveInfo\" # LiveInfo ainda usa username na URL\n",
        "            try:\n",
        "                response_liveinfo = requests.get(api_url_liveinfo)\n",
        "                response_liveinfo.raise_for_status()\n",
        "                data_liveinfo = response_liveinfo.json()\n",
        "                m3u8_url = data_liveinfo.get(\"cdnURL\") or data_liveinfo.get(\"edgeURL\")\n",
        "                if m3u8_url:\n",
        "                    # Adiciona stream encontrada via liveInfo aos candidatos\n",
        "                    streams_from_liveinfo.append({\n",
        "                        \"id\": user_id, # Inclui o ID\n",
        "                        \"username\": username,\n",
        "                        \"src\": m3u8_url,\n",
        "                        \"poster\": None # Poster do liveInfo geralmente n√£o √© direto, ser√° gerado\n",
        "                    })\n",
        "                else:\n",
        "                    print(f\"‚ö†Ô∏è liveInfo de '{username}' (ID: {user_id}) n√£o retornou cdnURL/edgeURL (usu√°rio possivelmente offline).\")\n",
        "                    # Registrar falha no liveInfo no log (AGORA USA ID)\n",
        "                    if \"register_failure\" in globals():\n",
        "                         register_failure(user_id, username, \"liveInfo sem cdnURL/edgeURL.\")\n",
        "\n",
        "            except Exception as ex:\n",
        "                print(f\"‚ùå Erro ao buscar liveInfo para '{username}' (ID: {user_id}): {ex}\")\n",
        "                 # Registrar erro de liveInfo no log (AGORA USA ID)\n",
        "                if \"register_failure\" in globals():\n",
        "                     register_failure(user_id, username, f\"Erro ao buscar liveInfo: {ex}\")\n",
        "\n",
        "            time.sleep(0.2) # Pequeno delay entre chamadas de liveInfo\n",
        "\n",
        "    # Junta candidatos da API principal e liveInfo.\n",
        "    # Antes de adicionar √† lista final, valida poster e evita duplicidade/blacklist FINAL.\n",
        "    final_streams_list = []\n",
        "    seen_ids = set() # Usa um set de IDs para controlar duplicidade na lista final\n",
        "    all_candidates = streams_candidates + streams_from_liveinfo\n",
        "\n",
        "    print(f\"Validando poster e filtrando {len(all_candidates)} candidatos...\")\n",
        "\n",
        "    for stream in all_candidates:\n",
        "        user_id = stream[\"id\"]\n",
        "        username = stream[\"username\"]\n",
        "        src = stream[\"src\"]\n",
        "        poster_info = stream[\"poster\"] # Pode ser URL ou None\n",
        "\n",
        "        # Verifica pela √öLTIMA VEZ se o ID j√° foi adicionado √† lista final,\n",
        "        # ou se entrou em processamento/blacklist desde a consulta inicial da API.\n",
        "        if user_id in seen_ids or user_id in ids_em_proc_ou_blacklist:\n",
        "            continue\n",
        "\n",
        "        poster_path = None\n",
        "        try:\n",
        "            # Tenta baixar poster original se existir\n",
        "            if poster_info and isinstance(poster_info, str) and poster_info.strip():\n",
        "                poster_path = download_and_save_poster(poster_info, username, temp_folder) # download_and_save_poster n√£o precisa de ID\n",
        "\n",
        "            # Se poster baixado for inv√°lido OU n√£o havia poster original, gera com ffmpeg\n",
        "            if not is_poster_valid(poster_path):\n",
        "                poster_path = generate_poster_with_ffmpeg(src, username, temp_folder) # generate_poster_with_ffmpeg n√£o precisa de ID\n",
        "\n",
        "            # Se mesmo ap√≥s todas as tentativas o poster for inv√°lido\n",
        "            if not is_poster_valid(poster_path):\n",
        "                # Registrar falha de poster no log (AGORA USA ID)\n",
        "                if \"register_failure\" in globals():\n",
        "                     register_failure(user_id, username, \"Poster inv√°lido ap√≥s todas tentativas.\")\n",
        "                continue # Pula para o pr√≥ximo stream se o poster for inv√°lido\n",
        "\n",
        "            # Se o poster √© v√°lido, limpa falhas relacionadas a poster/ffmpeg/conex√£o para este ID\n",
        "            if \"clear_failure\" in globals():\n",
        "                 clear_failure(user_id) # Limpa falhas pelo ID\n",
        "\n",
        "            # Adiciona √† lista final e marca ID como visto\n",
        "            final_streams_list.append({\n",
        "                \"id\": user_id, # Inclui o ID √∫nico no resultado final\n",
        "                \"username\": username,\n",
        "                \"src\": src,\n",
        "                \"poster_path\": poster_path # Passa o caminho LOCAL do poster v√°lido\n",
        "            })\n",
        "            seen_ids.add(user_id)\n",
        "\n",
        "            # Quebra o loop se atingiu o limite desejado\n",
        "            if len(final_streams_list) >= limit:\n",
        "                break\n",
        "\n",
        "        except Exception as e:\n",
        "            msg = f\"Falha inesperada durante valida√ß√£o de poster/stream para '{username}' (ID: {user_id}): {e}\"\n",
        "            print(f\"‚ùå {msg}\")\n",
        "            # Registrar falha gen√©rica no log (AGORA USA ID)\n",
        "            if \"register_failure\" in globals():\n",
        "                 register_failure(user_id, username, msg)\n",
        "\n",
        "\n",
        "    print(f\"üîé Selecionadas {len(final_streams_list)} streams v√°lidas (com poster) ap√≥s fallback (respeitando limit={limit}).\")\n",
        "    return final_streams_list\n",
        "\n",
        "# ============================\n",
        "# BUSCA DE USU√ÅRIOS ESPEC√çFICOS (AGORA COM ID)\n",
        "# ============================\n",
        "\n",
        "def buscar_usuarios_especificos(usuarios_lista, temp_folder=\"/content\"):\n",
        "    \"\"\"\n",
        "    Busca usu√°rios espec√≠ficos via API (por username), agora respeitando blacklist (por ID)\n",
        "    e controle de falhas (por ID) via log central. Inclui fallback via liveInfo e valida poster.\n",
        "    RETORNA LISTA DE DICION√ÅRIOS INCLUINDO O 'id' DA API.\n",
        "    \"\"\"\n",
        "    # Coleta IDs de usu√°rios em processamento ou blacklist\n",
        "    ids_em_proc_ou_blacklist = {e[\"id\"] for e in query_logs(sessao=\"processing\", status=\"in_progress\")} | \\\n",
        "                               {e[\"id\"] for e in query_logs(sessao=\"blacklist\", status=\"blacklisted\")}\n",
        "\n",
        "    # Primeiro, tenta encontrar os usu√°rios na lista na API principal (limite alto para pegar todos se online)\n",
        "    api_url = f\"https://api.xcam.gay/?limit={API_SEARCH_LIMIT}&page=1\"\n",
        "    print(f\"üîç Buscando usu√°rios espec√≠ficos ({len(usuarios_lista)}) em {api_url}\")\n",
        "    found_candidates = []\n",
        "    users_not_found_in_main = set(usuarios_lista) # Acompanha quem n√£o foi encontrado na API principal\n",
        "\n",
        "    try:\n",
        "        response = requests.get(api_url)\n",
        "        response.raise_for_status()\n",
        "        data = response.json()\n",
        "        items = data.get(\"broadcasts\", {}).get(\"items\", [])\n",
        "\n",
        "        for item in items:\n",
        "            user_id = str(item.get(\"id\")) # ** CAPTURA O ID **\n",
        "            username = item.get(\"username\", \"\")\n",
        "\n",
        "            if username in usuarios_lista: # Verifica se este √© um dos usu√°rios que procuramos\n",
        "                 users_not_found_in_main.discard(username) # Remove da lista de n√£o encontrados\n",
        "\n",
        "                 # Verifica se o ID est√° em proc/blacklist (AGORA VERIFICA PELO ID)\n",
        "                 if user_id in ids_em_proc_ou_blacklist:\n",
        "                     # print(f\"‚ÑπÔ∏è Usu√°rio '{username}' (ID: {user_id}) j√° processado/em blacklist/processing, ignorando.\")\n",
        "                     continue\n",
        "\n",
        "                 preview = item.get(\"preview\") or {}\n",
        "                 src = preview.get(\"src\")\n",
        "                 poster = preview.get(\"poster\") # Pode ser URL ou None\n",
        "\n",
        "                 if src:\n",
        "                     # Adiciona como candidato se tiver SRC (valida√ß√£o de poster depois)\n",
        "                     found_candidates.append({\n",
        "                         \"id\": user_id, # Inclui o ID\n",
        "                         \"username\": username,\n",
        "                         \"src\": src,\n",
        "                         \"poster\": poster # Pode ser URL ou None\n",
        "                     })\n",
        "                 else:\n",
        "                     # Marca para tentar via liveInfo se n√£o tiver SRC principal\n",
        "                     # Adiciona a lista de streams_without_preview para liveinfo fallback\n",
        "                     found_candidates.append({\n",
        "                        \"id\": user_id, # Inclui o ID\n",
        "                        \"username\": username,\n",
        "                        \"src\": None, # Indica que precisa de liveInfo\n",
        "                        \"poster\": None\n",
        "                    })\n",
        "\n",
        "\n",
        "        print(f\"Encontrados {len(found_candidates)} dos {len(usuarios_lista)} usu√°rios especificados na API principal (antes de fallback).\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Erro ao buscar usu√°rios espec√≠ficos na API principal: {e}\")\n",
        "        # Registrar erro de busca no log (AGORA USA ID ou Global)\n",
        "        if \"append_log\" in globals():\n",
        "             append_log({\n",
        "                 \"sessao\": \"busca\",\n",
        "                 \"evento\": \"erro_api_especificos\",\n",
        "                 \"id\": \"global\", # Erro global de API\n",
        "                 \"username\": \"global\",\n",
        "                 \"status\": \"erro\",\n",
        "                 \"detalhes\": f\"Erro ao buscar usu√°rios espec√≠ficos na API principal: {e}\"\n",
        "             })\n",
        "        # Em caso de erro na API principal, tenta buscar cada usu√°rio individualmente via liveInfo?\n",
        "        # Para simplificar, se a API principal falha, retornamos o que conseguimos ou vazio.\n",
        "        # Se o erro √© grave, talvez n√£o haja mais o que fazer.\n",
        "\n",
        "    # Fallback: busca via liveInfo para usu√°rios especificados que n√£o tinham SRC na API principal\n",
        "    streams_from_liveinfo = []\n",
        "    # Filtra os candidatos que precisam de liveInfo\n",
        "    candidates_for_liveinfo = [c for c in found_candidates if c.get(\"src\") is None]\n",
        "    # Adiciona usu√°rios que N√ÉO foram encontrados na API principal mas estavam na lista original\n",
        "    # Assume que se n√£o foi encontrado na lista grande da API principal, est√° offline ou precisa de liveInfo direto\n",
        "    # Isso pode gerar falsos positivos se o usu√°rio estiver offline\n",
        "    for uname in users_not_found_in_main:\n",
        "        # Tenta obter o ID antes de tentar liveInfo? LiveInfo n√£o retorna ID...\n",
        "        # Se o usu√°rio n√£o foi encontrado na API principal (com limite alto), √© prov√°vel que esteja offline.\n",
        "        # Buscar liveInfo sem ter um ID √© menos robusto.\n",
        "        # Vamos focar no fallback APENAS para usu√°rios ENCONTRADOS na API principal mas sem SRC.\n",
        "        # Se o usu√°rio da lista espec√≠fica n√£o apareceu na busca grande, assumimos offline por enquanto.\n",
        "        print(f\"‚ö†Ô∏è Usu√°rio '{uname}' especificado n√£o encontrado na busca da API principal. Assumindo offline ou inacess√≠vel.\")\n",
        "\n",
        "\n",
        "    if candidates_for_liveinfo:\n",
        "        print(f\"üîÅ Buscando liveInfo para {len(candidates_for_liveinfo)} usu√°rios espec√≠ficos sem URL na API principal...\")\n",
        "        for stream_info in candidates_for_liveinfo:\n",
        "            user_id = stream_info[\"id\"] # Usa o ID capturado da API principal\n",
        "            username = stream_info[\"username\"]\n",
        "\n",
        "            # Verifica novamente se entrou em proc/blacklist\n",
        "            if user_id in ids_em_proc_ou_blacklist:\n",
        "                 # print(f\"‚ÑπÔ∏è Usu√°rio '{username}' (ID: {user_id}) j√° processado/em blacklist/processing durante fallback, ignorando.\")\n",
        "                 continue\n",
        "\n",
        "            api_url_liveinfo = f\"https://api.xcam.gay/user/{username}/liveInfo\"\n",
        "            try:\n",
        "                response_liveinfo = requests.get(api_url_liveinfo)\n",
        "                response_liveinfo.raise_for_status()\n",
        "                data_liveinfo = response_liveinfo.json()\n",
        "                m3u8_url = data_liveinfo.get(\"cdnURL\") or data_liveinfo.get(\"edgeURL\")\n",
        "                if m3u8_url:\n",
        "                    # Adiciona stream encontrada via liveInfo\n",
        "                    streams_from_liveinfo.append({\n",
        "                        \"id\": user_id, # Inclui o ID\n",
        "                        \"username\": username,\n",
        "                        \"src\": m3u8_url,\n",
        "                        \"poster\": None # Poster do liveInfo geralmente n√£o √© direto, ser√° gerado\n",
        "                    })\n",
        "                else:\n",
        "                    print(f\"‚ö†Ô∏è liveInfo de '{username}' (ID: {user_id}) n√£o retornou cdnURL/edgeURL (usu√°rio possivelmente offline).\")\n",
        "                    # Registrar falha no liveInfo no log (AGORA USA ID)\n",
        "                    if \"register_failure\" in globals():\n",
        "                         register_failure(user_id, username, \"liveInfo sem cdnURL/edgeURL.\")\n",
        "\n",
        "            except Exception as ex:\n",
        "                print(f\"‚ùå Erro ao buscar liveInfo para '{username}' (ID: {user_id}): {ex}\")\n",
        "                # Registrar erro de liveInfo no log (AGORA USA ID)\n",
        "                if \"register_failure\" in globals():\n",
        "                     register_failure(user_id, username, f\"Erro ao buscar liveInfo: {ex}\")\n",
        "\n",
        "            time.sleep(0.2) # Pequeno delay\n",
        "\n",
        "    # Junta candidatos que tinham SRC e os encontrados via liveInfo.\n",
        "    # Antes de adicionar √† lista final, valida poster e evita duplicidade/blacklist FINAL.\n",
        "    final_streams_list = []\n",
        "    seen_ids = set() # Usa um set de IDs para controlar duplicidade na lista final\n",
        "    # Filtra os candidatos que TINHAM SRC na API principal\n",
        "    candidates_with_src = [c for c in found_candidates if c.get(\"src\") is not None]\n",
        "    all_candidates_post_fallback = candidates_with_src + streams_from_liveinfo\n",
        "\n",
        "    print(f\"Validando poster e filtrando {len(all_candidates_post_fallback)} candidatos ap√≥s fallback...\")\n",
        "\n",
        "\n",
        "    for stream in all_candidates_post_fallback:\n",
        "        user_id = stream[\"id\"]\n",
        "        username = stream[\"username\"]\n",
        "        src = stream[\"src\"]\n",
        "        poster_info = stream[\"poster\"] # Pode ser URL ou None\n",
        "\n",
        "        # Verifica pela √öLTIMA VEZ se o ID j√° foi adicionado √† lista final,\n",
        "        # ou se entrou em processamento/blacklist desde a consulta inicial.\n",
        "        if user_id in seen_ids or user_id in ids_em_proc_ou_blacklist:\n",
        "            continue\n",
        "\n",
        "        poster_path = None\n",
        "        try:\n",
        "            # Tenta baixar poster original se existir\n",
        "            if poster_info and isinstance(poster_info, str) and poster_info.strip():\n",
        "                poster_path = download_and_save_poster(poster_info, username, temp_folder)\n",
        "\n",
        "            # Se poster baixado for inv√°lido OU n√£o havia poster original, gera com ffmpeg\n",
        "            if not is_poster_valid(poster_path):\n",
        "                poster_path = generate_poster_with_ffmpeg(src, username, temp_folder)\n",
        "\n",
        "            # Se mesmo ap√≥s todas as tentativas o poster for inv√°lido\n",
        "            if not is_poster_valid(poster_path):\n",
        "                 # Registrar falha de poster no log (AGORA USA ID)\n",
        "                if \"register_failure\" in globals():\n",
        "                     register_failure(user_id, username, \"Poster inv√°lido ap√≥s todas tentativas.\")\n",
        "                continue # Pula para o pr√≥ximo stream\n",
        "\n",
        "            # Se o poster √© v√°lido, limpa falhas relacionadas a poster/ffmpeg/conex√£o para este ID\n",
        "            if \"clear_failure\" in globals():\n",
        "                 clear_failure(user_id) # Limpa falhas pelo ID\n",
        "\n",
        "            # Adiciona √† lista final e marca ID como visto\n",
        "            final_streams_list.append({\n",
        "                \"id\": user_id, # Inclui o ID √∫nico no resultado final\n",
        "                \"username\": username,\n",
        "                \"src\": src,\n",
        "                \"poster_path\": poster_path # Passa o caminho LOCAL do poster v√°lido\n",
        "            })\n",
        "            seen_ids.add(user_id)\n",
        "\n",
        "            # No modo espec√≠fico, buscamos todos da lista, ent√£o n√£o h√° limite de \"len(final_streams_list) >= limit\" aqui.\n",
        "            # Poder√≠amos adicionar um limite se quis√©ssemos parar ap√≥s encontrar N dos espec√≠ficos.\n",
        "\n",
        "        except Exception as e:\n",
        "            msg = f\"Falha inesperada durante valida√ß√£o de poster/stream para '{username}' (ID: {user_id}): {e}\"\n",
        "            print(f\"‚ùå {msg}\")\n",
        "            # Registrar falha gen√©rica no log (AGORA USA ID)\n",
        "            if \"register_failure\" in globals():\n",
        "                 register_failure(user_id, username, msg)\n",
        "\n",
        "    print(f\"üîé Encontrados e validados {len(final_streams_list)} dos {len(usuarios_lista)} usu√°rios especificados.\")\n",
        "    return final_streams_list\n",
        "\n",
        "\n",
        "# ============================\n",
        "# BUSCA DA PR√ìXIMA TRANSMISS√ÉO DISPON√çVEL (AGORA COM ID)\n",
        "# ============================\n",
        "\n",
        "def buscar_proxima_transmissao_livre(temp_folder=\"/content\"):\n",
        "    \"\"\"\n",
        "    Busca a pr√≥xima transmiss√£o ao vivo n√£o processada, com poster v√°lido e ignorando blacklist (por ID), tudo centralizado no log.\n",
        "    RETORNA DICION√ÅRIO INCLUINDO O 'id' DA API, OU None.\n",
        "    \"\"\"\n",
        "    # Coleta IDs de usu√°rios em processamento ou blacklist\n",
        "    ids_em_proc_ou_blacklist = {e[\"id\"] for e in query_logs(sessao=\"processing\", status=\"in_progress\")} | \\\n",
        "                               {e[\"id\"] for e in query_logs(sessao=\"blacklist\", status=\"blacklisted\")}\n",
        "\n",
        "\n",
        "    api_url_main = f\"https://api.xcam.gay/?limit=3333&page=1\" # Busca um lote grande para encontrar o pr√≥ximo r√°pido\n",
        "    print(f\"üîé Buscando pr√≥xima transmiss√£o livre em: {api_url_main}\")\n",
        "    try:\n",
        "        response_main = requests.get(api_url_main)\n",
        "        response_main.raise_for_status()\n",
        "        data_main = response_main.json()\n",
        "        items = data_main.get(\"broadcasts\", {}).get(\"items\", [])\n",
        "        print(f\"API principal retornou {len(items)} transmiss√µes.\")\n",
        "\n",
        "        # Primeiro, itera sobre os itens da API principal que t√™m SRC\n",
        "        for item in items:\n",
        "            # ** CAPTURA O ID AQUI **\n",
        "            user_id = str(item.get(\"id\")) # Garante que o ID seja string\n",
        "            username = item.get(\"username\", \"desconhecido\")\n",
        "            preview = item.get(\"preview\") or {}\n",
        "            src = preview.get(\"src\")\n",
        "            poster_info = preview.get(\"poster\") # Pode ser URL ou None\n",
        "\n",
        "            # Ignora se j√° est√° em processamento ou blacklist (AGORA VERIFICA PELO ID)\n",
        "            if user_id in ids_em_proc_ou_blacklist:\n",
        "                # print(f\"‚ÑπÔ∏è Usu√°rio '{username}' (ID: {user_id}) j√° processado/em blacklist/processing, ignorando.\")\n",
        "                continue\n",
        "\n",
        "            if src:\n",
        "                 # Se tem SRC e n√£o est√° em proc/blacklist, valida poster\n",
        "                poster_path = None\n",
        "                try:\n",
        "                    # Tenta baixar poster original se existir\n",
        "                    if poster_info and isinstance(poster_info, str) and poster_info.strip():\n",
        "                        poster_path = download_and_save_poster(poster_info, username, temp_folder)\n",
        "\n",
        "                    # Se poster baixado for inv√°lido OU n√£o havia poster original, gera com ffmpeg\n",
        "                    if not is_poster_valid(poster_path):\n",
        "                        poster_path = generate_poster_with_ffmpeg(src, username, temp_folder)\n",
        "\n",
        "                    # Se o poster √© v√°lido, limpa falhas relacionadas a poster/ffmpeg/conex√£o e retorna\n",
        "                    if is_poster_valid(poster_path):\n",
        "                        if \"clear_failure\" in globals():\n",
        "                             clear_failure(user_id) # Limpa falhas pelo ID\n",
        "                        print(f\"üéØ Transmiss√£o livre encontrada: '{username}' (ID: {user_id})\")\n",
        "                        return {\n",
        "                            \"id\": user_id, # Inclui o ID √∫nico no resultado\n",
        "                            \"username\": username,\n",
        "                            \"src\": src,\n",
        "                            \"poster_path\": poster_path # Passa o caminho LOCAL do poster v√°lido\n",
        "                        }\n",
        "                    else:\n",
        "                         # Se poster inv√°lido, registra falha e continua buscando\n",
        "                         if \"register_failure\" in globals():\n",
        "                             register_failure(user_id, username, \"Poster inv√°lido ap√≥s todas tentativas (busca pr√≥xima).\")\n",
        "                         continue # Pula para o pr√≥ximo item\n",
        "\n",
        "                except Exception as e:\n",
        "                    msg = f\"Falha inesperada durante valida√ß√£o de poster/stream para '{username}' (ID: {user_id}) na busca pr√≥xima: {e}\"\n",
        "                    print(f\"‚ùå {msg}\")\n",
        "                    # Registrar falha gen√©rica no log (AGORA USA ID)\n",
        "                    if \"register_failure\" in globals():\n",
        "                         register_failure(user_id, username, msg)\n",
        "                    continue # Pula para o pr√≥ximo item\n",
        "\n",
        "\n",
        "        # Se chegou aqui, nenhum item com SRC foi encontrado/validado na busca grande.\n",
        "        # Agora, itera sobre os itens sem SRC para tentar liveInfo\n",
        "        print(\"Nenhuma transmiss√£o livre com SRC encontrada, tentando liveInfo para os demais...\")\n",
        "        for item in items:\n",
        "             user_id = str(item.get(\"id\")) # ** CAPTURA O ID **\n",
        "             username = item.get(\"username\", \"desconhecido\")\n",
        "             preview = item.get(\"preview\") or {}\n",
        "             src = preview.get(\"src\") # Re-verifica SRC\n",
        "\n",
        "             # Ignora se tem SRC (j√° processado acima) ou se j√° est√° em proc/blacklist\n",
        "             if src or user_id in ids_em_proc_ou_blacklist:\n",
        "                  continue\n",
        "\n",
        "             # Se n√£o tem SRC e n√£o est√° em proc/blacklist, tenta liveInfo\n",
        "             api_url_liveinfo = f\"https://api.xcam.gay/user/{username}/liveInfo\"\n",
        "             try:\n",
        "                 response_liveinfo = requests.get(api_url_liveinfo)\n",
        "                 response_liveinfo.raise_for_status()\n",
        "                 data_liveinfo = response_liveinfo.json()\n",
        "                 m3u8_url = data_liveinfo.get(\"cdnURL\") or data_liveinfo.get(\"edgeURL\")\n",
        "                 if m3u8_url:\n",
        "                      # Se encontrou URL via liveInfo, valida poster e retorna\n",
        "                      poster_path = generate_poster_with_ffmpeg(m3u8_url, username, temp_folder)\n",
        "\n",
        "                      if is_poster_valid(poster_path):\n",
        "                           if \"clear_failure\" in globals():\n",
        "                                clear_failure(user_id) # Limpa falhas pelo ID\n",
        "                           print(f\"üéØ Transmiss√£o livre (pelo liveInfo) encontrada: '{username}' (ID: {user_id})\")\n",
        "                           return {\n",
        "                               \"id\": user_id, # Inclui o ID √∫nico no resultado\n",
        "                               \"username\": username,\n",
        "                               \"src\": m3u8_url,\n",
        "                               \"poster_path\": poster_path # Passa o caminho LOCAL do poster v√°lido\n",
        "                           }\n",
        "                      else:\n",
        "                           # Se poster inv√°lido, registra falha e continua buscando\n",
        "                           if \"register_failure\" in globals():\n",
        "                                register_failure(user_id, username, \"Poster inv√°lido (busca pr√≥xima liveInfo).\")\n",
        "                           continue # Pula para o pr√≥ximo item\n",
        "                 else:\n",
        "                      print(f\"‚ö†Ô∏è liveInfo de '{username}' (ID: {user_id}) n√£o retornou cdnURL/edgeURL.\")\n",
        "                      # Registrar falha no liveInfo no log (AGORA USA ID)\n",
        "                      if \"register_failure\" in globals():\n",
        "                           register_failure(user_id, username, \"liveInfo sem cdnURL/edgeURL (busca pr√≥xima).\")\n",
        "\n",
        "\n",
        "             except Exception as ex:\n",
        "                 msg = f\"Erro ao buscar liveInfo para '{username}' (ID: {user_id}) na busca pr√≥xima: {ex}\"\n",
        "                 print(f\"‚ùå {msg}\")\n",
        "                 # Registrar erro de liveInfo no log (AGORA USA ID)\n",
        "                 if \"register_failure\" in globals():\n",
        "                      register_failure(user_id, username, msg)\n",
        "\n",
        "             time.sleep(0.2) # Pequeno delay\n",
        "\n",
        "\n",
        "        # Se nenhum stream foi encontrado/validado ap√≥s varrer toda a lista da API (com SRC e liveInfo)\n",
        "        print(\"üö´ Nenhuma transmiss√£o livre encontrada ap√≥s varrer todas online.\")\n",
        "        return None # Retorna None se nenhum stream livre foi encontrado ap√≥s todas as tentativas\n",
        "\n",
        "    except Exception as e:\n",
        "        msg = f\"‚ùå Erro ao buscar transmiss√µes online (busca pr√≥xima): {e}\"\n",
        "        print(f\"‚ùå {msg}\")\n",
        "        # Registrar erro de busca no log (AGORA USA ID ou Global)\n",
        "        if \"append_log\" in globals():\n",
        "             append_log({\n",
        "                 \"sessao\": \"busca\",\n",
        "                 \"evento\": \"erro_api_proxima\",\n",
        "                 \"id\": \"global\", # Erro global de API\n",
        "                 \"username\": \"global\",\n",
        "                 \"status\": \"erro\",\n",
        "                 \"detalhes\": msg\n",
        "             })\n",
        "        return None # Retorna None em caso de erro na API\n",
        "\n",
        "# ================================================================\n",
        "# FIM DA C√âLULA 6 ‚Äî BUSCA, BLACKLIST E CONTROLE DE FALHAS CENTRALIZADOS (AGORA COM ID)\n",
        "# ================================================================\n",
        "\n",
        "# Observa√ß√µes:\n",
        "# - Toda manipula√ß√£o de blacklist, falha e processamento agora √© feita via fun√ß√µes do log centralizado (C√©lula 1), USANDO O ID √öNICO DA API.\n",
        "# - O username √© mantido nos registros de log para refer√™ncia humana, mas a l√≥gica de controle se baseia no 'id'.\n",
        "# - Nenhum uso de arquivos dispersos. Consultas e remo√ß√µes s√£o sempre via query_logs, append_log, remove_logs.\n",
        "# - Para m√°xima rastreabilidade, todos os eventos relevantes est√£o registrados no log √∫nico."
      ],
      "metadata": {
        "id": "h1jr7D0pJ7jS"
      },
      "id": "h1jr7D0pJ7jS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# C√©lula 7: Grava√ß√£o da Stream, Poster Autom√°tico, Controle de Falhas, Log Centralizado Seguro e Blacklist Inteligente\n",
        "\n",
        "**Objetivo:**  \n",
        "Automatizar a grava√ß√£o de transmiss√µes ao vivo com ffmpeg, garantindo robustez, rastreabilidade e integra√ß√£o total com a l√≥gica de blacklist tempor√°ria e controle de falhas **centralizados no log √∫nico** (`xcam_master.log`).  \n",
        "Esta c√©lula assegura o gerenciamento seguro do log de transmiss√µes em processamento, registro de sucesso/erro, integra√ß√£o direta com CI/CD, e a limpeza de arquivos tempor√°rios.\n",
        "\n",
        "## Estrat√©gia e melhorias implementadas\n",
        "\n",
        "- **Gerenciamento seguro e centralizado de log:**  \n",
        "  O usu√°rio √© registrado no log centralizado (`sessao=\"processing\"`, `status=\"in_progress\"`) antes da grava√ß√£o e removido ao final (sucesso ou erro), evitando duplicidade e permitindo paralelismo seguro. Todos os eventos (sucesso, erro, exce√ß√£o, dura√ß√£o insuficiente, etc.) s√£o registrados com rastreabilidade completa.\n",
        "- **Poster sempre v√°lido:**  \n",
        "  O sistema tenta baixar o poster da API. Se o poster estiver ausente, inv√°lido ou nulo, gera automaticamente uma imagem via ffmpeg, assegurando que toda transmiss√£o tenha um poster associado e v√°lido.\n",
        "- **Controle de tempo m√≠nimo e valida√ß√£o robusta:**  \n",
        "  Se a grava√ß√£o resultar em v√≠deo muito curto, tanto o arquivo de v√≠deo quanto o poster s√£o descartados imediatamente, e uma falha √© registrada para o usu√°rio no log central. O contador de falhas √© limpo automaticamente em caso de sucesso.\n",
        "- **Tratamento robusto de falhas e blacklist:**  \n",
        "  Qualquer falha (ffmpeg, exceptions, etc.) √© registrada no log √∫nico, e o usu√°rio √© escalado para a blacklist tempor√°ria quando atinge o limite configurado (`BLACKLIST_MAX_FAILURES`), evitando tentativas infinitas e desperd√≠cio de recursos.\n",
        "- **Limpeza automatizada:**  \n",
        "  Ap√≥s upload ou erro, todos os arquivos tempor√°rios (v√≠deo e poster) s√£o removidos, otimizando o uso do disco e mantendo o ambiente do Colab limpo.\n",
        "- **Feedback e rastreabilidade detalhados:**  \n",
        "  Todas as etapas cr√≠ticas s√£o registradas no log √∫nico e exibidas no console, facilitando diagn√≥stico, manuten√ß√£o e integra√ß√£o com pipelines CI/CD.\n",
        "- **C√≥digo modular e altamente documentado:**  \n",
        "  Todo o fluxo √© comentado passo a passo, pronto para manuten√ß√£o, revis√£o e entendimento por toda a equipe.\n",
        "\n",
        "---\n",
        "\n",
        "## Fluxo resumido da fun√ß√£o principal\n",
        "\n",
        "1. **Registra o usu√°rio** no log centralizado como processamento ativo (sessao=\"processing\", status=\"in_progress\").\n",
        "2. **Garante um poster v√°lido** (download ou gera√ß√£o autom√°tica).\n",
        "3. **Executa o ffmpeg** para gravar a transmiss√£o e monitora o progresso em tempo real.\n",
        "4. **Valida a grava√ß√£o**:\n",
        "   - Se falhar, registra no log central e trata blacklist/falhas.\n",
        "   - Se for curta demais, descarta e registra falha no log.\n",
        "   - Se for v√°lida, limpa contador de falhas no log e prossegue normalmente.\n",
        "5. **Ap√≥s upload ou erro**, remove o usu√°rio do log central e limpa arquivos tempor√°rios.\n",
        "\n",
        "---\n",
        "\n",
        "## Exemplo de uso\n",
        "\n",
        "```python\n",
        "resultado = gravar_stream(username=\"user123\", m3u8_url=\"https://cdn.xcam.gay/m3u8/...\", poster_url=\"https://api.xcam.gay/poster/...\")\n",
        "if resultado['upload_success']:\n",
        "    print(\"Grava√ß√£o e upload realizados com sucesso!\")\n",
        "else:\n",
        "    print(\"Falha na grava√ß√£o ou upload:\", resultado['abyss_response'])\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Seguran√ßa, rastreabilidade e integra√ß√£o\n",
        "\n",
        "- **Pronto para CI/CD e execu√ß√£o paralela:**  \n",
        "  O controle rigoroso de log centralizado e blacklist garante execu√ß√£o concorrente, segura e rastre√°vel por todo o pipeline XCam.\n",
        "- **Integra√ß√£o total com as fun√ß√µes globais:**  \n",
        "  Utiliza fun√ß√µes de blacklist e falha da C√©lula 6, promovendo rastreabilidade e controle centralizado, sem depend√™ncia de arquivos dispersos.\n",
        "- **Diagn√≥stico facilitado:**  \n",
        "  Mensagens e logs detalhados em cada etapa do processo, todos acess√≠veis via consulta ao log √∫nico (`xcam_master.log`).\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "jGFyqOUoKEF7"
      },
      "id": "jGFyqOUoKEF7"
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================\n",
        "# C√©lula 7: Grava√ß√£o Autom√°tica de Transmiss√£o, Controle de Log Centralizado, Limpeza e Blacklist Inteligente (AGORA USANDO ID)\n",
        "# ================================================================\n",
        "# Objetivo:\n",
        "# - Gravar transmiss√µes ao vivo utilizando ffmpeg, com controle rigoroso e centralizado de log de processamento, tratamento de falhas e integra√ß√£o com blacklist tempor√°ria (log √∫nico).\n",
        "# - Garantir que cada transmiss√£o seja registrada no log central no in√≠cio e removida ao final (sucesso ou erro), evitando duplicidade/processamento concorrente (sessao=\"processing\").\n",
        "# - Registrar falhas (ffmpeg, dura√ß√£o insuficiente, poster inv√°lido), escalando usu√°rios para a blacklist tempor√°ria via log central ao atingir o limite de tentativas, AGORA USANDO O ID.\n",
        "# - Assegurar limpeza robusta de arquivos tempor√°rios e rastreabilidade total via eventos no log √∫nico e mensagens detalhadas.\n",
        "# - Modular, preparado para integra√ß√£o com pipelines CI/CD, paralelismo e auditoria centralizada.\n",
        "# ================================================================\n",
        "\n",
        "def get_video_duration(filepath):\n",
        "    \"\"\"\n",
        "    Retorna a dura√ß√£o real do arquivo mp4, em segundos, utilizando ffprobe.\n",
        "    Retorna None em caso de erro ou se o arquivo n√£o existir.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        if not os.path.exists(filepath):\n",
        "            print(f\"‚ö†Ô∏è Arquivo para ffprobe n√£o encontrado: {filepath}\")\n",
        "            return None\n",
        "        cmd = [\n",
        "            \"ffprobe\", \"-v\", \"error\",\n",
        "            \"-show_entries\", \"format=duration\",\n",
        "            \"-of\", \"json\",\n",
        "            filepath\n",
        "        ]\n",
        "        result = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
        "        info = json.loads(result.stdout)\n",
        "        duration = float(info[\"format\"][\"duration\"])\n",
        "        return int(round(duration))\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è N√£o foi poss√≠vel obter dura√ß√£o via ffprobe para {filepath}: {e}\")\n",
        "        return None\n",
        "\n",
        "# Adicionando user_id como par√¢metro\n",
        "def gravar_stream(user_id, username, m3u8_url, poster_url=None, poster_frame_time=7):\n",
        "    \"\"\"\n",
        "    Grava a transmiss√£o ao vivo do usu√°rio (pelo ID) usando ffmpeg, com controle de erros, log centralizado e integra√ß√£o √† blacklist.\n",
        "    - Registra no log centralizado (sessao=\"processing\") no in√≠cio (status=\"in_progress\"), USANDO O ID.\n",
        "    - Remove do log ao finalizar, independentemente do resultado, USANDO O ID.\n",
        "    - Em caso de falha do ffmpeg ou grava√ß√£o muito curta, registra falha do usu√°rio no log (sessao=\"failure\"), USANDO O ID.\n",
        "    - Ao atingir N falhas consecutivas, usu√°rio entra na blacklist (fun√ß√µes de log centralizado), USANDO O ID.\n",
        "    - Limpa arquivos tempor√°rios ao final.\n",
        "    - Garante poster v√°lido: baixa da poster_url ou gera automaticamente com ffmpeg.\n",
        "    - poster_frame_time: segundo do v√≠deo onde a captura do poster ser√° feita, se necess√°rio.\n",
        "    \"\"\"\n",
        "    # --- Registro no log centralizado: PROCESSAMENTO INICIADO (USANDO ID) ---\n",
        "    # As fun√ß√µes mark_processing, unmark_processing, register_failure, clear_failure\n",
        "    # na C√©lula 6 j√° foram ajustadas para aceitar e usar user_id.\n",
        "    mark_processing(user_id, username) # Passa user_id e username\n",
        "\n",
        "    start_time_dt = datetime.now()\n",
        "    data_str = start_time_dt.strftime(\"%d-%m-%Y\")\n",
        "    horario_str = start_time_dt.strftime(\"%H-%M\")\n",
        "    temp_filename = f\"{username}_{start_time_dt.strftime('%Y%m%d_%H%M%S')}_temp.mp4\"\n",
        "    filepath = os.path.join(TEMP_OUTPUT_FOLDER, temp_filename)\n",
        "    append_log({\n",
        "        \"sessao\": \"processing\",\n",
        "        \"evento\": \"iniciar_gravacao\",\n",
        "        \"id\": user_id, # Usa o ID\n",
        "        \"username\": username,\n",
        "        \"status\": \"in_progress\",\n",
        "        \"detalhes\": f\"Grava√ß√£o iniciada para '{username}' (ID: {user_id}) em {filepath}\" # Adiciona ID nos detalhes\n",
        "    })\n",
        "\n",
        "    print(f\"\\nüé¨ Iniciando grava√ß√£o de: '{username}' (ID: {user_id}) | URL: {m3u8_url}) em {filepath}\") # Adiciona ID no print\n",
        "\n",
        "    # --- Garante poster v√°lido ---\n",
        "    # As fun√ß√µes de poster (download_and_save_poster, generate_poster_with_ffmpeg)\n",
        "    # n√£o precisam do ID para funcionar, apenas o username para o nome do arquivo tempor√°rio.\n",
        "    poster_temp_path = None\n",
        "    if poster_url:\n",
        "        poster_temp_path = download_and_save_poster(poster_url, username, TEMP_OUTPUT_FOLDER)\n",
        "    # generate_poster_with_ffmpeg j√° foi ajustada na C√©lula 3 para usar a tupla de tries correta\n",
        "    if not is_poster_valid(poster_temp_path) and m3u8_url:\n",
        "        poster_temp_path = generate_poster_with_ffmpeg(m3u8_url, username, TEMP_OUTPUT_FOLDER, frame_time=poster_frame_time)\n",
        "\n",
        "\n",
        "    ffmpeg_cmd = [\n",
        "        \"ffmpeg\", \"-i\", m3u8_url,\n",
        "        \"-t\", str(RECORD_SECONDS),\n",
        "        \"-c\", \"copy\", \"-y\", filepath\n",
        "    ]\n",
        "\n",
        "    start_time_process = time.time()\n",
        "    process = None\n",
        "\n",
        "    try:\n",
        "        process = subprocess.Popen(\n",
        "            ffmpeg_cmd,\n",
        "            stdout=subprocess.PIPE,\n",
        "            stderr=subprocess.STDOUT,\n",
        "            text=True,\n",
        "            bufsize=1,\n",
        "            universal_newlines=True\n",
        "        )\n",
        "\n",
        "        # --- Monitoramento de progresso do ffmpeg (logs em tempo real) ---\n",
        "        # log_progress usa apenas username\n",
        "        elapsed_seconds = 0\n",
        "        last_log_minute = -1\n",
        "        while True:\n",
        "            line = process.stdout.readline()\n",
        "            if not line and process.poll() is not None:\n",
        "                break\n",
        "            if \"time=\" in line:\n",
        "                try:\n",
        "                    match = re.search(r\"time=(\\d+):(\\d+):(\\d+)\", line)\n",
        "                    if match:\n",
        "                        h, m, s = map(int, match.groups())\n",
        "                        elapsed_seconds = h * 3600 + m * 60 + s\n",
        "                        if elapsed_seconds // 60 != last_log_minute:\n",
        "                            log_progress(username, elapsed_seconds, RECORD_SECONDS)\n",
        "                            last_log_minute = elapsed_seconds // 60\n",
        "                except Exception:\n",
        "                    pass\n",
        "\n",
        "        process.wait()\n",
        "        end_time_process = time.time()\n",
        "        elapsed_seconds_proc = round(end_time_process - start_time_process)\n",
        "        log_progress(username, elapsed_seconds_proc, RECORD_SECONDS)\n",
        "\n",
        "        # --- Se FFmpeg falhou, registra no log central e retorna erro (USANDO ID) ---\n",
        "        if process.returncode != 0:\n",
        "            msg = f\"FFmpeg falhou para '{username}' (ID: {user_id}). C√≥digo de sa√≠da: {process.returncode}\" # Adiciona ID na mensagem\n",
        "            print(f\"‚ùå {msg}\")\n",
        "            append_log({\n",
        "                \"sessao\": \"processing\",\n",
        "                \"evento\": \"erro_ffmpeg\",\n",
        "                \"id\": user_id, # Usa o ID\n",
        "                \"username\": username,\n",
        "                \"status\": \"erro\",\n",
        "                \"detalhes\": msg\n",
        "            })\n",
        "            register_failure(user_id, username, \"Erro FFmpeg\") # Passa user_id e username\n",
        "            return {\n",
        "                'user_id': user_id, # Inclui user_id no resultado\n",
        "                'username': username,\n",
        "                'filename': temp_filename,\n",
        "                'filepath': filepath,\n",
        "                'upload_success': False,\n",
        "                'abyss_response': msg\n",
        "            }\n",
        "\n",
        "        # --- Valida√ß√£o pelo tempo real do arquivo gravado (robusta) ---\n",
        "        elapsed_seconds_real = get_video_duration(filepath)\n",
        "        if elapsed_seconds_real is not None:\n",
        "            print(f\"‚úÖ Dura√ß√£o real do arquivo gravado: {elapsed_seconds_real}s (ffprobe)\")\n",
        "        else:\n",
        "            print(f\"‚ö†Ô∏è N√£o foi poss√≠vel aferir dura√ß√£o real, usando a do processo: {elapsed_seconds_proc}s\")\n",
        "            elapsed_seconds_real = elapsed_seconds_proc\n",
        "\n",
        "        if elapsed_seconds_real < RECORD_SECONDS_MIN:\n",
        "            msg = f\"Grava√ß√£o muito curta para '{username}' (ID: {user_id}). Dura√ß√£o gravada ({elapsed_seconds_real}s) menor que o m√≠nimo ({RECORD_SECONDS_MIN}s). Arquivo descartado.\" # Adiciona ID\n",
        "            print(f\"‚è© {msg}\")\n",
        "            append_log({\n",
        "                \"sessao\": \"processing\",\n",
        "                \"evento\": \"erro_duracao\",\n",
        "                \"id\": user_id, # Usa o ID\n",
        "                \"username\": username,\n",
        "                \"status\": \"erro\",\n",
        "                \"detalhes\": msg\n",
        "            })\n",
        "            register_failure(user_id, username, \"Grava√ß√£o muito curta\") # Passa user_id e username\n",
        "            if os.path.exists(filepath): os.remove(filepath)\n",
        "            if poster_temp_path and os.path.exists(poster_temp_path): os.remove(poster_temp_path)\n",
        "            return {\n",
        "                'user_id': user_id, # Inclui user_id no resultado\n",
        "                'username': username,\n",
        "                'filename': temp_filename,\n",
        "                'filepath': filepath,\n",
        "                'upload_success': False,\n",
        "                'abyss_response': \"Grava√ß√£o muito curta (descartada)\"\n",
        "            }\n",
        "\n",
        "        # --- Sucesso: limpa falhas acumuladas do usu√°rio no log central (USANDO ID) ---\n",
        "        clear_failure(user_id) # Passa user_id\n",
        "        tempo_formatado = format_seconds(elapsed_seconds_real)\n",
        "        final_filename = f\"{username}_{data_str}_{horario_str}_{tempo_formatado}.mp4\"\n",
        "        final_filepath = os.path.join(TEMP_OUTPUT_FOLDER, final_filename)\n",
        "\n",
        "        try:\n",
        "            os.rename(filepath, final_filepath)\n",
        "            print(f\"‚úÖ Arquivo renomeado para: {final_filename}\")\n",
        "            filepath_for_upload = final_filepath\n",
        "            filename_for_upload = final_filename\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Erro ao renomear arquivo {temp_filename} para {final_filename}: {e}\")\n",
        "            filepath_for_upload = filepath\n",
        "            filename_for_upload = temp_filename\n",
        "\n",
        "        # --- Realiza upload e atualiza√ß√£o do banco de dados (json) ---\n",
        "        # upload_to_abyss_and_update_json (C√©lula 8) precisar√° receber o user_id\n",
        "        success, abyss_resp, slug = upload_to_abyss_and_update_json(\n",
        "            filepath_for_upload, user_id, username, elapsed_seconds_real, # Passa user_id e username\n",
        "            poster_temp_path=poster_temp_path\n",
        "        )\n",
        "\n",
        "        # --- Loga sucesso de grava√ß√£o no log central (USANDO ID) ---\n",
        "        append_log({\n",
        "            \"sessao\": \"processing\",\n",
        "            \"evento\": \"sucesso_gravacao\",\n",
        "            \"id\": user_id, # Usa o ID\n",
        "            \"username\": username,\n",
        "            \"status\": \"ok\",\n",
        "            \"detalhes\": f\"Arquivo {filename_for_upload} gravado e enviado com sucesso para '{username}' (ID: {user_id}). Dura√ß√£o: {elapsed_seconds_real}s\" # Adiciona ID\n",
        "        })\n",
        "\n",
        "        return {\n",
        "            'user_id': user_id, # Inclui user_id no resultado\n",
        "            'username': username,\n",
        "            'filename': filename_for_upload,\n",
        "            'filepath': filepath_for_upload,\n",
        "            'upload_success': success,\n",
        "            'abyss_response': abyss_resp,\n",
        "            'slug': slug\n",
        "        }\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        msg = \"Comando 'ffmpeg' n√£o encontrado. Certifique-se de que foi instalado corretamente.\"\n",
        "        print(f\"‚ùå {msg}\")\n",
        "        # Registrar falha de ffmpeg n√£o encontrado (USANDO ID)\n",
        "        if 'register_failure' in globals(): # Verifica se a fun√ß√£o existe\n",
        "             register_failure(user_id, username, msg) # Passa user_id e username\n",
        "        append_log({\n",
        "            \"sessao\": \"processing\",\n",
        "            \"evento\": \"erro_ffmpeg_nao_encontrado\",\n",
        "            \"id\": user_id, # Usa o ID\n",
        "            \"username\": username,\n",
        "            \"status\": \"erro\",\n",
        "            \"detalhes\": msg\n",
        "        })\n",
        "        return {\n",
        "            'user_id': user_id, # Inclui user_id no resultado\n",
        "            'username': username,\n",
        "            'filename': None,\n",
        "            'filepath': None,\n",
        "            'upload_success': False,\n",
        "            'abyss_response': msg\n",
        "        }\n",
        "    except Exception as e:\n",
        "        msg = f\"Erro inesperado durante a execu√ß√£o do FFmpeg para '{username}' (ID: {user_id}): {e}\" # Adiciona ID\n",
        "        print(f\"‚ùå {msg}\")\n",
        "        # Registrar falha de execu√ß√£o de ffmpeg (USANDO ID)\n",
        "        if 'register_failure' in globals(): # Verifica se a fun√ß√£o existe\n",
        "             register_failure(user_id, username, msg) # Passa user_id e username\n",
        "        append_log({\n",
        "            \"sessao\": \"processing\",\n",
        "            \"evento\": \"erro_execucao_ffmpeg\",\n",
        "            \"id\": user_id, # Usa o ID\n",
        "            \"username\": username,\n",
        "            \"status\": \"erro\",\n",
        "            \"detalhes\": msg\n",
        "        })\n",
        "        return {\n",
        "            'user_id': user_id, # Inclui user_id no resultado\n",
        "            'username': username,\n",
        "            'filename': None,\n",
        "            'filepath': None,\n",
        "            'upload_success': False,\n",
        "            'abyss_response': msg\n",
        "        }\n",
        "    finally:\n",
        "        # --- Remove marca√ß√£o de processamento ativo no log central (USANDO ID) ---\n",
        "        unmark_processing(user_id) # Passa user_id\n",
        "\n",
        "        # --- Limpeza do arquivo de v√≠deo p√≥s-upload ---\n",
        "        if 'filepath_for_upload' in locals() and os.path.exists(filepath_for_upload):\n",
        "            try:\n",
        "                os.remove(filepath_for_upload)\n",
        "                print(f\"üóëÔ∏è Arquivo de v√≠deo tempor√°rio local removido do Colab: {filepath_for_upload}\")\n",
        "                # Log de limpeza\n",
        "                if 'append_log' in globals():\n",
        "                     append_log({\n",
        "                         \"sessao\": \"cleanup\",\n",
        "                         \"evento\": \"remover_video_temp\",\n",
        "                         \"id\": user_id, # Usa o ID\n",
        "                         \"username\": username,\n",
        "                         \"status\": \"ok\",\n",
        "                         \"detalhes\": f\"Arquivo de v√≠deo tempor√°rio local removido: {filepath_for_upload}\"\n",
        "                     })\n",
        "            except Exception as e:\n",
        "                print(f\"‚ö†Ô∏è N√£o foi poss√≠vel remover o arquivo de v√≠deo tempor√°rio local: {e}\")\n",
        "                # Log de erro de limpeza\n",
        "                if 'append_log' in globals():\n",
        "                     append_log({\n",
        "                         \"sessao\": \"cleanup\",\n",
        "                         \"evento\": \"erro_remover_video_temp\",\n",
        "                         \"id\": user_id, # Usa o ID\n",
        "                         \"username\": username,\n",
        "                         \"status\": \"erro\",\n",
        "                         \"detalhes\": f\"Erro ao remover arquivo de v√≠deo tempor√°rio local: {e}\"\n",
        "                     })\n",
        "\n",
        "\n",
        "        # --- Limpeza do poster tempor√°rio ---\n",
        "        # poster_temp_path √© o caminho ANTES da renomea√ß√£o com slug\n",
        "        if poster_temp_path and os.path.exists(poster_temp_path):\n",
        "            try:\n",
        "                os.remove(poster_temp_path)\n",
        "                # print(f\"üóëÔ∏è Poster tempor√°rio original removido: {poster_temp_path}\") # J√° logado na C√©lula 8 se movido\n",
        "            except Exception as e:\n",
        "                # print(f\"‚ö†Ô∏è N√£o foi poss√≠vel remover o poster tempor√°rio original: {e}\") # J√° logado na C√©lula 8 se movido\n",
        "                pass # A C√©lula 8 lida com a limpeza do poster renomeado/movido\n",
        "\n",
        "\n",
        "# ================================================================\n",
        "# Fim da C√©lula 7 ‚Äî Grava√ß√£o, Log Centralizado e Blacklist Inteligente (AGORA USANDO ID)\n",
        "# ================================================================\n",
        "\n",
        "# Observa√ß√µes e recomenda√ß√µes:\n",
        "# - Toda manipula√ß√£o de status, falha, blacklist e processamento √© feita via fun√ß√µes do log centralizado (C√©lula 1 e 6), AGORA USANDO O ID.\n",
        "# - Mensagens claras e detalhadas e logging estruturado garantem rastreabilidade, CI/CD e manuten√ß√£o.\n",
        "# - Pronto para execu√ß√£o concorrente, pipelines e auditoria centralizada no XCam."
      ],
      "metadata": {
        "id": "eJ_jrfNgKZNr"
      },
      "id": "eJ_jrfNgKZNr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# C√©lula 8: Upload para Abyss.to, Atualiza√ß√£o do rec.json, Commit Poster, Sincroniza√ß√£o com Google Drive ‚Äî Log Centralizado\n",
        "\n",
        "**Objetivo:**  \n",
        "Realizar upload do v√≠deo gravado para Abyss.to, registrar e atualizar todos os metadados relevantes no arquivo `rec.json` do usu√°rio, garantir a movimenta√ß√£o/renomea√ß√£o adequada do poster e executar o commit/push automatizado de arquivos alterados, sincronizando tamb√©m com o Google Drive e **registrando todas as a√ß√µes relevantes no log centralizado (`xcam_master.log`)**.  \n",
        "O processo √© otimizado para processamento em lote: os arquivos modificados s√≥ s√£o enviados quando o n√∫mero atingir o limiar (`COMMIT_PUSH_THRESHOLD`), promovendo efici√™ncia, rastreabilidade e integridade do reposit√≥rio, mesmo em execu√ß√£o paralela.\n",
        "\n",
        "---\n",
        "\n",
        "## Estrat√©gia e melhorias implementadas\n",
        "\n",
        "- **Commit/push em lote otimizado e rastre√°vel:**  \n",
        "  Arquivos alterados s√£o acumulados em um buffer protegido por lock. O commit e push s√£o executados automaticamente quando a quantidade de arquivos atinge o threshold configurado, reduzindo conflitos e otimizando o workflow CI/CD. Todas as a√ß√µes de commit s√£o registradas no log central para auditoria.\n",
        "- **Sincroniza√ß√£o autom√°tica com o Google Drive:**  \n",
        "  Sempre que `rec.json` ou poster s√£o atualizados, uma c√≥pia √© feita para o diret√≥rio correspondente do usu√°rio no Google Drive (se dispon√≠vel), garantindo redund√¢ncia, persist√™ncia e f√°cil acesso externo aos metadados e imagens. Falhas na sincroniza√ß√£o tamb√©m s√£o logadas.\n",
        "- **Atomicidade, concorr√™ncia e log centralizado:**  \n",
        "  O acesso ao buffer de commit √© protegido por lock (`threading.Lock`), assegurando integridade mesmo em processamento paralelo ou m√∫ltiplos workers. Cada etapa cr√≠tica (upload, poster, commit, rec.json) √© registrada via `append_log` para rastreabilidade total.\n",
        "- **Poster sempre correto e rastre√°vel:**  \n",
        "  O poster utilizado √© sempre movido/renomeado para o local definitivo e associado ao v√≠deo pelo nome (`slug`). O caminho √© sincronizado tanto no reposit√≥rio quanto no Drive, e o evento √© registrado no log.\n",
        "- **Atualiza√ß√£o robusta do rec.json:**  \n",
        "  O hist√≥rico do usu√°rio √© preenchido com todos os campos, incluindo poster, urlIframe, data, hor√°rio e tempo formatado. O padr√£o da estrutura JSON √© rigorosamente seguido, facilitando a integra√ß√£o, an√°lise e exporta√ß√£o dos dados. Atualiza√ß√µes e falhas s√£o sempre logadas.\n",
        "- **Limpeza autom√°tica de arquivos tempor√°rios:**  \n",
        "  Ap√≥s mover, copiar e commitar os arquivos, os tempor√°rios s√£o removidos, mantendo o ambiente Colab limpo e eficiente, com logs de sucesso ou falha de limpeza.\n",
        "\n",
        "---\n",
        "\n",
        "## Como funciona o fluxo principal\n",
        "\n",
        "1. **Faz upload do v√≠deo para Abyss.to** e recebe a confirma√ß√£o (slug, url, urlIframe). Evento de sucesso ou falha registrado no log.\n",
        "2. **Move/renomeia o poster** para o local definitivo no reposit√≥rio, associando ao v√≠deo pelo slug. Evento registrado no log.\n",
        "3. **Atualiza ou cria `rec.json`** do usu√°rio, preenchendo todos os metadados da grava√ß√£o. Evento registrado no log.\n",
        "4. **Adiciona arquivos alterados ao buffer de commit** (com lock para evitar concorr√™ncia) e registra a√ß√£o no log.\n",
        "5. **Sincroniza** `rec.json` e poster no Google Drive, mantendo redund√¢ncia e facilidade de acesso. Falhas de sync s√£o logadas.\n",
        "6. **Executa commit/push autom√°tico em lote** ao atingir o limiar definido; ao final do processamento faz o commit/push dos arquivos restantes, sempre registrando eventos no log central.\n",
        "7. **Limpa arquivos tempor√°rios** garantindo efici√™ncia, organiza√ß√£o do ambiente e registro de sucesso/falha no log.\n",
        "\n",
        "---\n",
        "\n",
        "## Exemplo de uso recomendado\n",
        "\n",
        "```python\n",
        "# Ap√≥s concluir o upload e gerar poster:\n",
        "upload_success, abyss_response, slug = upload_to_abyss_and_update_json(\n",
        "    filepath=arquivo_video,\n",
        "    username=\"usuario\",\n",
        "    duration_seconds=duracao,\n",
        "    poster_temp_path=caminho_poster_temp\n",
        ")\n",
        "\n",
        "# Ao final do processamento, para garantir commit dos arquivos restantes:\n",
        "commit_push_restantes()\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Seguran√ßa, rastreabilidade e integra√ß√£o\n",
        "\n",
        "- **Processo compat√≠vel com execu√ß√£o concorrente** e pipelines CI/CD.\n",
        "- **Commit/push protegido contra condi√ß√µes de corrida**, garantindo atomicidade dos dados no reposit√≥rio.\n",
        "- **Sincroniza√ß√£o Drive robusta**, ideal para ambientes colaborativos ou para garantir backup.\n",
        "- **Toda a√ß√£o relevante registrada no log centralizado**: upload, poster, commit, rec.json, limpeza e falhas.\n",
        "- **Mensagens e logs claros** facilitam manuten√ß√£o, auditoria e diagn√≥stico r√°pido em todo o pipeline XCam.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "YjGKDlbIKaLs"
      },
      "id": "YjGKDlbIKaLs"
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================\n",
        "# C√©lula 8: Upload para Abyss.to, Atualiza√ß√£o do rec.json e Poster no Google Drive\n",
        "# ================================================================\n",
        "# Objetivo:\n",
        "# - Fazer upload do v√≠deo gravado para Abyss.to e registrar corretamente os metadados.\n",
        "# - Salvar grava√ß√£o e poster temporariamente no Colab.\n",
        "# - Renomear poster tempor√°rio com slug (no Colab temp).\n",
        "# - LER/ESCREVER rec.json DIRETAMENTE no Google Drive.\n",
        "# - MOVER poster renomeado do Colab temp para o Google Drive.\n",
        "# - Limpar arquivos tempor√°rios locais ap√≥s uso.\n",
        "# - Modular, preparado para CI/CD, concorr√™ncia e integra√ß√£o total ao pipeline XCam.\n",
        "# ================================================================\n",
        "\n",
        "# Caminho base no Google Drive para arquivos permanentes (rec.json, posters)\n",
        "DRIVE_USER_BASE = \"/content/drive/MyDrive/XCam.Drive/user\"\n",
        "\n",
        "def upload_to_abyss_and_update_json(\n",
        "    filepath, username, duration_seconds, poster_temp_path=None\n",
        "):\n",
        "    \"\"\"\n",
        "    Realiza upload do v√≠deo, atualiza rec.json do usu√°rio (no Drive),\n",
        "    renomeia poster com slug (no Colab temp) e MOVE para o Google Drive.\n",
        "    - Salva grava√ß√£o e poster temporariamente no Colab.\n",
        "    - L√ä/ESCREVE rec.json DIRETAMENTE no Drive.\n",
        "    - Renomeia poster tempor√°rio no Colab temp com o slug retornado.\n",
        "    - MOVE poster renomeado do Colab temp para o Drive.\n",
        "    - Limpa arquivos tempor√°rios locais ap√≥s uso.\n",
        "    - Toda a√ß√£o relevante √© registrada no log centralizado via append_log().\n",
        "    \"\"\"\n",
        "    file_name = os.path.basename(filepath) # Nome do arquivo de v√≠deo renomeado (username_data_horario_tempo.mp4)\n",
        "    file_type = 'video/mp4'\n",
        "    print(f\"‚¨ÜÔ∏è Upload de: {file_name} para Abyss.to...\")\n",
        "\n",
        "    upload_success = False\n",
        "    abyss_response = \"Upload falhou - Sem resposta\"\n",
        "    uploaded_url = None\n",
        "    video_id = None\n",
        "    slug = None\n",
        "\n",
        "    # ---- Upload do v√≠deo para Abyss.to ----\n",
        "    try:\n",
        "        with open(filepath, 'rb') as f:\n",
        "            files = { 'file': (file_name, f, file_type) }\n",
        "            response = requests.post(ABYSS_UPLOAD_URL, files=files)\n",
        "            resp_json = response.json()\n",
        "            abyss_response = resp_json\n",
        "            if resp_json.get('status'):\n",
        "                upload_success = True\n",
        "                uploaded_url = resp_json.get('url') or resp_json.get('urlIframe')\n",
        "                video_id = resp_json.get('slug') or resp_json.get('video')\n",
        "                slug = video_id\n",
        "                print(f\"üì§ Upload bem-sucedido. URL: {uploaded_url} | SLUG: {slug}\")\n",
        "                append_log({\n",
        "                    \"sessao\": \"upload\",\n",
        "                    \"evento\": \"upload_sucesso\",\n",
        "                    \"id\": username,\n",
        "                    \"username\": username,\n",
        "                    \"status\": \"ok\",\n",
        "                    \"detalhes\": f\"Arquivo {file_name} enviado para Abyss.to. URL: {uploaded_url}, SLUG: {slug}\"\n",
        "                })\n",
        "            else:\n",
        "                print(f\"‚ùå Falha no upload. Mensagem: {resp_json.get('message','')}\")\n",
        "                append_log({\n",
        "                    \"sessao\": \"upload\",\n",
        "                    \"evento\": \"upload_falhou\",\n",
        "                    \"id\": username,\n",
        "                    \"username\": username,\n",
        "                    \"status\": \"erro\",\n",
        "                    \"detalhes\": f\"Falha no upload. Mensagem: {resp_json.get('message','')}\"\n",
        "                })\n",
        "    except Exception as e:\n",
        "        abyss_response = f\"Erro no upload: {e}\"\n",
        "        print(f\"‚ùå Erro no upload: {e}\")\n",
        "        append_log({\n",
        "            \"sessao\": \"upload\",\n",
        "            \"evento\": \"upload_falhou\",\n",
        "            \"id\": username,\n",
        "            \"username\": username,\n",
        "            \"status\": \"erro\",\n",
        "            \"detalhes\": f\"Exce√ß√£o no upload: {e}\"\n",
        "        })\n",
        "\n",
        "    poster_temp_renamed_path = None\n",
        "    drive_json_filepath = os.path.join(DRIVE_USER_BASE, username, \"rec.json\")\n",
        "    drive_user_dir = os.path.join(DRIVE_USER_BASE, username) # Pasta do usu√°rio no Drive\n",
        "\n",
        "    if upload_success and slug:\n",
        "        # ---- Renomeia o poster tempor√°rio com o slug retornado (no diret√≥rio tempor√°rio do Colab) ----\n",
        "        # O poster_temp_path j√° est√° em TEMP_OUTPUT_FOLDER (gerado/baixado pela C√©lula 7)\n",
        "        if poster_temp_path and os.path.exists(poster_temp_path):\n",
        "            try:\n",
        "                # O novo nome ser√° {slug}.jpg\n",
        "                poster_final_name = f\"{slug}.jpg\"\n",
        "                # A renomea√ß√£o ocorre dentro do diret√≥rio TEMPOR√ÅRIO do Colab\n",
        "                poster_temp_renamed_path = os.path.join(TEMP_OUTPUT_FOLDER, poster_final_name)\n",
        "                # Move (renomeia) o poster DENTRO do diret√≥rio tempor√°rio\n",
        "                shutil.move(poster_temp_path, poster_temp_renamed_path)\n",
        "                print(f\"üñºÔ∏è Poster tempor√°rio renomeado para {poster_final_name} em {TEMP_OUTPUT_FOLDER}\")\n",
        "                append_log({\n",
        "                    \"sessao\": \"poster\",\n",
        "                    \"evento\": \"poster_renomeado_temp\",\n",
        "                    \"id\": username,\n",
        "                    \"username\": username,\n",
        "                    \"status\": \"ok\",\n",
        "                    \"detalhes\": f\"Poster tempor√°rio renomeado para {poster_final_name} no Colab temp.\"\n",
        "                })\n",
        "            except Exception as e:\n",
        "                print(f\"‚ùå Erro ao renomear poster tempor√°rio no Colab: {e}\")\n",
        "                # Tenta limpar o poster tempor√°rio original se o renomeio falhar\n",
        "                if os.path.exists(poster_temp_path):\n",
        "                    try:\n",
        "                        os.remove(poster_temp_path)\n",
        "                    except Exception as clean_e:\n",
        "                        print(f\"‚ö†Ô∏è Falha ao limpar poster tempor√°rio original ap√≥s erro: {clean_e}\")\n",
        "                poster_temp_renamed_path = None # Garante que n√£o tentaremos mover um arquivo que n√£o existe\n",
        "                append_log({\n",
        "                    \"sessao\": \"poster\",\n",
        "                    \"evento\": \"erro_renomear_poster_temp\",\n",
        "                    \"id\": username,\n",
        "                    \"username\": username,\n",
        "                    \"status\": \"erro\",\n",
        "                    \"detalhes\": f\"Erro ao renomear poster tempor√°rio no Colab: {e}\"\n",
        "                })\n",
        "        else:\n",
        "             print(f\"‚ö†Ô∏è Poster tempor√°rio n√£o encontrado ou inv√°lido para renomear com slug.\")\n",
        "             append_log({\n",
        "                \"sessao\": \"poster\",\n",
        "                \"evento\": \"poster_temp_nao_encontrado\",\n",
        "                \"id\": username,\n",
        "                \"username\": username,\n",
        "                \"status\": \"aviso\",\n",
        "                \"detalhes\": \"Poster tempor√°rio n√£o encontrado ou inv√°lido para renomear com slug.\"\n",
        "            })\n",
        "\n",
        "\n",
        "        # ---- Atualiza/Cria rec.json do usu√°rio (DIRETAMENTE no Google Drive) ----\n",
        "        try:\n",
        "            # Caminho no Drive onde o rec.json deve estar/ser salvo\n",
        "            os.makedirs(drive_user_dir, exist_ok=True) # Garante que a pasta do usu√°rio no Drive exista\n",
        "\n",
        "            file_base = file_name.replace('.mp4', '')\n",
        "            parts = file_base.split('_')\n",
        "            if len(parts) >= 4:\n",
        "                json_data = parts[-3]\n",
        "                json_horario = parts[-2]\n",
        "                json_tempo = parts[-1]\n",
        "            else:\n",
        "                now = datetime.now()\n",
        "                json_data = now.strftime(\"%d-%m-%Y\")\n",
        "                json_horario = now.strftime(\"%H-%M\")\n",
        "                json_tempo = format_seconds(duration_seconds)\n",
        "\n",
        "            # A URL do poster no rec.json aponta para onde ele estar√° PUBLICAMENTE dispon√≠vel\n",
        "            # (presumindo que o conte√∫do do Drive ser√° servido ou sincronizado externamente)\n",
        "            poster_url_final = f\"https://db.xcam.gay/user/{username}/{slug}.jpg\" if slug else \"\"\n",
        "            url_iframe_final = f\"https://short.icu/{slug}?thumbnail={poster_url_final}\" if slug else \"\"\n",
        "\n",
        "            new_video_entry = {\n",
        "                \"video\": slug if slug else \"ID_n√£o_retornado\",\n",
        "                \"title\": file_base,\n",
        "                \"file\": file_name, # O nome do arquivo de v√≠deo original √© mantido como refer√™ncia\n",
        "                \"url\": uploaded_url if uploaded_url else \"URL_n√£o_retornada\",\n",
        "                \"poster\": poster_url_final, # Esta URL deve ser acess√≠vel publicamente\n",
        "                \"urlIframe\": url_iframe_final, # Esta URL deve ser acess√≠vel publicamente\n",
        "                \"data\": json_data,\n",
        "                \"horario\": json_horario,\n",
        "                \"tempo\": json_tempo\n",
        "            }\n",
        "\n",
        "            def zerar_base(username):\n",
        "                return {\n",
        "                    \"username\": username,\n",
        "                    \"records\": 0,\n",
        "                    \"videos\": []\n",
        "                }\n",
        "\n",
        "            # Carrega ou inicializa rec.json (DIRETAMENTE do Drive)\n",
        "            rec_data = zerar_base(username) # Inicializa com base zero por seguran√ßa\n",
        "            if os.path.exists(drive_json_filepath):\n",
        "                 try:\n",
        "                     with open(drive_json_filepath, 'r', encoding='utf-8') as f:\n",
        "                         loaded = json.load(f)\n",
        "                     # Valida se a estrutura carregada √© razo√°vel, sen√£o cria uma nova\n",
        "                     valid = (\n",
        "                         isinstance(loaded, dict)\n",
        "                         and \"username\" in loaded\n",
        "                         and \"records\" in loaded\n",
        "                         and \"videos\" in loaded\n",
        "                         and isinstance(loaded[\"videos\"], list)\n",
        "                     )\n",
        "                     rec_data = loaded if valid else zerar_base(username)\n",
        "                     print(f\"üìù Carregado rec.json existente do Drive para {username}\")\n",
        "                 except Exception as read_drive_e:\n",
        "                      print(f\"‚ö†Ô∏è Erro ao ler rec.json existente no Drive ({drive_json_filepath}), criando novo: {read_drive_e}\")\n",
        "                      # Se der erro na leitura, rec_data j√° est√° zerada\n",
        "\n",
        "            # Adiciona novo v√≠deo ao hist√≥rico (no objeto carregado/novo)\n",
        "            rec_data[\"records\"] += 1\n",
        "            rec_data[\"videos\"].append(new_video_entry)\n",
        "\n",
        "            # Salva rec.json (DIRETAMENTE no Drive)\n",
        "            with open(drive_json_filepath, 'w', encoding='utf-8') as f:\n",
        "                json.dump(rec_data, f, indent=2, ensure_ascii=False)\n",
        "            print(f\"‚úÖ rec.json para {username} atualizado DIRETAMENTE no Drive: {drive_json_filepath}\")\n",
        "\n",
        "            append_log({\n",
        "                \"sessao\": \"recjson\",\n",
        "                \"evento\": \"recjson_atualizado_drive\",\n",
        "                \"id\": username,\n",
        "                \"username\": username,\n",
        "                \"status\": \"ok\",\n",
        "                \"detalhes\": f\"rec.json atualizado diretamente no Drive em {drive_json_filepath}\"\n",
        "            })\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Erro ao atualizar rec.json no Drive: {e}\")\n",
        "            abyss_response = f\"Upload sucesso, erro no JSON do Drive: {e}\"\n",
        "            # json_temp_path = None # N√£o existe mais json_temp_path neste fluxo\n",
        "            append_log({\n",
        "                \"sessao\": \"recjson\",\n",
        "                \"evento\": \"erro_atualizar_recjson_drive\",\n",
        "                \"id\": username,\n",
        "                \"username\": username,\n",
        "                \"status\": \"erro\",\n",
        "                \"detalhes\": f\"Erro ao atualizar rec.json no Drive: {e}\"\n",
        "            })\n",
        "\n",
        "\n",
        "        # ---- MOVER poster renomeado (do Colab temp) para o Google Drive ----\n",
        "        if poster_temp_renamed_path and os.path.exists(poster_temp_renamed_path):\n",
        "            # O destino √© a pasta do usu√°rio no Drive\n",
        "            drive_poster_filepath = os.path.join(drive_user_dir, os.path.basename(poster_temp_renamed_path))\n",
        "            try:\n",
        "                shutil.move(poster_temp_renamed_path, drive_poster_filepath)\n",
        "                print(f\"üóÇÔ∏è Poster movido para o Drive: {drive_poster_filepath}\")\n",
        "                append_log({\n",
        "                    \"sessao\": \"poster\",\n",
        "                    \"evento\": \"poster_movido_drive\",\n",
        "                    \"id\": username,\n",
        "                    \"username\": username,\n",
        "                    \"status\": \"ok\",\n",
        "                    \"detalhes\": f\"Poster movido para o Drive em {drive_poster_filepath}\"\n",
        "                })\n",
        "            except Exception as e:\n",
        "                print(f\"‚ùå Falha ao MOVER poster para o Drive: {e}\")\n",
        "                append_log({\n",
        "                    \"sessao\": \"poster\",\n",
        "                    \"evento\": \"erro_mover_poster_drive\",\n",
        "                    \"id\": username,\n",
        "                    \"username\": username,\n",
        "                    \"status\": \"erro\",\n",
        "                    \"detalhes\": f\"Erro ao mover poster para o Drive: {e}\"\n",
        "                })\n",
        "        else:\n",
        "             print(f\"‚ö†Ô∏è Poster tempor√°rio renomeado n√£o encontrado para mover para o Drive.\")\n",
        "             append_log({\n",
        "                \"sessao\": \"poster\",\n",
        "                \"evento\": \"poster_temp_renomeado_nao_encontrado\",\n",
        "                \"id\": username,\n",
        "                \"username\": username,\n",
        "                \"status\": \"aviso\",\n",
        "                \"detalhes\": \"Poster tempor√°rio renomeado n√£o encontrado para mover para o Drive.\"\n",
        "            })\n",
        "\n",
        "\n",
        "    # ---- Limpeza do arquivo de v√≠deo tempor√°rio local ----\n",
        "    # Esta limpeza j√° estava presente no bloco finally da gravar_stream (C√©lula 7),\n",
        "    # mas vamos garantir aqui tamb√©m por seguran√ßa, caso a chamada venha de outro lugar.\n",
        "    # O arquivo de v√≠deo renomeado est√° em TEMP_OUTPUT_FOLDER\n",
        "    if os.path.exists(filepath): # filepath √© o caminho do v√≠deo renomeado em TEMP_OUTPUT_FOLDER\n",
        "        try:\n",
        "            os.remove(filepath)\n",
        "            print(f\"üóëÔ∏è Arquivo de v√≠deo tempor√°rio local removido: {filepath}\")\n",
        "            append_log({\n",
        "                \"sessao\": \"cleanup\",\n",
        "                \"evento\": \"remover_video_temp\",\n",
        "                \"id\": username,\n",
        "                \"username\": username,\n",
        "                \"status\": \"ok\",\n",
        "                \"detalhes\": f\"Arquivo de v√≠deo tempor√°rio local removido: {filepath}\"\n",
        "            })\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è N√£o foi poss√≠vel remover o arquivo de v√≠deo tempor√°rio local: {e}\")\n",
        "            append_log({\n",
        "                \"sessao\": \"cleanup\",\n",
        "                \"evento\": \"erro_remover_video_temp\",\n",
        "                \"id\": username,\n",
        "                \"username\": username,\n",
        "                \"status\": \"erro\",\n",
        "                \"detalhes\": f\"Erro ao remover arquivo de v√≠deo tempor√°rio local: {e}\"\n",
        "            })\n",
        "\n",
        "    # ---- Limpeza do diret√≥rio tempor√°rio do usu√°rio, se estiver vazio ----\n",
        "    # O diret√≥rio tempor√°rio do usu√°rio pode n√£o ter sido criado se o upload falhou antes.\n",
        "    # TEMP_OUTPUT_FOLDER √© o diret√≥rio geral. N√£o vamos remover subdiret√≥rios espec√≠ficos aqui.\n",
        "    # A limpeza do diret√≥rio temp do usu√°rio pode ser feita de forma mais robusta em outro local ou manualmente.\n",
        "    # Manteremos a limpeza apenas dos arquivos espec√≠ficos manipulados.\n",
        "\n",
        "    return upload_success, abyss_response, slug\n",
        "\n",
        "# A fun√ß√£o de commit final pendente n√£o √© mais necess√°ria, pois o commit √© gerenciado externamente.\n",
        "# def commit_push_restantes():\n",
        "#     \"\"\"\n",
        "#     Esta fun√ß√£o n√£o √© mais necess√°ria pois o commit/push √© gerenciado externamente.\n",
        "#     \"\"\"\n",
        "#     pass # L√≥gica de commit/push removida\n",
        "\n",
        "# ================================================================\n",
        "# FIM DA C√©lula 8 ‚Äî Upload, Metadados e Posters no Google Drive (com log centralizado)\n",
        "# ================================================================\n",
        "\n",
        "# Observa√ß√µes:\n",
        "# - A grava√ß√£o e o poster inicial ficam no Colab temp.\n",
        "# - O rec.json √© lido e escrito DIRETAMENTE no Drive.\n",
        "# - O poster renomeado √© MOVIDO do Colab temp para o Drive.\n",
        "# - Certifique-se de que o Google Drive esteja montado antes de executar esta c√©lula.\n",
        "# - A URL do poster no rec.json (db.xcam.gay) presume que o conte√∫do do Drive ser√° servido publicamente de alguma forma.\n",
        "# - O commit/push agora √© gerenciado por um script externo que deve ler os arquivos do Drive.\n",
        "# - Toda a√ß√£o relevante registrada no log centralizado para total rastreabilidade/auditoria."
      ],
      "metadata": {
        "id": "vMTiCrJ5Kp81"
      },
      "id": "vMTiCrJ5Kp81",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# C√©lula 9: Processamento Autom√°tico, Paralelismo e Supervisor Din√¢mico com Blacklist\n",
        "\n",
        "**Objetivo:**  \n",
        "Controlar e orquestrar todo o pipeline do notebook, garantindo processamento cont√≠nuo, paralelo, eficiente e seguro de transmiss√µes ao vivo. O supervisor din√¢mico mant√©m o lote sempre cheio, respeita a blacklist tempor√°ria e o log central, e integra todas as fun√ß√µes cr√≠ticas das c√©lulas anteriores, garantindo m√°xima resili√™ncia e rastreabilidade.\n",
        "\n",
        "---\n",
        "\n",
        "## Estrat√©gia e melhorias implementadas\n",
        "\n",
        "- **Paralelismo seguro e eficiente:**  \n",
        "  Utiliza m√∫ltiplos processos para gravar e processar transmiss√µes simultaneamente, otimizando o uso de recursos e acelerando o processamento em lote.\n",
        "- **Supervisor din√¢mico e lote sempre cheio:**  \n",
        "  O supervisor monitora constantemente as vagas livres no lote e preenche em tempo real com novas transmiss√µes v√°lidas, evitando ociosidade e maximizando a efici√™ncia.\n",
        "- **Controle centralizado de duplicidade:**  \n",
        "  Antes de processar qualquer transmiss√£o, consulta o log central de processamento para evitar duplicidade, mesmo em ambientes concorrentes ou paralelos.\n",
        "- **Respeito integral √† blacklist tempor√°ria:**  \n",
        "  Transmiss√µes de usu√°rios em blacklist n√£o s√£o tentadas novamente durante o ciclo vigente, economizando recursos e evitando loops problem√°ticos.\n",
        "- **Logs robustos e detalhados:**  \n",
        "  Cada etapa do processamento √© registrada com timestamp, status e contexto, facilitando auditoria, troubleshooting e acompanhamento em produ√ß√£o.\n",
        "- **Commit/push autom√°tico e seguro:**  \n",
        "  Ao final do ciclo (ou quando atingido o threshold), todos os arquivos alterados s√£o enviados ao reposit√≥rio, garantindo consist√™ncia e persist√™ncia dos dados.\n",
        "- **Design modular e Clean Architecture:**  \n",
        "  Fun√ß√µes separadas para supervis√£o, workers, busca, commit, log, etc., facilitando manuten√ß√£o, reuso e integra√ß√£o com CI/CD.\n",
        "\n",
        "---\n",
        "\n",
        "## Como funciona o fluxo principal\n",
        "\n",
        "1. **Inicializa√ß√£o:**  \n",
        "   - Determina o modo de opera√ß√£o: grava√ß√£o de usu√°rios espec√≠ficos ou busca autom√°tica.\n",
        "   - Calcula o tamanho do lote alvo (`LIMIT_DEFAULT` ou `API_SEARCH_LIMIT`).\n",
        "\n",
        "2. **Preenchimento do lote:**  \n",
        "   - Busca transmiss√µes v√°lidas (n√£o duplicadas, n√£o em blacklist) e lan√ßa workers para cada uma, registrando no log de processamento.\n",
        "   - Utiliza fun√ß√µes otimizadas de busca (`buscar_proxima_transmissao_livre` e `buscar_usuarios_especificos`), integradas √† blacklist e ao log.\n",
        "\n",
        "3. **Supervis√£o din√¢mica:**  \n",
        "   - Monitora o ciclo de vida dos workers/processos.\n",
        "   - Preenche imediatamente cada vaga livre com nova transmiss√£o dispon√≠vel, at√© esgotar as op√ß√µes v√°lidas.\n",
        "\n",
        "4. **Respeito √† blacklist:**  \n",
        "   - Antes de qualquer grava√ß√£o, verifica se o usu√°rio est√° em blacklist tempor√°ria.\n",
        "   - Usu√°rios problem√°ticos nunca s√£o tentados duas vezes no mesmo ciclo.\n",
        "\n",
        "5. **Logs detalhados:**  \n",
        "   - Todas as opera√ß√µes geram logs padronizados com n√≠vel (INFO, WORKER, BUSCA, ERRO, etc.) e timestamp.\n",
        "\n",
        "6. **Finaliza√ß√£o segura:**  \n",
        "   - Ao final do processamento, executa commit/push dos arquivos pendentes, garantindo persist√™ncia e integridade do reposit√≥rio.\n",
        "\n",
        "---\n",
        "\n",
        "## Exemplo de uso recomendado\n",
        "\n",
        "```python\n",
        "# Fun√ß√£o principal do notebook: dispara o supervisor din√¢mico\n",
        "main()\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Seguran√ßa, rastreabilidade e integra√ß√£o\n",
        "\n",
        "- **Pronto para execu√ß√£o concorrente e ambientes CI/CD.**\n",
        "- **A l√≥gica de blacklist e commit est√° totalmente integrada ao fluxo, garantindo m√°xima resili√™ncia.**\n",
        "- **Logs detalhados e arquitetura modular facilitam diagn√≥stico, manuten√ß√£o e evolu√ß√£o do pipeline XCam.**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "iwgt8f8iKq4y"
      },
      "id": "iwgt8f8iKq4y"
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "# ================================================================\n",
        "# C√©lula 9: Supervisor Din√¢mico ‚Äî Execu√ß√£o Paralela, Lote Sempre Cheio, Blacklist e Log Centralizado (AGORA USANDO ID)\n",
        "# ================================================================\n",
        "# Objetivo:\n",
        "# - Manter o lote de grava√ß√µes sempre cheio, preenchendo vagas em tempo real com m√°xima efici√™ncia e seguran√ßa.\n",
        "# - Garantir que usu√°rios problem√°ticos (em blacklist - por ID) n√£o sejam tentados novamente no ciclo vigente.\n",
        "# - Prevenir duplicidade consultando log central de processamento (por ID) antes de iniciar qualquer grava√ß√£o.\n",
        "# - Integrar-se com a l√≥gica de blacklist, commit/push autom√°tico, limpeza de recursos e log robusto, TUDO BASEADO NO ID.\n",
        "# - Modularidade e clareza, pronta para integra√ß√£o com pipelines CI/CD, execu√ß√£o concorrente e ambientes colaborativos.\n",
        "# ================================================================\n",
        "\n",
        "from multiprocessing import Process, Manager # Garantir imports\n",
        "\n",
        "def log_supervisor(msg, level=\"INFO\"):\n",
        "    \"\"\"\n",
        "    Log supervisor padronizado para todas as etapas do pipeline.\n",
        "    Tamb√©m registra cada evento relevante no log centralizado (sessao supervisor).\n",
        "    Pode incluir ID/username se relevante para o evento.\n",
        "    \"\"\"\n",
        "    from datetime import datetime\n",
        "    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "    print(f\"[{timestamp}] [{level}] {msg}\")\n",
        "    # Registro tamb√©m no log central (sessao supervisor)\n",
        "    append_log({\n",
        "        \"sessao\": \"supervisor\",\n",
        "        \"evento\": level,\n",
        "        \"id\": \"global\", # Evento global do supervisor\n",
        "        \"username\": \"global\",\n",
        "        \"status\": \"info\" if level != \"ERRO\" else \"erro\",\n",
        "        \"detalhes\": msg\n",
        "    })\n",
        "\n",
        "# Adicionando user_id como par√¢metro para o worker\n",
        "def worker(user_id, username, m3u8_url, poster_path, results):\n",
        "    \"\"\"\n",
        "    Worker dedicado: grava a stream, faz upload, atualiza rec.json/poster, integra ao log.\n",
        "    Recebe o ID do usu√°rio e o passa para a fun√ß√£o gravar_stream (C√©lula 7).\n",
        "    O processamento √© rastreado via log central, e o status final √© adicionado √† lista de resultados.\n",
        "    \"\"\"\n",
        "    # gravar_stream agora espera user_id como primeiro par√¢metro\n",
        "    log_supervisor(f\"Iniciando grava√ß√£o: '{username}' (ID: {user_id}) | URL: {m3u8_url[:50]}...\", \"WORKER\") # Loga o ID\n",
        "    result = gravar_stream(user_id, username, m3u8_url, poster_url=poster_path) # Passa user_id para gravar_stream\n",
        "    log_supervisor(\n",
        "        f\"Finalizou grava√ß√£o: '{username}' (ID: {user_id}) | Sucesso: {result.get('upload_success')} | \" # Loga o ID\n",
        "        f\"Arquivo: {result.get('filename')} | Abyss: {result.get('abyss_response')}\", \"WORKER\")\n",
        "    results.append(result)\n",
        "    # Registro do resultado no log central (j√° feito dentro de gravar_stream, mas refor√ßa aqui)\n",
        "    # append_log({\n",
        "    #     \"sessao\": \"supervisor\",\n",
        "    #     \"evento\": \"worker_result\",\n",
        "    #     \"id\": user_id, # Usa o ID aqui\n",
        "    #     \"username\": username,\n",
        "    #     \"status\": \"ok\" if result.get(\"upload_success\") else \"erro\",\n",
        "    #     \"detalhes\": str(result)\n",
        "    # })\n",
        "\n",
        "\n",
        "# Supervisor din√¢mico, agora usando ID para controle de estado\n",
        "def supervisor_dinamico(usuarios_especificos=None):\n",
        "    \"\"\"\n",
        "    Supervisor din√¢mico de transmiss√µes ao vivo:\n",
        "    - Mant√©m o lote de grava√ß√µes sempre cheio, preenchendo vagas em tempo real.\n",
        "    - Evita duplicidade e concorr√™ncia consultando log central (sessao=\"processing\", status=\"in_progress\"), AGORA PELO ID.\n",
        "    - Respeita blacklist centralizada (pelo ID), n√£o processando usu√°rios bloqueados no ciclo vigente.\n",
        "    - Log detalhado e modular para diagn√≥stico, CI/CD e rastreabilidade.\n",
        "    \"\"\"\n",
        "\n",
        "    # Determina o tamanho do lote com base no modo operacional\n",
        "    pool_size = LIMIT_DEFAULT if not usuarios_especificos else API_SEARCH_LIMIT\n",
        "    running = []\n",
        "    results = Manager().list()\n",
        "    # N√£o precisamos mais do seen_usernames local, pois o log central √© a fonte de verdade para o estado (is_processing, is_in_blacklist)\n",
        "    # seen_usernames = set()\n",
        "\n",
        "    log_supervisor(f\"Supervisor din√¢mico iniciado | Lote alvo: {pool_size} | Modo: {'espec√≠fico' if usuarios_especificos else 'autom√°tico'}\")\n",
        "\n",
        "    # A fun√ß√£o atualizar_seen_usernames local n√£o √© mais necess√°ria,\n",
        "    # pois is_processing e is_in_blacklist consultam o log central diretamente.\n",
        "    # def atualizar_seen_usernames():\n",
        "    #     \"\"\"\n",
        "    #     Atualiza o conjunto de usernames j√° processados diretamente do log central (sessao='processing').\n",
        "    #     Garante robustez em ambientes concorrentes e previne duplicidade.\n",
        "    #     \"\"\"\n",
        "    #     entries = query_logs(sessao=\"processing\", status=\"in_progress\")\n",
        "    #     seen_usernames.update([e[\"username\"] for e in entries])\n",
        "\n",
        "    def buscar_nova_transmissao():\n",
        "        \"\"\"\n",
        "        Busca uma nova transmiss√£o livre para preencher o lote:\n",
        "        - Modo espec√≠fico: busca em lista fornecida (agora retorna ID).\n",
        "        - Modo autom√°tico: busca pr√≥xima transmiss√£o livre dispon√≠vel (agora retorna ID).\n",
        "        - Sempre consulta blacklist (pelo ID) e log central (pelo ID) antes de liberar.\n",
        "        \"\"\"\n",
        "        # N√£o precisamos mais chamar atualizar_seen_usernames() aqui.\n",
        "        # A l√≥gica dentro de is_in_blacklist e is_processing consulta o log central diretamente.\n",
        "\n",
        "        if usuarios_especificos:\n",
        "            # buscar_usuarios_especificos agora retorna lista com ID\n",
        "            candidatos = buscar_usuarios_especificos(usuarios_especificos)\n",
        "            for s in candidatos:\n",
        "                user_id = s[\"id\"] # Captura o ID retornado pela fun√ß√£o de busca\n",
        "                username = s[\"username\"]\n",
        "                # Verifica se o ID est√° em blacklist ou processando (AGORA CONSULTANDO PELO ID)\n",
        "                if not is_in_blacklist(user_id) and not is_processing(user_id):\n",
        "                    log_supervisor(f\"Nova transmiss√£o encontrada (espec√≠fico): '{username}' (ID: {user_id})\", \"BUSCA\") # Loga o ID\n",
        "                    return s # Retorna o dicion√°rio com id, username, src, poster_path\n",
        "                else:\n",
        "                    # Loga que o ID est√° sendo ignorado\n",
        "                    status_detail = \"\"\n",
        "                    if is_in_blacklist(user_id): status_detail += \"blacklist \"\n",
        "                    if is_processing(user_id): status_detail += \"processing \"\n",
        "                    log_supervisor(f\"Usu√°rio '{username}' (ID: {user_id}) j√° em {status_detail.strip()}, ignorando.\", \"BUSCA\")\n",
        "            log_supervisor(\"Nenhuma transmiss√£o espec√≠fica livre encontrada (todos em blacklist/log ou offline).\", \"BUSCA\")\n",
        "            return None\n",
        "        else:\n",
        "            # Busca otimizada: tenta at√© 10 vezes buscar pr√≥xima transmiss√£o livre\n",
        "            for tentativa in range(1, 11):\n",
        "                log_supervisor(f\"Buscando pr√≥xima transmiss√£o livre: tentativa {tentativa}\", \"BUSCA\")\n",
        "                # buscar_proxima_transmissao_livre agora retorna dicion√°rio com ID\n",
        "                stream = buscar_proxima_transmissao_livre()\n",
        "                if stream:\n",
        "                    user_id = stream[\"id\"] # Captura o ID retornado pela fun√ß√£o de busca\n",
        "                    username = stream[\"username\"]\n",
        "                    # Verifica se o ID est√° em blacklist ou processando (AGORA CONSULTANDO PELO ID)\n",
        "                    if not is_in_blacklist(user_id) and not is_processing(user_id):\n",
        "                        log_supervisor(f\"Nova transmiss√£o encontrada: '{username}' (ID: {user_id})\", \"BUSCA\") # Loga o ID\n",
        "                        return stream # Retorna o dicion√°rio com id, username, src, poster_path\n",
        "                    else:\n",
        "                        # Loga que o ID est√° sendo ignorado\n",
        "                        status_detail = \"\"\n",
        "                        if is_in_blacklist(user_id): status_detail += \"blacklist \"\n",
        "                        if is_processing(user_id): status_detail += \"processing \"\n",
        "                        log_supervisor(f\"Usu√°rio '{username}' (ID: {user_id}) j√° em {status_detail.strip()}, ignorando.\", \"BUSCA\")\n",
        "                else:\n",
        "                    log_supervisor(f\"buscar_proxima_transmissao_livre retornou None na tentativa {tentativa}.\", \"BUSCA\")\n",
        "\n",
        "            log_supervisor(\"Nenhuma transmiss√£o livre encontrada ap√≥s tentativas (todos em blacklist/log ou offline).\", \"BUSCA\")\n",
        "            return None\n",
        "\n",
        "    # ========== Fase 1: Preenchimento do lote inicial ==========\n",
        "    log_supervisor(f\"Preenchendo lote inicial com at√© {pool_size} transmiss√µes...\", \"STARTUP\")\n",
        "    tentativas = 0\n",
        "    max_tentativas = 100 # Limita as tentativas totais para preencher o lote inicial\n",
        "    while len(running) < pool_size and tentativas < max_tentativas:\n",
        "        stream = buscar_nova_transmissao() # Retorna dicion√°rio com id, username, src, poster_path\n",
        "        if not stream:\n",
        "            log_supervisor(\"Fim das transmiss√µes dispon√≠veis para preencher lote inicial.\", \"STARTUP\")\n",
        "            break # Sai do loop se n√£o encontrar mais streams\n",
        "\n",
        "        user_id = stream[\"id\"] # Obt√©m o ID do dicion√°rio retornado\n",
        "        username = stream[\"username\"]\n",
        "        m3u8_url = stream[\"src\"]\n",
        "        poster_path = stream[\"poster_path\"] # Caminho do poster tempor√°rio v√°lido\n",
        "\n",
        "\n",
        "        # Marca no log central como em processamento para evitar duplicidade (USANDO ID)\n",
        "        mark_processing(user_id, username) # Passa user_id e username\n",
        "\n",
        "        log_supervisor(f\"Lan√ßando processo para: '{username}' (ID: {user_id}) | {len(running)+1}/{pool_size}\", \"STARTUP\") # Loga o ID\n",
        "        # Passa o user_id para a fun√ß√£o worker\n",
        "        p = Process(target=worker, args=(user_id, username, m3u8_url, poster_path, results))\n",
        "        running.append(p)\n",
        "        p.start()\n",
        "        tentativas += 1 # Incrementa tentativas\n",
        "\n",
        "    log_supervisor(f\"Lote inicial lan√ßado com {len(running)} transmiss√µes.\", \"STARTUP\")\n",
        "\n",
        "\n",
        "    # ========== Fase 2: Loop din√¢mico de preenchimento cont√≠nuo ==========\n",
        "    # Monitora processos ativos e busca novas streams para manter o lote cheio\n",
        "    while True:\n",
        "        # Atualiza a lista de processos ativos\n",
        "        antes = len(running)\n",
        "        running = [p for p in running if p.is_alive()]\n",
        "        depois = len(running)\n",
        "\n",
        "        # Se algum processo finalizou\n",
        "        if antes != depois:\n",
        "            log_supervisor(f\"{antes-depois} grava√ß√µes finalizaram. Vagas livres: {pool_size-len(running)}\", \"LOOP\")\n",
        "\n",
        "        vagas_livres = pool_size - len(running)\n",
        "\n",
        "        # Se houver vagas livres, busca novas streams para preencher\n",
        "        if vagas_livres > 0:\n",
        "            # Busca at√© o n√∫mero de vagas livres, mas com limite de tentativas para n√£o travar\n",
        "            preenchidas_nesta_rodada = 0\n",
        "            for _ in range(vagas_livres):\n",
        "                stream = buscar_nova_transmissao() # Retorna dicion√°rio com id, username, src, poster_path\n",
        "                if not stream:\n",
        "                    # Se n√£o encontrar mais streams dispon√≠veis ap√≥s todas as tentativas internas, sai do loop de preenchimento\n",
        "                    log_supervisor(\"N√£o h√° mais transmiss√µes para preencher as vagas livres.\", \"LOOP\")\n",
        "                    break # Sai do loop interno de preenchimento de vagas\n",
        "\n",
        "                user_id = stream[\"id\"] # Obt√©m o ID do dicion√°rio retornado\n",
        "                username = stream[\"username\"]\n",
        "                m3u8_url = stream[\"src\"]\n",
        "                poster_path = stream[\"poster_path\"] # Caminho do poster tempor√°rio v√°lido\n",
        "\n",
        "                # Marca no log central como em processamento (USANDO ID)\n",
        "                mark_processing(user_id, username) # Passa user_id e username\n",
        "\n",
        "                log_supervisor(f\"Lan√ßando nova grava√ß√£o: '{username}' (ID: {user_id}) | Vaga preenchida {len(running)+1}/{pool_size}\", \"LOOP\") # Loga o ID\n",
        "                # Passa o user_id para a fun√ß√£o worker\n",
        "                p = Process(target=worker, args=(user_id, username, m3u8_url, poster_path, results))\n",
        "                running.append(p)\n",
        "                p.start()\n",
        "                preenchidas_nesta_rodada += 1 # Conta quantas vagas foram preenchidas nesta rodada\n",
        "\n",
        "            if preenchidas_nesta_rodada == 0 and vagas_livres > 0 and not stream:\n",
        "                 # Condi√ß√£o para sair do loop principal: n√£o h√° processos rodando E n√£o h√° mais streams dispon√≠veis\n",
        "                 # (a busca_nova_transmissao retornou None ap√≥s v√°rias tentativas)\n",
        "                 if not running:\n",
        "                      log_supervisor(\"N√£o h√° processos ativos e n√£o h√° mais transmiss√µes dispon√≠veis.\", \"END\")\n",
        "                      break\n",
        "\n",
        "\n",
        "        # Se n√£o houver processos rodando e n√£o conseguimos preencher nenhuma vaga nesta rodada,\n",
        "        # significa que todas as transmiss√µes dispon√≠veis j√° foram processadas ou est√£o em blacklist/processing.\n",
        "        # A condi√ß√£o `if not stream:` dentro do loop de vagas + `if not running:` fora do loop de vagas\n",
        "        # j√° lida com isso, mas podemos adicionar uma checagem expl√≠cita.\n",
        "        # if not running and vagas_livres == pool_size and stream is None:\n",
        "        #      log_supervisor(\"Todas as transmiss√µes poss√≠veis j√° foram processadas ou est√£o bloqueadas.\", \"END\")\n",
        "        #      break\n",
        "\n",
        "\n",
        "        # Log de status peri√≥dico\n",
        "        log_supervisor(\n",
        "            f\"Transmiss√µes ativas: {len(running)} | Lote alvo: {pool_size} | Buffer de resultados: {len(results)}\",\n",
        "            \"STATUS\"\n",
        "        )\n",
        "\n",
        "        # Aguarda um pouco antes de verificar novamente\n",
        "        time.sleep(5) # Aumentado o sleep para reduzir a frequ√™ncia da busca quando o lote est√° cheio\n",
        "\n",
        "        # Condi√ß√£o de sa√≠da mais robusta: se n√£o h√° processos rodando E a √∫ltima busca n√£o encontrou streams\n",
        "        if not running and (stream is None or (isinstance(stream, list) and len(stream) == 0)):\n",
        "             log_supervisor(\"N√£o h√° processos ativos e a √∫ltima busca n√£o encontrou transmiss√µes.\", \"END\")\n",
        "             break\n",
        "\n",
        "\n",
        "    # ========== Fase 3: Finaliza√ß√£o ==========\n",
        "    log_supervisor(f\"Processamento din√¢mico conclu√≠do! Total de transmiss√µes gravadas/processadas: {len(results)}\", \"RESUMO\")\n",
        "    # A chamada para commit_push_restantes() foi removida pois o commit √© gerenciado externamente.\n",
        "    log_supervisor(\"Supervisor din√¢mico finalizado.\", \"END\")\n",
        "\n",
        "\n",
        "# Fun√ß√£o principal para iniciar o supervisor\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Fun√ß√£o principal: inicia o notebook perguntando se o usu√°rio quer gravar transmiss√µes espec√≠ficas ou autom√°ticas.\n",
        "    Dispara o supervisor din√¢mico na modalidade selecionada.\n",
        "    \"\"\"\n",
        "    # Certificar-se que as vari√°veis globais essenciais da C√©lula 1 est√£o carregadas\n",
        "    # Isso √© feito executando a C√©lula 1 antes desta.\n",
        "    if 'LOG_PATH' not in globals():\n",
        "        print(\"‚ö†Ô∏è Vari√°veis globais da C√©lula 1 n√£o carregadas. Execute a C√©lula 1 primeiro.\")\n",
        "        return # Sai se a C√©lula 1 n√£o foi executada\n",
        "\n",
        "    usuarios_especificos = perguntar_transmissoes_especificas() # perguntar_transmissoes_especificas est√° na C√©lula 1\n",
        "    log_supervisor(\"Iniciando busca e grava√ß√£o de streams (supervisor din√¢mico)...\", \"MAIN\")\n",
        "    supervisor_dinamico(usuarios_especificos=usuarios_especificos)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Garante que as fun√ß√µes de log da C√©lula 1 estejam dispon√≠veis\n",
        "    # Em um notebook, geralmente as c√©lulas s√£o executadas em ordem,\n",
        "    # ent√£o C√©lula 1 j√° teria definido append_log, query_logs, etc.\n",
        "    # Se rodando como script Python, precisaria importar ou definir as fun√ß√µes de log aqui.\n",
        "    # Para o contexto do Colab, assume-se que C√©lula 1 j√° rodou.\n",
        "\n",
        "    # Adicionando um try-except para garantir que main() seja chamada\n",
        "    # apenas se estiver em um ambiente interativo como Colab/IPython\n",
        "    try:\n",
        "        if 'google.colab' in str(get_ipython()):\n",
        "            main()\n",
        "        else:\n",
        "            print(\"N√£o est√° rodando em Colab/IPython. Execute main() manualmente se desejar.\")\n",
        "    except NameError:\n",
        "        print(\"N√£o est√° rodando em Colab/IPython. Execute main() se desejar.\")\n",
        "\n",
        "\n",
        "# ================================================================\n",
        "# FIM DA C√âLULA 9 ‚Äî Supervisor Din√¢mico, Lote Cheio e Blacklist Centralizados (AGORA USANDO ID)\n",
        "# ================================================================\n",
        "\n",
        "# Observa√ß√µes e recomenda√ß√µes:\n",
        "# - Toda l√≥gica de blacklist, processamento e falhas agora se baseia no ID √∫nico do usu√°rio no log centralizado para m√°xima rastreabilidade.\n",
        "# - O log central √© a fonte de verdade para sincroniza√ß√£o entre workers/processos.\n",
        "# - Modularidade, logs claros e tratamento de erro garantem manuten√ß√£o e evolu√ß√£o seguras.\n",
        "# - Pronto para ambientes colaborativos (Colab, CI/CD, pipelines paralelos).\n",
        "# - Certifique-se de executar as C√©lulas 1, 3, 6, 7 e 8 antes desta."
      ],
      "metadata": {
        "id": "5WKQV9g_LB9M"
      },
      "id": "5WKQV9g_LB9M",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2eac76d"
      },
      "source": [
        "# C√©lula XX: Limpeza do Arquivo de Log Central do Google Drive\n",
        "\n",
        "**Objetivo:**\\\n",
        "Esta c√©lula permite remover o arquivo de log central (`xcam_master.log`) do Google Drive. √â uma opera√ß√£o √∫til para limpar um log corrompido que esteja causando erros (como `JSONDecodeError` ou `UnicodeDecodeError`) ou simplesmente para iniciar o registro de eventos do zero.\n",
        "\n",
        "## Principais pontos e funcionalidades\n",
        "\n",
        "- **Remo√ß√£o segura:** Verifica se o arquivo de log existe antes de tentar remov√™-lo.\n",
        "- **Tratamento de erros:** Inclui um bloco `try-except` para capturar e reportar quaisquer problemas que possam ocorrer durante a remo√ß√£o do arquivo.\n",
        "- **Feedback claro:** Imprime mensagens indicando se o arquivo foi removido com sucesso, se houve um erro ou se o arquivo n√£o foi encontrado.\n",
        "- **Utilidade para depura√ß√£o:** Essencial para resetar o estado do log quando ele se corrompe devido a falhas inesperadas de escrita ou outros problemas de sistema de arquivos.\n",
        "\n",
        "* * *\n",
        "\n",
        "## Como funciona a c√©lula\n",
        "\n",
        "- **Define o caminho** completo para o arquivo de log central no Google Drive.\n",
        "- **Verifica** se o arquivo existe nesse local.\n",
        "- **Tenta remover** o arquivo.\n",
        "- **Imprime** o resultado da opera√ß√£o (sucesso, erro ou arquivo n√£o encontrado).\n",
        "\n",
        "* * *\n",
        "\n",
        "## Exemplo de execu√ß√£o"
      ],
      "id": "d2eac76d"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8332447"
      },
      "source": [
        "import os\n",
        "\n",
        "log_file_drive = '/content/drive/MyDrive/XCam.Drive/logs/xcam_master.log'\n",
        "if os.path.exists(log_file_drive):\n",
        "    try:\n",
        "        os.remove(log_file_drive)\n",
        "        print(f\"Arquivo de log do Drive removido: {log_file_drive}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Erro ao remover arquivo de log do Drive: {e}\")\n",
        "else:\n",
        "    print(f\"Arquivo de log do Drive n√£o encontrado: {log_file_drive}\")"
      ],
      "id": "c8332447",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "c9hve1ySGVAs"
      ],
      "cell_execution_strategy": "setup",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}