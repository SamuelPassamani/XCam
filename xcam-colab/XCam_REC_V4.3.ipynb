{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SamuelPassamani/XCam/blob/main/xcam-colab/XCam_REC_V4.3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Célula 1: Configurações Auxiliares, Parâmetros Globais e Log Centralizado\n",
        "\n",
        "**Objetivo:**  \n",
        "Esta célula inicializa e centraliza todas as variáveis globais, parâmetros essenciais e agora também fornece um utilitário robusto para o log único do notebook XCam.  \n",
        "Permite ajuste rápido e seguro do comportamento do notebook, incluindo limites de processamento, controle de gravação, commit automático e mecanismos de resiliência contra transmissões problemáticas.\n",
        "\n",
        "## Principais pontos e melhorias implementadas\n",
        "\n",
        "- **Centralização dos parâmetros globais:**  \n",
        "  Todos os valores críticos (limites, thresholds, caminhos) são definidos e propagados como globais pelo notebook.\n",
        "- **Log único modular e estruturado (`xcam_master.log`):**  \n",
        "  Todas as operações relevantes (busca, gravação, blacklist, commit, erros, etc.) agora são registradas em um único arquivo JSON Lines.  \n",
        "  Cada entrada inclui sessão, evento, id, username, id_username, timestamps, status e detalhes.\n",
        "- **Funções utilitárias para o log:**  \n",
        "  Adição, busca, remoção e atualização de eventos são facilitadas por funções modulares (CRUD), promovendo robustez, rastreabilidade e fácil manutenção.\n",
        "- **Blacklist, falhas e processamento padronizados por `id`:**  \n",
        "  Toda lógica de controle é feita via identificador único (`id`) e referência `{id}:{username}` (`id_username`), garantindo unicidade e eliminando inconsistências.\n",
        "- **Uso consistente do campo `sessao`:**  \n",
        "  Todos os registros são organizados por sessões lógicas, facilitando filtros, relatórios e auditoria.\n",
        "- **Função interativa para seleção de transmissões específicas:**  \n",
        "  Permite ao usuário informar nomes de usuários para filtrar transmissões antes do processamento.\n",
        "- **Comentários detalhados:**  \n",
        "  Cada etapa do código está documentada para orientar ajustes, manutenção e integração por toda a equipe.\n",
        "\n",
        "---\n",
        "\n",
        "## Parâmetros globais controlados nesta célula\n",
        "\n",
        "- **`LIMIT_DEFAULT`**: Quantidade máxima de transmissões processadas em paralelo/lote.\n",
        "- **`PAGE_DEFAULT`**: Página inicial para busca na API.\n",
        "- **`RECORD_SECONDS`**: Tempo máximo de gravação de cada vídeo (em segundos).\n",
        "- **`RECORD_SECONDS_MIN`**: Tempo mínimo exigido para considerar o vídeo válido (em segundos).\n",
        "- **`API_SEARCH_LIMIT`**: Limite de transmissões retornadas ao buscar usuários específicos.\n",
        "- **`COMMIT_PUSH_THRESHOLD`**: Quantidade de transmissões processadas até realizar commit/push automático (0 = commit imediato a cada gravação).\n",
        "- **`LOG_PATH`**: Caminho do arquivo único de log (JSONL).\n",
        "- **`BLACKLIST_TIMEOUT`**: Tempo de expiração da blacklist (em segundos).\n",
        "- **`BLACKLIST_MAX_FAILURES`**: Quantidade de falhas consecutivas antes de banir temporariamente o usuário.\n",
        "\n",
        "---\n",
        "\n",
        "## Estrutura do log único (`xcam_master.log`)\n",
        "\n",
        "Cada entrada segue o modelo:\n",
        "```json\n",
        "{\n",
        "  \"timestamp\": \"2025-06-06T06:15:00Z\",\n",
        "  \"sessao\": \"busca|gravação|blacklist|processing|failure|success|commit|erro|...\",\n",
        "  \"evento\": \"...\",\n",
        "  \"id\": \"...\",           // identificador único (primário)\n",
        "  \"username\": \"...\",     // nome do usuário para exibição\n",
        "  \"id_username\": \"...\",  // referência padrão \"{id}:{username}\" para consultas e auditoria\n",
        "  \"status\": \"...\",       // ok|erro|blacklisted|expirado|...\n",
        "  \"detalhes\": \"...\",     // informações adicionais (motivo, paths, etc)\n",
        "}\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Funções utilitárias para o log\n",
        "\n",
        "- **`append_log(entry, log_path=LOG_PATH)`**: Adiciona uma nova entrada ao log central (gera campo `id_username` automaticamente).\n",
        "- **`read_logs(log_path=LOG_PATH)`**: Lê todas as entradas do log.\n",
        "- **`query_logs(...)`**: Consulta entradas do log por filtros opcionais (sessão, id, id_username, status, etc).\n",
        "- **`remove_logs(condition_fn, log_path=LOG_PATH)`**: Remove todas as entradas que satisfaçam a condição.\n",
        "- **`update_log_entry(match_fn, update_fn, log_path=LOG_PATH)`**: Atualiza entradas do log conforme regra.\n",
        "\n",
        "---\n",
        "\n",
        "## Exemplo de uso das funções (a serem aplicadas nas próximas células)\n",
        "\n",
        "```python\n",
        "append_log({\n",
        "    \"sessao\": \"processing\",\n",
        "    \"evento\": \"iniciado\",\n",
        "    \"id\": \"abc123\",\n",
        "    \"username\": \"Manugic_\",\n",
        "    \"status\": \"ok\",\n",
        "    \"detalhes\": \"URL válida\"\n",
        "})\n",
        "\n",
        "# Consultar blacklist:\n",
        "logs_blacklist = query_logs(sessao=\"blacklist\", status=\"blacklisted\")\n",
        "\n",
        "# Remover registros expirados:\n",
        "remove_logs(lambda entry: entry[\"sessao\"] == \"processing\" and expirou(entry), log_path=LOG_PATH)\n",
        "\n",
        "# Atualizar status:\n",
        "update_log_entry(lambda e: e[\"id\"]==\"abc123\" and e[\"sessao\"]==\"processing\", lambda e: e.update({\"status\":\"ok\"}))\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Função interativa\n",
        "\n",
        "Permite ao usuário informar transmissões específicas a serem gravadas antes de iniciar o processamento.\n",
        "\n",
        "---\n",
        "\n",
        "## Segurança, rastreabilidade e manutenção\n",
        "\n",
        "- Todos os parâmetros globais são definidos no início e propagados para todo o notebook, garantindo consistência.\n",
        "- O log único fornece rastreabilidade detalhada e elimina arquivos dispersos (blacklist, falha, etc).\n",
        "- Uso do padrão `{id}:{username}` para referência e auditoria.\n",
        "- Ajuste qualquer valor diretamente nesta célula para alterar o comportamento global do notebook de forma segura.\n",
        "- Comentários detalhados auxiliam a compreensão, integração e manutenção por toda a equipe.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "c9hve1ySGVAs"
      },
      "id": "c9hve1ySGVAs"
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================\n",
        "# Célula 1: Configuração Global, Parâmetros e Log Único Estruturado\n",
        "# ================================================================\n",
        "# Objetivo:\n",
        "# - Centralizar configurações globais e thresholds\n",
        "# - Definir e montar caminhos do notebook\n",
        "# - Fornecer utilitário robusto para LOG ÚNICO MODULAR (JSONL)\n",
        "#   => Todas as células e funções usarão este log para registrar, consultar e manipular eventos\n",
        "# - Garantir padronização, rastreabilidade, unicidade e fácil manutenção futura\n",
        "#\n",
        "# Estratégia:\n",
        "# - Log único estruturado (JSONL): sessão, evento, id, username, id_username, timestamps, status, detalhes\n",
        "# - Funções CRUD para log: adicionar, buscar, atualizar, remover (para blacklist, processing, falhas, auditoria)\n",
        "# - Blacklist e controles baseados em id (com username apenas para exibição)\n",
        "# - Parâmetros globais facilmente editáveis e propagados via globals()\n",
        "# - Uso consistente de \"sessao\" para diferenciar tipos de registros\n",
        "# ================================================================\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "import json\n",
        "\n",
        "# ============================\n",
        "# PARÂMETROS GLOBAIS EDITÁVEIS\n",
        "# ============================\n",
        "# Modifique abaixo conforme necessidade do ambiente ou processamento\n",
        "\n",
        "# Limites e thresholds principais de processamento\n",
        "LIMIT_DEFAULT = 100             # Máximo de transmissões processadas por rodada\n",
        "PAGE_DEFAULT = 1               # Página padrão para busca na API\n",
        "RECORD_SECONDS = 12780         # Duração máxima da gravação (em segundos)\n",
        "RECORD_SECONDS_MIN = 420       # Duração mínima válida (em segundos)\n",
        "API_SEARCH_LIMIT = 3333        # Limite ao buscar usuários específicos\n",
        "# COMMIT_PUSH_THRESHOLD removido pois o commit/push é gerenciado externamente\n",
        "\n",
        "# Caminhos de arquivos principais\n",
        "BASE_PATH = '/content' # Mantido para referência, mas LOG_PATH vai para o Drive\n",
        "DRIVE_BASE_LOG_PATH = '/content/drive/MyDrive/XCam.Drive/logs' # Novo caminho base para logs no Drive\n",
        "LOG_PATH = f\"{DRIVE_BASE_LOG_PATH}/xcam_master.log\"          # Arquivo único de log central MOVIDO PARA O DRIVE\n",
        "BLACKLIST_TIMEOUT = 15 * 60                        # Blacklist: tempo de expiração (segundos)\n",
        "BLACKLIST_MAX_FAILURES = 3                         # Blacklist: falhas para banimento temporário\n",
        "\n",
        "# Garante que o diretório de logs no Drive exista\n",
        "os.makedirs(DRIVE_BASE_LOG_PATH, exist_ok=True)\n",
        "print(f\"Diretório de logs no Drive garantido: {DRIVE_BASE_LOG_PATH}\")\n",
        "\n",
        "\n",
        "# ============================\n",
        "# ATUALIZAÇÃO GLOBAL DOS PARÂMETROS\n",
        "# ============================\n",
        "# Propaga parâmetros como globais do notebook\n",
        "globals().update({\n",
        "    'LIMIT_DEFAULT': LIMIT_DEFAULT,\n",
        "    'PAGE_DEFAULT': PAGE_DEFAULT,\n",
        "    'RECORD_SECONDS': RECORD_SECONDS,\n",
        "    'RECORD_SECONDS_MIN': RECORD_SECONDS_MIN,\n",
        "    'API_SEARCH_LIMIT': API_SEARCH_LIMIT,\n",
        "    'LOG_PATH': LOG_PATH, # Atualizado para o caminho do Drive\n",
        "    'BLACKLIST_TIMEOUT': BLACKLIST_TIMEOUT,\n",
        "    'BLACKLIST_MAX_FAILURES': BLACKLIST_MAX_FAILURES\n",
        "})\n",
        "\n",
        "# =============================================================================\n",
        "# UTILITÁRIO DE LOG ÚNICO MODULAR (JSONL) — Clean Architecture\n",
        "# -----------------------------------------------------------------------------\n",
        "# Cada entrada: {\n",
        "#   \"timestamp\": \"2025-06-06T06:15:00Z\",\n",
        "#   \"sessao\": \"busca|gravação|blacklist|processing|failure|commit|erro|...\",\n",
        "#   \"evento\": \"...\",\n",
        "#   \"id\": \"...\",               # identificador primário (ex: id da transmissão)\n",
        "#   \"username\": \"...\",         # apenas referência humana\n",
        "#   \"id_username\": \"...\",      # padrão \"{id}:{username}\" para fácil leitura/humano\n",
        "#   \"status\": \"...\",           # ok|erro|blacklisted|expirado|...\n",
        "#   \"detalhes\": \"...\",         # informações adicionais/motivo/paths\n",
        "# }\n",
        "# =============================================================================\n",
        "\n",
        "from datetime import datetime\n",
        "\n",
        "def now_iso():\n",
        "    \"\"\"Retorna timestamp UTC em formato ISO.\"\"\"\n",
        "    return datetime.utcnow().isoformat() + \"Z\"\n",
        "\n",
        "def make_id_username(id, username):\n",
        "    \"\"\"Gera o identificador de referência padrão para logs: '{id}:{username}'.\"\"\"\n",
        "    return f\"{id}:{username}\"\n",
        "\n",
        "def append_log(entry, log_path=LOG_PATH):\n",
        "    \"\"\"\n",
        "    Adiciona uma nova entrada ao log central (JSONL).\n",
        "    Campos obrigatórios: sessao, evento, id, username, status.\n",
        "    - 'id' DEVE ser chave primária (único por transmissão/processo).\n",
        "    - 'username' é apenas referência humana.\n",
        "    - 'id_username' sempre gerado para facilitar auditoria/consulta.\n",
        "    - 'sessao' obrigatório e padronizado para facilitar filtros e consultas.\n",
        "    \"\"\"\n",
        "    entry.setdefault(\"timestamp\", now_iso())\n",
        "    for field in [\"sessao\", \"evento\", \"id\", \"username\", \"status\"]:\n",
        "        entry.setdefault(field, \"\")\n",
        "    # Padrão de referência único e fácil busca\n",
        "    entry[\"id_username\"] = make_id_username(entry[\"id\"], entry[\"username\"])\n",
        "    # Evitar duplicidade de id+sessao+evento (unicidade lógica)\n",
        "    logs = []\n",
        "    # Verifica se o arquivo existe ANTES de tentar ler\n",
        "    if os.path.exists(log_path):\n",
        "        try:\n",
        "            with open(log_path, \"r\", encoding=\"utf-8\") as f:\n",
        "                # Lê linha por linha e tenta parsear JSON. Ignora linhas inválidas com aviso.\n",
        "                for line in f:\n",
        "                    line = line.strip()\n",
        "                    if line:\n",
        "                        try:\n",
        "                            logs.append(json.loads(line))\n",
        "                        except json.JSONDecodeError as e:\n",
        "                            print(f\"⚠️ Aviso: Linha inválida no log '{log_path}', ignorada: {line} - Erro: {e}\")\n",
        "        except Exception as e:\n",
        "             print(f\"❌ Erro inesperado ao ler log '{log_path}', inicializando lista vazia: {e}\")\n",
        "             logs = []\n",
        "\n",
        "\n",
        "    # Checa unicidade apenas para eventos que não podem ser duplicados (ex: processing, blacklist, etc)\n",
        "    if entry[\"sessao\"] in {\"processing\", \"blacklist\", \"failure\", \"success\"}:\n",
        "        key = (entry[\"id\"], entry[\"sessao\"], entry[\"evento\"])\n",
        "        # Encontra o índice da entrada existente, se houver\n",
        "        existing_index = next((i for i, e in enumerate(logs) if (e.get(\"id\"), e.get(\"sessao\"), e.get(\"evento\")) == key), -1)\n",
        "\n",
        "        if existing_index != -1:\n",
        "            # Atualiza o registro existente ao invés de duplicar\n",
        "            logs[existing_index].update(entry)\n",
        "            # Escreve o arquivo completo de volta (substitui)\n",
        "            try:\n",
        "                with open(log_path, \"w\", encoding=\"utf-8\") as f:\n",
        "                    for l in logs:\n",
        "                        f.write(json.dumps(l, ensure_ascii=False) + \"\\n\")\n",
        "                return # Retorna após atualizar\n",
        "            except Exception as e:\n",
        "                print(f\"❌ Erro ao reescrever log '{log_path}' após atualização: {e}\")\n",
        "                # Em caso de erro ao reescrever, tenta apenas append abaixo como fallback?\n",
        "                # Ou seria melhor parar? Por segurança, vamos tentar append (pode gerar duplicidade temporária)\n",
        "                pass # Continua para o append abaixo em caso de erro ao reescrever\n",
        "\n",
        "    # Se não existe ou se houve erro ao reescrever, apenas append a nova entrada\n",
        "    try:\n",
        "        with open(log_path, \"a\", encoding=\"utf-8\") as f:\n",
        "            f.write(json.dumps(entry, ensure_ascii=False) + \"\\n\")\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Erro ao adicionar entrada ao log '{log_path}': {e}\")\n",
        "\n",
        "\n",
        "def read_logs(log_path=LOG_PATH):\n",
        "    \"\"\"Lê todas as entradas do log central.\"\"\"\n",
        "    if not os.path.exists(log_path):\n",
        "        return []\n",
        "    logs = []\n",
        "    try:\n",
        "        with open(log_path, \"r\", encoding=\"utf-8\") as f:\n",
        "            for line in f:\n",
        "                line = line.strip()\n",
        "                if line:\n",
        "                    try:\n",
        "                        logs.append(json.loads(line))\n",
        "                    except json.JSONDecodeError as e:\n",
        "                         print(f\"⚠️ Aviso: Linha inválida no log '{log_path}', ignorada: {line} - Erro: {e}\")\n",
        "    except Exception as e:\n",
        "         print(f\"❌ Erro inesperado ao ler log '{log_path}': {e}\")\n",
        "         return []\n",
        "    return logs\n",
        "\n",
        "\n",
        "def query_logs(sessao=None, id=None, username=None, id_username=None, evento=None, status=None, after=None, before=None, log_path=LOG_PATH):\n",
        "    \"\"\"\n",
        "    Consulta entradas do log por filtros opcionais.\n",
        "    Filtros disponíveis: sessao, id, username, id_username, evento, status, after, before.\n",
        "    - after/before: string ISO ou datetime\n",
        "    \"\"\"\n",
        "    logs = read_logs(log_path)\n",
        "    result = []\n",
        "    for entry in logs:\n",
        "        if sessao and entry.get(\"sessao\") != sessao:\n",
        "            continue\n",
        "        if id and entry.get(\"id\") != id:\n",
        "            continue\n",
        "        if username and entry.get(\"username\") != username:\n",
        "            continue\n",
        "        if id_username and entry.get(\"id_username\") != id_username:\n",
        "            continue\n",
        "        if evento and entry.get(\"evento\") != evento:\n",
        "            continue\n",
        "        if status and entry.get(\"status\") != status:\n",
        "            continue\n",
        "        ts = entry.get(\"timestamp\")\n",
        "        if after:\n",
        "            after_val = after if isinstance(after, str) else after.isoformat()\n",
        "            if ts < after_val:\n",
        "                continue\n",
        "        if before:\n",
        "            before_val = before if isinstance(before, str) else before.isoformat()\n",
        "            if ts > before_val:\n",
        "                continue\n",
        "        result.append(entry)\n",
        "    return result\n",
        "\n",
        "def remove_logs(condition_fn, log_path=LOG_PATH):\n",
        "    \"\"\"\n",
        "    Remove do log central todas as entradas que satisfaçam condition_fn(entry).\n",
        "    Útil para expurgar logs expirados, blacklists vencidas, eventos processados, etc.\n",
        "    \"\"\"\n",
        "    logs = read_logs(log_path)\n",
        "    kept = [entry for entry in logs if not condition_fn(entry)]\n",
        "    # Só reescreve se houve remoção ou se o arquivo existia e agora está vazio\n",
        "    if len(kept) < len(logs) or (len(logs) > 0 and len(kept) == 0):\n",
        "        try:\n",
        "            with open(log_path, \"w\", encoding=\"utf-8\") as f:\n",
        "                for entry in kept:\n",
        "                    f.write(json.dumps(entry, ensure_ascii=False) + \"\\n\")\n",
        "            print(f\"✅ {len(logs) - len(kept)} entradas removidas do log '{log_path}'.\")\n",
        "            return len(logs) - len(kept)\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Erro ao reescrever log '{log_path}' após remoção: {e}\")\n",
        "            return 0 # Não podemos confirmar quantas foram removidas no arquivo\n",
        "    else:\n",
        "         print(f\"ℹ️ Nenhuma entrada satisfez a condição de remoção no log '{log_path}'.\")\n",
        "         return 0\n",
        "\n",
        "\n",
        "def update_log_entry(match_fn, update_fn, log_path=LOG_PATH):\n",
        "    \"\"\"\n",
        "    Atualiza entradas do log central: se match_fn(entry)==True, aplica update_fn(entry).\n",
        "    Exemplo: promover status de \"pending\" para \"ok\".\n",
        "    \"\"\"\n",
        "    logs = read_logs(log_path)\n",
        "    updated = 0\n",
        "    # Cria uma cópia para iterar enquanto modifica a original (ou uma nova lista)\n",
        "    new_logs = []\n",
        "    made_changes = False\n",
        "    for entry in logs:\n",
        "        # Cria uma cópia da entrada para modificar, se necessário\n",
        "        entry_copy = entry.copy()\n",
        "        if match_fn(entry_copy):\n",
        "            update_fn(entry_copy)\n",
        "            updated += 1\n",
        "            made_changes = True\n",
        "        new_logs.append(entry_copy)\n",
        "\n",
        "    if made_changes:\n",
        "        try:\n",
        "            with open(log_path, \"w\", encoding=\"utf-8\") as f:\n",
        "                for entry in new_logs:\n",
        "                    f.write(json.dumps(entry, ensure_ascii=False) + \"\\n\")\n",
        "            print(f\"✅ {updated} entradas atualizadas no log '{log_path}'.\")\n",
        "        except Exception as e:\n",
        "             print(f\"❌ Erro ao reescrever log '{log_path}' após atualização: {e}\")\n",
        "\n",
        "    return updated\n",
        "\n",
        "# Exemplos de uso (para as próximas células):\n",
        "# append_log({\"sessao\":\"processing\", \"evento\":\"iniciado\", \"id\":\"123456\", \"username\":\"Manugic_\", \"status\":\"ok\", \"detalhes\":\"URL válida\"})\n",
        "# logs_blacklist = query_logs(sessao=\"blacklist\", status=\"blacklisted\")\n",
        "# remove_logs(lambda entry: entry[\"sessao\"]==\"processing\" and expirou(entry), log_path=LOG_PATH)\n",
        "# update_log_entry(lambda e: e[\"id\"]==\"123456\" and e[\"sessao\"]==\"processing\", lambda e: e.update({\"status\":\"ok\"}))\n",
        "\n",
        "# =============================================================================\n",
        "# FUNÇÃO INTERATIVA (opcional) PARA ESCOLHA DE TRANSMISSÕES ESPECÍFICAS\n",
        "# =============================================================================\n",
        "def perguntar_transmissoes_especificas():\n",
        "    \"\"\"\n",
        "    Pergunta ao usuário se deseja informar transmissões específicas para gravar,\n",
        "    recebendo nomes de usuário separados por vírgula e retornando lista limpa.\n",
        "    Retorna lista vazia caso não deseje selecionar usuários.\n",
        "    \"\"\"\n",
        "    resp = input('Deseja gravar alguma transmissão específica? (sim/não): ').strip().lower()\n",
        "    if resp.startswith('s'):\n",
        "        usuarios = input('Informe o(s) nome(s) de usuário, separados por vírgula (ex: userNovo234, jovemPT): ')\n",
        "        usuarios_lista = [u.strip() for u in usuarios.split(',') if u.strip()]\n",
        "        return usuarios_lista\n",
        "    return []\n",
        "\n",
        "# =============================================================================\n",
        "# DICAS DE USO EM OUTRAS CÉLULAS:\n",
        "# - Para registrar evento: append_log({...})\n",
        "# - Para consultar blacklist: query_logs(sessao=\"blacklist\", status=\"blacklisted\")\n",
        "# - Para remover registros expirados: remove_logs(lambda e: ...)\n",
        "# - Para atualizar status: update_log_entry(lambda e: ..., lambda e: ...)\n",
        "# - Sempre use o id como chave primária e id_username para referência em relatórios/auditoria\n",
        "# =============================================================================\n",
        "\n",
        "# ============================\n",
        "# FIM DA CÉLULA 1\n",
        "# ============================"
      ],
      "metadata": {
        "id": "j5pPh353GLMD"
      },
      "id": "j5pPh353GLMD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Célula 2: Instalação e Validação do ffmpeg\n",
        "\n",
        "**Objetivo:**  \n",
        "Esta célula garante que o utilitário `ffmpeg` esteja instalado e disponível no ambiente Google Colab. O ffmpeg é indispensável para a gravação dos vídeos das transmissões e para o processamento de mídia ao longo do pipeline do notebook XCam.\n",
        "\n",
        "## Pontos principais e melhorias implementadas\n",
        "\n",
        "- **Verificação pré-instalação:**  \n",
        "  Antes de instalar, verifica se o ffmpeg já está disponível no ambiente, tornando o processo idempotente e eficiente.\n",
        "- **Instalação automatizada:**  \n",
        "  Efetua a instalação via `apt-get` apenas se necessário, reduzindo o tempo de setup em execuções futuras.\n",
        "- **Validação pós-instalação:**  \n",
        "  Exibe a versão instalada do ffmpeg, garantindo transparência e rastreabilidade.\n",
        "- **Mensagens detalhadas:**  \n",
        "  O usuário recebe logs informativos sobre cada etapa, facilitando o diagnóstico em caso de erros.\n",
        "- **Design modular:**  \n",
        "  Estrutura pronta para ser utilizada em outros ambientes (Colab, local, server) com pequenas adaptações.\n",
        "\n",
        "---\n",
        "\n",
        "## Como funciona a célula\n",
        "\n",
        "- **Verifica se o ffmpeg está instalado (no PATH do sistema).**\n",
        "- **Se não estiver, instala automaticamente via apt-get.**\n",
        "- **Valida e exibe a versão instalada após o processo.**\n",
        "- **Em caso de falha, exibe erro detalhado e interrompe o fluxo para evitar inconsistências futuras.**\n",
        "\n",
        "---\n",
        "\n",
        "## Exemplo de uso das funções nesta célula\n",
        "\n",
        "```python\n",
        "if not is_ffmpeg_installed():\n",
        "    install_ffmpeg()\n",
        "show_ffmpeg_version()\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Segurança, rastreabilidade e manutenção\n",
        "\n",
        "- A célula torna o setup do ambiente mais robusto, impedindo falhas silenciosas relacionadas à ausência de ffmpeg.\n",
        "- Mensagens e validações ajudam a equipe a identificar rapidamente problemas de ambiente ou permissões.\n",
        "- O padrão modular facilita a reutilização do código em diferentes notebooks ou pipelines do projeto XCam.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "WXs0o6OPHXbi"
      },
      "id": "WXs0o6OPHXbi"
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================\n",
        "# Célula 2: Instalação e Validação do FFMPEG no Colab e Linux\n",
        "# ================================================================\n",
        "# Objetivo:\n",
        "# - Garantir que o utilitário ffmpeg está instalado e disponível no ambiente (Colab ou Linux)\n",
        "# - Validar a instalação e exibir a versão instalada para rastreabilidade\n",
        "# - Tornar a etapa idempotente, evitando instalações desnecessárias (safe to rerun)\n",
        "# - Fornecer feedback detalhado e logs a cada etapa para diagnóstico rápido\n",
        "#\n",
        "# Estratégia aplicada:\n",
        "# - Checa se ffmpeg está disponível no PATH do sistema\n",
        "# - Caso não esteja, instala automaticamente via apt-get (compatível Colab/Linux)\n",
        "# - Valida a instalação e exibe a versão instalada\n",
        "# - Modularidade e robustez para uso em pipelines, CI/CD e ambientes colaborativos\n",
        "# ================================================================\n",
        "\n",
        "import subprocess   # Importação obrigatória para checagem e instalação do ffmpeg\n",
        "import sys\n",
        "\n",
        "def is_ffmpeg_installed():\n",
        "    \"\"\"\n",
        "    Verifica se o ffmpeg está instalado e disponível no PATH do sistema.\n",
        "    Retorna True se estiver, False caso contrário.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        result = subprocess.run([\"ffmpeg\", \"-version\"], capture_output=True, text=True)\n",
        "        return result.returncode == 0\n",
        "    except Exception:\n",
        "        return False\n",
        "\n",
        "def install_ffmpeg():\n",
        "    \"\"\"\n",
        "    Instala o ffmpeg via apt-get caso não esteja presente.\n",
        "    Somente para sistemas baseados em Debian/Ubuntu (inclui Google Colab).\n",
        "    \"\"\"\n",
        "    print(\"[INFO] Iniciando instalação do ffmpeg via apt-get...\")\n",
        "    try:\n",
        "        # Atualiza pacotes e instala ffmpeg de forma silenciosa para logs limpos\n",
        "        subprocess.run(\"apt-get update -y\", shell=True, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "        subprocess.run(\"apt-get install -y ffmpeg\", shell=True, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "        print(\"[INFO] ffmpeg instalado com sucesso.\")\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"[ERRO] Falha ao instalar ffmpeg via apt-get: {e}\")\n",
        "        print(\"🔴 Tente rodar manualmente ou verifique permissões/root.\")\n",
        "        raise\n",
        "\n",
        "def show_ffmpeg_version():\n",
        "    \"\"\"\n",
        "    Exibe a versão instalada do ffmpeg, se disponível.\n",
        "    Mostra as duas primeiras linhas para rastreabilidade.\n",
        "    \"\"\"\n",
        "    print(\"[INFO] Versão do ffmpeg instalada:\")\n",
        "    try:\n",
        "        result = subprocess.run([\"ffmpeg\", \"-version\"], capture_output=True, text=True)\n",
        "        if result.returncode == 0:\n",
        "            linhas = result.stdout.strip().split('\\n')\n",
        "            for l in linhas[:2]:\n",
        "                print(l)\n",
        "        else:\n",
        "            print(\"[ERRO] ffmpeg instalado, mas não foi possível obter a versão.\")\n",
        "    except Exception as e:\n",
        "        print(f\"[ERRO] Não foi possível exibir a versão do ffmpeg: {e}\")\n",
        "\n",
        "# ================================================================\n",
        "# EXECUÇÃO DA ETAPA DE SETUP — Sempre idempotente e segura\n",
        "# ================================================================\n",
        "\n",
        "if not is_ffmpeg_installed():\n",
        "    print(\"[WARN] ffmpeg não encontrado no ambiente.\")\n",
        "    try:\n",
        "        install_ffmpeg()\n",
        "    except Exception:\n",
        "        raise RuntimeError(\"[ERRO] Falha ao instalar o ffmpeg. Verifique permissões ou tente novamente.\")\n",
        "    if not is_ffmpeg_installed():\n",
        "        # Última checagem após instalação\n",
        "        raise RuntimeError(\"[ERRO] Falha ao instalar o ffmpeg. Verifique permissões, root ou tente novamente.\")\n",
        "    else:\n",
        "        print(\"[OK] ffmpeg instalado e pronto para uso.\")\n",
        "else:\n",
        "    print(\"[OK] ffmpeg já está instalado no ambiente.\")\n",
        "\n",
        "show_ffmpeg_version()\n",
        "\n",
        "# ================================================================\n",
        "# FIM DA CÉLULA 2 — Instalação e Validação do ffmpeg\n",
        "# ================================================================\n",
        "#\n",
        "# Observações técnicas:\n",
        "# - ffmpeg deve estar disponível para todas as etapas do pipeline XCam.\n",
        "# - Para obter o caminho absoluto: subprocess.run(['which', 'ffmpeg'], capture_output=True, text=True).stdout.strip()\n",
        "# - Célula idempotente: pode ser executada múltiplas vezes sem efeitos colaterais.\n",
        "# - Pronta para uso em pipelines, scripts automatizados e ambientes colaborativos."
      ],
      "metadata": {
        "id": "vIODn0c2HiHz"
      },
      "id": "vIODn0c2HiHz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Célula 3: Imports Essenciais, Utilitários e Preparação do Ambiente\n",
        "\n",
        "**Objetivo:**  \n",
        "Importa todas as bibliotecas essenciais do Python necessárias para o funcionamento do notebook, incluindo módulos para requisições HTTP, processamento paralelo, manipulação de datas, controle de subprocessos e exibição interativa.  \n",
        "Centraliza funções utilitárias robustas e padronizadas para processamento, download de poster, geração automática de poster com ffmpeg e exibição de progresso, totalmente integradas ao log único centralizado definido na Célula 1.\n",
        "\n",
        "## Principais pontos e melhorias implementadas\n",
        "\n",
        "- **Centralização de imports essenciais:**  \n",
        "  Todos os módulos fundamentais (os, requests, multiprocessing, datetime, json, time, subprocess, math, re, IPython) estão disponíveis e prontos para uso global.\n",
        "- **Funções utilitárias padronizadas:**  \n",
        "  Funções para formatação de segundos, exibição de progresso, download e validação de poster, geração de poster via ffmpeg (com fallback e múltiplas tentativas) e integração direta ao log centralizado, seguindo Clean Architecture.\n",
        "- **Remoção de logs temporários dispersos:**  \n",
        "  Toda rastreabilidade de eventos (incluindo processamento, blacklist, falhas e auditoria) agora é feita apenas pelo log único centralizado (LOG_PATH), eliminando arquivos dispersos como LOG_PROCESSAMENTO_PATH, BLACKLIST_PATH ou FAILURE_LOG_PATH.\n",
        "- **Robustez, clareza e modularidade:**  \n",
        "  As funções possuem tratamento de erros, são preparadas para uso concorrente, possuem fallback inteligente (poster placeholder) e integração automática com o pipeline e o log centralizado.\n",
        "- **Pronto para uso em todo o notebook:**  \n",
        "  Todas as funções aqui definidas são utilizadas em toda a automação, promovendo reuso, legibilidade e manutenção facilitada em pipelines concorrentes ou distribuídos.\n",
        "\n",
        "---\n",
        "\n",
        "## Funções utilitárias disponíveis nesta célula\n",
        "\n",
        "- **`format_seconds(seconds)`**: Formata um valor em segundos para string legível (ex: \"1h23m45s\").\n",
        "- **`log_progress(username, elapsed_seconds, total_seconds)`**: Exibe o progresso da gravação de cada transmissão.\n",
        "- **`download_and_save_poster(poster_url, username, temp_folder)`**: Baixa e salva o poster da transmissão a partir de uma URL remota ou retorna se for um caminho local.\n",
        "- **`generate_poster_with_ffmpeg(m3u8_url, username, temp_folder, tries=(7,1,15,30), timeout=30)`**: Gera automaticamente um poster usando ffmpeg, tentando múltiplos pontos e, em caso de falha, gera um placeholder e registra o erro no log centralizado.\n",
        "- **`is_poster_valid(poster_path)`**: Verifica se o arquivo de poster é válido (existe e não está vazio).\n",
        "\n",
        "---\n",
        "\n",
        "## Exemplo de uso das funções\n",
        "\n",
        "```python\n",
        "# Formatar segundos em string legível\n",
        "tempo = format_seconds(385)\n",
        "\n",
        "# Exibir progresso\n",
        "log_progress(\"userNovo234\", 385, 12780)\n",
        "\n",
        "# Download do poster\n",
        "poster_path = download_and_save_poster(url_poster, \"userNovo234\", \"/content/temp\")\n",
        "\n",
        "# Geração automática de poster via ffmpeg (com fallback e registro no log)\n",
        "if not is_poster_valid(poster_path):\n",
        "    poster_path = generate_poster_with_ffmpeg(m3u8_url, \"userNovo234\", \"/content/temp\")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Segurança, rastreabilidade e manutenção\n",
        "\n",
        "- Todas as funções são preparadas para tratamento de erros, integração com processos concorrentes e fallback inteligente.\n",
        "- O log temporário de processamento foi removido, garantindo que todo o rastreio e auditoria sejam feitos via log único centralizado da Célula 1.\n",
        "- Funções de geração de poster integram fallback (placeholder) e registro detalhado de falhas no log central.\n",
        "- Comentários detalhados facilitam manutenção, entendimento e evolução do notebook para toda a equipe.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "90qvXC0rHtWb"
      },
      "id": "90qvXC0rHtWb"
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================\n",
        "# Célula 3: Imports Essenciais, Utilitários e Preparação do Ambiente\n",
        "# ================================================================\n",
        "# Objetivo:\n",
        "# - Importar bibliotecas essenciais para todo o notebook\n",
        "# - Centralizar funções auxiliares de formatação, download e geração de poster\n",
        "# - Remover dependências de logs temporários dispersos, integrando ao log único do sistema (LOG_PATH)\n",
        "# - Garantir robustez, clareza e modularidade para as próximas células\n",
        "#\n",
        "# Estratégia aplicada:\n",
        "# - Apenas os imports necessários para o funcionamento do notebook\n",
        "# - Funções auxiliares adaptadas para Clean Architecture e integração com o log centralizado (Célula 1)\n",
        "# - Função de geração de poster com ffmpeg robusta, com múltiplas tentativas e fallback\n",
        "# - Modularidade: funções isoladas, reusáveis, prontas para testes e integração\n",
        "# ================================================================\n",
        "\n",
        "import os\n",
        "import requests\n",
        "from multiprocessing import Manager, Process\n",
        "from datetime import datetime\n",
        "import json\n",
        "import time\n",
        "import subprocess\n",
        "import math\n",
        "import re\n",
        "import shutil\n",
        "import threading\n",
        "\n",
        "from IPython import get_ipython\n",
        "from IPython.display import display\n",
        "\n",
        "# ============================\n",
        "# UTILITÁRIOS DE FORMATAÇÃO E PROGRESSO\n",
        "# ============================\n",
        "\n",
        "def format_seconds(seconds):\n",
        "    \"\"\"\n",
        "    Formata segundos em string legível (e.g., 1h23m45s).\n",
        "    \"\"\"\n",
        "    total_seconds = int(seconds)\n",
        "    hours = total_seconds // 3600\n",
        "    minutes = (total_seconds % 3600) // 60\n",
        "    seconds = total_seconds % 60\n",
        "    parts = []\n",
        "    if hours > 0:\n",
        "        parts.append(f\"{hours}h\")\n",
        "    if minutes > 0 or (hours == 0 and seconds > 0):\n",
        "        parts.append(f\"{minutes}m\")\n",
        "    if seconds > 0 or total_seconds == 0:\n",
        "        parts.append(f\"{seconds}s\")\n",
        "    return \"\".join(parts) if parts else \"0s\"\n",
        "\n",
        "def log_progress(username, elapsed_seconds, total_seconds):\n",
        "    \"\"\"\n",
        "    Exibe progresso da gravação de cada transmissão em tempo real.\n",
        "    \"\"\"\n",
        "    percent = min((elapsed_seconds / total_seconds) * 100, 100)\n",
        "    tempo = format_seconds(elapsed_seconds)\n",
        "    minutos_gravados = math.floor(elapsed_seconds / 60)\n",
        "    minutos_restantes = max(0, math.ceil((total_seconds - elapsed_seconds) / 60))\n",
        "    print(f\"⏱️ [{username}] Gravados: {minutos_gravados} min | Restantes: {minutos_restantes} min | Tempo total: {tempo} — 📊 {percent:.1f}% concluído\")\n",
        "\n",
        "# ============================\n",
        "# UTILITÁRIO PARA DOWNLOAD DE POSTER\n",
        "# ============================\n",
        "\n",
        "def download_and_save_poster(poster_url, username, temp_folder):\n",
        "    \"\"\"\n",
        "    Baixa e salva o poster (thumbnail) a partir de uma URL HTTP/HTTPS.\n",
        "    Se for um caminho local existente, retorna esse caminho.\n",
        "    Retorna o caminho do arquivo salvo, ou None em caso de erro.\n",
        "    \"\"\"\n",
        "    # Se for um caminho local válido, retorna diretamente\n",
        "    if os.path.exists(poster_url):\n",
        "        return poster_url\n",
        "    # Download de URL HTTP/HTTPS\n",
        "    if isinstance(poster_url, str) and (poster_url.startswith(\"http://\") or poster_url.startswith(\"https://\")):\n",
        "        try:\n",
        "            response = requests.get(poster_url, timeout=15)\n",
        "            response.raise_for_status()\n",
        "            ext = os.path.splitext(poster_url)[1].lower()\n",
        "            if ext not in [\".jpg\", \".jpeg\", \".png\"]:\n",
        "                ext = \".jpg\"\n",
        "            poster_temp_path = os.path.join(temp_folder, f\"{username}_poster_temp{ext}\")\n",
        "            with open(poster_temp_path, \"wb\") as f:\n",
        "                f.write(response.content)\n",
        "            print(f\"🖼️ Poster baixado em: {poster_temp_path}\")\n",
        "            return poster_temp_path\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Erro ao baixar poster {poster_url}: {e}\")\n",
        "            return None\n",
        "    else:\n",
        "        print(f\"❌ poster_url inválido ou não encontrado: {poster_url}\")\n",
        "        return None\n",
        "\n",
        "# ============================\n",
        "# UTILITÁRIO PARA GERAR POSTER COM FFMPEG (com fallback e log central)\n",
        "# ============================\n",
        "\n",
        "def generate_poster_with_ffmpeg(m3u8_url, username, temp_folder, tries=(3, 1, 7, 15, 30), timeout=30):\n",
        "    \"\"\"\n",
        "    Gera um poster (screenshot) usando ffmpeg a partir da URL .m3u8 da transmissão.\n",
        "    Tenta múltiplos pontos no vídeo caso haja erro (robustez).\n",
        "    Integra ao log centralizado via append_log em caso de falha.\n",
        "    Retorna o caminho do arquivo gerado ou None em caso de erro.\n",
        "    \"\"\"\n",
        "    from IPython.display import clear_output\n",
        "    import requests # Garantir requests está importado aqui\n",
        "\n",
        "    # --- Checa se a URL está acessível antes de rodar ffmpeg ---\n",
        "    try:\n",
        "        # Usar um timeout curto para a checagem inicial\n",
        "        head_resp = requests.head(m3u8_url, timeout=5)\n",
        "        if not head_resp.ok:\n",
        "            msg = f\"Stream offline ou não disponível para {username} (status {head_resp.status_code})\"\n",
        "            print(f\"⚠️ {msg}\")\n",
        "            # Registrar falha de conexão no log central\n",
        "            if \"register_failure\" in globals():\n",
        "                 register_failure(username, msg)\n",
        "            return None # Retorna None imediatamente se a stream não estiver acessível\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        msg = f\"Erro de conexão ao acessar stream de {username}: {e}\"\n",
        "        print(f\"❌ {msg}\")\n",
        "        # Registrar falha de conexão no log central\n",
        "        if \"register_failure\" in globals():\n",
        "             register_failure(username, msg)\n",
        "        return None # Retorna None imediatamente em caso de erro de conexão\n",
        "    except Exception as e:\n",
        "        msg = f\"Erro inesperado na checagem de stream para {username}: {e}\"\n",
        "        print(f\"❌ {msg}\")\n",
        "        # Registrar falha genérica na checagem\n",
        "        if \"register_failure\" in globals():\n",
        "             register_failure(username, msg)\n",
        "        return None # Retorna None em caso de qualquer outra exceção na checagem\n",
        "\n",
        "\n",
        "    # --- Tenta gerar poster com ffmpeg (se a checagem inicial passou) ---\n",
        "    for frame_time in tries:\n",
        "        poster_ffmpeg_path = os.path.join(temp_folder, f\"{username}_poster_ffmpeg_{frame_time}.jpg\")\n",
        "        command = [\n",
        "            \"ffmpeg\",\n",
        "            \"-y\",\n",
        "            \"-analyzeduration\", \"10M\",\n",
        "            \"-probesize\", \"50M\",\n",
        "            \"-ss\", str(frame_time),\n",
        "            \"-i\", m3u8_url,\n",
        "            \"-vframes\", \"1\",\n",
        "            \"-q:v\", \"2\",\n",
        "            poster_ffmpeg_path\n",
        "        ]\n",
        "        try:\n",
        "            print(f\"🎬 Tentando gerar poster para {username} com ffmpeg no segundo {frame_time}...\")\n",
        "            result = subprocess.run(\n",
        "                command,\n",
        "                stdout=subprocess.PIPE,\n",
        "                stderr=subprocess.PIPE,\n",
        "                timeout=timeout\n",
        "            )\n",
        "            if result.returncode == 0 and os.path.exists(poster_ffmpeg_path) and os.path.getsize(poster_ffmpeg_path) > 0:\n",
        "                print(f\"🖼️ Poster gerado via ffmpeg: {poster_ffmpeg_path}\")\n",
        "                # Limpa falhas relacionadas a poster/ffmpeg se a geração for bem-sucedida\n",
        "                if \"clear_failure\" in globals():\n",
        "                    clear_failure(username)\n",
        "                return poster_ffmpeg_path\n",
        "            else:\n",
        "                msg = f\"ffmpeg não conseguiu gerar poster para {username} no segundo {frame_time}. Código: {result.returncode}\"\n",
        "                print(f\"❌ {msg}\\nSTDOUT:\\n{result.stdout.decode(errors='ignore')}\\nSTDERR:\\n{result.stderr.decode(errors='ignore')}\")\n",
        "                # Registrar falha específica de ffmpeg no log central\n",
        "                if \"append_log\" in globals():\n",
        "                    append_log({\n",
        "                        \"sessao\": \"poster\",\n",
        "                        \"evento\": \"erro_ffmpeg_frame\",\n",
        "                        \"id\": username,\n",
        "                        \"username\": username,\n",
        "                        \"status\": \"erro\",\n",
        "                        \"detalhes\": f\"{msg} | stdout: {result.stdout.decode(errors='ignore')[:200]} | stderr: {result.stderr.decode(errors='ignore')[:200]}\"\n",
        "                    })\n",
        "\n",
        "        except subprocess.TimeoutExpired:\n",
        "            msg = f\"Tempo excedido ao tentar gerar poster para {username} via ffmpeg (segundo {frame_time}).\"\n",
        "            print(f\"⏰ {msg}\")\n",
        "            # Registrar timeout de ffmpeg no log central\n",
        "            if \"append_log\" in globals():\n",
        "                append_log({\n",
        "                    \"sessao\": \"poster\",\n",
        "                    \"evento\": \"timeout_ffmpeg\",\n",
        "                    \"id\": username,\n",
        "                    \"username\": username,\n",
        "                    \"status\": \"erro\",\n",
        "                    \"detalhes\": msg\n",
        "                })\n",
        "        except Exception as e:\n",
        "            msg = f\"Erro inesperado ao rodar ffmpeg para poster ({username}, segundo {frame_time}): {e}\"\n",
        "            print(f\"❌ {msg}\")\n",
        "            # Registrar exceção de ffmpeg no log central\n",
        "            if \"append_log\" in globals():\n",
        "                append_log({\n",
        "                    \"sessao\": \"poster\",\n",
        "                    \"evento\": \"excecao_ffmpeg\",\n",
        "                    \"id\": username,\n",
        "                    \"username\": username,\n",
        "                    \"status\": \"erro\",\n",
        "                    \"detalhes\": msg\n",
        "                })\n",
        "\n",
        "\n",
        "    # --- Fallback: gera um poster placeholder se todas as tentativas falharem ---\n",
        "    placeholder_path = os.path.join(temp_folder, f\"{username}_placeholder.jpg\")\n",
        "    try:\n",
        "        from PIL import Image, ImageDraw\n",
        "        img = Image.new('RGB', (640, 360), color=(80, 80, 80))\n",
        "        d = ImageDraw.Draw(img)\n",
        "        d.text((10, 150), f\"Poster indisponível\\n{username}\", fill=(255, 255, 255))\n",
        "        img.save(placeholder_path)\n",
        "        print(f\"⚠️ Poster placeholder gerado para {username}: {placeholder_path}\")\n",
        "        # Registrar geração de placeholder no log central\n",
        "        if \"append_log\" in globals():\n",
        "             append_log({\n",
        "                 \"sessao\": \"poster\",\n",
        "                 \"evento\": \"placeholder_gerado\",\n",
        "                 \"id\": username,\n",
        "                 \"username\": username,\n",
        "                 \"status\": \"aviso\",\n",
        "                 \"detalhes\": f\"Poster placeholder gerado após falha no ffmpeg.\"\n",
        "             })\n",
        "        return placeholder_path\n",
        "    except Exception as e:\n",
        "        msg = f\"Erro ao gerar placeholder para {username}: {e}\"\n",
        "        print(f\"❌ {msg}\")\n",
        "        # Registrar falha na geração de placeholder no log central\n",
        "        if \"append_log\" in globals():\n",
        "             append_log({\n",
        "                 \"sessao\": \"poster\",\n",
        "                 \"evento\": \"erro_placeholder\",\n",
        "                 \"id\": username,\n",
        "                 \"username\": username,\n",
        "                 \"status\": \"erro\",\n",
        "                 \"detalhes\": msg\n",
        "             })\n",
        "        return None\n",
        "\n",
        "# ============================\n",
        "# VALIDAÇÃO DE POSTER\n",
        "# ============================\n",
        "\n",
        "def is_poster_valid(poster_path):\n",
        "    \"\"\"\n",
        "    Verifica se o poster existe e não está vazio.\n",
        "    \"\"\"\n",
        "    return poster_path and os.path.exists(poster_path) and os.path.getsize(poster_path) > 0\n",
        "\n",
        "# ============================\n",
        "# FIM DA CÉLULA 3\n",
        "# ============================\n",
        "\n",
        "# Observações:\n",
        "# - Todas as funções de logging, blacklist, falha e auditoria devem ser feitas via utilitário de log centralizado (Célula 1).\n",
        "# - LOG_PROCESSAMENTO_PATH, BLACKLIST_PATH, FAILURE_LOG_PATH e outros logs dispersos não devem mais ser usados.\n",
        "# - O pipeline está pronto para Clean Architecture, máxima rastreabilidade e integração.\n",
        "# - Funções aqui são modulares, reusáveis e preparadas para tratamento de exceções e logging detalhado."
      ],
      "metadata": {
        "id": "hOetz0nGICkz"
      },
      "id": "hOetz0nGICkz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Célula 4: Clonagem do Repositório GitHub no Colab e Google Drive\n",
        "\n",
        "**Objetivo:**  \n",
        "Esta célula garante que o repositório do projeto XCam seja sempre clonado de forma limpa e sincronizada no ambiente local do Colab e, se disponível, também no Google Drive para persistência.  \n",
        "Assegura ambiente pronto, atualizado, seguro para gravações e processamento, e prepara diretórios padronizados para integração com o restante do pipeline.\n",
        "\n",
        "## Principais pontos e melhorias implementadas\n",
        "\n",
        "- **Clonagem idempotente e limpa:**  \n",
        "  Remove repositórios antigos antes de clonar para evitar conflitos, arquivos órfãos ou problemas de sincronização.\n",
        "- **Clonagem para ambiente temporário e persistente:**  \n",
        "  O repositório é clonado tanto para `/content` (Colab) quanto para o Drive (`/content/drive/MyDrive/XCam.Drive`) se o Drive estiver montado.\n",
        "- **Preparação de diretórios de gravação e processamento:**  \n",
        "  Estrutura de diretórios temporários criada automaticamente, garantindo organização dos dados.\n",
        "- **Exportação de variáveis globais:**  \n",
        "  Todos os caminhos, URLs e configurações relevantes são disponibilizados via `globals().update()` para uso em todo o notebook.\n",
        "- **Mensagens e validações detalhadas:**  \n",
        "  Feedback informativo sobre o status de cada etapa, facilitando o diagnóstico e a manutenção.\n",
        "- **Pronto para CI/CD e integrações futuras:**  \n",
        "  Token e URLs preparados para automações, integrações externas e uploads (Abyss.to, etc).\n",
        "\n",
        "---\n",
        "\n",
        "## Parâmetros globais definidos nesta célula\n",
        "\n",
        "- **`GITHUB_USER`**, **`GITHUB_REPO`**, **`GITHUB_BRANCH`**, **`GITHUB_TOKEN`**: Configurações do repositório e autenticação.\n",
        "- **`repo_url`**: URL do repositório autenticada para clone/push.\n",
        "- **`TEMP_OUTPUT_FOLDER`**: Pasta para gravações temporárias.\n",
        "- **`BASE_REPO_FOLDER`**: Localização do repositório no ambiente Colab.\n",
        "- **`DRIVE_MOUNT`**, **`DRIVE_REPO_FOLDER`**: Caminhos no Google Drive para persistência (se montado).\n",
        "- **`ABYSS_UPLOAD_URL`**: URL de upload para integração com sistemas externos.\n",
        "\n",
        "---\n",
        "\n",
        "## Como funciona a célula\n",
        "\n",
        "- **Remove repositórios antigos e diretórios temporários**, evitando resíduos de execuções anteriores.\n",
        "- **Clona o repositório do GitHub** para `/content` (Colab).\n",
        "- **Se o Google Drive estiver montado**, faz o mesmo clone no diretório persistente do Drive.\n",
        "- **Cria diretórios temporários necessários** para gravações e arquivos intermediários.\n",
        "- **Exporta todas as variáveis configuradas** para uso global no notebook.\n",
        "- **Exibe mensagens informativas** sobre cada etapa e alerta caso o Drive não esteja disponível.\n",
        "\n",
        "---\n",
        "\n",
        "## Exemplo de uso das variáveis globais\n",
        "\n",
        "```python\n",
        "print(BASE_REPO_FOLDER)        # Caminho do repositório clonado no Colab\n",
        "print(DRIVE_REPO_FOLDER)      # Caminho do repositório no Drive (se montado)\n",
        "print(TEMP_OUTPUT_FOLDER)     # Pasta temporária para gravações\n",
        "print(ABYSS_UPLOAD_URL)       # URL de upload para integração externa\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Segurança, rastreabilidade e manutenção\n",
        "\n",
        "- Garantia de ambiente limpo a cada execução, evitando conflitos de arquivos e branches.\n",
        "- Persistência dos dados no Drive (se montado), evitando perda de gravações em caso de reinicialização do Colab.\n",
        "- Comentários detalhados e estrutura modular facilitam a manutenção, integração com CI/CD e futuras expansões no pipeline do XCam.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "hpRIMtyFIY0q"
      },
      "id": "hpRIMtyFIY0q"
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================\n",
        "# Célula 4: Clonagem do Repositório GitHub no Colab e no Google Drive\n",
        "# ================================================================\n",
        "# Objetivo:\n",
        "# - Garantir ambiente limpo e sincronizado para o repositório XCam em todas as execuções\n",
        "# - Clonar o repositório tanto para o ambiente efêmero do Colab quanto para o Google Drive (persistência)\n",
        "# - Preparar diretórios de trabalho para gravações e processamento temporário\n",
        "# - Fornecer feedback claro sobre o status da operação\n",
        "#\n",
        "# Estratégia aplicada:\n",
        "# - Remove repositórios antigos antes de clonar (evita conflitos e arquivos órfãos)\n",
        "# - Utiliza token pessoal para autenticação segura e push futuro (CI/CD)\n",
        "# - Cria estrutura de diretórios padronizada (módulos, gravações, cache, etc.)\n",
        "# - Valida se o Drive está montado antes de tentar operações persistentes\n",
        "# - Comentários detalhados para fácil manutenção e evolução\n",
        "# ================================================================\n",
        "\n",
        "# ============================\n",
        "# CONFIGURAÇÕES DO GITHUB\n",
        "# ============================\n",
        "GITHUB_USER = \"SamuelPassamani\"\n",
        "GITHUB_REPO = \"XCam\"\n",
        "GITHUB_BRANCH = \"main\"\n",
        "GITHUB_TOKEN = \"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\"\n",
        "\n",
        "repo_url = f\"https://{GITHUB_USER}:{GITHUB_TOKEN}@github.com/{GITHUB_USER}/{GITHUB_REPO}.git\"\n",
        "\n",
        "# ============================\n",
        "# CLONAGEM PARA O COLAB\n",
        "# ============================\n",
        "print(f\"⏳ Limpando ambiente e clonando '{GITHUB_REPO}' para o Colab...\")\n",
        "!rm -rf {GITHUB_REPO}\n",
        "!git clone -b {GITHUB_BRANCH} {repo_url}\n",
        "print(f\"✅ Repositório clonado em /content/{GITHUB_REPO}\")\n",
        "\n",
        "# ============================\n",
        "# ESTRUTURA DE DIRETÓRIOS TEMPORÁRIOS\n",
        "# ============================\n",
        "TEMP_OUTPUT_FOLDER = \"/content/temp_recordings\"  # Para gravações temporárias\n",
        "os.makedirs(TEMP_OUTPUT_FOLDER, exist_ok=True)\n",
        "BASE_REPO_FOLDER = f\"/content/{GITHUB_REPO}\"\n",
        "\n",
        "# ============================\n",
        "# CLONAGEM PARA O GOOGLE DRIVE (PERSISTÊNCIA)\n",
        "# ============================\n",
        "DRIVE_MOUNT = \"/content/drive/MyDrive/XCam.Drive\"\n",
        "DRIVE_REPO_FOLDER = f\"{DRIVE_MOUNT}/{GITHUB_REPO}\"\n",
        "\n",
        "if os.path.exists(DRIVE_MOUNT):\n",
        "    print(f\"⏳ Limpando repositório antigo no Drive (se existir)...\")\n",
        "    !rm -rf \"{DRIVE_REPO_FOLDER}\"\n",
        "    print(f\"⏳ Clonando '{GITHUB_REPO}' para o Drive em {DRIVE_REPO_FOLDER} ...\")\n",
        "    !git clone -b {GITHUB_BRANCH} {repo_url} \"{DRIVE_REPO_FOLDER}\"\n",
        "    print(f\"✅ Repositório também clonado no Drive: {DRIVE_REPO_FOLDER}\")\n",
        "else:\n",
        "    print(f\"⚠️ Google Drive não está montado em {DRIVE_MOUNT}.\\nℹ️ Use a célula de montagem antes de prosseguir para garantir persistência.\")\n",
        "\n",
        "# ============================\n",
        "# CONFIGURAÇÃO DE ENDPOINTS DE UPLOAD/INTEGRAÇÃO\n",
        "# ============================\n",
        "ABYSS_UPLOAD_URL = 'http://up.hydrax.net/0128263f78f0b426d617bb61c2a8ff43'\n",
        "globals().update({\n",
        "    'GITHUB_USER': GITHUB_USER,\n",
        "    'GITHUB_REPO': GITHUB_REPO,\n",
        "    'GITHUB_BRANCH': GITHUB_BRANCH,\n",
        "    'GITHUB_TOKEN': GITHUB_TOKEN,\n",
        "    'repo_url': repo_url,\n",
        "    'TEMP_OUTPUT_FOLDER': TEMP_OUTPUT_FOLDER,\n",
        "    'BASE_REPO_FOLDER': BASE_REPO_FOLDER,\n",
        "    'DRIVE_MOUNT': DRIVE_MOUNT,\n",
        "    'DRIVE_REPO_FOLDER': DRIVE_REPO_FOLDER,\n",
        "    'ABYSS_UPLOAD_URL': ABYSS_UPLOAD_URL\n",
        "})\n",
        "\n",
        "# ============================\n",
        "# FIM DA CÉLULA 4\n",
        "# ============================\n",
        "\n",
        "# Observações:\n",
        "# - Os caminhos globais são exportados via globals().update() para uso em todo o notebook.\n",
        "# - Recomenda-se sempre rodar esta célula após alterar tokens ou trocar branches para garantir ambiente limpo e sincronizado.\n",
        "# - O endpoint ABYSS_UPLOAD_URL pode ser atualizado conforme integrações futuras."
      ],
      "metadata": {
        "id": "Uof_0QCrIlf7"
      },
      "id": "Uof_0QCrIlf7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Célula 5: Commit e Push Automáticos (rec.json, posters, etc.)\n",
        "\n",
        "**Objetivo:**  \n",
        "Automatiza o processo de commit e push dos arquivos modificados (ex: rec.json, posters e demais artefatos importantes) para o repositório GitHub, garantindo rastreabilidade, atomicidade e integração contínua (CI/CD) do pipeline XCam.\n",
        "\n",
        "## Principais pontos e melhorias implementadas\n",
        "\n",
        "- **Função robusta e modular:**  \n",
        "  A função `git_commit_and_push()` aceita um caminho único (string) ou uma lista de arquivos, permitindo commit em lote e integração com estratégias de batch commit (threshold).\n",
        "- **Configuração automatizada de usuário e e-mail do git:**  \n",
        "  Garante commits válidos para rastreabilidade, auditoria e integração com pipelines automáticos.\n",
        "- **Validação de caminhos e mensagens informativas:**  \n",
        "  Apenas arquivos existentes são adicionados. Mensagens de sucesso, erro ou aviso detalhadas facilitam troubleshooting e manutenção.\n",
        "- **Compatível com commit vazio:**  \n",
        "  Permite o uso do parâmetro `--allow-empty` para garantir que o pipeline siga mesmo sem alterações detectadas, útil para sincronização e CI/CD.\n",
        "- **Push autenticado via token:**  \n",
        "  Utiliza o token pessoal fornecido nas variáveis globais para garantir push seguro e sem intervenção manual.\n",
        "- **Design pronto para integração com logs centralizados:**  \n",
        "  Recomenda-se registrar todas as ações relevantes de commit/push utilizando o log único modular definido na Célula 1.\n",
        "\n",
        "---\n",
        "\n",
        "## Parâmetros e variáveis globais utilizados\n",
        "\n",
        "- **`GITHUB_USER`**, **`GITHUB_REPO`**, **`GITHUB_TOKEN`**: Definidos nas células anteriores para autenticação e configuração do repositório.\n",
        "- **`repo_dir`**: Caminho absoluto do repositório clonado no ambiente Colab.\n",
        "- **`file_paths`**: String ou lista de arquivos a serem commitados e enviados.\n",
        "- **`commit_message`**: Mensagem do commit, customizável conforme a operação realizada.\n",
        "\n",
        "---\n",
        "\n",
        "## Como funciona a função principal\n",
        "\n",
        "- **Valida a existência do repositório local** antes de prosseguir.\n",
        "- **Aceita arquivos únicos ou múltiplos** para commit (string ou lista).\n",
        "- **Adiciona apenas arquivos existentes** ao staging, com avisos para arquivos não encontrados.\n",
        "- **Realiza commit (mesmo vazio) e push autenticado** para o repositório remoto.\n",
        "- **Emite mensagens claras** de sucesso, erro ou aviso ao longo do processo.\n",
        "\n",
        "---\n",
        "\n",
        "## Exemplo de uso típico\n",
        "\n",
        "```python\n",
        "# Commit e push de um único arquivo\n",
        "git_commit_and_push(\"data/rec.json\", \"Atualiza rec.json de gravação\")\n",
        "\n",
        "# Commit e push em lote (lista de arquivos)\n",
        "git_commit_and_push([\n",
        "    \"data/rec.json\",\n",
        "    \"posters/user1_poster.jpg\",\n",
        "    \"posters/user2_poster.jpg\"\n",
        "], \"Batch commit de múltiplos arquivos\")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Segurança, rastreabilidade e manutenção\n",
        "\n",
        "- **Rastreabilidade garantida** por mensagens de commit claras e integração recomendada com o log modular (Célula 1).\n",
        "- **Atomicidade** em operações batch, evitando inconsistências de dados no repositório.\n",
        "- **Pronto para integração com pipelines CI/CD**, webhooks e controles de auditoria.\n",
        "- **Mensagens e tratamento de erros detalhados** facilitam o diagnóstico e a evolução do sistema.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "M5iL_9BoIoj7"
      },
      "id": "M5iL_9BoIoj7"
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================\n",
        "# Célula 5: Commit e Push Automáticos (rec.json, posters, etc.)\n",
        "# ================================================================\n",
        "# Objetivo:\n",
        "# - Automatizar o processo de commit e push dos arquivos modificados (rec.json, posters, etc.) para o repositório GitHub\n",
        "# - Suportar tanto commit de arquivo único como em lote, permitindo estratégia de batch commit baseada em thresholds\n",
        "# - Garantir rastreabilidade, atomicidade e integração segura (CI/CD)\n",
        "#\n",
        "# Estratégia aplicada:\n",
        "# - Função modular e robusta, preparada para integração com logs e auditoria\n",
        "# - Permite commit vazio por segurança, evitando falhas em pipelines sincronizados\n",
        "# - Mensagens e tratamento de erros detalhados para facilitar troubleshooting\n",
        "# - Utilização de variáveis globais para caminhos, usuário e token definidos nas células anteriores\n",
        "# - Design pronto para evolução, reuso e integração com ferramentas externas (ex: webhooks, jobs, etc.)\n",
        "# ================================================================\n",
        "\n",
        "# A lógica de commit e push agora é gerenciada por um script externo.\n",
        "# Esta célula foi mantida para referência, mas a função git_commit_and_push\n",
        "# foi removida pois não será mais executada internamente.\n",
        "\n",
        "# def git_commit_and_push(file_paths, commit_message=\"Atualiza rec.json\"):\n",
        "#     \"\"\"\n",
        "#     Realiza git add, commit e push dos arquivos especificados.\n",
        "#     - file_paths pode ser uma string (arquivo único) ou uma lista de arquivos.\n",
        "#     - commit_message é a mensagem de commit utilizada.\n",
        "\n",
        "#     Estratégia:\n",
        "#     - Ajusta diretório para o repositório local clonado no Colab\n",
        "#     - Configura usuário e e-mail do git (necessários para CI/CD)\n",
        "#     - Adiciona arquivos ao staging (aceita múltiplos arquivos)\n",
        "#     - Realiza commit (permite commit vazio)\n",
        "#     - Realiza push autenticado via token\n",
        "#     \"\"\"\n",
        "#     # ============================\n",
        "#     # VALIDAÇÃO E AJUSTE DE ENTRADAS\n",
        "#     # ============================\n",
        "#     repo_dir = f\"/content/{GITHUB_REPO}\"\n",
        "#     if not os.path.exists(repo_dir):\n",
        "#         raise FileNotFoundError(f\"Repositório '{repo_dir}' não encontrado. Verifique se a célula de clonagem foi executada.\")\n",
        "#     os.chdir(repo_dir)\n",
        "\n",
        "#     # Aceita string ou lista de arquivos\n",
        "#     if isinstance(file_paths, str):\n",
        "#         file_paths = [file_paths]\n",
        "#     elif not isinstance(file_paths, list):\n",
        "#         raise ValueError(\"file_paths deve ser uma string ou uma lista de caminhos.\")\n",
        "\n",
        "#     # ============================\n",
        "#     # CONFIGURAÇÃO DO USUÁRIO GIT (CI/CD)\n",
        "#     # ============================\n",
        "#     subprocess.run([\"git\", \"config\", \"user.email\", \"contato@aserio.work\"], check=True)\n",
        "#     subprocess.run([\"git\", \"config\", \"user.name\", \"SamuelPassamani\"], check=True)\n",
        "\n",
        "#     # ============================\n",
        "#     # ADIÇÃO DOS ARQUIVOS AO STAGING\n",
        "#     # ============================\n",
        "#     for file_path in file_paths:\n",
        "#         # Verifica se o arquivo existe antes de adicionar\n",
        "#         if not os.path.exists(file_path):\n",
        "#             print(f\"⚠️ Aviso: arquivo '{file_path}' não existe e será ignorado no commit.\")\n",
        "#             continue\n",
        "#         subprocess.run([\"git\", \"add\", file_path], check=True)\n",
        "\n",
        "#     # ============================\n",
        "#     # COMMIT (PERMITE COMMIT VAZIO)\n",
        "#     # ============================\n",
        "#     try:\n",
        "#         subprocess.run(\n",
        "#             [\"git\", \"commit\", \"-m\", commit_message, \"--allow-empty\"],\n",
        "#             check=False  # Não força erro se não houver mudanças\n",
        "#         )\n",
        "#     except Exception as e:\n",
        "#         print(f\"❌ Erro ao tentar realizar commit: {e}\")\n",
        "\n",
        "#     # ============================\n",
        "#     # PUSH PARA O REPOSITÓRIO REMOTO (AUTENTICADO)\n",
        "#     # ============================\n",
        "#     try:\n",
        "#         remote_url = f\"https://{GITHUB_USER}:{GITHUB_TOKEN}@github.com/{GITHUB_USER}/{GITHUB_REPO}.git\"\n",
        "#         subprocess.run(\n",
        "#             [\"git\", \"push\", remote_url],\n",
        "#             check=True\n",
        "#         )\n",
        "#         print(f\"✅ Push realizado com sucesso! ({commit_message})\")\n",
        "#     except Exception as e:\n",
        "#         print(f\"❌ Erro ao tentar realizar push: {e}\")\n",
        "\n",
        "# ============================\n",
        "# FIM DA CÉLULA 5\n",
        "# ============================\n",
        "\n",
        "# Dicas e melhores práticas:\n",
        "# - A lógica de commit e push agora é gerenciada por um script externo.\n",
        "# - Certifique-se de que seu script externo gerencie corretamente o commit e push\n",
        "#   dos arquivos alterados (como o rec.json e os posters).\n",
        "# - Monitore os logs do seu script externo para verificar o status dos commits e pushes."
      ],
      "metadata": {
        "id": "1aQn1G6yI6Gz"
      },
      "id": "1aQn1G6yI6Gz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Célula 6: Busca de Transmissões na API XCam, Blacklist Temporária, Fallback via liveInfo e Busca Inteligente/Unitária — Centralização no Log Único\n",
        "\n",
        "**Objetivo:**  \n",
        "Realizar a busca das transmissões ativas na API principal da XCam, mantendo o lote de transmissões sempre completo até o `LIMIT_DEFAULT` e sem duplicidades, utilizando agora o controle de blacklist temporária, falhas e transmissões em processamento **totalmente centralizados no log único** (`xcam_master.log`).  \n",
        "Inclui funções de busca unitária/inteligente (para manter “lote cheio” continuamente), gerenciamento automático de poster com geração via ffmpeg e rastreabilidade máxima para auditoria e manutenção.\n",
        "\n",
        "## Estratégia e melhorias implementadas\n",
        "\n",
        "- **Blacklist e controle de falhas centralizados:**  \n",
        "  Usuários problemáticos são bloqueados temporariamente após atingirem o limite de falhas (`BLACKLIST_MAX_FAILURES`), com todos os eventos registrados via sessões (`sessao`) no log único.  \n",
        "  Não há mais leitura ou escrita em arquivos dispersos de blacklist/falha — toda consulta e registro é feita por funções do log central (`append_log`, `query_logs`, `remove_logs`).\n",
        "- **Busca em lote e unitária com fallback:**  \n",
        "  Consulta a API principal com limite alto para preencher o lote rapidamente; fallback automático via `/liveInfo` para usuários sem `src`.\n",
        "- **Controle de duplicidade e fila inteligente:**  \n",
        "  Antes de incluir qualquer transmissão, verifica no log central se já está em processamento (`sessao=\"processing\"`), além de checar blacklist, evitando tentativas repetidas ou travamento em streams problemáticos.\n",
        "- **Poster garantido:**  \n",
        "  Se o poster estiver ausente, inválido ou nulo, gera automaticamente uma imagem via ffmpeg a partir do stream, garantindo sempre um arquivo válido para cada transmissão.\n",
        "- **Eficiência, paralelismo e rastreabilidade:**  \n",
        "  Funções preparadas para execução concorrente e integração CI/CD, com toda a rastreabilidade possível (inclusive limpeza automática de eventos expirados).\n",
        "- **Compatibilidade com busca de usuários específicos:**  \n",
        "  Busca protegida por blacklist/falhas, fallback via `/liveInfo` e controle de processamento já em lote.\n",
        "- **Design modular e Clean Architecture:**  \n",
        "  Funções separadas para busca em lote (`get_broadcasts`), busca por usuários (`buscar_usuarios_especificos`) e busca unitária/primeira transmissão livre (`buscar_proxima_transmissao_livre`), todas com integração nativa ao log centralizado.\n",
        "\n",
        "---\n",
        "\n",
        "## Como funciona cada função\n",
        "\n",
        "- **get_broadcasts:**  \n",
        "  Retorna um lote de transmissões válidas, sempre checando blacklist, log de processamento e gerando poster se necessário. Realiza fallback automático para `/liveInfo` se não encontrar o src na API principal. Todos os eventos de falha, blacklist ou sucesso são registrados no log único.\n",
        "- **buscar_usuarios_especificos:**  \n",
        "  Busca apenas os usuários informados, respeitando sempre o controle centralizado de blacklist/falhas, com fallback via `/liveInfo` quando necessário.\n",
        "- **buscar_proxima_transmissao_livre:**  \n",
        "  Busca rapidamente a próxima transmissão livre para processamento, sempre utilizando os mesmos critérios de controle, garantindo agilidade na fila e eficiência máxima — tudo com rastreabilidade total no log.\n",
        "\n",
        "---\n",
        "\n",
        "## Detalhes técnicos e recomendações\n",
        "\n",
        "- **Blacklist e falhas totalmente centralizados:**  \n",
        "  Funções `register_failure`, `clear_failure`, `add_to_blacklist`, `is_in_blacklist`, `get_failures` operam exclusivamente sobre o log único, eliminando arquivos auxiliares e promovendo rastreabilidade, auditoria e manutenção facilitada.\n",
        "- **Arquitetura limpa e modular:**  \n",
        "  Código 100% integrado ao log centralizado, pronto para execução concorrente, CI/CD e manutenção.\n",
        "- **Poster sempre válido:**  \n",
        "  Funções utilitárias garantem que cada transmissão só é liberada para gravação se houver poster válido (baixado ou gerado).\n",
        "- **Tratamento de erros robusto e logging automático:**  \n",
        "  Toda etapa crítica possui tratamento de exceções, registro detalhado de eventos e mensagens claras para facilitar monitoramento e evolução.\n",
        "- **Limpeza automática de eventos expirados:**  \n",
        "  Sempre que uma blacklist ou falha expira, o log é automaticamente limpo, garantindo performance e precisão.\n",
        "\n",
        "---\n",
        "\n",
        "## Exemplo de uso das funções\n",
        "\n",
        "```python\n",
        "# Buscar lote completo de transmissões válidas (integrado ao log central)\n",
        "streams = get_broadcasts(limit=LIMIT_DEFAULT)\n",
        "\n",
        "# Buscar apenas usuários específicos (com proteção centralizada)\n",
        "streams_especificos = buscar_usuarios_especificos([\"user1\", \"user2\"])\n",
        "\n",
        "# Buscar a próxima transmissão livre disponível (total rastreabilidade)\n",
        "proxima_stream = buscar_proxima_transmissao_livre()\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Rastreabilidade, manutenção e integração\n",
        "\n",
        "- **Toda blacklist, falha, evento de processamento e sucesso é registrado no log único centralizado (`xcam_master.log`).**\n",
        "- **Funções compatíveis com execução paralela, CI/CD e auditoria.**\n",
        "- **Mensagens detalhadas e arquitetura modular facilitam manutenção, entendimento e futuras expansões no pipeline XCam.**\n",
        "- **Eliminação completa de arquivos dispersos como BLACKLIST_PATH, FAILURE_LOG_PATH ou xcam_processing.log.**\n",
        "- **Uso consistente dos campos `sessao`, `id`, `username`, `status`, `detalhes` e timestamps ISO, conforme padrão global do notebook.**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "BZ4c3Uk1I7AK"
      },
      "id": "BZ4c3Uk1I7AK"
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================\n",
        "# Célula 6: Busca de Transmissões com Blacklist Temporária e Controle de Falhas Centralizados\n",
        "# ================================================================\n",
        "# Objetivo:\n",
        "# - Buscar transmissões ao vivo na API XCam, considerando blacklist e controle de falhas por usuário, ambos centralizados no log único (xcam_master.log)\n",
        "# - Evitar loops infinitos e tentativas repetidas em usuários problemáticos via sessões de blacklist/falha no log único\n",
        "# - Garantir sempre poster válido (via download ou ffmpeg) antes de liberar qualquer transmissão para processamento\n",
        "# - Modularização robusta, integração total com log único, sem leitura/escrita direta em arquivos dispersos\n",
        "# - CAPTURAR E USAR O \"id\" ÚNICO DO USUÁRIO DA API PARA CONTROLE NO LOG\n",
        "#\n",
        "# Estratégia aplicada:\n",
        "# - Toda a lógica de blacklist e falhas opera via funções utilitárias do log centralizado (Célula 1), AGORA USANDO O 'id'\n",
        "# - Sessões do log: \"blacklist\" (usuários banidos temporariamente), \"failure\" (falhas por usuário), \"processing\" (transmissão em processamento)\n",
        "# - Cada evento registrado no log contém: sessao, evento, id (AGORA ID ÚNICO DA API), username, status, detalhes, timestamp\n",
        "# - Não existe mais uso de arquivos como BLACKLIST_PATH, FAILURE_LOG_PATH ou LOG_PROCESSAMENTO_PATH\n",
        "# ================================================================\n",
        "\n",
        "# ============================\n",
        "# FUNÇÕES DE BLACKLIST E FALHAS CENTRALIZADAS NO LOG (AGORA BASEADO EM ID)\n",
        "# ============================\n",
        "\n",
        "# As funções abaixo usarão o 'id' do usuário como chave primária para consultar/manipular o log central.\n",
        "\n",
        "def is_in_blacklist(user_id, now=None):\n",
        "    \"\"\"\n",
        "    Verifica se o usuário (pelo ID) está atualmente na blacklist (sessao='blacklist' e status='blacklisted' e não expirado).\n",
        "    Remove automaticamente entradas expiradas.\n",
        "    \"\"\"\n",
        "    now = now or time.time()\n",
        "    # Busca todos eventos atuais de blacklist desse ID de usuário\n",
        "    entries = query_logs(sessao=\"blacklist\", id=user_id, status=\"blacklisted\")\n",
        "    for entry in entries:\n",
        "        ts_log = entry.get(\"timestamp\")\n",
        "        # timestamp ISO para epoch\n",
        "        try:\n",
        "            ts_epoch = datetime.fromisoformat(ts_log.replace(\"Z\", \"+00:00\")).timestamp() if ts_log else 0\n",
        "        except ValueError: # Tratar possíveis erros de formato ISO\n",
        "            ts_epoch = 0\n",
        "            print(f\"⚠️ Aviso: Formato de timestamp inválido no log para entrada blacklist (id: {user_id}): {ts_log}\")\n",
        "\n",
        "        # Verifica expiração\n",
        "        if now - ts_epoch < BLACKLIST_TIMEOUT:\n",
        "            return True\n",
        "        else:\n",
        "            # Remove entrada expirada (usando id e timestamp para garantir unicidade na remoção)\n",
        "            removed_count = remove_logs(lambda e: e.get(\"sessao\") == \"blacklist\" and e.get(\"id\") == user_id and e.get(\"timestamp\") == ts_log)\n",
        "            # print(f\"ℹ️ Removidas {removed_count} entradas de blacklist expiradas para ID {user_id}\") # O remove_logs já loga\n",
        "    return False\n",
        "\n",
        "def add_to_blacklist(user_id, username):\n",
        "    \"\"\"\n",
        "    Adiciona usuário (pelo ID) à blacklist temporária via log central.\n",
        "    Registra também o username para referência.\n",
        "    \"\"\"\n",
        "    # Primeiro, limpa entradas antigas de blacklist para este ID (garante que só haja uma ativa)\n",
        "    remove_logs(lambda e: e.get(\"sessao\") == \"blacklist\" and e.get(\"id\") == user_id)\n",
        "\n",
        "    entry = {\n",
        "        \"sessao\": \"blacklist\",\n",
        "        \"evento\": \"add_blacklist\",\n",
        "        \"id\": user_id,\n",
        "        \"username\": username, # Mantém username para referência\n",
        "        \"status\": \"blacklisted\",\n",
        "        \"detalhes\": f\"Banido temporariamente por atingir o limite de falhas ({BLACKLIST_MAX_FAILURES})\"\n",
        "    }\n",
        "    append_log(entry)\n",
        "    print(f\"⚠️ Usuário '{username}' (ID: {user_id}) adicionado à blacklist temporária (registrado no log centralizado).\")\n",
        "\n",
        "def get_failures(user_id):\n",
        "    \"\"\"\n",
        "    Conta o número de falhas registradas para o usuário (pelo ID) (sessao='failure' e status='erro' não expiradas).\n",
        "    \"\"\"\n",
        "    # Busca falhas nos últimos BLACKLIST_TIMEOUT segundos (expira junto com blacklist)\n",
        "    now = time.time()\n",
        "    entries = query_logs(sessao=\"failure\", id=user_id, status=\"erro\")\n",
        "    valid_failures = []\n",
        "    for entry in entries:\n",
        "        ts_log = entry.get(\"timestamp\")\n",
        "        try:\n",
        "            ts_epoch = datetime.fromisoformat(ts_log.replace(\"Z\", \"+00:00\")).timestamp() if ts_log else 0\n",
        "        except ValueError: # Tratar possíveis erros de formato ISO\n",
        "            ts_epoch = 0\n",
        "            print(f\"⚠️ Aviso: Formato de timestamp inválido no log para entrada failure (id: {user_id}): {ts_log}\")\n",
        "\n",
        "        if now - ts_epoch < BLACKLIST_TIMEOUT:\n",
        "            valid_failures.append(entry)\n",
        "        else:\n",
        "            # Remove entrada expirada (usando id e timestamp para garantir unicidade na remoção)\n",
        "            removed_count = remove_logs(lambda e: e.get(\"sessao\") == \"failure\" and e.get(\"id\") == user_id and e.get(\"timestamp\") == ts_log)\n",
        "            # print(f\"ℹ️ Removidas {removed_count} entradas de falha expiradas para ID {user_id}\") # O remove_logs já loga\n",
        "    return len(valid_failures)\n",
        "\n",
        "def register_failure(user_id, username, details=\"\"):\n",
        "    \"\"\"\n",
        "    Registra uma falha para o usuário (pelo ID). Move para blacklist se exceder o limite.\n",
        "    Registra também o username para referência.\n",
        "    \"\"\"\n",
        "    # Limpa falhas antigas expiradas antes de adicionar uma nova para este ID\n",
        "    now = time.time()\n",
        "    remove_logs(lambda e: e.get(\"sessao\") == \"failure\" and e.get(\"id\") == user_id and (datetime.fromisoformat(e.get(\"timestamp\",\"\").replace(\"Z\", \"+00:00\")).timestamp() if e.get(\"timestamp\") else 0) < now - BLACKLIST_TIMEOUT)\n",
        "\n",
        "    append_log({\n",
        "        \"sessao\": \"failure\",\n",
        "        \"evento\": \"registrar_falha\",\n",
        "        \"id\": user_id,\n",
        "        \"username\": username, # Mantém username para referência\n",
        "        \"status\": \"erro\",\n",
        "        \"detalhes\": details\n",
        "    })\n",
        "    failures = get_failures(user_id)\n",
        "    print(f\"❌ Falha registrada para '{username}' (ID: {user_id}). Total de falhas recentes: {failures}/{BLACKLIST_MAX_FAILURES}\")\n",
        "\n",
        "    if failures >= BLACKLIST_MAX_FAILURES:\n",
        "        add_to_blacklist(user_id, username)\n",
        "        # Limpa falhas após blacklisting para este ID\n",
        "        remove_logs(lambda e: e.get(\"sessao\") == \"failure\" and e.get(\"id\") == user_id)\n",
        "        print(f\"✅ Falhas limpas para ID {user_id} após blacklisting.\")\n",
        "\n",
        "\n",
        "def clear_failure(user_id):\n",
        "    \"\"\"\n",
        "    Limpa todas as falhas registradas para o usuário (pelo ID).\n",
        "    \"\"\"\n",
        "    removed = remove_logs(lambda e: e.get(\"sessao\") == \"failure\" and e.get(\"id\") == user_id)\n",
        "    if removed > 0:\n",
        "        # Podemos adicionar um log de sucesso de limpeza aqui, se necessário\n",
        "        # append_log({\"sessao\": \"failure\", \"evento\": \"limpar_falhas\", \"id\": user_id, \"status\": \"ok\", \"detalhes\": f\"{removed} falhas limpas\"})\n",
        "        print(f\"✅ {removed} falhas limpas para ID {user_id}.\")\n",
        "    # else:\n",
        "    #     print(f\"ℹ️ Nenhuma falha encontrada para limpar para ID {user_id}.\") # remove_logs já loga se nada foi removido\n",
        "\n",
        "\n",
        "def is_processing(user_id):\n",
        "    \"\"\"\n",
        "    Verifica se o usuário (pelo ID) está marcado como em processamento ativo.\n",
        "    \"\"\"\n",
        "    # Procura por entrada de processamento 'in_progress' para este ID\n",
        "    entries = query_logs(sessao=\"processing\", id=user_id, status=\"in_progress\")\n",
        "    return len(entries) > 0\n",
        "\n",
        "def mark_processing(user_id, username):\n",
        "    \"\"\"\n",
        "    Marca o usuário/transmissão (pelo ID) como em processamento ativo via log central.\n",
        "    Registra também o username para referência.\n",
        "    \"\"\"\n",
        "    # Remove entradas antigas de processamento para este ID antes de adicionar a nova (garante unicidade)\n",
        "    remove_logs(lambda e: e.get(\"sessao\") == \"processing\" and e.get(\"id\") == user_id)\n",
        "\n",
        "    append_log({\n",
        "        \"sessao\": \"processing\",\n",
        "        \"evento\": \"iniciar\",\n",
        "        \"id\": user_id,\n",
        "        \"username\": username, # Mantém username para referência\n",
        "        \"status\": \"in_progress\",\n",
        "        \"detalhes\": \"\"\n",
        "    })\n",
        "    # print(f\"ℹ️ Usuário '{username}' (ID: {user_id}) marcado como 'in_progress' no log.\")\n",
        "\n",
        "\n",
        "def unmark_processing(user_id):\n",
        "    \"\"\"\n",
        "    Remove marcação de processamento ativo para o usuário (pelo ID).\n",
        "    \"\"\"\n",
        "    # Remove entradas de processamento 'in_progress' para este ID\n",
        "    removed = remove_logs(lambda e: e.get(\"sessao\") == \"processing\" and e.get(\"id\") == user_id and e.get(\"status\") == \"in_progress\")\n",
        "    # if removed > 0:\n",
        "    #     print(f\"ℹ️ Marcação 'in_progress' removida para ID {user_id}.\")\n",
        "    # else:\n",
        "    #      print(f\"ℹ️ Nenhuma marcação 'in_progress' encontrada para remover para ID {user_id}.\") # remove_logs já loga se nada foi removido\n",
        "\n",
        "\n",
        "# ============================\n",
        "# BUSCA DE TRANSMISSÕES NA API XCAM (AGORA CAPTURANDO O ID E USANDO NO CONTROLE)\n",
        "# ============================\n",
        "\n",
        "def get_broadcasts(limit=LIMIT_DEFAULT, page=PAGE_DEFAULT, usuarios_especificos=None, temp_folder=\"/content\"):\n",
        "    \"\"\"\n",
        "    Busca transmissões ao vivo, respeitando blacklist (por ID), falhas (por ID) e log de processamento (por ID) via log centralizado.\n",
        "    Garante poster válido (download ou ffmpeg) e faz fallback automático.\n",
        "    RETORNA LISTA DE DICIONÁRIOS INCLUINDO O 'id' DA API.\n",
        "    \"\"\"\n",
        "    # Coleta IDs de usuários atualmente em processamento ou blacklist\n",
        "    ids_em_proc_ou_blacklist = {e[\"id\"] for e in query_logs(sessao=\"processing\", status=\"in_progress\")} | \\\n",
        "                               {e[\"id\"] for e in query_logs(sessao=\"blacklist\", status=\"blacklisted\")}\n",
        "\n",
        "\n",
        "    if usuarios_especificos:\n",
        "        # Note: Buscar por username específico na API e depois filtrar por ID no log é necessário\n",
        "        # A API principal não parece permitir busca por lista de IDs diretamente\n",
        "        api_url_main = f\"https://api.xcam.gay/?limit={API_SEARCH_LIMIT}&page=1\" # Ainda busca um lote grande para encontrar específicos\n",
        "        print(f\"🌐 Acessando API principal (buscando usuários específicos) em: {api_url_main}\")\n",
        "    else:\n",
        "        # Busca um lote grande para ter mais chances de encontrar usuários disponíveis\n",
        "        api_url_main = f\"https://api.xcam.gay/?limit=3333\"\n",
        "        print(f\"🌐 Acessando API principal (buscando todas transmissões online) em: {api_url_main}\")\n",
        "\n",
        "    streams_candidates = [] # streams que tem src ou que precisam de liveInfo\n",
        "    streams_without_preview = [] # streams sem src na API principal\n",
        "\n",
        "    try:\n",
        "        response_main = requests.get(api_url_main)\n",
        "        response_main.raise_for_status()\n",
        "        data_main = response_main.json()\n",
        "        broadcasts_data = data_main.get(\"broadcasts\")\n",
        "        if not broadcasts_data:\n",
        "            print(\"⚠️ Chave 'broadcasts' não encontrada na resposta da API principal.\")\n",
        "            return []\n",
        "        items = broadcasts_data.get(\"items\")\n",
        "        if not isinstance(items, list):\n",
        "            print(f\"⚠️ Chave 'items' não encontrada ou não é uma lista em 'broadcasts'.\")\n",
        "            return []\n",
        "\n",
        "        print(f\"API principal retornou {len(items)} transmissões.\")\n",
        "\n",
        "        for item in items:\n",
        "            # ** CAPTURA O ID AQUI **\n",
        "            user_id = str(item.get(\"id\")) # Garante que o ID seja string\n",
        "            username = item.get(\"username\", \"desconhecido\")\n",
        "            preview = item.get(\"preview\") or {}\n",
        "            src = preview.get(\"src\")\n",
        "            poster = preview.get(\"poster\")\n",
        "\n",
        "            # Ignora se já está em processamento ou blacklist (AGORA VERIFICA PELO ID)\n",
        "            if user_id in ids_em_proc_ou_blacklist:\n",
        "                # print(f\"ℹ️ Usuário '{username}' (ID: {user_id}) já processado/em blacklist/processing, ignorando.\")\n",
        "                continue\n",
        "\n",
        "            # Ignora se está buscando específicos e este usuário/ID não está na lista\n",
        "            if usuarios_especificos and username not in usuarios_especificos: # Continua filtrando por username se especificado\n",
        "                 # Poderíamos também adicionar uma lista de IDs específicos, se a API permitisse buscar por ID.\n",
        "                continue\n",
        "\n",
        "            stream_info = {\n",
        "                 \"id\": user_id, # Inclui o ID\n",
        "                 \"username\": username,\n",
        "                 \"src\": src,\n",
        "                 \"poster\": poster # Isso pode ser URL ou None\n",
        "            }\n",
        "\n",
        "            if src:\n",
        "                streams_candidates.append(stream_info) # Adiciona streams com src para processar/validar poster\n",
        "            else:\n",
        "                 streams_without_preview.append(stream_info) # Adiciona streams sem src para tentar liveInfo\n",
        "\n",
        "        print(f\"✅ {len(streams_candidates)} transmissões com URL na API principal, {len(streams_without_preview)} sem URL.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Erro ao acessar API principal: {e}\")\n",
        "        # Registrar erro de busca no log\n",
        "        if \"append_log\" in globals():\n",
        "             append_log({\n",
        "                 \"sessao\": \"busca\",\n",
        "                 \"evento\": \"erro_api_principal\",\n",
        "                 \"id\": \"global\", # Erro global de API\n",
        "                 \"username\": \"global\",\n",
        "                 \"status\": \"erro\",\n",
        "                 \"detalhes\": f\"Erro ao acessar API principal: {e}\"\n",
        "             })\n",
        "        return [] # Retorna vazio em caso de erro na API principal\n",
        "\n",
        "    # Fallback: busca via liveInfo para streams sem URL na API principal\n",
        "    streams_from_liveinfo = []\n",
        "    if streams_without_preview:\n",
        "        print(f\"🔁 Buscando liveInfo para {len(streams_without_preview)} streams sem URL na API principal...\")\n",
        "        for stream_info in streams_without_preview:\n",
        "            user_id = stream_info[\"id\"] # Usa o ID capturado\n",
        "            username = stream_info[\"username\"]\n",
        "\n",
        "            # Verifica novamente se entrou em proc/blacklist enquanto processávamos a lista\n",
        "            if user_id in ids_em_proc_ou_blacklist:\n",
        "                 # print(f\"ℹ️ Usuário '{username}' (ID: {user_id}) já processado/em blacklist/processing durante fallback, ignorando.\")\n",
        "                 continue\n",
        "\n",
        "            api_url_liveinfo = f\"https://api.xcam.gay/user/{username}/liveInfo\" # LiveInfo ainda usa username na URL\n",
        "            try:\n",
        "                response_liveinfo = requests.get(api_url_liveinfo)\n",
        "                response_liveinfo.raise_for_status()\n",
        "                data_liveinfo = response_liveinfo.json()\n",
        "                m3u8_url = data_liveinfo.get(\"cdnURL\") or data_liveinfo.get(\"edgeURL\")\n",
        "                if m3u8_url:\n",
        "                    # Adiciona stream encontrada via liveInfo aos candidatos\n",
        "                    streams_from_liveinfo.append({\n",
        "                        \"id\": user_id, # Inclui o ID\n",
        "                        \"username\": username,\n",
        "                        \"src\": m3u8_url,\n",
        "                        \"poster\": None # Poster do liveInfo geralmente não é direto, será gerado\n",
        "                    })\n",
        "                else:\n",
        "                    print(f\"⚠️ liveInfo de '{username}' (ID: {user_id}) não retornou cdnURL/edgeURL (usuário possivelmente offline).\")\n",
        "                    # Registrar falha no liveInfo no log (AGORA USA ID)\n",
        "                    if \"register_failure\" in globals():\n",
        "                         register_failure(user_id, username, \"liveInfo sem cdnURL/edgeURL.\")\n",
        "\n",
        "            except Exception as ex:\n",
        "                print(f\"❌ Erro ao buscar liveInfo para '{username}' (ID: {user_id}): {ex}\")\n",
        "                 # Registrar erro de liveInfo no log (AGORA USA ID)\n",
        "                if \"register_failure\" in globals():\n",
        "                     register_failure(user_id, username, f\"Erro ao buscar liveInfo: {ex}\")\n",
        "\n",
        "            time.sleep(0.2) # Pequeno delay entre chamadas de liveInfo\n",
        "\n",
        "    # Junta candidatos da API principal e liveInfo.\n",
        "    # Antes de adicionar à lista final, valida poster e evita duplicidade/blacklist FINAL.\n",
        "    final_streams_list = []\n",
        "    seen_ids = set() # Usa um set de IDs para controlar duplicidade na lista final\n",
        "    all_candidates = streams_candidates + streams_from_liveinfo\n",
        "\n",
        "    print(f\"Validando poster e filtrando {len(all_candidates)} candidatos...\")\n",
        "\n",
        "    for stream in all_candidates:\n",
        "        user_id = stream[\"id\"]\n",
        "        username = stream[\"username\"]\n",
        "        src = stream[\"src\"]\n",
        "        poster_info = stream[\"poster\"] # Pode ser URL ou None\n",
        "\n",
        "        # Verifica pela ÚLTIMA VEZ se o ID já foi adicionado à lista final,\n",
        "        # ou se entrou em processamento/blacklist desde a consulta inicial da API.\n",
        "        if user_id in seen_ids or user_id in ids_em_proc_ou_blacklist:\n",
        "            continue\n",
        "\n",
        "        poster_path = None\n",
        "        try:\n",
        "            # Tenta baixar poster original se existir\n",
        "            if poster_info and isinstance(poster_info, str) and poster_info.strip():\n",
        "                poster_path = download_and_save_poster(poster_info, username, temp_folder) # download_and_save_poster não precisa de ID\n",
        "\n",
        "            # Se poster baixado for inválido OU não havia poster original, gera com ffmpeg\n",
        "            if not is_poster_valid(poster_path):\n",
        "                poster_path = generate_poster_with_ffmpeg(src, username, temp_folder) # generate_poster_with_ffmpeg não precisa de ID\n",
        "\n",
        "            # Se mesmo após todas as tentativas o poster for inválido\n",
        "            if not is_poster_valid(poster_path):\n",
        "                # Registrar falha de poster no log (AGORA USA ID)\n",
        "                if \"register_failure\" in globals():\n",
        "                     register_failure(user_id, username, \"Poster inválido após todas tentativas.\")\n",
        "                continue # Pula para o próximo stream se o poster for inválido\n",
        "\n",
        "            # Se o poster é válido, limpa falhas relacionadas a poster/ffmpeg/conexão para este ID\n",
        "            if \"clear_failure\" in globals():\n",
        "                 clear_failure(user_id) # Limpa falhas pelo ID\n",
        "\n",
        "            # Adiciona à lista final e marca ID como visto\n",
        "            final_streams_list.append({\n",
        "                \"id\": user_id, # Inclui o ID único no resultado final\n",
        "                \"username\": username,\n",
        "                \"src\": src,\n",
        "                \"poster_path\": poster_path # Passa o caminho LOCAL do poster válido\n",
        "            })\n",
        "            seen_ids.add(user_id)\n",
        "\n",
        "            # Quebra o loop se atingiu o limite desejado\n",
        "            if len(final_streams_list) >= limit:\n",
        "                break\n",
        "\n",
        "        except Exception as e:\n",
        "            msg = f\"Falha inesperada durante validação de poster/stream para '{username}' (ID: {user_id}): {e}\"\n",
        "            print(f\"❌ {msg}\")\n",
        "            # Registrar falha genérica no log (AGORA USA ID)\n",
        "            if \"register_failure\" in globals():\n",
        "                 register_failure(user_id, username, msg)\n",
        "\n",
        "\n",
        "    print(f\"🔎 Selecionadas {len(final_streams_list)} streams válidas (com poster) após fallback (respeitando limit={limit}).\")\n",
        "    return final_streams_list\n",
        "\n",
        "# ============================\n",
        "# BUSCA DE USUÁRIOS ESPECÍFICOS (AGORA COM ID)\n",
        "# ============================\n",
        "\n",
        "def buscar_usuarios_especificos(usuarios_lista, temp_folder=\"/content\"):\n",
        "    \"\"\"\n",
        "    Busca usuários específicos via API (por username), agora respeitando blacklist (por ID)\n",
        "    e controle de falhas (por ID) via log central. Inclui fallback via liveInfo e valida poster.\n",
        "    RETORNA LISTA DE DICIONÁRIOS INCLUINDO O 'id' DA API.\n",
        "    \"\"\"\n",
        "    # Coleta IDs de usuários em processamento ou blacklist\n",
        "    ids_em_proc_ou_blacklist = {e[\"id\"] for e in query_logs(sessao=\"processing\", status=\"in_progress\")} | \\\n",
        "                               {e[\"id\"] for e in query_logs(sessao=\"blacklist\", status=\"blacklisted\")}\n",
        "\n",
        "    # Primeiro, tenta encontrar os usuários na lista na API principal (limite alto para pegar todos se online)\n",
        "    api_url = f\"https://api.xcam.gay/?limit={API_SEARCH_LIMIT}&page=1\"\n",
        "    print(f\"🔍 Buscando usuários específicos ({len(usuarios_lista)}) em {api_url}\")\n",
        "    found_candidates = []\n",
        "    users_not_found_in_main = set(usuarios_lista) # Acompanha quem não foi encontrado na API principal\n",
        "\n",
        "    try:\n",
        "        response = requests.get(api_url)\n",
        "        response.raise_for_status()\n",
        "        data = response.json()\n",
        "        items = data.get(\"broadcasts\", {}).get(\"items\", [])\n",
        "\n",
        "        for item in items:\n",
        "            user_id = str(item.get(\"id\")) # ** CAPTURA O ID **\n",
        "            username = item.get(\"username\", \"\")\n",
        "\n",
        "            if username in usuarios_lista: # Verifica se este é um dos usuários que procuramos\n",
        "                 users_not_found_in_main.discard(username) # Remove da lista de não encontrados\n",
        "\n",
        "                 # Verifica se o ID está em proc/blacklist (AGORA VERIFICA PELO ID)\n",
        "                 if user_id in ids_em_proc_ou_blacklist:\n",
        "                     # print(f\"ℹ️ Usuário '{username}' (ID: {user_id}) já processado/em blacklist/processing, ignorando.\")\n",
        "                     continue\n",
        "\n",
        "                 preview = item.get(\"preview\") or {}\n",
        "                 src = preview.get(\"src\")\n",
        "                 poster = preview.get(\"poster\") # Pode ser URL ou None\n",
        "\n",
        "                 if src:\n",
        "                     # Adiciona como candidato se tiver SRC (validação de poster depois)\n",
        "                     found_candidates.append({\n",
        "                         \"id\": user_id, # Inclui o ID\n",
        "                         \"username\": username,\n",
        "                         \"src\": src,\n",
        "                         \"poster\": poster # Pode ser URL ou None\n",
        "                     })\n",
        "                 else:\n",
        "                     # Marca para tentar via liveInfo se não tiver SRC principal\n",
        "                     # Adiciona a lista de streams_without_preview para liveinfo fallback\n",
        "                     found_candidates.append({\n",
        "                        \"id\": user_id, # Inclui o ID\n",
        "                        \"username\": username,\n",
        "                        \"src\": None, # Indica que precisa de liveInfo\n",
        "                        \"poster\": None\n",
        "                    })\n",
        "\n",
        "\n",
        "        print(f\"Encontrados {len(found_candidates)} dos {len(usuarios_lista)} usuários especificados na API principal (antes de fallback).\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Erro ao buscar usuários específicos na API principal: {e}\")\n",
        "        # Registrar erro de busca no log (AGORA USA ID ou Global)\n",
        "        if \"append_log\" in globals():\n",
        "             append_log({\n",
        "                 \"sessao\": \"busca\",\n",
        "                 \"evento\": \"erro_api_especificos\",\n",
        "                 \"id\": \"global\", # Erro global de API\n",
        "                 \"username\": \"global\",\n",
        "                 \"status\": \"erro\",\n",
        "                 \"detalhes\": f\"Erro ao buscar usuários específicos na API principal: {e}\"\n",
        "             })\n",
        "        # Em caso de erro na API principal, tenta buscar cada usuário individualmente via liveInfo?\n",
        "        # Para simplificar, se a API principal falha, retornamos o que conseguimos ou vazio.\n",
        "        # Se o erro é grave, talvez não haja mais o que fazer.\n",
        "\n",
        "    # Fallback: busca via liveInfo para usuários especificados que não tinham SRC na API principal\n",
        "    streams_from_liveinfo = []\n",
        "    # Filtra os candidatos que precisam de liveInfo\n",
        "    candidates_for_liveinfo = [c for c in found_candidates if c.get(\"src\") is None]\n",
        "    # Adiciona usuários que NÃO foram encontrados na API principal mas estavam na lista original\n",
        "    # Assume que se não foi encontrado na lista grande da API principal, está offline ou precisa de liveInfo direto\n",
        "    # Isso pode gerar falsos positivos se o usuário estiver offline\n",
        "    for uname in users_not_found_in_main:\n",
        "        # Tenta obter o ID antes de tentar liveInfo? LiveInfo não retorna ID...\n",
        "        # Se o usuário não foi encontrado na API principal (com limite alto), é provável que esteja offline.\n",
        "        # Buscar liveInfo sem ter um ID é menos robusto.\n",
        "        # Vamos focar no fallback APENAS para usuários ENCONTRADOS na API principal mas sem SRC.\n",
        "        # Se o usuário da lista específica não apareceu na busca grande, assumimos offline por enquanto.\n",
        "        print(f\"⚠️ Usuário '{uname}' especificado não encontrado na busca da API principal. Assumindo offline ou inacessível.\")\n",
        "\n",
        "\n",
        "    if candidates_for_liveinfo:\n",
        "        print(f\"🔁 Buscando liveInfo para {len(candidates_for_liveinfo)} usuários específicos sem URL na API principal...\")\n",
        "        for stream_info in candidates_for_liveinfo:\n",
        "            user_id = stream_info[\"id\"] # Usa o ID capturado da API principal\n",
        "            username = stream_info[\"username\"]\n",
        "\n",
        "            # Verifica novamente se entrou em proc/blacklist\n",
        "            if user_id in ids_em_proc_ou_blacklist:\n",
        "                 # print(f\"ℹ️ Usuário '{username}' (ID: {user_id}) já processado/em blacklist/processing durante fallback, ignorando.\")\n",
        "                 continue\n",
        "\n",
        "            api_url_liveinfo = f\"https://api.xcam.gay/user/{username}/liveInfo\"\n",
        "            try:\n",
        "                response_liveinfo = requests.get(api_url_liveinfo)\n",
        "                response_liveinfo.raise_for_status()\n",
        "                data_liveinfo = response_liveinfo.json()\n",
        "                m3u8_url = data_liveinfo.get(\"cdnURL\") or data_liveinfo.get(\"edgeURL\")\n",
        "                if m3u8_url:\n",
        "                    # Adiciona stream encontrada via liveInfo\n",
        "                    streams_from_liveinfo.append({\n",
        "                        \"id\": user_id, # Inclui o ID\n",
        "                        \"username\": username,\n",
        "                        \"src\": m3u8_url,\n",
        "                        \"poster\": None # Poster do liveInfo geralmente não é direto, será gerado\n",
        "                    })\n",
        "                else:\n",
        "                    print(f\"⚠️ liveInfo de '{username}' (ID: {user_id}) não retornou cdnURL/edgeURL (usuário possivelmente offline).\")\n",
        "                    # Registrar falha no liveInfo no log (AGORA USA ID)\n",
        "                    if \"register_failure\" in globals():\n",
        "                         register_failure(user_id, username, \"liveInfo sem cdnURL/edgeURL.\")\n",
        "\n",
        "            except Exception as ex:\n",
        "                print(f\"❌ Erro ao buscar liveInfo para '{username}' (ID: {user_id}): {ex}\")\n",
        "                # Registrar erro de liveInfo no log (AGORA USA ID)\n",
        "                if \"register_failure\" in globals():\n",
        "                     register_failure(user_id, username, f\"Erro ao buscar liveInfo: {ex}\")\n",
        "\n",
        "            time.sleep(0.2) # Pequeno delay\n",
        "\n",
        "    # Junta candidatos que tinham SRC e os encontrados via liveInfo.\n",
        "    # Antes de adicionar à lista final, valida poster e evita duplicidade/blacklist FINAL.\n",
        "    final_streams_list = []\n",
        "    seen_ids = set() # Usa um set de IDs para controlar duplicidade na lista final\n",
        "    # Filtra os candidatos que TINHAM SRC na API principal\n",
        "    candidates_with_src = [c for c in found_candidates if c.get(\"src\") is not None]\n",
        "    all_candidates_post_fallback = candidates_with_src + streams_from_liveinfo\n",
        "\n",
        "    print(f\"Validando poster e filtrando {len(all_candidates_post_fallback)} candidatos após fallback...\")\n",
        "\n",
        "\n",
        "    for stream in all_candidates_post_fallback:\n",
        "        user_id = stream[\"id\"]\n",
        "        username = stream[\"username\"]\n",
        "        src = stream[\"src\"]\n",
        "        poster_info = stream[\"poster\"] # Pode ser URL ou None\n",
        "\n",
        "        # Verifica pela ÚLTIMA VEZ se o ID já foi adicionado à lista final,\n",
        "        # ou se entrou em processamento/blacklist desde a consulta inicial.\n",
        "        if user_id in seen_ids or user_id in ids_em_proc_ou_blacklist:\n",
        "            continue\n",
        "\n",
        "        poster_path = None\n",
        "        try:\n",
        "            # Tenta baixar poster original se existir\n",
        "            if poster_info and isinstance(poster_info, str) and poster_info.strip():\n",
        "                poster_path = download_and_save_poster(poster_info, username, temp_folder)\n",
        "\n",
        "            # Se poster baixado for inválido OU não havia poster original, gera com ffmpeg\n",
        "            if not is_poster_valid(poster_path):\n",
        "                poster_path = generate_poster_with_ffmpeg(src, username, temp_folder)\n",
        "\n",
        "            # Se mesmo após todas as tentativas o poster for inválido\n",
        "            if not is_poster_valid(poster_path):\n",
        "                 # Registrar falha de poster no log (AGORA USA ID)\n",
        "                if \"register_failure\" in globals():\n",
        "                     register_failure(user_id, username, \"Poster inválido após todas tentativas.\")\n",
        "                continue # Pula para o próximo stream\n",
        "\n",
        "            # Se o poster é válido, limpa falhas relacionadas a poster/ffmpeg/conexão para este ID\n",
        "            if \"clear_failure\" in globals():\n",
        "                 clear_failure(user_id) # Limpa falhas pelo ID\n",
        "\n",
        "            # Adiciona à lista final e marca ID como visto\n",
        "            final_streams_list.append({\n",
        "                \"id\": user_id, # Inclui o ID único no resultado final\n",
        "                \"username\": username,\n",
        "                \"src\": src,\n",
        "                \"poster_path\": poster_path # Passa o caminho LOCAL do poster válido\n",
        "            })\n",
        "            seen_ids.add(user_id)\n",
        "\n",
        "            # No modo específico, buscamos todos da lista, então não há limite de \"len(final_streams_list) >= limit\" aqui.\n",
        "            # Poderíamos adicionar um limite se quiséssemos parar após encontrar N dos específicos.\n",
        "\n",
        "        except Exception as e:\n",
        "            msg = f\"Falha inesperada durante validação de poster/stream para '{username}' (ID: {user_id}): {e}\"\n",
        "            print(f\"❌ {msg}\")\n",
        "            # Registrar falha genérica no log (AGORA USA ID)\n",
        "            if \"register_failure\" in globals():\n",
        "                 register_failure(user_id, username, msg)\n",
        "\n",
        "    print(f\"🔎 Encontrados e validados {len(final_streams_list)} dos {len(usuarios_lista)} usuários especificados.\")\n",
        "    return final_streams_list\n",
        "\n",
        "\n",
        "# ============================\n",
        "# BUSCA DA PRÓXIMA TRANSMISSÃO DISPONÍVEL (AGORA COM ID)\n",
        "# ============================\n",
        "\n",
        "def buscar_proxima_transmissao_livre(temp_folder=\"/content\"):\n",
        "    \"\"\"\n",
        "    Busca a próxima transmissão ao vivo não processada, com poster válido e ignorando blacklist (por ID), tudo centralizado no log.\n",
        "    RETORNA DICIONÁRIO INCLUINDO O 'id' DA API, OU None.\n",
        "    \"\"\"\n",
        "    # Coleta IDs de usuários em processamento ou blacklist\n",
        "    ids_em_proc_ou_blacklist = {e[\"id\"] for e in query_logs(sessao=\"processing\", status=\"in_progress\")} | \\\n",
        "                               {e[\"id\"] for e in query_logs(sessao=\"blacklist\", status=\"blacklisted\")}\n",
        "\n",
        "\n",
        "    api_url_main = f\"https://api.xcam.gay/?limit=3333&page=1\" # Busca um lote grande para encontrar o próximo rápido\n",
        "    print(f\"🔎 Buscando próxima transmissão livre em: {api_url_main}\")\n",
        "    try:\n",
        "        response_main = requests.get(api_url_main)\n",
        "        response_main.raise_for_status()\n",
        "        data_main = response_main.json()\n",
        "        items = data_main.get(\"broadcasts\", {}).get(\"items\", [])\n",
        "        print(f\"API principal retornou {len(items)} transmissões.\")\n",
        "\n",
        "        # Primeiro, itera sobre os itens da API principal que têm SRC\n",
        "        for item in items:\n",
        "            # ** CAPTURA O ID AQUI **\n",
        "            user_id = str(item.get(\"id\")) # Garante que o ID seja string\n",
        "            username = item.get(\"username\", \"desconhecido\")\n",
        "            preview = item.get(\"preview\") or {}\n",
        "            src = preview.get(\"src\")\n",
        "            poster_info = preview.get(\"poster\") # Pode ser URL ou None\n",
        "\n",
        "            # Ignora se já está em processamento ou blacklist (AGORA VERIFICA PELO ID)\n",
        "            if user_id in ids_em_proc_ou_blacklist:\n",
        "                # print(f\"ℹ️ Usuário '{username}' (ID: {user_id}) já processado/em blacklist/processing, ignorando.\")\n",
        "                continue\n",
        "\n",
        "            if src:\n",
        "                 # Se tem SRC e não está em proc/blacklist, valida poster\n",
        "                poster_path = None\n",
        "                try:\n",
        "                    # Tenta baixar poster original se existir\n",
        "                    if poster_info and isinstance(poster_info, str) and poster_info.strip():\n",
        "                        poster_path = download_and_save_poster(poster_info, username, temp_folder)\n",
        "\n",
        "                    # Se poster baixado for inválido OU não havia poster original, gera com ffmpeg\n",
        "                    if not is_poster_valid(poster_path):\n",
        "                        poster_path = generate_poster_with_ffmpeg(src, username, temp_folder)\n",
        "\n",
        "                    # Se o poster é válido, limpa falhas relacionadas a poster/ffmpeg/conexão e retorna\n",
        "                    if is_poster_valid(poster_path):\n",
        "                        if \"clear_failure\" in globals():\n",
        "                             clear_failure(user_id) # Limpa falhas pelo ID\n",
        "                        print(f\"🎯 Transmissão livre encontrada: '{username}' (ID: {user_id})\")\n",
        "                        return {\n",
        "                            \"id\": user_id, # Inclui o ID único no resultado\n",
        "                            \"username\": username,\n",
        "                            \"src\": src,\n",
        "                            \"poster_path\": poster_path # Passa o caminho LOCAL do poster válido\n",
        "                        }\n",
        "                    else:\n",
        "                         # Se poster inválido, registra falha e continua buscando\n",
        "                         if \"register_failure\" in globals():\n",
        "                             register_failure(user_id, username, \"Poster inválido após todas tentativas (busca próxima).\")\n",
        "                         continue # Pula para o próximo item\n",
        "\n",
        "                except Exception as e:\n",
        "                    msg = f\"Falha inesperada durante validação de poster/stream para '{username}' (ID: {user_id}) na busca próxima: {e}\"\n",
        "                    print(f\"❌ {msg}\")\n",
        "                    # Registrar falha genérica no log (AGORA USA ID)\n",
        "                    if \"register_failure\" in globals():\n",
        "                         register_failure(user_id, username, msg)\n",
        "                    continue # Pula para o próximo item\n",
        "\n",
        "\n",
        "        # Se chegou aqui, nenhum item com SRC foi encontrado/validado na busca grande.\n",
        "        # Agora, itera sobre os itens sem SRC para tentar liveInfo\n",
        "        print(\"Nenhuma transmissão livre com SRC encontrada, tentando liveInfo para os demais...\")\n",
        "        for item in items:\n",
        "             user_id = str(item.get(\"id\")) # ** CAPTURA O ID **\n",
        "             username = item.get(\"username\", \"desconhecido\")\n",
        "             preview = item.get(\"preview\") or {}\n",
        "             src = preview.get(\"src\") # Re-verifica SRC\n",
        "\n",
        "             # Ignora se tem SRC (já processado acima) ou se já está em proc/blacklist\n",
        "             if src or user_id in ids_em_proc_ou_blacklist:\n",
        "                  continue\n",
        "\n",
        "             # Se não tem SRC e não está em proc/blacklist, tenta liveInfo\n",
        "             api_url_liveinfo = f\"https://api.xcam.gay/user/{username}/liveInfo\"\n",
        "             try:\n",
        "                 response_liveinfo = requests.get(api_url_liveinfo)\n",
        "                 response_liveinfo.raise_for_status()\n",
        "                 data_liveinfo = response_liveinfo.json()\n",
        "                 m3u8_url = data_liveinfo.get(\"cdnURL\") or data_liveinfo.get(\"edgeURL\")\n",
        "                 if m3u8_url:\n",
        "                      # Se encontrou URL via liveInfo, valida poster e retorna\n",
        "                      poster_path = generate_poster_with_ffmpeg(m3u8_url, username, temp_folder)\n",
        "\n",
        "                      if is_poster_valid(poster_path):\n",
        "                           if \"clear_failure\" in globals():\n",
        "                                clear_failure(user_id) # Limpa falhas pelo ID\n",
        "                           print(f\"🎯 Transmissão livre (pelo liveInfo) encontrada: '{username}' (ID: {user_id})\")\n",
        "                           return {\n",
        "                               \"id\": user_id, # Inclui o ID único no resultado\n",
        "                               \"username\": username,\n",
        "                               \"src\": m3u8_url,\n",
        "                               \"poster_path\": poster_path # Passa o caminho LOCAL do poster válido\n",
        "                           }\n",
        "                      else:\n",
        "                           # Se poster inválido, registra falha e continua buscando\n",
        "                           if \"register_failure\" in globals():\n",
        "                                register_failure(user_id, username, \"Poster inválido (busca próxima liveInfo).\")\n",
        "                           continue # Pula para o próximo item\n",
        "                 else:\n",
        "                      print(f\"⚠️ liveInfo de '{username}' (ID: {user_id}) não retornou cdnURL/edgeURL.\")\n",
        "                      # Registrar falha no liveInfo no log (AGORA USA ID)\n",
        "                      if \"register_failure\" in globals():\n",
        "                           register_failure(user_id, username, \"liveInfo sem cdnURL/edgeURL (busca próxima).\")\n",
        "\n",
        "\n",
        "             except Exception as ex:\n",
        "                 msg = f\"Erro ao buscar liveInfo para '{username}' (ID: {user_id}) na busca próxima: {ex}\"\n",
        "                 print(f\"❌ {msg}\")\n",
        "                 # Registrar erro de liveInfo no log (AGORA USA ID)\n",
        "                 if \"register_failure\" in globals():\n",
        "                      register_failure(user_id, username, msg)\n",
        "\n",
        "             time.sleep(0.2) # Pequeno delay\n",
        "\n",
        "\n",
        "        # Se nenhum stream foi encontrado/validado após varrer toda a lista da API (com SRC e liveInfo)\n",
        "        print(\"🚫 Nenhuma transmissão livre encontrada após varrer todas online.\")\n",
        "        return None # Retorna None se nenhum stream livre foi encontrado após todas as tentativas\n",
        "\n",
        "    except Exception as e:\n",
        "        msg = f\"❌ Erro ao buscar transmissões online (busca próxima): {e}\"\n",
        "        print(f\"❌ {msg}\")\n",
        "        # Registrar erro de busca no log (AGORA USA ID ou Global)\n",
        "        if \"append_log\" in globals():\n",
        "             append_log({\n",
        "                 \"sessao\": \"busca\",\n",
        "                 \"evento\": \"erro_api_proxima\",\n",
        "                 \"id\": \"global\", # Erro global de API\n",
        "                 \"username\": \"global\",\n",
        "                 \"status\": \"erro\",\n",
        "                 \"detalhes\": msg\n",
        "             })\n",
        "        return None # Retorna None em caso de erro na API\n",
        "\n",
        "# ================================================================\n",
        "# FIM DA CÉLULA 6 — BUSCA, BLACKLIST E CONTROLE DE FALHAS CENTRALIZADOS (AGORA COM ID)\n",
        "# ================================================================\n",
        "\n",
        "# Observações:\n",
        "# - Toda manipulação de blacklist, falha e processamento agora é feita via funções do log centralizado (Célula 1), USANDO O ID ÚNICO DA API.\n",
        "# - O username é mantido nos registros de log para referência humana, mas a lógica de controle se baseia no 'id'.\n",
        "# - Nenhum uso de arquivos dispersos. Consultas e remoções são sempre via query_logs, append_log, remove_logs.\n",
        "# - Para máxima rastreabilidade, todos os eventos relevantes estão registrados no log único."
      ],
      "metadata": {
        "id": "h1jr7D0pJ7jS"
      },
      "id": "h1jr7D0pJ7jS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Célula 7: Gravação da Stream, Poster Automático, Controle de Falhas, Log Centralizado Seguro e Blacklist Inteligente\n",
        "\n",
        "**Objetivo:**  \n",
        "Automatizar a gravação de transmissões ao vivo com ffmpeg, garantindo robustez, rastreabilidade e integração total com a lógica de blacklist temporária e controle de falhas **centralizados no log único** (`xcam_master.log`).  \n",
        "Esta célula assegura o gerenciamento seguro do log de transmissões em processamento, registro de sucesso/erro, integração direta com CI/CD, e a limpeza de arquivos temporários.\n",
        "\n",
        "## Estratégia e melhorias implementadas\n",
        "\n",
        "- **Gerenciamento seguro e centralizado de log:**  \n",
        "  O usuário é registrado no log centralizado (`sessao=\"processing\"`, `status=\"in_progress\"`) antes da gravação e removido ao final (sucesso ou erro), evitando duplicidade e permitindo paralelismo seguro. Todos os eventos (sucesso, erro, exceção, duração insuficiente, etc.) são registrados com rastreabilidade completa.\n",
        "- **Poster sempre válido:**  \n",
        "  O sistema tenta baixar o poster da API. Se o poster estiver ausente, inválido ou nulo, gera automaticamente uma imagem via ffmpeg, assegurando que toda transmissão tenha um poster associado e válido.\n",
        "- **Controle de tempo mínimo e validação robusta:**  \n",
        "  Se a gravação resultar em vídeo muito curto, tanto o arquivo de vídeo quanto o poster são descartados imediatamente, e uma falha é registrada para o usuário no log central. O contador de falhas é limpo automaticamente em caso de sucesso.\n",
        "- **Tratamento robusto de falhas e blacklist:**  \n",
        "  Qualquer falha (ffmpeg, exceptions, etc.) é registrada no log único, e o usuário é escalado para a blacklist temporária quando atinge o limite configurado (`BLACKLIST_MAX_FAILURES`), evitando tentativas infinitas e desperdício de recursos.\n",
        "- **Limpeza automatizada:**  \n",
        "  Após upload ou erro, todos os arquivos temporários (vídeo e poster) são removidos, otimizando o uso do disco e mantendo o ambiente do Colab limpo.\n",
        "- **Feedback e rastreabilidade detalhados:**  \n",
        "  Todas as etapas críticas são registradas no log único e exibidas no console, facilitando diagnóstico, manutenção e integração com pipelines CI/CD.\n",
        "- **Código modular e altamente documentado:**  \n",
        "  Todo o fluxo é comentado passo a passo, pronto para manutenção, revisão e entendimento por toda a equipe.\n",
        "\n",
        "---\n",
        "\n",
        "## Fluxo resumido da função principal\n",
        "\n",
        "1. **Registra o usuário** no log centralizado como processamento ativo (sessao=\"processing\", status=\"in_progress\").\n",
        "2. **Garante um poster válido** (download ou geração automática).\n",
        "3. **Executa o ffmpeg** para gravar a transmissão e monitora o progresso em tempo real.\n",
        "4. **Valida a gravação**:\n",
        "   - Se falhar, registra no log central e trata blacklist/falhas.\n",
        "   - Se for curta demais, descarta e registra falha no log.\n",
        "   - Se for válida, limpa contador de falhas no log e prossegue normalmente.\n",
        "5. **Após upload ou erro**, remove o usuário do log central e limpa arquivos temporários.\n",
        "\n",
        "---\n",
        "\n",
        "## Exemplo de uso\n",
        "\n",
        "```python\n",
        "resultado = gravar_stream(username=\"user123\", m3u8_url=\"https://cdn.xcam.gay/m3u8/...\", poster_url=\"https://api.xcam.gay/poster/...\")\n",
        "if resultado['upload_success']:\n",
        "    print(\"Gravação e upload realizados com sucesso!\")\n",
        "else:\n",
        "    print(\"Falha na gravação ou upload:\", resultado['abyss_response'])\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Segurança, rastreabilidade e integração\n",
        "\n",
        "- **Pronto para CI/CD e execução paralela:**  \n",
        "  O controle rigoroso de log centralizado e blacklist garante execução concorrente, segura e rastreável por todo o pipeline XCam.\n",
        "- **Integração total com as funções globais:**  \n",
        "  Utiliza funções de blacklist e falha da Célula 6, promovendo rastreabilidade e controle centralizado, sem dependência de arquivos dispersos.\n",
        "- **Diagnóstico facilitado:**  \n",
        "  Mensagens e logs detalhados em cada etapa do processo, todos acessíveis via consulta ao log único (`xcam_master.log`).\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "jGFyqOUoKEF7"
      },
      "id": "jGFyqOUoKEF7"
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================\n",
        "# Célula 7: Gravação Automática de Transmissão, Controle de Log Centralizado, Limpeza e Blacklist Inteligente (AGORA USANDO ID)\n",
        "# ================================================================\n",
        "# Objetivo:\n",
        "# - Gravar transmissões ao vivo utilizando ffmpeg, com controle rigoroso e centralizado de log de processamento, tratamento de falhas e integração com blacklist temporária (log único).\n",
        "# - Garantir que cada transmissão seja registrada no log central no início e removida ao final (sucesso ou erro), evitando duplicidade/processamento concorrente (sessao=\"processing\").\n",
        "# - Registrar falhas (ffmpeg, duração insuficiente, poster inválido), escalando usuários para a blacklist temporária via log central ao atingir o limite de tentativas, AGORA USANDO O ID.\n",
        "# - Assegurar limpeza robusta de arquivos temporários e rastreabilidade total via eventos no log único e mensagens detalhadas.\n",
        "# - Modular, preparado para integração com pipelines CI/CD, paralelismo e auditoria centralizada.\n",
        "# ================================================================\n",
        "\n",
        "def get_video_duration(filepath):\n",
        "    \"\"\"\n",
        "    Retorna a duração real do arquivo mp4, em segundos, utilizando ffprobe.\n",
        "    Retorna None em caso de erro ou se o arquivo não existir.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        if not os.path.exists(filepath):\n",
        "            print(f\"⚠️ Arquivo para ffprobe não encontrado: {filepath}\")\n",
        "            return None\n",
        "        cmd = [\n",
        "            \"ffprobe\", \"-v\", \"error\",\n",
        "            \"-show_entries\", \"format=duration\",\n",
        "            \"-of\", \"json\",\n",
        "            filepath\n",
        "        ]\n",
        "        result = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
        "        info = json.loads(result.stdout)\n",
        "        duration = float(info[\"format\"][\"duration\"])\n",
        "        return int(round(duration))\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ Não foi possível obter duração via ffprobe para {filepath}: {e}\")\n",
        "        return None\n",
        "\n",
        "# Adicionando user_id como parâmetro\n",
        "def gravar_stream(user_id, username, m3u8_url, poster_url=None, poster_frame_time=7):\n",
        "    \"\"\"\n",
        "    Grava a transmissão ao vivo do usuário (pelo ID) usando ffmpeg, com controle de erros, log centralizado e integração à blacklist.\n",
        "    - Registra no log centralizado (sessao=\"processing\") no início (status=\"in_progress\"), USANDO O ID.\n",
        "    - Remove do log ao finalizar, independentemente do resultado, USANDO O ID.\n",
        "    - Em caso de falha do ffmpeg ou gravação muito curta, registra falha do usuário no log (sessao=\"failure\"), USANDO O ID.\n",
        "    - Ao atingir N falhas consecutivas, usuário entra na blacklist (funções de log centralizado), USANDO O ID.\n",
        "    - Limpa arquivos temporários ao final.\n",
        "    - Garante poster válido: baixa da poster_url ou gera automaticamente com ffmpeg.\n",
        "    - poster_frame_time: segundo do vídeo onde a captura do poster será feita, se necessário.\n",
        "    \"\"\"\n",
        "    # --- Registro no log centralizado: PROCESSAMENTO INICIADO (USANDO ID) ---\n",
        "    # As funções mark_processing, unmark_processing, register_failure, clear_failure\n",
        "    # na Célula 6 já foram ajustadas para aceitar e usar user_id.\n",
        "    mark_processing(user_id, username) # Passa user_id e username\n",
        "\n",
        "    start_time_dt = datetime.now()\n",
        "    data_str = start_time_dt.strftime(\"%d-%m-%Y\")\n",
        "    horario_str = start_time_dt.strftime(\"%H-%M\")\n",
        "    temp_filename = f\"{username}_{start_time_dt.strftime('%Y%m%d_%H%M%S')}_temp.mp4\"\n",
        "    filepath = os.path.join(TEMP_OUTPUT_FOLDER, temp_filename)\n",
        "    append_log({\n",
        "        \"sessao\": \"processing\",\n",
        "        \"evento\": \"iniciar_gravacao\",\n",
        "        \"id\": user_id, # Usa o ID\n",
        "        \"username\": username,\n",
        "        \"status\": \"in_progress\",\n",
        "        \"detalhes\": f\"Gravação iniciada para '{username}' (ID: {user_id}) em {filepath}\" # Adiciona ID nos detalhes\n",
        "    })\n",
        "\n",
        "    print(f\"\\n🎬 Iniciando gravação de: '{username}' (ID: {user_id}) | URL: {m3u8_url}) em {filepath}\") # Adiciona ID no print\n",
        "\n",
        "    # --- Garante poster válido ---\n",
        "    # As funções de poster (download_and_save_poster, generate_poster_with_ffmpeg)\n",
        "    # não precisam do ID para funcionar, apenas o username para o nome do arquivo temporário.\n",
        "    poster_temp_path = None\n",
        "    if poster_url:\n",
        "        poster_temp_path = download_and_save_poster(poster_url, username, TEMP_OUTPUT_FOLDER)\n",
        "    # generate_poster_with_ffmpeg já foi ajustada na Célula 3 para usar a tupla de tries correta\n",
        "    if not is_poster_valid(poster_temp_path) and m3u8_url:\n",
        "        poster_temp_path = generate_poster_with_ffmpeg(m3u8_url, username, TEMP_OUTPUT_FOLDER, frame_time=poster_frame_time)\n",
        "\n",
        "\n",
        "    ffmpeg_cmd = [\n",
        "        \"ffmpeg\", \"-i\", m3u8_url,\n",
        "        \"-t\", str(RECORD_SECONDS),\n",
        "        \"-c\", \"copy\", \"-y\", filepath\n",
        "    ]\n",
        "\n",
        "    start_time_process = time.time()\n",
        "    process = None\n",
        "\n",
        "    try:\n",
        "        process = subprocess.Popen(\n",
        "            ffmpeg_cmd,\n",
        "            stdout=subprocess.PIPE,\n",
        "            stderr=subprocess.STDOUT,\n",
        "            text=True,\n",
        "            bufsize=1,\n",
        "            universal_newlines=True\n",
        "        )\n",
        "\n",
        "        # --- Monitoramento de progresso do ffmpeg (logs em tempo real) ---\n",
        "        # log_progress usa apenas username\n",
        "        elapsed_seconds = 0\n",
        "        last_log_minute = -1\n",
        "        while True:\n",
        "            line = process.stdout.readline()\n",
        "            if not line and process.poll() is not None:\n",
        "                break\n",
        "            if \"time=\" in line:\n",
        "                try:\n",
        "                    match = re.search(r\"time=(\\d+):(\\d+):(\\d+)\", line)\n",
        "                    if match:\n",
        "                        h, m, s = map(int, match.groups())\n",
        "                        elapsed_seconds = h * 3600 + m * 60 + s\n",
        "                        if elapsed_seconds // 60 != last_log_minute:\n",
        "                            log_progress(username, elapsed_seconds, RECORD_SECONDS)\n",
        "                            last_log_minute = elapsed_seconds // 60\n",
        "                except Exception:\n",
        "                    pass\n",
        "\n",
        "        process.wait()\n",
        "        end_time_process = time.time()\n",
        "        elapsed_seconds_proc = round(end_time_process - start_time_process)\n",
        "        log_progress(username, elapsed_seconds_proc, RECORD_SECONDS)\n",
        "\n",
        "        # --- Se FFmpeg falhou, registra no log central e retorna erro (USANDO ID) ---\n",
        "        if process.returncode != 0:\n",
        "            msg = f\"FFmpeg falhou para '{username}' (ID: {user_id}). Código de saída: {process.returncode}\" # Adiciona ID na mensagem\n",
        "            print(f\"❌ {msg}\")\n",
        "            append_log({\n",
        "                \"sessao\": \"processing\",\n",
        "                \"evento\": \"erro_ffmpeg\",\n",
        "                \"id\": user_id, # Usa o ID\n",
        "                \"username\": username,\n",
        "                \"status\": \"erro\",\n",
        "                \"detalhes\": msg\n",
        "            })\n",
        "            register_failure(user_id, username, \"Erro FFmpeg\") # Passa user_id e username\n",
        "            return {\n",
        "                'user_id': user_id, # Inclui user_id no resultado\n",
        "                'username': username,\n",
        "                'filename': temp_filename,\n",
        "                'filepath': filepath,\n",
        "                'upload_success': False,\n",
        "                'abyss_response': msg\n",
        "            }\n",
        "\n",
        "        # --- Validação pelo tempo real do arquivo gravado (robusta) ---\n",
        "        elapsed_seconds_real = get_video_duration(filepath)\n",
        "        if elapsed_seconds_real is not None:\n",
        "            print(f\"✅ Duração real do arquivo gravado: {elapsed_seconds_real}s (ffprobe)\")\n",
        "        else:\n",
        "            print(f\"⚠️ Não foi possível aferir duração real, usando a do processo: {elapsed_seconds_proc}s\")\n",
        "            elapsed_seconds_real = elapsed_seconds_proc\n",
        "\n",
        "        if elapsed_seconds_real < RECORD_SECONDS_MIN:\n",
        "            msg = f\"Gravação muito curta para '{username}' (ID: {user_id}). Duração gravada ({elapsed_seconds_real}s) menor que o mínimo ({RECORD_SECONDS_MIN}s). Arquivo descartado.\" # Adiciona ID\n",
        "            print(f\"⏩ {msg}\")\n",
        "            append_log({\n",
        "                \"sessao\": \"processing\",\n",
        "                \"evento\": \"erro_duracao\",\n",
        "                \"id\": user_id, # Usa o ID\n",
        "                \"username\": username,\n",
        "                \"status\": \"erro\",\n",
        "                \"detalhes\": msg\n",
        "            })\n",
        "            register_failure(user_id, username, \"Gravação muito curta\") # Passa user_id e username\n",
        "            if os.path.exists(filepath): os.remove(filepath)\n",
        "            if poster_temp_path and os.path.exists(poster_temp_path): os.remove(poster_temp_path)\n",
        "            return {\n",
        "                'user_id': user_id, # Inclui user_id no resultado\n",
        "                'username': username,\n",
        "                'filename': temp_filename,\n",
        "                'filepath': filepath,\n",
        "                'upload_success': False,\n",
        "                'abyss_response': \"Gravação muito curta (descartada)\"\n",
        "            }\n",
        "\n",
        "        # --- Sucesso: limpa falhas acumuladas do usuário no log central (USANDO ID) ---\n",
        "        clear_failure(user_id) # Passa user_id\n",
        "        tempo_formatado = format_seconds(elapsed_seconds_real)\n",
        "        final_filename = f\"{username}_{data_str}_{horario_str}_{tempo_formatado}.mp4\"\n",
        "        final_filepath = os.path.join(TEMP_OUTPUT_FOLDER, final_filename)\n",
        "\n",
        "        try:\n",
        "            os.rename(filepath, final_filepath)\n",
        "            print(f\"✅ Arquivo renomeado para: {final_filename}\")\n",
        "            filepath_for_upload = final_filepath\n",
        "            filename_for_upload = final_filename\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Erro ao renomear arquivo {temp_filename} para {final_filename}: {e}\")\n",
        "            filepath_for_upload = filepath\n",
        "            filename_for_upload = temp_filename\n",
        "\n",
        "        # --- Realiza upload e atualização do banco de dados (json) ---\n",
        "        # upload_to_abyss_and_update_json (Célula 8) precisará receber o user_id\n",
        "        success, abyss_resp, slug = upload_to_abyss_and_update_json(\n",
        "            filepath_for_upload, user_id, username, elapsed_seconds_real, # Passa user_id e username\n",
        "            poster_temp_path=poster_temp_path\n",
        "        )\n",
        "\n",
        "        # --- Loga sucesso de gravação no log central (USANDO ID) ---\n",
        "        append_log({\n",
        "            \"sessao\": \"processing\",\n",
        "            \"evento\": \"sucesso_gravacao\",\n",
        "            \"id\": user_id, # Usa o ID\n",
        "            \"username\": username,\n",
        "            \"status\": \"ok\",\n",
        "            \"detalhes\": f\"Arquivo {filename_for_upload} gravado e enviado com sucesso para '{username}' (ID: {user_id}). Duração: {elapsed_seconds_real}s\" # Adiciona ID\n",
        "        })\n",
        "\n",
        "        return {\n",
        "            'user_id': user_id, # Inclui user_id no resultado\n",
        "            'username': username,\n",
        "            'filename': filename_for_upload,\n",
        "            'filepath': filepath_for_upload,\n",
        "            'upload_success': success,\n",
        "            'abyss_response': abyss_resp,\n",
        "            'slug': slug\n",
        "        }\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        msg = \"Comando 'ffmpeg' não encontrado. Certifique-se de que foi instalado corretamente.\"\n",
        "        print(f\"❌ {msg}\")\n",
        "        # Registrar falha de ffmpeg não encontrado (USANDO ID)\n",
        "        if 'register_failure' in globals(): # Verifica se a função existe\n",
        "             register_failure(user_id, username, msg) # Passa user_id e username\n",
        "        append_log({\n",
        "            \"sessao\": \"processing\",\n",
        "            \"evento\": \"erro_ffmpeg_nao_encontrado\",\n",
        "            \"id\": user_id, # Usa o ID\n",
        "            \"username\": username,\n",
        "            \"status\": \"erro\",\n",
        "            \"detalhes\": msg\n",
        "        })\n",
        "        return {\n",
        "            'user_id': user_id, # Inclui user_id no resultado\n",
        "            'username': username,\n",
        "            'filename': None,\n",
        "            'filepath': None,\n",
        "            'upload_success': False,\n",
        "            'abyss_response': msg\n",
        "        }\n",
        "    except Exception as e:\n",
        "        msg = f\"Erro inesperado durante a execução do FFmpeg para '{username}' (ID: {user_id}): {e}\" # Adiciona ID\n",
        "        print(f\"❌ {msg}\")\n",
        "        # Registrar falha de execução de ffmpeg (USANDO ID)\n",
        "        if 'register_failure' in globals(): # Verifica se a função existe\n",
        "             register_failure(user_id, username, msg) # Passa user_id e username\n",
        "        append_log({\n",
        "            \"sessao\": \"processing\",\n",
        "            \"evento\": \"erro_execucao_ffmpeg\",\n",
        "            \"id\": user_id, # Usa o ID\n",
        "            \"username\": username,\n",
        "            \"status\": \"erro\",\n",
        "            \"detalhes\": msg\n",
        "        })\n",
        "        return {\n",
        "            'user_id': user_id, # Inclui user_id no resultado\n",
        "            'username': username,\n",
        "            'filename': None,\n",
        "            'filepath': None,\n",
        "            'upload_success': False,\n",
        "            'abyss_response': msg\n",
        "        }\n",
        "    finally:\n",
        "        # --- Remove marcação de processamento ativo no log central (USANDO ID) ---\n",
        "        unmark_processing(user_id) # Passa user_id\n",
        "\n",
        "        # --- Limpeza do arquivo de vídeo pós-upload ---\n",
        "        if 'filepath_for_upload' in locals() and os.path.exists(filepath_for_upload):\n",
        "            try:\n",
        "                os.remove(filepath_for_upload)\n",
        "                print(f\"🗑️ Arquivo de vídeo temporário local removido do Colab: {filepath_for_upload}\")\n",
        "                # Log de limpeza\n",
        "                if 'append_log' in globals():\n",
        "                     append_log({\n",
        "                         \"sessao\": \"cleanup\",\n",
        "                         \"evento\": \"remover_video_temp\",\n",
        "                         \"id\": user_id, # Usa o ID\n",
        "                         \"username\": username,\n",
        "                         \"status\": \"ok\",\n",
        "                         \"detalhes\": f\"Arquivo de vídeo temporário local removido: {filepath_for_upload}\"\n",
        "                     })\n",
        "            except Exception as e:\n",
        "                print(f\"⚠️ Não foi possível remover o arquivo de vídeo temporário local: {e}\")\n",
        "                # Log de erro de limpeza\n",
        "                if 'append_log' in globals():\n",
        "                     append_log({\n",
        "                         \"sessao\": \"cleanup\",\n",
        "                         \"evento\": \"erro_remover_video_temp\",\n",
        "                         \"id\": user_id, # Usa o ID\n",
        "                         \"username\": username,\n",
        "                         \"status\": \"erro\",\n",
        "                         \"detalhes\": f\"Erro ao remover arquivo de vídeo temporário local: {e}\"\n",
        "                     })\n",
        "\n",
        "\n",
        "        # --- Limpeza do poster temporário ---\n",
        "        # poster_temp_path é o caminho ANTES da renomeação com slug\n",
        "        if poster_temp_path and os.path.exists(poster_temp_path):\n",
        "            try:\n",
        "                os.remove(poster_temp_path)\n",
        "                # print(f\"🗑️ Poster temporário original removido: {poster_temp_path}\") # Já logado na Célula 8 se movido\n",
        "            except Exception as e:\n",
        "                # print(f\"⚠️ Não foi possível remover o poster temporário original: {e}\") # Já logado na Célula 8 se movido\n",
        "                pass # A Célula 8 lida com a limpeza do poster renomeado/movido\n",
        "\n",
        "\n",
        "# ================================================================\n",
        "# Fim da Célula 7 — Gravação, Log Centralizado e Blacklist Inteligente (AGORA USANDO ID)\n",
        "# ================================================================\n",
        "\n",
        "# Observações e recomendações:\n",
        "# - Toda manipulação de status, falha, blacklist e processamento é feita via funções do log centralizado (Célula 1 e 6), AGORA USANDO O ID.\n",
        "# - Mensagens claras e detalhadas e logging estruturado garantem rastreabilidade, CI/CD e manutenção.\n",
        "# - Pronto para execução concorrente, pipelines e auditoria centralizada no XCam."
      ],
      "metadata": {
        "id": "eJ_jrfNgKZNr"
      },
      "id": "eJ_jrfNgKZNr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Célula 8: Upload para Abyss.to, Atualização do rec.json, Commit Poster, Sincronização com Google Drive — Log Centralizado\n",
        "\n",
        "**Objetivo:**  \n",
        "Realizar upload do vídeo gravado para Abyss.to, registrar e atualizar todos os metadados relevantes no arquivo `rec.json` do usuário, garantir a movimentação/renomeação adequada do poster e executar o commit/push automatizado de arquivos alterados, sincronizando também com o Google Drive e **registrando todas as ações relevantes no log centralizado (`xcam_master.log`)**.  \n",
        "O processo é otimizado para processamento em lote: os arquivos modificados só são enviados quando o número atingir o limiar (`COMMIT_PUSH_THRESHOLD`), promovendo eficiência, rastreabilidade e integridade do repositório, mesmo em execução paralela.\n",
        "\n",
        "---\n",
        "\n",
        "## Estratégia e melhorias implementadas\n",
        "\n",
        "- **Commit/push em lote otimizado e rastreável:**  \n",
        "  Arquivos alterados são acumulados em um buffer protegido por lock. O commit e push são executados automaticamente quando a quantidade de arquivos atinge o threshold configurado, reduzindo conflitos e otimizando o workflow CI/CD. Todas as ações de commit são registradas no log central para auditoria.\n",
        "- **Sincronização automática com o Google Drive:**  \n",
        "  Sempre que `rec.json` ou poster são atualizados, uma cópia é feita para o diretório correspondente do usuário no Google Drive (se disponível), garantindo redundância, persistência e fácil acesso externo aos metadados e imagens. Falhas na sincronização também são logadas.\n",
        "- **Atomicidade, concorrência e log centralizado:**  \n",
        "  O acesso ao buffer de commit é protegido por lock (`threading.Lock`), assegurando integridade mesmo em processamento paralelo ou múltiplos workers. Cada etapa crítica (upload, poster, commit, rec.json) é registrada via `append_log` para rastreabilidade total.\n",
        "- **Poster sempre correto e rastreável:**  \n",
        "  O poster utilizado é sempre movido/renomeado para o local definitivo e associado ao vídeo pelo nome (`slug`). O caminho é sincronizado tanto no repositório quanto no Drive, e o evento é registrado no log.\n",
        "- **Atualização robusta do rec.json:**  \n",
        "  O histórico do usuário é preenchido com todos os campos, incluindo poster, urlIframe, data, horário e tempo formatado. O padrão da estrutura JSON é rigorosamente seguido, facilitando a integração, análise e exportação dos dados. Atualizações e falhas são sempre logadas.\n",
        "- **Limpeza automática de arquivos temporários:**  \n",
        "  Após mover, copiar e commitar os arquivos, os temporários são removidos, mantendo o ambiente Colab limpo e eficiente, com logs de sucesso ou falha de limpeza.\n",
        "\n",
        "---\n",
        "\n",
        "## Como funciona o fluxo principal\n",
        "\n",
        "1. **Faz upload do vídeo para Abyss.to** e recebe a confirmação (slug, url, urlIframe). Evento de sucesso ou falha registrado no log.\n",
        "2. **Move/renomeia o poster** para o local definitivo no repositório, associando ao vídeo pelo slug. Evento registrado no log.\n",
        "3. **Atualiza ou cria `rec.json`** do usuário, preenchendo todos os metadados da gravação. Evento registrado no log.\n",
        "4. **Adiciona arquivos alterados ao buffer de commit** (com lock para evitar concorrência) e registra ação no log.\n",
        "5. **Sincroniza** `rec.json` e poster no Google Drive, mantendo redundância e facilidade de acesso. Falhas de sync são logadas.\n",
        "6. **Executa commit/push automático em lote** ao atingir o limiar definido; ao final do processamento faz o commit/push dos arquivos restantes, sempre registrando eventos no log central.\n",
        "7. **Limpa arquivos temporários** garantindo eficiência, organização do ambiente e registro de sucesso/falha no log.\n",
        "\n",
        "---\n",
        "\n",
        "## Exemplo de uso recomendado\n",
        "\n",
        "```python\n",
        "# Após concluir o upload e gerar poster:\n",
        "upload_success, abyss_response, slug = upload_to_abyss_and_update_json(\n",
        "    filepath=arquivo_video,\n",
        "    username=\"usuario\",\n",
        "    duration_seconds=duracao,\n",
        "    poster_temp_path=caminho_poster_temp\n",
        ")\n",
        "\n",
        "# Ao final do processamento, para garantir commit dos arquivos restantes:\n",
        "commit_push_restantes()\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Segurança, rastreabilidade e integração\n",
        "\n",
        "- **Processo compatível com execução concorrente** e pipelines CI/CD.\n",
        "- **Commit/push protegido contra condições de corrida**, garantindo atomicidade dos dados no repositório.\n",
        "- **Sincronização Drive robusta**, ideal para ambientes colaborativos ou para garantir backup.\n",
        "- **Toda ação relevante registrada no log centralizado**: upload, poster, commit, rec.json, limpeza e falhas.\n",
        "- **Mensagens e logs claros** facilitam manutenção, auditoria e diagnóstico rápido em todo o pipeline XCam.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "YjGKDlbIKaLs"
      },
      "id": "YjGKDlbIKaLs"
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================\n",
        "# Célula 8: Upload para Abyss.to, Atualização do rec.json e Poster no Google Drive\n",
        "# ================================================================\n",
        "# Objetivo:\n",
        "# - Fazer upload do vídeo gravado para Abyss.to e registrar corretamente os metadados.\n",
        "# - Salvar gravação e poster temporariamente no Colab.\n",
        "# - Renomear poster temporário com slug (no Colab temp).\n",
        "# - LER/ESCREVER rec.json DIRETAMENTE no Google Drive.\n",
        "# - MOVER poster renomeado do Colab temp para o Google Drive.\n",
        "# - Limpar arquivos temporários locais após uso.\n",
        "# - Modular, preparado para CI/CD, concorrência e integração total ao pipeline XCam.\n",
        "# ================================================================\n",
        "\n",
        "# Caminho base no Google Drive para arquivos permanentes (rec.json, posters)\n",
        "DRIVE_USER_BASE = \"/content/drive/MyDrive/XCam.Drive/user\"\n",
        "\n",
        "def upload_to_abyss_and_update_json(\n",
        "    filepath, username, duration_seconds, poster_temp_path=None\n",
        "):\n",
        "    \"\"\"\n",
        "    Realiza upload do vídeo, atualiza rec.json do usuário (no Drive),\n",
        "    renomeia poster com slug (no Colab temp) e MOVE para o Google Drive.\n",
        "    - Salva gravação e poster temporariamente no Colab.\n",
        "    - LÊ/ESCREVE rec.json DIRETAMENTE no Drive.\n",
        "    - Renomeia poster temporário no Colab temp com o slug retornado.\n",
        "    - MOVE poster renomeado do Colab temp para o Drive.\n",
        "    - Limpa arquivos temporários locais após uso.\n",
        "    - Toda ação relevante é registrada no log centralizado via append_log().\n",
        "    \"\"\"\n",
        "    file_name = os.path.basename(filepath) # Nome do arquivo de vídeo renomeado (username_data_horario_tempo.mp4)\n",
        "    file_type = 'video/mp4'\n",
        "    print(f\"⬆️ Upload de: {file_name} para Abyss.to...\")\n",
        "\n",
        "    upload_success = False\n",
        "    abyss_response = \"Upload falhou - Sem resposta\"\n",
        "    uploaded_url = None\n",
        "    video_id = None\n",
        "    slug = None\n",
        "\n",
        "    # ---- Upload do vídeo para Abyss.to ----\n",
        "    try:\n",
        "        with open(filepath, 'rb') as f:\n",
        "            files = { 'file': (file_name, f, file_type) }\n",
        "            response = requests.post(ABYSS_UPLOAD_URL, files=files)\n",
        "            resp_json = response.json()\n",
        "            abyss_response = resp_json\n",
        "            if resp_json.get('status'):\n",
        "                upload_success = True\n",
        "                uploaded_url = resp_json.get('url') or resp_json.get('urlIframe')\n",
        "                video_id = resp_json.get('slug') or resp_json.get('video')\n",
        "                slug = video_id\n",
        "                print(f\"📤 Upload bem-sucedido. URL: {uploaded_url} | SLUG: {slug}\")\n",
        "                append_log({\n",
        "                    \"sessao\": \"upload\",\n",
        "                    \"evento\": \"upload_sucesso\",\n",
        "                    \"id\": username,\n",
        "                    \"username\": username,\n",
        "                    \"status\": \"ok\",\n",
        "                    \"detalhes\": f\"Arquivo {file_name} enviado para Abyss.to. URL: {uploaded_url}, SLUG: {slug}\"\n",
        "                })\n",
        "            else:\n",
        "                print(f\"❌ Falha no upload. Mensagem: {resp_json.get('message','')}\")\n",
        "                append_log({\n",
        "                    \"sessao\": \"upload\",\n",
        "                    \"evento\": \"upload_falhou\",\n",
        "                    \"id\": username,\n",
        "                    \"username\": username,\n",
        "                    \"status\": \"erro\",\n",
        "                    \"detalhes\": f\"Falha no upload. Mensagem: {resp_json.get('message','')}\"\n",
        "                })\n",
        "    except Exception as e:\n",
        "        abyss_response = f\"Erro no upload: {e}\"\n",
        "        print(f\"❌ Erro no upload: {e}\")\n",
        "        append_log({\n",
        "            \"sessao\": \"upload\",\n",
        "            \"evento\": \"upload_falhou\",\n",
        "            \"id\": username,\n",
        "            \"username\": username,\n",
        "            \"status\": \"erro\",\n",
        "            \"detalhes\": f\"Exceção no upload: {e}\"\n",
        "        })\n",
        "\n",
        "    poster_temp_renamed_path = None\n",
        "    drive_json_filepath = os.path.join(DRIVE_USER_BASE, username, \"rec.json\")\n",
        "    drive_user_dir = os.path.join(DRIVE_USER_BASE, username) # Pasta do usuário no Drive\n",
        "\n",
        "    if upload_success and slug:\n",
        "        # ---- Renomeia o poster temporário com o slug retornado (no diretório temporário do Colab) ----\n",
        "        # O poster_temp_path já está em TEMP_OUTPUT_FOLDER (gerado/baixado pela Célula 7)\n",
        "        if poster_temp_path and os.path.exists(poster_temp_path):\n",
        "            try:\n",
        "                # O novo nome será {slug}.jpg\n",
        "                poster_final_name = f\"{slug}.jpg\"\n",
        "                # A renomeação ocorre dentro do diretório TEMPORÁRIO do Colab\n",
        "                poster_temp_renamed_path = os.path.join(TEMP_OUTPUT_FOLDER, poster_final_name)\n",
        "                # Move (renomeia) o poster DENTRO do diretório temporário\n",
        "                shutil.move(poster_temp_path, poster_temp_renamed_path)\n",
        "                print(f\"🖼️ Poster temporário renomeado para {poster_final_name} em {TEMP_OUTPUT_FOLDER}\")\n",
        "                append_log({\n",
        "                    \"sessao\": \"poster\",\n",
        "                    \"evento\": \"poster_renomeado_temp\",\n",
        "                    \"id\": username,\n",
        "                    \"username\": username,\n",
        "                    \"status\": \"ok\",\n",
        "                    \"detalhes\": f\"Poster temporário renomeado para {poster_final_name} no Colab temp.\"\n",
        "                })\n",
        "            except Exception as e:\n",
        "                print(f\"❌ Erro ao renomear poster temporário no Colab: {e}\")\n",
        "                # Tenta limpar o poster temporário original se o renomeio falhar\n",
        "                if os.path.exists(poster_temp_path):\n",
        "                    try:\n",
        "                        os.remove(poster_temp_path)\n",
        "                    except Exception as clean_e:\n",
        "                        print(f\"⚠️ Falha ao limpar poster temporário original após erro: {clean_e}\")\n",
        "                poster_temp_renamed_path = None # Garante que não tentaremos mover um arquivo que não existe\n",
        "                append_log({\n",
        "                    \"sessao\": \"poster\",\n",
        "                    \"evento\": \"erro_renomear_poster_temp\",\n",
        "                    \"id\": username,\n",
        "                    \"username\": username,\n",
        "                    \"status\": \"erro\",\n",
        "                    \"detalhes\": f\"Erro ao renomear poster temporário no Colab: {e}\"\n",
        "                })\n",
        "        else:\n",
        "             print(f\"⚠️ Poster temporário não encontrado ou inválido para renomear com slug.\")\n",
        "             append_log({\n",
        "                \"sessao\": \"poster\",\n",
        "                \"evento\": \"poster_temp_nao_encontrado\",\n",
        "                \"id\": username,\n",
        "                \"username\": username,\n",
        "                \"status\": \"aviso\",\n",
        "                \"detalhes\": \"Poster temporário não encontrado ou inválido para renomear com slug.\"\n",
        "            })\n",
        "\n",
        "\n",
        "        # ---- Atualiza/Cria rec.json do usuário (DIRETAMENTE no Google Drive) ----\n",
        "        try:\n",
        "            # Caminho no Drive onde o rec.json deve estar/ser salvo\n",
        "            os.makedirs(drive_user_dir, exist_ok=True) # Garante que a pasta do usuário no Drive exista\n",
        "\n",
        "            file_base = file_name.replace('.mp4', '')\n",
        "            parts = file_base.split('_')\n",
        "            if len(parts) >= 4:\n",
        "                json_data = parts[-3]\n",
        "                json_horario = parts[-2]\n",
        "                json_tempo = parts[-1]\n",
        "            else:\n",
        "                now = datetime.now()\n",
        "                json_data = now.strftime(\"%d-%m-%Y\")\n",
        "                json_horario = now.strftime(\"%H-%M\")\n",
        "                json_tempo = format_seconds(duration_seconds)\n",
        "\n",
        "            # A URL do poster no rec.json aponta para onde ele estará PUBLICAMENTE disponível\n",
        "            # (presumindo que o conteúdo do Drive será servido ou sincronizado externamente)\n",
        "            poster_url_final = f\"https://db.xcam.gay/user/{username}/{slug}.jpg\" if slug else \"\"\n",
        "            url_iframe_final = f\"https://short.icu/{slug}?thumbnail={poster_url_final}\" if slug else \"\"\n",
        "\n",
        "            new_video_entry = {\n",
        "                \"video\": slug if slug else \"ID_não_retornado\",\n",
        "                \"title\": file_base,\n",
        "                \"file\": file_name, # O nome do arquivo de vídeo original é mantido como referência\n",
        "                \"url\": uploaded_url if uploaded_url else \"URL_não_retornada\",\n",
        "                \"poster\": poster_url_final, # Esta URL deve ser acessível publicamente\n",
        "                \"urlIframe\": url_iframe_final, # Esta URL deve ser acessível publicamente\n",
        "                \"data\": json_data,\n",
        "                \"horario\": json_horario,\n",
        "                \"tempo\": json_tempo\n",
        "            }\n",
        "\n",
        "            def zerar_base(username):\n",
        "                return {\n",
        "                    \"username\": username,\n",
        "                    \"records\": 0,\n",
        "                    \"videos\": []\n",
        "                }\n",
        "\n",
        "            # Carrega ou inicializa rec.json (DIRETAMENTE do Drive)\n",
        "            rec_data = zerar_base(username) # Inicializa com base zero por segurança\n",
        "            if os.path.exists(drive_json_filepath):\n",
        "                 try:\n",
        "                     with open(drive_json_filepath, 'r', encoding='utf-8') as f:\n",
        "                         loaded = json.load(f)\n",
        "                     # Valida se a estrutura carregada é razoável, senão cria uma nova\n",
        "                     valid = (\n",
        "                         isinstance(loaded, dict)\n",
        "                         and \"username\" in loaded\n",
        "                         and \"records\" in loaded\n",
        "                         and \"videos\" in loaded\n",
        "                         and isinstance(loaded[\"videos\"], list)\n",
        "                     )\n",
        "                     rec_data = loaded if valid else zerar_base(username)\n",
        "                     print(f\"📝 Carregado rec.json existente do Drive para {username}\")\n",
        "                 except Exception as read_drive_e:\n",
        "                      print(f\"⚠️ Erro ao ler rec.json existente no Drive ({drive_json_filepath}), criando novo: {read_drive_e}\")\n",
        "                      # Se der erro na leitura, rec_data já está zerada\n",
        "\n",
        "            # Adiciona novo vídeo ao histórico (no objeto carregado/novo)\n",
        "            rec_data[\"records\"] += 1\n",
        "            rec_data[\"videos\"].append(new_video_entry)\n",
        "\n",
        "            # Salva rec.json (DIRETAMENTE no Drive)\n",
        "            with open(drive_json_filepath, 'w', encoding='utf-8') as f:\n",
        "                json.dump(rec_data, f, indent=2, ensure_ascii=False)\n",
        "            print(f\"✅ rec.json para {username} atualizado DIRETAMENTE no Drive: {drive_json_filepath}\")\n",
        "\n",
        "            append_log({\n",
        "                \"sessao\": \"recjson\",\n",
        "                \"evento\": \"recjson_atualizado_drive\",\n",
        "                \"id\": username,\n",
        "                \"username\": username,\n",
        "                \"status\": \"ok\",\n",
        "                \"detalhes\": f\"rec.json atualizado diretamente no Drive em {drive_json_filepath}\"\n",
        "            })\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Erro ao atualizar rec.json no Drive: {e}\")\n",
        "            abyss_response = f\"Upload sucesso, erro no JSON do Drive: {e}\"\n",
        "            # json_temp_path = None # Não existe mais json_temp_path neste fluxo\n",
        "            append_log({\n",
        "                \"sessao\": \"recjson\",\n",
        "                \"evento\": \"erro_atualizar_recjson_drive\",\n",
        "                \"id\": username,\n",
        "                \"username\": username,\n",
        "                \"status\": \"erro\",\n",
        "                \"detalhes\": f\"Erro ao atualizar rec.json no Drive: {e}\"\n",
        "            })\n",
        "\n",
        "\n",
        "        # ---- MOVER poster renomeado (do Colab temp) para o Google Drive ----\n",
        "        if poster_temp_renamed_path and os.path.exists(poster_temp_renamed_path):\n",
        "            # O destino é a pasta do usuário no Drive\n",
        "            drive_poster_filepath = os.path.join(drive_user_dir, os.path.basename(poster_temp_renamed_path))\n",
        "            try:\n",
        "                shutil.move(poster_temp_renamed_path, drive_poster_filepath)\n",
        "                print(f\"🗂️ Poster movido para o Drive: {drive_poster_filepath}\")\n",
        "                append_log({\n",
        "                    \"sessao\": \"poster\",\n",
        "                    \"evento\": \"poster_movido_drive\",\n",
        "                    \"id\": username,\n",
        "                    \"username\": username,\n",
        "                    \"status\": \"ok\",\n",
        "                    \"detalhes\": f\"Poster movido para o Drive em {drive_poster_filepath}\"\n",
        "                })\n",
        "            except Exception as e:\n",
        "                print(f\"❌ Falha ao MOVER poster para o Drive: {e}\")\n",
        "                append_log({\n",
        "                    \"sessao\": \"poster\",\n",
        "                    \"evento\": \"erro_mover_poster_drive\",\n",
        "                    \"id\": username,\n",
        "                    \"username\": username,\n",
        "                    \"status\": \"erro\",\n",
        "                    \"detalhes\": f\"Erro ao mover poster para o Drive: {e}\"\n",
        "                })\n",
        "        else:\n",
        "             print(f\"⚠️ Poster temporário renomeado não encontrado para mover para o Drive.\")\n",
        "             append_log({\n",
        "                \"sessao\": \"poster\",\n",
        "                \"evento\": \"poster_temp_renomeado_nao_encontrado\",\n",
        "                \"id\": username,\n",
        "                \"username\": username,\n",
        "                \"status\": \"aviso\",\n",
        "                \"detalhes\": \"Poster temporário renomeado não encontrado para mover para o Drive.\"\n",
        "            })\n",
        "\n",
        "\n",
        "    # ---- Limpeza do arquivo de vídeo temporário local ----\n",
        "    # Esta limpeza já estava presente no bloco finally da gravar_stream (Célula 7),\n",
        "    # mas vamos garantir aqui também por segurança, caso a chamada venha de outro lugar.\n",
        "    # O arquivo de vídeo renomeado está em TEMP_OUTPUT_FOLDER\n",
        "    if os.path.exists(filepath): # filepath é o caminho do vídeo renomeado em TEMP_OUTPUT_FOLDER\n",
        "        try:\n",
        "            os.remove(filepath)\n",
        "            print(f\"🗑️ Arquivo de vídeo temporário local removido: {filepath}\")\n",
        "            append_log({\n",
        "                \"sessao\": \"cleanup\",\n",
        "                \"evento\": \"remover_video_temp\",\n",
        "                \"id\": username,\n",
        "                \"username\": username,\n",
        "                \"status\": \"ok\",\n",
        "                \"detalhes\": f\"Arquivo de vídeo temporário local removido: {filepath}\"\n",
        "            })\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Não foi possível remover o arquivo de vídeo temporário local: {e}\")\n",
        "            append_log({\n",
        "                \"sessao\": \"cleanup\",\n",
        "                \"evento\": \"erro_remover_video_temp\",\n",
        "                \"id\": username,\n",
        "                \"username\": username,\n",
        "                \"status\": \"erro\",\n",
        "                \"detalhes\": f\"Erro ao remover arquivo de vídeo temporário local: {e}\"\n",
        "            })\n",
        "\n",
        "    # ---- Limpeza do diretório temporário do usuário, se estiver vazio ----\n",
        "    # O diretório temporário do usuário pode não ter sido criado se o upload falhou antes.\n",
        "    # TEMP_OUTPUT_FOLDER é o diretório geral. Não vamos remover subdiretórios específicos aqui.\n",
        "    # A limpeza do diretório temp do usuário pode ser feita de forma mais robusta em outro local ou manualmente.\n",
        "    # Manteremos a limpeza apenas dos arquivos específicos manipulados.\n",
        "\n",
        "    return upload_success, abyss_response, slug\n",
        "\n",
        "# A função de commit final pendente não é mais necessária, pois o commit é gerenciado externamente.\n",
        "# def commit_push_restantes():\n",
        "#     \"\"\"\n",
        "#     Esta função não é mais necessária pois o commit/push é gerenciado externamente.\n",
        "#     \"\"\"\n",
        "#     pass # Lógica de commit/push removida\n",
        "\n",
        "# ================================================================\n",
        "# FIM DA Célula 8 — Upload, Metadados e Posters no Google Drive (com log centralizado)\n",
        "# ================================================================\n",
        "\n",
        "# Observações:\n",
        "# - A gravação e o poster inicial ficam no Colab temp.\n",
        "# - O rec.json é lido e escrito DIRETAMENTE no Drive.\n",
        "# - O poster renomeado é MOVIDO do Colab temp para o Drive.\n",
        "# - Certifique-se de que o Google Drive esteja montado antes de executar esta célula.\n",
        "# - A URL do poster no rec.json (db.xcam.gay) presume que o conteúdo do Drive será servido publicamente de alguma forma.\n",
        "# - O commit/push agora é gerenciado por um script externo que deve ler os arquivos do Drive.\n",
        "# - Toda ação relevante registrada no log centralizado para total rastreabilidade/auditoria."
      ],
      "metadata": {
        "id": "vMTiCrJ5Kp81"
      },
      "id": "vMTiCrJ5Kp81",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Célula 9: Processamento Automático, Paralelismo e Supervisor Dinâmico com Blacklist\n",
        "\n",
        "**Objetivo:**  \n",
        "Controlar e orquestrar todo o pipeline do notebook, garantindo processamento contínuo, paralelo, eficiente e seguro de transmissões ao vivo. O supervisor dinâmico mantém o lote sempre cheio, respeita a blacklist temporária e o log central, e integra todas as funções críticas das células anteriores, garantindo máxima resiliência e rastreabilidade.\n",
        "\n",
        "---\n",
        "\n",
        "## Estratégia e melhorias implementadas\n",
        "\n",
        "- **Paralelismo seguro e eficiente:**  \n",
        "  Utiliza múltiplos processos para gravar e processar transmissões simultaneamente, otimizando o uso de recursos e acelerando o processamento em lote.\n",
        "- **Supervisor dinâmico e lote sempre cheio:**  \n",
        "  O supervisor monitora constantemente as vagas livres no lote e preenche em tempo real com novas transmissões válidas, evitando ociosidade e maximizando a eficiência.\n",
        "- **Controle centralizado de duplicidade:**  \n",
        "  Antes de processar qualquer transmissão, consulta o log central de processamento para evitar duplicidade, mesmo em ambientes concorrentes ou paralelos.\n",
        "- **Respeito integral à blacklist temporária:**  \n",
        "  Transmissões de usuários em blacklist não são tentadas novamente durante o ciclo vigente, economizando recursos e evitando loops problemáticos.\n",
        "- **Logs robustos e detalhados:**  \n",
        "  Cada etapa do processamento é registrada com timestamp, status e contexto, facilitando auditoria, troubleshooting e acompanhamento em produção.\n",
        "- **Commit/push automático e seguro:**  \n",
        "  Ao final do ciclo (ou quando atingido o threshold), todos os arquivos alterados são enviados ao repositório, garantindo consistência e persistência dos dados.\n",
        "- **Design modular e Clean Architecture:**  \n",
        "  Funções separadas para supervisão, workers, busca, commit, log, etc., facilitando manutenção, reuso e integração com CI/CD.\n",
        "\n",
        "---\n",
        "\n",
        "## Como funciona o fluxo principal\n",
        "\n",
        "1. **Inicialização:**  \n",
        "   - Determina o modo de operação: gravação de usuários específicos ou busca automática.\n",
        "   - Calcula o tamanho do lote alvo (`LIMIT_DEFAULT` ou `API_SEARCH_LIMIT`).\n",
        "\n",
        "2. **Preenchimento do lote:**  \n",
        "   - Busca transmissões válidas (não duplicadas, não em blacklist) e lança workers para cada uma, registrando no log de processamento.\n",
        "   - Utiliza funções otimizadas de busca (`buscar_proxima_transmissao_livre` e `buscar_usuarios_especificos`), integradas à blacklist e ao log.\n",
        "\n",
        "3. **Supervisão dinâmica:**  \n",
        "   - Monitora o ciclo de vida dos workers/processos.\n",
        "   - Preenche imediatamente cada vaga livre com nova transmissão disponível, até esgotar as opções válidas.\n",
        "\n",
        "4. **Respeito à blacklist:**  \n",
        "   - Antes de qualquer gravação, verifica se o usuário está em blacklist temporária.\n",
        "   - Usuários problemáticos nunca são tentados duas vezes no mesmo ciclo.\n",
        "\n",
        "5. **Logs detalhados:**  \n",
        "   - Todas as operações geram logs padronizados com nível (INFO, WORKER, BUSCA, ERRO, etc.) e timestamp.\n",
        "\n",
        "6. **Finalização segura:**  \n",
        "   - Ao final do processamento, executa commit/push dos arquivos pendentes, garantindo persistência e integridade do repositório.\n",
        "\n",
        "---\n",
        "\n",
        "## Exemplo de uso recomendado\n",
        "\n",
        "```python\n",
        "# Função principal do notebook: dispara o supervisor dinâmico\n",
        "main()\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Segurança, rastreabilidade e integração\n",
        "\n",
        "- **Pronto para execução concorrente e ambientes CI/CD.**\n",
        "- **A lógica de blacklist e commit está totalmente integrada ao fluxo, garantindo máxima resiliência.**\n",
        "- **Logs detalhados e arquitetura modular facilitam diagnóstico, manutenção e evolução do pipeline XCam.**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "iwgt8f8iKq4y"
      },
      "id": "iwgt8f8iKq4y"
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "# ================================================================\n",
        "# Célula 9: Supervisor Dinâmico — Execução Paralela, Lote Sempre Cheio, Blacklist e Log Centralizado (AGORA USANDO ID)\n",
        "# ================================================================\n",
        "# Objetivo:\n",
        "# - Manter o lote de gravações sempre cheio, preenchendo vagas em tempo real com máxima eficiência e segurança.\n",
        "# - Garantir que usuários problemáticos (em blacklist - por ID) não sejam tentados novamente no ciclo vigente.\n",
        "# - Prevenir duplicidade consultando log central de processamento (por ID) antes de iniciar qualquer gravação.\n",
        "# - Integrar-se com a lógica de blacklist, commit/push automático, limpeza de recursos e log robusto, TUDO BASEADO NO ID.\n",
        "# - Modularidade e clareza, pronta para integração com pipelines CI/CD, execução concorrente e ambientes colaborativos.\n",
        "# ================================================================\n",
        "\n",
        "from multiprocessing import Process, Manager # Garantir imports\n",
        "\n",
        "def log_supervisor(msg, level=\"INFO\"):\n",
        "    \"\"\"\n",
        "    Log supervisor padronizado para todas as etapas do pipeline.\n",
        "    Também registra cada evento relevante no log centralizado (sessao supervisor).\n",
        "    Pode incluir ID/username se relevante para o evento.\n",
        "    \"\"\"\n",
        "    from datetime import datetime\n",
        "    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "    print(f\"[{timestamp}] [{level}] {msg}\")\n",
        "    # Registro também no log central (sessao supervisor)\n",
        "    append_log({\n",
        "        \"sessao\": \"supervisor\",\n",
        "        \"evento\": level,\n",
        "        \"id\": \"global\", # Evento global do supervisor\n",
        "        \"username\": \"global\",\n",
        "        \"status\": \"info\" if level != \"ERRO\" else \"erro\",\n",
        "        \"detalhes\": msg\n",
        "    })\n",
        "\n",
        "# Adicionando user_id como parâmetro para o worker\n",
        "def worker(user_id, username, m3u8_url, poster_path, results):\n",
        "    \"\"\"\n",
        "    Worker dedicado: grava a stream, faz upload, atualiza rec.json/poster, integra ao log.\n",
        "    Recebe o ID do usuário e o passa para a função gravar_stream (Célula 7).\n",
        "    O processamento é rastreado via log central, e o status final é adicionado à lista de resultados.\n",
        "    \"\"\"\n",
        "    # gravar_stream agora espera user_id como primeiro parâmetro\n",
        "    log_supervisor(f\"Iniciando gravação: '{username}' (ID: {user_id}) | URL: {m3u8_url[:50]}...\", \"WORKER\") # Loga o ID\n",
        "    result = gravar_stream(user_id, username, m3u8_url, poster_url=poster_path) # Passa user_id para gravar_stream\n",
        "    log_supervisor(\n",
        "        f\"Finalizou gravação: '{username}' (ID: {user_id}) | Sucesso: {result.get('upload_success')} | \" # Loga o ID\n",
        "        f\"Arquivo: {result.get('filename')} | Abyss: {result.get('abyss_response')}\", \"WORKER\")\n",
        "    results.append(result)\n",
        "    # Registro do resultado no log central (já feito dentro de gravar_stream, mas reforça aqui)\n",
        "    # append_log({\n",
        "    #     \"sessao\": \"supervisor\",\n",
        "    #     \"evento\": \"worker_result\",\n",
        "    #     \"id\": user_id, # Usa o ID aqui\n",
        "    #     \"username\": username,\n",
        "    #     \"status\": \"ok\" if result.get(\"upload_success\") else \"erro\",\n",
        "    #     \"detalhes\": str(result)\n",
        "    # })\n",
        "\n",
        "\n",
        "# Supervisor dinâmico, agora usando ID para controle de estado\n",
        "def supervisor_dinamico(usuarios_especificos=None):\n",
        "    \"\"\"\n",
        "    Supervisor dinâmico de transmissões ao vivo:\n",
        "    - Mantém o lote de gravações sempre cheio, preenchendo vagas em tempo real.\n",
        "    - Evita duplicidade e concorrência consultando log central (sessao=\"processing\", status=\"in_progress\"), AGORA PELO ID.\n",
        "    - Respeita blacklist centralizada (pelo ID), não processando usuários bloqueados no ciclo vigente.\n",
        "    - Log detalhado e modular para diagnóstico, CI/CD e rastreabilidade.\n",
        "    \"\"\"\n",
        "\n",
        "    # Determina o tamanho do lote com base no modo operacional\n",
        "    pool_size = LIMIT_DEFAULT if not usuarios_especificos else API_SEARCH_LIMIT\n",
        "    running = []\n",
        "    results = Manager().list()\n",
        "    # Não precisamos mais do seen_usernames local, pois o log central é a fonte de verdade para o estado (is_processing, is_in_blacklist)\n",
        "    # seen_usernames = set()\n",
        "\n",
        "    log_supervisor(f\"Supervisor dinâmico iniciado | Lote alvo: {pool_size} | Modo: {'específico' if usuarios_especificos else 'automático'}\")\n",
        "\n",
        "    # A função atualizar_seen_usernames local não é mais necessária,\n",
        "    # pois is_processing e is_in_blacklist consultam o log central diretamente.\n",
        "    # def atualizar_seen_usernames():\n",
        "    #     \"\"\"\n",
        "    #     Atualiza o conjunto de usernames já processados diretamente do log central (sessao='processing').\n",
        "    #     Garante robustez em ambientes concorrentes e previne duplicidade.\n",
        "    #     \"\"\"\n",
        "    #     entries = query_logs(sessao=\"processing\", status=\"in_progress\")\n",
        "    #     seen_usernames.update([e[\"username\"] for e in entries])\n",
        "\n",
        "    def buscar_nova_transmissao():\n",
        "        \"\"\"\n",
        "        Busca uma nova transmissão livre para preencher o lote:\n",
        "        - Modo específico: busca em lista fornecida (agora retorna ID).\n",
        "        - Modo automático: busca próxima transmissão livre disponível (agora retorna ID).\n",
        "        - Sempre consulta blacklist (pelo ID) e log central (pelo ID) antes de liberar.\n",
        "        \"\"\"\n",
        "        # Não precisamos mais chamar atualizar_seen_usernames() aqui.\n",
        "        # A lógica dentro de is_in_blacklist e is_processing consulta o log central diretamente.\n",
        "\n",
        "        if usuarios_especificos:\n",
        "            # buscar_usuarios_especificos agora retorna lista com ID\n",
        "            candidatos = buscar_usuarios_especificos(usuarios_especificos)\n",
        "            for s in candidatos:\n",
        "                user_id = s[\"id\"] # Captura o ID retornado pela função de busca\n",
        "                username = s[\"username\"]\n",
        "                # Verifica se o ID está em blacklist ou processando (AGORA CONSULTANDO PELO ID)\n",
        "                if not is_in_blacklist(user_id) and not is_processing(user_id):\n",
        "                    log_supervisor(f\"Nova transmissão encontrada (específico): '{username}' (ID: {user_id})\", \"BUSCA\") # Loga o ID\n",
        "                    return s # Retorna o dicionário com id, username, src, poster_path\n",
        "                else:\n",
        "                    # Loga que o ID está sendo ignorado\n",
        "                    status_detail = \"\"\n",
        "                    if is_in_blacklist(user_id): status_detail += \"blacklist \"\n",
        "                    if is_processing(user_id): status_detail += \"processing \"\n",
        "                    log_supervisor(f\"Usuário '{username}' (ID: {user_id}) já em {status_detail.strip()}, ignorando.\", \"BUSCA\")\n",
        "            log_supervisor(\"Nenhuma transmissão específica livre encontrada (todos em blacklist/log ou offline).\", \"BUSCA\")\n",
        "            return None\n",
        "        else:\n",
        "            # Busca otimizada: tenta até 10 vezes buscar próxima transmissão livre\n",
        "            for tentativa in range(1, 11):\n",
        "                log_supervisor(f\"Buscando próxima transmissão livre: tentativa {tentativa}\", \"BUSCA\")\n",
        "                # buscar_proxima_transmissao_livre agora retorna dicionário com ID\n",
        "                stream = buscar_proxima_transmissao_livre()\n",
        "                if stream:\n",
        "                    user_id = stream[\"id\"] # Captura o ID retornado pela função de busca\n",
        "                    username = stream[\"username\"]\n",
        "                    # Verifica se o ID está em blacklist ou processando (AGORA CONSULTANDO PELO ID)\n",
        "                    if not is_in_blacklist(user_id) and not is_processing(user_id):\n",
        "                        log_supervisor(f\"Nova transmissão encontrada: '{username}' (ID: {user_id})\", \"BUSCA\") # Loga o ID\n",
        "                        return stream # Retorna o dicionário com id, username, src, poster_path\n",
        "                    else:\n",
        "                        # Loga que o ID está sendo ignorado\n",
        "                        status_detail = \"\"\n",
        "                        if is_in_blacklist(user_id): status_detail += \"blacklist \"\n",
        "                        if is_processing(user_id): status_detail += \"processing \"\n",
        "                        log_supervisor(f\"Usuário '{username}' (ID: {user_id}) já em {status_detail.strip()}, ignorando.\", \"BUSCA\")\n",
        "                else:\n",
        "                    log_supervisor(f\"buscar_proxima_transmissao_livre retornou None na tentativa {tentativa}.\", \"BUSCA\")\n",
        "\n",
        "            log_supervisor(\"Nenhuma transmissão livre encontrada após tentativas (todos em blacklist/log ou offline).\", \"BUSCA\")\n",
        "            return None\n",
        "\n",
        "    # ========== Fase 1: Preenchimento do lote inicial ==========\n",
        "    log_supervisor(f\"Preenchendo lote inicial com até {pool_size} transmissões...\", \"STARTUP\")\n",
        "    tentativas = 0\n",
        "    max_tentativas = 100 # Limita as tentativas totais para preencher o lote inicial\n",
        "    while len(running) < pool_size and tentativas < max_tentativas:\n",
        "        stream = buscar_nova_transmissao() # Retorna dicionário com id, username, src, poster_path\n",
        "        if not stream:\n",
        "            log_supervisor(\"Fim das transmissões disponíveis para preencher lote inicial.\", \"STARTUP\")\n",
        "            break # Sai do loop se não encontrar mais streams\n",
        "\n",
        "        user_id = stream[\"id\"] # Obtém o ID do dicionário retornado\n",
        "        username = stream[\"username\"]\n",
        "        m3u8_url = stream[\"src\"]\n",
        "        poster_path = stream[\"poster_path\"] # Caminho do poster temporário válido\n",
        "\n",
        "\n",
        "        # Marca no log central como em processamento para evitar duplicidade (USANDO ID)\n",
        "        mark_processing(user_id, username) # Passa user_id e username\n",
        "\n",
        "        log_supervisor(f\"Lançando processo para: '{username}' (ID: {user_id}) | {len(running)+1}/{pool_size}\", \"STARTUP\") # Loga o ID\n",
        "        # Passa o user_id para a função worker\n",
        "        p = Process(target=worker, args=(user_id, username, m3u8_url, poster_path, results))\n",
        "        running.append(p)\n",
        "        p.start()\n",
        "        tentativas += 1 # Incrementa tentativas\n",
        "\n",
        "    log_supervisor(f\"Lote inicial lançado com {len(running)} transmissões.\", \"STARTUP\")\n",
        "\n",
        "\n",
        "    # ========== Fase 2: Loop dinâmico de preenchimento contínuo ==========\n",
        "    # Monitora processos ativos e busca novas streams para manter o lote cheio\n",
        "    while True:\n",
        "        # Atualiza a lista de processos ativos\n",
        "        antes = len(running)\n",
        "        running = [p for p in running if p.is_alive()]\n",
        "        depois = len(running)\n",
        "\n",
        "        # Se algum processo finalizou\n",
        "        if antes != depois:\n",
        "            log_supervisor(f\"{antes-depois} gravações finalizaram. Vagas livres: {pool_size-len(running)}\", \"LOOP\")\n",
        "\n",
        "        vagas_livres = pool_size - len(running)\n",
        "\n",
        "        # Se houver vagas livres, busca novas streams para preencher\n",
        "        if vagas_livres > 0:\n",
        "            # Busca até o número de vagas livres, mas com limite de tentativas para não travar\n",
        "            preenchidas_nesta_rodada = 0\n",
        "            for _ in range(vagas_livres):\n",
        "                stream = buscar_nova_transmissao() # Retorna dicionário com id, username, src, poster_path\n",
        "                if not stream:\n",
        "                    # Se não encontrar mais streams disponíveis após todas as tentativas internas, sai do loop de preenchimento\n",
        "                    log_supervisor(\"Não há mais transmissões para preencher as vagas livres.\", \"LOOP\")\n",
        "                    break # Sai do loop interno de preenchimento de vagas\n",
        "\n",
        "                user_id = stream[\"id\"] # Obtém o ID do dicionário retornado\n",
        "                username = stream[\"username\"]\n",
        "                m3u8_url = stream[\"src\"]\n",
        "                poster_path = stream[\"poster_path\"] # Caminho do poster temporário válido\n",
        "\n",
        "                # Marca no log central como em processamento (USANDO ID)\n",
        "                mark_processing(user_id, username) # Passa user_id e username\n",
        "\n",
        "                log_supervisor(f\"Lançando nova gravação: '{username}' (ID: {user_id}) | Vaga preenchida {len(running)+1}/{pool_size}\", \"LOOP\") # Loga o ID\n",
        "                # Passa o user_id para a função worker\n",
        "                p = Process(target=worker, args=(user_id, username, m3u8_url, poster_path, results))\n",
        "                running.append(p)\n",
        "                p.start()\n",
        "                preenchidas_nesta_rodada += 1 # Conta quantas vagas foram preenchidas nesta rodada\n",
        "\n",
        "            if preenchidas_nesta_rodada == 0 and vagas_livres > 0 and not stream:\n",
        "                 # Condição para sair do loop principal: não há processos rodando E não há mais streams disponíveis\n",
        "                 # (a busca_nova_transmissao retornou None após várias tentativas)\n",
        "                 if not running:\n",
        "                      log_supervisor(\"Não há processos ativos e não há mais transmissões disponíveis.\", \"END\")\n",
        "                      break\n",
        "\n",
        "\n",
        "        # Se não houver processos rodando e não conseguimos preencher nenhuma vaga nesta rodada,\n",
        "        # significa que todas as transmissões disponíveis já foram processadas ou estão em blacklist/processing.\n",
        "        # A condição `if not stream:` dentro do loop de vagas + `if not running:` fora do loop de vagas\n",
        "        # já lida com isso, mas podemos adicionar uma checagem explícita.\n",
        "        # if not running and vagas_livres == pool_size and stream is None:\n",
        "        #      log_supervisor(\"Todas as transmissões possíveis já foram processadas ou estão bloqueadas.\", \"END\")\n",
        "        #      break\n",
        "\n",
        "\n",
        "        # Log de status periódico\n",
        "        log_supervisor(\n",
        "            f\"Transmissões ativas: {len(running)} | Lote alvo: {pool_size} | Buffer de resultados: {len(results)}\",\n",
        "            \"STATUS\"\n",
        "        )\n",
        "\n",
        "        # Aguarda um pouco antes de verificar novamente\n",
        "        time.sleep(5) # Aumentado o sleep para reduzir a frequência da busca quando o lote está cheio\n",
        "\n",
        "        # Condição de saída mais robusta: se não há processos rodando E a última busca não encontrou streams\n",
        "        if not running and (stream is None or (isinstance(stream, list) and len(stream) == 0)):\n",
        "             log_supervisor(\"Não há processos ativos e a última busca não encontrou transmissões.\", \"END\")\n",
        "             break\n",
        "\n",
        "\n",
        "    # ========== Fase 3: Finalização ==========\n",
        "    log_supervisor(f\"Processamento dinâmico concluído! Total de transmissões gravadas/processadas: {len(results)}\", \"RESUMO\")\n",
        "    # A chamada para commit_push_restantes() foi removida pois o commit é gerenciado externamente.\n",
        "    log_supervisor(\"Supervisor dinâmico finalizado.\", \"END\")\n",
        "\n",
        "\n",
        "# Função principal para iniciar o supervisor\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Função principal: inicia o notebook perguntando se o usuário quer gravar transmissões específicas ou automáticas.\n",
        "    Dispara o supervisor dinâmico na modalidade selecionada.\n",
        "    \"\"\"\n",
        "    # Certificar-se que as variáveis globais essenciais da Célula 1 estão carregadas\n",
        "    # Isso é feito executando a Célula 1 antes desta.\n",
        "    if 'LOG_PATH' not in globals():\n",
        "        print(\"⚠️ Variáveis globais da Célula 1 não carregadas. Execute a Célula 1 primeiro.\")\n",
        "        return # Sai se a Célula 1 não foi executada\n",
        "\n",
        "    usuarios_especificos = perguntar_transmissoes_especificas() # perguntar_transmissoes_especificas está na Célula 1\n",
        "    log_supervisor(\"Iniciando busca e gravação de streams (supervisor dinâmico)...\", \"MAIN\")\n",
        "    supervisor_dinamico(usuarios_especificos=usuarios_especificos)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Garante que as funções de log da Célula 1 estejam disponíveis\n",
        "    # Em um notebook, geralmente as células são executadas em ordem,\n",
        "    # então Célula 1 já teria definido append_log, query_logs, etc.\n",
        "    # Se rodando como script Python, precisaria importar ou definir as funções de log aqui.\n",
        "    # Para o contexto do Colab, assume-se que Célula 1 já rodou.\n",
        "\n",
        "    # Adicionando um try-except para garantir que main() seja chamada\n",
        "    # apenas se estiver em um ambiente interativo como Colab/IPython\n",
        "    try:\n",
        "        if 'google.colab' in str(get_ipython()):\n",
        "            main()\n",
        "        else:\n",
        "            print(\"Não está rodando em Colab/IPython. Execute main() manualmente se desejar.\")\n",
        "    except NameError:\n",
        "        print(\"Não está rodando em Colab/IPython. Execute main() se desejar.\")\n",
        "\n",
        "\n",
        "# ================================================================\n",
        "# FIM DA CÉLULA 9 — Supervisor Dinâmico, Lote Cheio e Blacklist Centralizados (AGORA USANDO ID)\n",
        "# ================================================================\n",
        "\n",
        "# Observações e recomendações:\n",
        "# - Toda lógica de blacklist, processamento e falhas agora se baseia no ID único do usuário no log centralizado para máxima rastreabilidade.\n",
        "# - O log central é a fonte de verdade para sincronização entre workers/processos.\n",
        "# - Modularidade, logs claros e tratamento de erro garantem manutenção e evolução seguras.\n",
        "# - Pronto para ambientes colaborativos (Colab, CI/CD, pipelines paralelos).\n",
        "# - Certifique-se de executar as Células 1, 3, 6, 7 e 8 antes desta."
      ],
      "metadata": {
        "id": "5WKQV9g_LB9M"
      },
      "id": "5WKQV9g_LB9M",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2eac76d"
      },
      "source": [
        "# Célula XX: Limpeza do Arquivo de Log Central do Google Drive\n",
        "\n",
        "**Objetivo:**\\\n",
        "Esta célula permite remover o arquivo de log central (`xcam_master.log`) do Google Drive. É uma operação útil para limpar um log corrompido que esteja causando erros (como `JSONDecodeError` ou `UnicodeDecodeError`) ou simplesmente para iniciar o registro de eventos do zero.\n",
        "\n",
        "## Principais pontos e funcionalidades\n",
        "\n",
        "- **Remoção segura:** Verifica se o arquivo de log existe antes de tentar removê-lo.\n",
        "- **Tratamento de erros:** Inclui um bloco `try-except` para capturar e reportar quaisquer problemas que possam ocorrer durante a remoção do arquivo.\n",
        "- **Feedback claro:** Imprime mensagens indicando se o arquivo foi removido com sucesso, se houve um erro ou se o arquivo não foi encontrado.\n",
        "- **Utilidade para depuração:** Essencial para resetar o estado do log quando ele se corrompe devido a falhas inesperadas de escrita ou outros problemas de sistema de arquivos.\n",
        "\n",
        "* * *\n",
        "\n",
        "## Como funciona a célula\n",
        "\n",
        "- **Define o caminho** completo para o arquivo de log central no Google Drive.\n",
        "- **Verifica** se o arquivo existe nesse local.\n",
        "- **Tenta remover** o arquivo.\n",
        "- **Imprime** o resultado da operação (sucesso, erro ou arquivo não encontrado).\n",
        "\n",
        "* * *\n",
        "\n",
        "## Exemplo de execução"
      ],
      "id": "d2eac76d"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8332447"
      },
      "source": [
        "import os\n",
        "\n",
        "log_file_drive = '/content/drive/MyDrive/XCam.Drive/logs/xcam_master.log'\n",
        "if os.path.exists(log_file_drive):\n",
        "    try:\n",
        "        os.remove(log_file_drive)\n",
        "        print(f\"Arquivo de log do Drive removido: {log_file_drive}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Erro ao remover arquivo de log do Drive: {e}\")\n",
        "else:\n",
        "    print(f\"Arquivo de log do Drive não encontrado: {log_file_drive}\")"
      ],
      "id": "c8332447",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "c9hve1ySGVAs"
      ],
      "cell_execution_strategy": "setup",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}