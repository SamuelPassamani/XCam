{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SamuelPassamani/XCam/blob/main/xcam-colab/XCam_REC_V3.2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Célula 1: Configurações Auxiliares e Parâmetros Gerais\n",
        "\n",
        "**Objetivo:**  \n",
        "Esta célula inicializa e centraliza as variáveis globais e parâmetros de controle essenciais para ajuste rápido e seguro do comportamento do notebook, incluindo limites de processamento, controle de gravação, e configurações de commit automático.\n",
        "\n",
        "*   Quantidade máxima de transmissões processadas em paralelo/lote (`LIMIT_DEFAULT`)\n",
        "*   Página inicial para busca na API (`PAGE_DEFAULT`)\n",
        "*   Tempo máximo de gravação de cada vídeo em segundos (`RECORD_SECONDS`)\n",
        "*   Tempo mínimo de gravação exigido para considerar o vídeo válido (`RECORD_SECONDS_MIN`)\n",
        "*   Limite de transmissões retornadas ao buscar usuários específicos (`API_SEARCH_LIMIT`)\n",
        "*   Quantidade de transmissões processadas até realizar commit/push automático (`COMMIT_PUSH_THRESHOLD`)\n",
        "    * **Novo:** Pode ser ajustado para controlar a frequência com que os arquivos são enviados ao repositório (por exemplo, 10 transmissões por commit). Defina como 0 para commit imediato a cada gravação.\n",
        "\n",
        "**Interatividade:**  \n",
        "Inclui a função `perguntar_transmissoes_especificas()` que pergunta ao usuário se deseja gravar transmissões de usuários específicos. Caso positivo, solicita os nomes dos usuários (separados por vírgula) e retorna uma lista limpa e pronta para uso.\n",
        "\n",
        "**Funcionamento e Segurança:**  \n",
        "- Todos os parâmetros globais são definidos no início e propagados para todo o notebook, garantindo consistência e fácil manutenção.\n",
        "- Ajuste qualquer valor diretamente nesta célula para alterar o comportamento global do notebook sem risco de inconsistência.\n",
        "- A função interativa permite filtrar transmissões específicas antes do início do processamento.\n",
        "- Os comentários detalhados auxiliam na compreensão e ajuste seguro dos parâmetros, evitando conflitos ou mau funcionamento.\n",
        "\n",
        "**Exemplo de uso interativo:**  \n",
        "Antes de iniciar o processamento, você pode ajustar qualquer parâmetro de controle.  \n",
        "O notebook perguntará se você quer gravar transmissões de usuários específicos e, se desejar, basta informar os nomes separados por vírgula (ex: \"userNovo234, jovemPT\").\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "c9hve1ySGVAs"
      },
      "id": "c9hve1ySGVAs"
    },
    {
      "cell_type": "code",
      "source": [
        "# Célula 1: Configurações Auxiliares e Parâmetros Gerais\n",
        "# ------------------------------------------------------\n",
        "# Esta célula define e documenta todos os principais parâmetros do sistema,\n",
        "# facilitando o ajuste do comportamento global do notebook de modo seguro e organizado.\n",
        "# Também inclui função para seleção opcional de transmissões específicas por nome de usuário.\n",
        "#\n",
        "# ATENÇÃO:\n",
        "# - Todos os parâmetros estão centralizados nesta célula.\n",
        "# - Se alterar aqui, o valor refletirá em todo o notebook.\n",
        "# - Use os comentários para entender facilmente cada parâmetro antes de ajustar.\n",
        "# - Não remova a chamada a 'globals().update()', pois ela garante acesso global seguro.\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "\n",
        "# ============================\n",
        "# PARÂMETROS GLOBAIS EDITÁVEIS\n",
        "# ============================\n",
        "\n",
        "LIMIT_DEFAULT = 25             # Quantidade máxima de transmissões processadas em paralelo/lote.\n",
        "PAGE_DEFAULT = 1               # Página inicial para busca na API.\n",
        "RECORD_SECONDS = 420           # Tempo máximo de gravação de cada vídeo (em segundos).\n",
        "RECORD_SECONDS_MIN = 300       # Tempo mínimo exigido para considerar o vídeo válido (em segundos).\n",
        "API_SEARCH_LIMIT = 1000        # Limite de transmissões retornadas ao buscar usuários específicos.\n",
        "COMMIT_PUSH_THRESHOLD = 10     # Quantidade de transmissões processadas antes de commit/push automático (0 = commit imediato a cada vídeo).\n",
        "\n",
        "# ============================\n",
        "# ATUALIZAÇÃO GLOBAL DOS PARÂMETROS\n",
        "# ============================\n",
        "# Isto garante que todos os scripts e funções do notebook possam acessar os parâmetros acima\n",
        "# como variáveis globais, evitando conflitos ou inconsistência de valores.\n",
        "globals().update({\n",
        "    'LIMIT_DEFAULT': LIMIT_DEFAULT,\n",
        "    'PAGE_DEFAULT': PAGE_DEFAULT,\n",
        "    'RECORD_SECONDS': RECORD_SECONDS,\n",
        "    'RECORD_SECONDS_MIN': RECORD_SECONDS_MIN,\n",
        "    'API_SEARCH_LIMIT': API_SEARCH_LIMIT,\n",
        "    'COMMIT_PUSH_THRESHOLD': COMMIT_PUSH_THRESHOLD\n",
        "})\n",
        "\n",
        "# ============================\n",
        "# FUNÇÃO INTERATIVA (opcional)\n",
        "# ============================\n",
        "def perguntar_transmissoes_especificas():\n",
        "    \"\"\"\n",
        "    Pergunta ao usuário se deseja informar transmissões específicas para gravar,\n",
        "    recebendo nomes de usuário separados por vírgula e retornando lista limpa.\n",
        "    Retorna lista vazia caso não deseje selecionar usuários.\n",
        "    \"\"\"\n",
        "    resp = input('Deseja gravar alguma transmissão específica? (sim/não): ').strip().lower()\n",
        "    if resp.startswith('s'):\n",
        "        usuarios = input('Informe o(s) nome(s) de usuário, separados por vírgula (ex: userNovo234, jovemPT): ')\n",
        "        usuarios_lista = [u.strip() for u in usuarios.split(',') if u.strip()]\n",
        "        return usuarios_lista\n",
        "    return []"
      ],
      "metadata": {
        "id": "j5pPh353GLMD"
      },
      "id": "j5pPh353GLMD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Célula 2: Instalação do ffmpeg\n",
        "\n",
        "**Objetivo:**\n",
        "Garante que o ffmpeg esteja instalado no ambiente do Google Colab. O ffmpeg é fundamental para gravar os vídeos das transmissões.\n",
        "\n",
        "**Como funciona:**\n",
        "Executa comandos de instalação do ffmpeg, necessários para o funcionamento correto das próximas etapas."
      ],
      "metadata": {
        "id": "WXs0o6OPHXbi"
      },
      "id": "WXs0o6OPHXbi"
    },
    {
      "cell_type": "code",
      "source": [
        "# Célula 2: Instalação do ffmpeg\n",
        "# ------------------------------\n",
        "# Garante que o ffmpeg está instalado no ambiente Colab.\n",
        "\n",
        "!apt-get update -y\n",
        "!apt-get install -y ffmpeg"
      ],
      "metadata": {
        "id": "vIODn0c2HiHz"
      },
      "id": "vIODn0c2HiHz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Célula 3: Imports Essenciais e Funções Utilitárias\n",
        "\n",
        "**Objetivo:**  \n",
        "Importa todas as bibliotecas do Python necessárias para o funcionamento do notebook, incluindo módulos para requisições HTTP, processamento paralelo, manipulação de data/hora, controle de subprocessos e exibição interativa.  \n",
        "Também define funções utilitárias robustas para:\n",
        "\n",
        "*   Formatar o tempo de gravação (`format_seconds`)\n",
        "*   Exibir logs de progresso do processamento (`log_progress`)\n",
        "*   Baixar e salvar a imagem de poster de cada transmissão (`download_and_save_poster`)\n",
        "*   Gerar poster automaticamente com ffmpeg a partir da transmissão ao vivo caso o poster esteja ausente ou inválido (`generate_poster_with_ffmpeg`)\n",
        "*   Validar se o poster é válido (`is_poster_valid`)\n",
        "*   **Concorrência/Log:** Garante a criação do arquivo de log temporário para controlar transmissões atualmente em processamento e já inclui, de forma opcional, um lock global para garantir escrita thread-safe em cenários de execução paralela.\n",
        "\n",
        "**Como funciona:**  \n",
        "Essas funções são usadas em várias partes do notebook para:\n",
        "- Manipular e exibir tempos de gravação de forma amigável.\n",
        "- Acompanhar e reportar o progresso de gravações em tempo real.\n",
        "- Garantir que cada transmissão tenha sempre um poster válido, seja baixando da API, seja gerando automaticamente com ffmpeg.\n",
        "- Manter o controle das transmissões em processamento por meio do arquivo de log temporário, auxiliando na prevenção de duplicidade e facilitando o processamento paralelo contínuo e seguro.\n",
        "- Os comentários detalhados facilitam a manutenção e o entendimento para futuras adaptações do notebook.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "90qvXC0rHtWb"
      },
      "id": "90qvXC0rHtWb"
    },
    {
      "cell_type": "code",
      "source": [
        "# Célula 3: Imports essenciais e utilitários\n",
        "# ------------------------------------------\n",
        "# Importação de bibliotecas e funções auxiliares de formatação e download.\n",
        "# Também garante a criação do arquivo de log temporário para controle de transmissões em processamento.\n",
        "# ADIÇÃO: Função para gerar poster com ffmpeg caso não haja poster válido na API.\n",
        "# CORREÇÃO: Antes de rodar ffmpeg, testa se a URL do stream está acessível (HEAD).\n",
        "# Se não estiver, retorna None e faz o tratamento do erro de stream offline.\n",
        "\n",
        "import os\n",
        "import requests\n",
        "import multiprocessing\n",
        "from datetime import datetime\n",
        "import json\n",
        "import time\n",
        "import subprocess\n",
        "import math\n",
        "import re\n",
        "\n",
        "from IPython import get_ipython\n",
        "from IPython.display import display\n",
        "\n",
        "# Caminho do arquivo de log temporário\n",
        "LOG_PROCESSAMENTO_PATH = \"/content/xcam_processing.log\"\n",
        "\n",
        "# Garante que o arquivo de log temporário exista ao iniciar o notebook\n",
        "if not os.path.exists(LOG_PROCESSAMENTO_PATH):\n",
        "    with open(LOG_PROCESSAMENTO_PATH, \"w\") as f:\n",
        "        f.write(\"\")  # Cria arquivo vazio\n",
        "\n",
        "def format_seconds(seconds):\n",
        "    total_seconds = int(seconds)\n",
        "    hours = total_seconds // 3600\n",
        "    minutes = (total_seconds % 3600) // 60\n",
        "    seconds = total_seconds % 60\n",
        "    parts = []\n",
        "    if hours > 0: parts.append(f\"{hours}h\")\n",
        "    if minutes > 0 or (hours == 0 and seconds > 0): parts.append(f\"{minutes}m\")\n",
        "    if seconds > 0 or total_seconds == 0: parts.append(f\"{seconds}s\")\n",
        "    return \"\".join(parts) if parts else \"0s\"\n",
        "\n",
        "def log_progress(username, elapsed_seconds, total_seconds):\n",
        "    percent = min((elapsed_seconds / total_seconds) * 100, 100)\n",
        "    tempo = format_seconds(elapsed_seconds)\n",
        "    minutos_gravados = math.floor(elapsed_seconds / 60)\n",
        "    minutos_restantes = max(0, math.ceil((total_seconds - elapsed_seconds) / 60))\n",
        "    print(f\"⏱️ [{username}] Gravados: {minutos_gravados} min | Restantes: {minutos_restantes} min | Tempo total: {tempo} — 📊 {percent:.1f}% concluído\")\n",
        "\n",
        "def download_and_save_poster(poster_url, username, temp_folder):\n",
        "    \"\"\"\n",
        "    Baixa e salva o poster a partir de uma URL HTTP/HTTPS.\n",
        "    Ou, se receber um caminho local existente, apenas retorna esse caminho.\n",
        "    Retorna o caminho do arquivo salvo, ou None em caso de erro.\n",
        "    \"\"\"\n",
        "    # Se for um caminho local já existente, apenas retorna\n",
        "    if os.path.exists(poster_url):\n",
        "        return poster_url\n",
        "    # Se for uma URL HTTP/HTTPS, faz o download normalmente\n",
        "    if isinstance(poster_url, str) and (poster_url.startswith(\"http://\") or poster_url.startswith(\"https://\")):\n",
        "        try:\n",
        "            response = requests.get(poster_url, timeout=15)\n",
        "            response.raise_for_status()\n",
        "            ext = os.path.splitext(poster_url)[1].lower()\n",
        "            if ext not in [\".jpg\", \".jpeg\", \".png\"]:\n",
        "                ext = \".jpg\"\n",
        "            poster_temp_path = os.path.join(temp_folder, f\"{username}_poster_temp{ext}\")\n",
        "            with open(poster_temp_path, \"wb\") as f:\n",
        "                f.write(response.content)\n",
        "            print(f\"🖼️ Poster baixado em: {poster_temp_path}\")\n",
        "            return poster_temp_path\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Erro ao baixar poster {poster_url}: {e}\")\n",
        "            return None\n",
        "    else:\n",
        "        print(f\"❌ poster_url inválido ou não encontrado: {poster_url}\")\n",
        "        return None\n",
        "\n",
        "def generate_poster_with_ffmpeg(m3u8_url, username, temp_folder, frame_time=7, timeout=20):\n",
        "    \"\"\"\n",
        "    Gera um poster (screenshot) usando ffmpeg a partir da URL .m3u8 da transmissão.\n",
        "    Retorna o caminho do arquivo gerado ou None em caso de erro.\n",
        "    frame_time: segundo do vídeo em que o poster será capturado (padrão: 7s para evitar frame preto).\n",
        "    Antes de rodar o ffmpeg, faz uma checagem HTTP HEAD para saber se a URL do stream está ativa.\n",
        "    \"\"\"\n",
        "    # Checa se a URL está acessível antes de rodar ffmpeg\n",
        "    try:\n",
        "        head_resp = requests.head(m3u8_url, timeout=5)\n",
        "        if not head_resp.ok:\n",
        "            print(f\"⚠️ Stream offline ou não disponível para {username} (status {head_resp.status_code})\")\n",
        "            return None\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ Erro de conexão ao acessar stream de {username}: {e}\")\n",
        "        return None\n",
        "\n",
        "    poster_ffmpeg_path = os.path.join(temp_folder, f\"{username}_poster_ffmpeg.jpg\")\n",
        "    # Comando ffmpeg: captura 1 frame após frame_time segundos de vídeo\n",
        "    command = [\n",
        "        \"ffmpeg\",\n",
        "        \"-y\",  # sobrescreve arquivo se já existir\n",
        "        \"-ss\", str(frame_time),  # avança para frame_time segundos antes de capturar\n",
        "        \"-i\", m3u8_url,\n",
        "        \"-vframes\", \"1\",\n",
        "        \"-q:v\", \"2\",  # qualidade alta\n",
        "        poster_ffmpeg_path\n",
        "    ]\n",
        "    try:\n",
        "        print(f\"🎬 Gerando poster com ffmpeg para {username} no segundo {frame_time}...\")\n",
        "        # subprocess.run com timeout para evitar travamento caso a URL esteja offline/inválida\n",
        "        result = subprocess.run(\n",
        "            command,\n",
        "            stdout=subprocess.PIPE,\n",
        "            stderr=subprocess.PIPE,\n",
        "            timeout=timeout\n",
        "        )\n",
        "        if result.returncode == 0 and os.path.exists(poster_ffmpeg_path):\n",
        "            print(f\"🖼️ Poster gerado via ffmpeg: {poster_ffmpeg_path}\")\n",
        "            return poster_ffmpeg_path\n",
        "        else:\n",
        "            print(f\"❌ ffmpeg não conseguiu gerar poster para {username}. Saída: {result.stderr.decode(errors='ignore')}\")\n",
        "            return None\n",
        "    except subprocess.TimeoutExpired:\n",
        "        print(f\"⏰ Tempo excedido ao tentar gerar poster para {username} via ffmpeg.\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Erro inesperado ao gerar poster via ffmpeg: {e}\")\n",
        "        return None\n",
        "\n",
        "def is_poster_valid(poster_path):\n",
        "    \"\"\"\n",
        "    Verifica se o poster existe e não está vazio.\n",
        "    \"\"\"\n",
        "    return poster_path and os.path.exists(poster_path) and os.path.getsize(poster_path) > 0"
      ],
      "metadata": {
        "id": "hOetz0nGICkz"
      },
      "id": "hOetz0nGICkz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Célula 4: Clonagem do Repositório GitHub para o Colab\n",
        "\n",
        "**Objetivo:**\n",
        "Clona o repositório do GitHub para o ambiente local do Colab, garantindo que o ambiente sempre esteja atualizado e pronto para armazenar os arquivos gerados.\n",
        "\n",
        "**Como funciona:**\n",
        "Remove qualquer repositório anterior para evitar conflitos, clona o novo, prepara pastas temporárias e define a URL de upload para o Abyss.to."
      ],
      "metadata": {
        "id": "hpRIMtyFIY0q"
      },
      "id": "hpRIMtyFIY0q"
    },
    {
      "cell_type": "code",
      "source": [
        "# Célula 4: Clonagem do repositório GitHub para o Colab e para o Drive\n",
        "# --------------------------------------------------------------------\n",
        "# Clona o repositório para o ambiente Colab E também para o Google Drive (se montado),\n",
        "# garantindo ambiente limpo, persistência e sincronização para futuras execuções.\n",
        "\n",
        "GITHUB_USER = \"SamuelPassamani\"\n",
        "GITHUB_REPO = \"XCam\"\n",
        "GITHUB_BRANCH = \"main\"\n",
        "GITHUB_TOKEN = \"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\"\n",
        "\n",
        "repo_url = f\"https://{GITHUB_USER}:{GITHUB_TOKEN}@github.com/{GITHUB_USER}/{GITHUB_REPO}.git\"\n",
        "\n",
        "# Clona para o ambiente Colab\n",
        "!rm -rf {GITHUB_REPO}\n",
        "!git clone -b {GITHUB_BRANCH} {repo_url}\n",
        "\n",
        "# Caminhos locais\n",
        "TEMP_OUTPUT_FOLDER = \"/content/temp_recordings\"\n",
        "os.makedirs(TEMP_OUTPUT_FOLDER, exist_ok=True)\n",
        "BASE_REPO_FOLDER = f\"/content/{GITHUB_REPO}\"\n",
        "\n",
        "# Caminho para o Drive (se montado)\n",
        "DRIVE_MOUNT = \"/content/drive/MyDrive/XCam.Drive\"\n",
        "DRIVE_REPO_FOLDER = f\"{DRIVE_MOUNT}/{GITHUB_REPO}\"\n",
        "\n",
        "# Clona também para o Drive, se estiver montado\n",
        "import os\n",
        "if os.path.exists(DRIVE_MOUNT):\n",
        "    # Remove repositório antigo no Drive (se existir), depois clona\n",
        "    !rm -rf \"{DRIVE_REPO_FOLDER}\"\n",
        "    !git clone -b {GITHUB_BRANCH} {repo_url} \"{DRIVE_REPO_FOLDER}\"\n",
        "    print(f\"✅ Repositório também clonado no Drive: {DRIVE_REPO_FOLDER}\")\n",
        "else:\n",
        "    print(f\"⚠️ Google Drive não está montado em {DRIVE_MOUNT}.\")\n",
        "\n",
        "ABYSS_UPLOAD_URL = 'http://up.hydrax.net/0128263f78f0b426d617bb61c2a8ff43'"
      ],
      "metadata": {
        "id": "Uof_0QCrIlf7"
      },
      "id": "Uof_0QCrIlf7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Célula 5: Commit e Push Automáticos (rec.json e poster)\n",
        "\n",
        "---\n",
        "\n",
        "**Objetivo:**\n",
        "Define a função git_commit_and_push() para garantir que apenas arquivos importantes (JSON de gravação e posters de imagem) sejam adicionados, commitados e enviados ao repositório.\n",
        "\n",
        "**Como funciona:**\n",
        "Configura o git, adiciona o arquivo desejado, faz commit e push para o repositório remoto."
      ],
      "metadata": {
        "id": "M5iL_9BoIoj7"
      },
      "id": "M5iL_9BoIoj7"
    },
    {
      "cell_type": "code",
      "source": [
        "# Célula 5: Commit e Push automáticos (rec.json e poster)\n",
        "# -------------------------------------------------------\n",
        "# Esta função agora aceita tanto um caminho único (str) quanto uma lista de caminhos (list) para realizar commit e push.\n",
        "# O comportamento original para um único arquivo é preservado, mas agora é possível realizar commit em lote,\n",
        "# conforme necessário para a estratégia de batch commit com threshold.\n",
        "\n",
        "def git_commit_and_push(file_paths, commit_message=\"Atualiza rec.json\"):\n",
        "    \"\"\"\n",
        "    Realiza git add, commit e push dos arquivos especificados.\n",
        "    - file_paths pode ser uma string (arquivo único) ou uma lista de arquivos.\n",
        "    - commit_message é a mensagem de commit utilizada.\n",
        "    \"\"\"\n",
        "    repo_dir = f\"/content/{GITHUB_REPO}\"\n",
        "    os.chdir(repo_dir)\n",
        "    subprocess.run([\"git\", \"config\", \"user.email\", \"contato@aserio.work\"])\n",
        "    subprocess.run([\"git\", \"config\", \"user.name\", \"SamuelPassamani\"])\n",
        "\n",
        "    # Permite tanto um arquivo único quanto uma lista de arquivos\n",
        "    if isinstance(file_paths, str):\n",
        "        file_paths = [file_paths]\n",
        "\n",
        "    # Adiciona cada arquivo ao staging do git\n",
        "    for file_path in file_paths:\n",
        "        subprocess.run([\"git\", \"add\", file_path])\n",
        "\n",
        "    # Realiza o commit (permite commit vazio por segurança)\n",
        "    subprocess.run([\"git\", \"commit\", \"-m\", commit_message, \"--allow-empty\"], check=False)\n",
        "\n",
        "    # Push para o repositório remoto usando autenticação via token\n",
        "    subprocess.run([\n",
        "        \"git\", \"push\", f\"https://{GITHUB_USER}:{GITHUB_TOKEN}@github.com/{GITHUB_USER}/{GITHUB_REPO}.git\"\n",
        "    ])"
      ],
      "metadata": {
        "id": "1aQn1G6yI6Gz"
      },
      "id": "1aQn1G6yI6Gz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Célula 6: Busca de Transmissões na API XCam, com Fallback via liveInfo e Busca Inteligente/Unitária\n",
        "\n",
        "**Objetivo:**  \n",
        "Busca as transmissões ativas na API principal da XCam, garantindo que o lote retornado esteja sempre completo até `LIMIT_DEFAULT` e que não haja duplicidade, consultando o log de transmissões em processamento.  \n",
        "Além disso, inclui uma função de busca unitária/inteligente de transmissões livres, fundamental para manter o processamento contínuo e o “lote cheio” conforme a lógica moderna do notebook.  \n",
        "Também assegura que cada transmissão tenha um poster válido: se o poster não estiver presente, for nulo ou inválido, o notebook gera automaticamente uma imagem de poster usando ffmpeg a partir da URL da transmissão ao vivo (.m3u8).\n",
        "\n",
        "**Como funciona:**\n",
        "\n",
        "* Para cada transmissão encontrada, retorna um dicionário com username, src (endereço do stream) e poster (imagem local gerada ou baixada).\n",
        "* Se for solicitado buscar usuários específicos, só retorna esses.\n",
        "* Caso algum usuário não tenha src na API principal, faz nova chamada à API `/liveInfo` para tentar encontrar o link da transmissão.\n",
        "* Caso o poster esteja ausente, vazio, nulo ou inválido (tanto na API principal quanto na liveInfo), o notebook gera e salva automaticamente uma imagem de poster via ffmpeg no momento do processamento.\n",
        "* Antes de adicionar uma transmissão ao lote, verifica se ela já está em processamento (consultando o log temporário) e se não há duplicidade na seleção.\n",
        "* O lote final respeita sempre o `LIMIT_DEFAULT` de transmissões válidas, preenchendo com fallback se necessário.\n",
        "\n",
        "**Atualizações e melhorias recentes:**\n",
        "\n",
        "- **Busca em lote otimizada:** Agora, ao buscar transmissões para preencher o lote, a função utiliza um `limit` alto (ex: 1500) e `page=1`, recebendo todas as transmissões online de uma só vez. Isso reduz o número de requisições, acelera o preenchimento do lote e melhora a eficiência de todo o processamento.\n",
        "- **Busca unitária otimizada:** A busca unitária (`buscar_proxima_transmissao_livre`) também foi ajustada para buscar todas as transmissões online em uma única chamada (limit alto, page=1), retornando rapidamente a próxima transmissão livre e válida, sem precisar varrer página por página.\n",
        "- **Eficiência e paralelismo:** Essas melhorias garantem que o supervisor consiga manter o lote sempre cheio, caso existam transmissões disponíveis, e que o uso de processamento paralelo seja maximizado.\n",
        "- **Controle de duplicidade robusto:** O sistema continua consultando o log de transmissões em processamento, garantindo que transmissões já processadas ou em andamento não sejam selecionadas novamente.\n",
        "- **Compatibilidade mantida:** O comportamento para busca de usuários específicos permanece inalterado e totalmente compatível com as demais funções do notebook.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "BZ4c3Uk1I7AK"
      },
      "id": "BZ4c3Uk1I7AK"
    },
    {
      "cell_type": "code",
      "source": [
        "# Célula 6: Busca de transmissões na API XCam, com fallback via liveInfo e busca unitária/inteligente (OTIMIZADA)\n",
        "# ----------------------------------------------------------------------------------------------------------------\n",
        "# Nesta versão, tanto a busca em lote quanto a busca unitária buscam TODAS as transmissões online de uma vez só (limit alto, page=1).\n",
        "# Isso garante máxima eficiência, reduz o número de requisições à API e mantém o lote sempre cheio, respeitando LIMIT_DEFAULT.\n",
        "# Os comentários detalham cada etapa para facilitar manutenção, depuração e entendimento do fluxo.\n",
        "\n",
        "def get_broadcasts(limit=LIMIT_DEFAULT, page=PAGE_DEFAULT, usuarios_especificos=None, temp_folder=\"/content\"):\n",
        "    \"\"\"\n",
        "    Busca transmissões ao vivo via API principal da XCam.\n",
        "    Se usuarios_especificos for fornecido (lista), retorna apenas essas transmissões.\n",
        "    Caso contrário, busca todas as transmissões online em uma única chamada (limit alto, page=1),\n",
        "    preenchendo o lote até o máximo permitido por 'limit' (ex: 25).\n",
        "    Faz fallback via liveInfo para transmissões sem src.\n",
        "    Garante poster válido: se ausente, gera com ffmpeg a partir do src/m3u8.\n",
        "    Evita duplicidade (checa log de transmissões em processamento) e respeita LIMIT_DEFAULT.\n",
        "    \"\"\"\n",
        "    LOG_PROCESSAMENTO_PATH = \"/content/xcam_processing.log\"\n",
        "\n",
        "    # Carrega transmissões já em processamento para evitar duplicidade\n",
        "    transmissao_em_proc = set()\n",
        "    if os.path.exists(LOG_PROCESSAMENTO_PATH):\n",
        "        with open(LOG_PROCESSAMENTO_PATH, \"r\") as f:\n",
        "            transmissao_em_proc = set([line.strip() for line in f if line.strip()])\n",
        "\n",
        "    # Escolhe a URL da API conforme o modo (usuários específicos ou todos)\n",
        "    if usuarios_especificos:\n",
        "        api_url_main = f\"https://api.xcam.gay/?limit={API_SEARCH_LIMIT}&page=1\"\n",
        "        print(f\"🌐 Acessando API principal (usuários específicos): {api_url_main}\")\n",
        "    else:\n",
        "        api_url_main = f\"https://api.xcam.gay/?limit=1500&page=1\"\n",
        "        print(f\"🌐 Acessando API principal (todas transmissões online): {api_url_main}\")\n",
        "\n",
        "    streams_from_main = []\n",
        "    streams_without_preview = []\n",
        "\n",
        "    try:\n",
        "        response_main = requests.get(api_url_main)\n",
        "        response_main.raise_for_status()\n",
        "        data_main = response_main.json()\n",
        "        broadcasts_data = data_main.get(\"broadcasts\")\n",
        "        if not broadcasts_data:\n",
        "            print(\"⚠️ Chave 'broadcasts' não encontrada na resposta da API principal.\")\n",
        "            return []\n",
        "        items = broadcasts_data.get(\"items\")\n",
        "        if not isinstance(items, list):\n",
        "            print(f\"⚠️ Chave 'items' não encontrada ou não é uma lista em 'broadcasts'.\")\n",
        "            return []\n",
        "\n",
        "        # Percorre todas as transmissões retornadas pela API principal\n",
        "        for item in items:\n",
        "            preview = item.get(\"preview\") or {}\n",
        "            src = preview.get(\"src\")\n",
        "            poster = preview.get(\"poster\")\n",
        "            username = item.get(\"username\", \"desconhecido\")\n",
        "            # Evita duplicidade: só adiciona se não estiver em processamento\n",
        "            if username in transmissao_em_proc:\n",
        "                continue\n",
        "            if usuarios_especificos and username not in usuarios_especificos:\n",
        "                continue\n",
        "            if src:\n",
        "                poster_path = None\n",
        "                if poster and isinstance(poster, str) and poster.strip():\n",
        "                    poster_path = download_and_save_poster(poster, username, temp_folder)\n",
        "                if not is_poster_valid(poster_path):\n",
        "                    poster_path = generate_poster_with_ffmpeg(src, username, temp_folder)\n",
        "                streams_from_main.append({\n",
        "                    \"username\": username,\n",
        "                    \"src\": src,\n",
        "                    \"poster\": poster_path\n",
        "                })\n",
        "            else:\n",
        "                streams_without_preview.append({\"username\": username})\n",
        "\n",
        "        print(f\"✅ {len(streams_from_main)} transmissões com URL na API principal (total consultado).\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Erro ao acessar API principal: {e}\")\n",
        "        return []\n",
        "\n",
        "    # Fallback: busca via liveInfo para streams sem URL na API principal\n",
        "    streams_from_liveinfo = []\n",
        "    if streams_without_preview:\n",
        "        print(f\"🔁 Buscando liveInfo para {len(streams_without_preview)} streams sem URL na API principal...\")\n",
        "        for stream_info in streams_without_preview:\n",
        "            username = stream_info[\"username\"]\n",
        "            if username in transmissao_em_proc:\n",
        "                continue\n",
        "            if usuarios_especificos and username not in usuarios_especificos:\n",
        "                continue\n",
        "            api_url_liveinfo = f\"https://api.xcam.gay/user/{username}/liveInfo\"\n",
        "            try:\n",
        "                response_liveinfo = requests.get(api_url_liveinfo)\n",
        "                response_liveinfo.raise_for_status()\n",
        "                data_liveinfo = response_liveinfo.json()\n",
        "                m3u8_url = data_liveinfo.get(\"cdnURL\") or data_liveinfo.get(\"edgeURL\")\n",
        "                poster_path = None\n",
        "                if m3u8_url:\n",
        "                    poster_path = generate_poster_with_ffmpeg(m3u8_url, username, temp_folder)\n",
        "                    streams_from_liveinfo.append({\n",
        "                        \"username\": username,\n",
        "                        \"src\": m3u8_url,\n",
        "                        \"poster\": poster_path\n",
        "                    })\n",
        "                else:\n",
        "                    print(f\"⚠️ liveInfo de {username} não retornou cdnURL/edgeURL (usuário possivelmente offline).\")\n",
        "            except Exception as ex:\n",
        "                print(f\"❌ Erro ao buscar liveInfo para {username}: {ex}\")\n",
        "            time.sleep(0.5)\n",
        "\n",
        "    # Junta, evita duplicidade de usuário e respeita 'limit' FINAL\n",
        "    final_streams_list = []\n",
        "    seen_usernames = set()\n",
        "    for stream in streams_from_main + streams_from_liveinfo:\n",
        "        username = stream[\"username\"]\n",
        "        if username in seen_usernames or username in transmissao_em_proc:\n",
        "            continue\n",
        "        final_streams_list.append(stream)\n",
        "        seen_usernames.add(username)\n",
        "        if len(final_streams_list) >= limit:\n",
        "            break\n",
        "\n",
        "    print(f\"🔎 Selecionadas {len(final_streams_list)} streams válidas após fallback (respeitando limit={limit}).\")\n",
        "    return final_streams_list\n",
        "\n",
        "def buscar_usuarios_especificos(usuarios_lista, temp_folder=\"/content\"):\n",
        "    \"\"\"\n",
        "    Busca usuários específicos via API, utilizando um limit alto.\n",
        "    Fallback via liveInfo para usuários sem src.\n",
        "    Garante poster válido: se ausente, gera com ffmpeg a partir do src/m3u8.\n",
        "    Considera log de transmissões em processamento para evitar duplicidade.\n",
        "    \"\"\"\n",
        "    LOG_PROCESSAMENTO_PATH = \"/content/xcam_processing.log\"\n",
        "    transmissao_em_proc = set()\n",
        "    if os.path.exists(LOG_PROCESSAMENTO_PATH):\n",
        "        with open(LOG_PROCESSAMENTO_PATH, \"r\") as f:\n",
        "            transmissao_em_proc = set([line.strip() for line in f if line.strip()])\n",
        "\n",
        "    api_url = f\"https://api.xcam.gay/?limit={API_SEARCH_LIMIT}&page=1\"\n",
        "    print(f\"🔍 Buscando usuários específicos em {api_url}\")\n",
        "    try:\n",
        "        response = requests.get(api_url)\n",
        "        response.raise_for_status()\n",
        "        data = response.json()\n",
        "        items = data.get(\"broadcasts\", {}).get(\"items\", [])\n",
        "        encontrados = []\n",
        "        sem_src = []\n",
        "        for item in items:\n",
        "            username = item.get(\"username\", \"\")\n",
        "            if username in usuarios_lista and username not in transmissao_em_proc:\n",
        "                preview = item.get(\"preview\") or {}\n",
        "                src = preview.get(\"src\")\n",
        "                poster = preview.get(\"poster\")\n",
        "                poster_path = None\n",
        "                if src:\n",
        "                    if poster and isinstance(poster, str) and poster.strip():\n",
        "                        poster_path = download_and_save_poster(poster, username, temp_folder)\n",
        "                    if not is_poster_valid(poster_path):\n",
        "                        poster_path = generate_poster_with_ffmpeg(src, username, temp_folder)\n",
        "                    encontrados.append({\n",
        "                        \"username\": username,\n",
        "                        \"src\": src,\n",
        "                        \"poster\": poster_path\n",
        "                    })\n",
        "                else:\n",
        "                    sem_src.append(username)\n",
        "        for username in sem_src:\n",
        "            if username in transmissao_em_proc:\n",
        "                continue\n",
        "            api_url_liveinfo = f\"https://api.xcam.gay/user/{username}/liveInfo\"\n",
        "            try:\n",
        "                response_liveinfo = requests.get(api_url_liveinfo)\n",
        "                response_liveinfo.raise_for_status()\n",
        "                data_liveinfo = response_liveinfo.json()\n",
        "                m3u8_url = data_liveinfo.get(\"cdnURL\") or data_liveinfo.get(\"edgeURL\")\n",
        "                poster_path = None\n",
        "                if m3u8_url:\n",
        "                    poster_path = generate_poster_with_ffmpeg(m3u8_url, username, temp_folder)\n",
        "                    encontrados.append({\n",
        "                        \"username\": username,\n",
        "                        \"src\": m3u8_url,\n",
        "                        \"poster\": poster_path\n",
        "                    })\n",
        "                else:\n",
        "                    print(f\"⚠️ liveInfo de {username} não retornou cdnURL/edgeURL (usuário possivelmente offline).\")\n",
        "            except Exception as ex:\n",
        "                print(f\"❌ Erro ao buscar liveInfo para {username}: {ex}\")\n",
        "            time.sleep(0.5)\n",
        "        print(f\"Encontrados {len(encontrados)} dos {len(usuarios_lista)} usuários procurados (incluindo fallback).\")\n",
        "        return encontrados\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Erro ao buscar usuários específicos: {e}\")\n",
        "        return []\n",
        "\n",
        "def buscar_proxima_transmissao_livre(temp_folder=\"/content\"):\n",
        "    \"\"\"\n",
        "    Busca unitária/inteligente: retorna a PRÓXIMA transmissão AO VIVO não processada e já com poster válido.\n",
        "    Agora otimizada: em vez de varrer página por página, busca todas as transmissões online de uma vez só (limit alto, page=1).\n",
        "    Assim, reduz número de requisições, encontra rapidamente a próxima vaga disponível e evita downloads desnecessários.\n",
        "    \"\"\"\n",
        "    LOG_PROCESSAMENTO_PATH = \"/content/xcam_processing.log\"\n",
        "    transmissao_em_proc = set()\n",
        "    if os.path.exists(LOG_PROCESSAMENTO_PATH):\n",
        "        with open(LOG_PROCESSAMENTO_PATH, \"r\") as f:\n",
        "            transmissao_em_proc = set([line.strip() for line in f if line.strip()])\n",
        "\n",
        "    api_url_main = f\"https://api.xcam.gay/?limit=1500&page=1\"\n",
        "    print(f\"🔎 Buscando próxima transmissão livre (todas de uma vez): {api_url_main}\")\n",
        "    try:\n",
        "        response_main = requests.get(api_url_main)\n",
        "        response_main.raise_for_status()\n",
        "        data_main = response_main.json()\n",
        "        items = data_main.get(\"broadcasts\", {}).get(\"items\", [])\n",
        "        for item in items:\n",
        "            username = item.get(\"username\", \"desconhecido\")\n",
        "            if username in transmissao_em_proc:\n",
        "                continue\n",
        "            preview = item.get(\"preview\") or {}\n",
        "            src = preview.get(\"src\")\n",
        "            poster = preview.get(\"poster\")\n",
        "            # Só seleciona se houver src válido\n",
        "            if src:\n",
        "                poster_path = None\n",
        "                if poster and isinstance(poster, str) and poster.strip():\n",
        "                    poster_path = download_and_save_poster(poster, username, temp_folder)\n",
        "                if not is_poster_valid(poster_path):\n",
        "                    poster_path = generate_poster_with_ffmpeg(src, username, temp_folder)\n",
        "                print(f\"🎯 Transmissão livre encontrada: {username}\")\n",
        "                return {\n",
        "                    \"username\": username,\n",
        "                    \"src\": src,\n",
        "                    \"poster\": poster_path\n",
        "                }\n",
        "            else:\n",
        "                # Fallback para o PRIMEIRO candidato sem src\n",
        "                api_url_liveinfo = f\"https://api.xcam.gay/user/{username}/liveInfo\"\n",
        "                try:\n",
        "                    response_liveinfo = requests.get(api_url_liveinfo)\n",
        "                    response_liveinfo.raise_for_status()\n",
        "                    data_liveinfo = response_liveinfo.json()\n",
        "                    m3u8_url = data_liveinfo.get(\"cdnURL\") or data_liveinfo.get(\"edgeURL\")\n",
        "                    poster_path = None\n",
        "                    if m3u8_url:\n",
        "                        poster_path = generate_poster_with_ffmpeg(m3u8_url, username, temp_folder)\n",
        "                        print(f\"🎯 Transmissão livre (pelo liveInfo) encontrada: {username}\")\n",
        "                        return {\n",
        "                            \"username\": username,\n",
        "                            \"src\": m3u8_url,\n",
        "                            \"poster\": poster_path\n",
        "                        }\n",
        "                except Exception as ex:\n",
        "                    print(f\"❌ Erro ao buscar liveInfo para {username}: {ex}\")\n",
        "                time.sleep(0.5)\n",
        "        print(\"🚫 Nenhuma transmissão livre encontrada após varrer todas online.\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Erro ao buscar transmissões online: {e}\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "h1jr7D0pJ7jS"
      },
      "id": "h1jr7D0pJ7jS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Célula 7: Gravação da Stream, Download/Geração do Poster, Controle de Tempo Mínimo e Gerenciamento de Log\n",
        "\n",
        "**Objetivo:**  \n",
        "Grava a transmissão ao vivo do usuário usando ffmpeg. Durante a gravação, baixa o poster da transmissão ou, caso ele esteja ausente, inválido ou não possa ser baixado, gera automaticamente uma imagem de poster utilizando ffmpeg a partir da própria stream. Ao final, verifica se o tempo de gravação atingiu o mínimo desejado para ser considerado válido.  \n",
        "Agora, além disso, atualiza o log de transmissões em processamento ao iniciar e sempre remove ao finalizar a gravação (com sucesso ou erro), garantindo o controle, a unicidade e evitando vazamento de processamento no sistema.\n",
        "\n",
        "**Como funciona:**\n",
        "\n",
        "*  Se o vídeo gravado for muito curto, descarta imediatamente o vídeo e o poster associado.\n",
        "*  Se atingir o tempo mínimo, renomeia o vídeo, faz upload, renomeia o poster e chama a função de atualização de JSON.\n",
        "*  Antes de iniciar a gravação, registra o usuário no log de transmissões em processamento; ao finalizar (com sucesso ou erro/exception), remove o usuário desse log para liberar espaço para novas transmissões.\n",
        "*  Garante que sempre haverá um poster válido para cada transmissão, baixando da API quando possível ou gerando automaticamente com ffmpeg caso necessário.\n",
        "*  Inclui limpeza de arquivos temporários após upload para otimizar o uso de espaço e manter o ambiente Colab organizado.\n",
        "*  A manipulação do log é feita de modo robusto, mesmo em situações de erro ou interrupção, evitando inconsistências no processamento contínuo/paralelo.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "jGFyqOUoKEF7"
      },
      "id": "jGFyqOUoKEF7"
    },
    {
      "cell_type": "code",
      "source": [
        "# Célula 7: Gravação de stream, download/geração do poster, atualização e remoção do log ao finalizar\n",
        "# -------------------------------------------------------------------------------------------------\n",
        "# Esta célula garante controle rigoroso do log de transmissões em processamento:\n",
        "# - Adiciona o usuário ao log no início da gravação.\n",
        "# - Remove do log assim que a gravação encerra (com sucesso ou erro), mesmo em caso de exceção.\n",
        "# - Manipulação do log é robusta, evitando duplicidade e vazamentos.\n",
        "# - Garante limpeza de arquivos temporários após uso.\n",
        "# - Calcula a duração real do arquivo usando ffprobe para garantir a validade da gravação.\n",
        "\n",
        "def get_video_duration(filepath):\n",
        "    \"\"\"\n",
        "    Utiliza ffprobe para obter a duração real do arquivo mp4, em segundos.\n",
        "    Retorna None em caso de erro.\n",
        "    \"\"\"\n",
        "    import subprocess\n",
        "    import json\n",
        "    try:\n",
        "        cmd = [\n",
        "            \"ffprobe\", \"-v\", \"error\",\n",
        "            \"-show_entries\", \"format=duration\",\n",
        "            \"-of\", \"json\",\n",
        "            filepath\n",
        "        ]\n",
        "        result = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
        "        info = json.loads(result.stdout)\n",
        "        duration = float(info[\"format\"][\"duration\"])\n",
        "        return int(round(duration))\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ Não foi possível obter duração via ffprobe: {e}\")\n",
        "        return None\n",
        "\n",
        "def gravar_stream(username, m3u8_url, poster_url=None, poster_frame_time=7):\n",
        "    \"\"\"\n",
        "    Grava a transmissão ao vivo do usuário usando ffmpeg.\n",
        "    - Garante poster válido: baixa da poster_url, ou gera automaticamente com ffmpeg se ausente/inválido.\n",
        "    - Controla o tempo mínimo de gravação e gerencia o log de transmissões em processamento.\n",
        "    - Remove do log ao finalizar a gravação, independentemente do resultado.\n",
        "    - Limpa arquivos temporários ao final.\n",
        "    poster_frame_time: tempo (em segundos) do vídeo onde a captura do poster será feita, se gerado via ffmpeg.\n",
        "    \"\"\"\n",
        "    LOG_PROCESSAMENTO_PATH = \"/content/xcam_processing.log\"\n",
        "\n",
        "    # Adiciona a transmissão ao log de transmissões em processamento (thread-safe se usar lock)\n",
        "    try:\n",
        "        with open(LOG_PROCESSAMENTO_PATH, \"a\") as f:\n",
        "            f.write(f\"{username}\\n\")\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Erro ao registrar transmissão em processamento no log: {e}\")\n",
        "\n",
        "    start_time_dt = datetime.now()\n",
        "    data_str = start_time_dt.strftime(\"%d-%m-%Y\")\n",
        "    horario_str = start_time_dt.strftime(\"%H-%M\")\n",
        "    temp_filename = f\"{username}_{start_time_dt.strftime('%Y%m%d_%H%M%S')}_temp.mp4\"\n",
        "    filepath = os.path.join(TEMP_OUTPUT_FOLDER, temp_filename)\n",
        "\n",
        "    print(f\"\\n🎬 Iniciando gravação de: {username} (URL: {m3u8_url}) em {filepath}\")\n",
        "\n",
        "    # Garantia de poster válido:\n",
        "    poster_temp_path = None\n",
        "    if poster_url:\n",
        "        poster_temp_path = download_and_save_poster(poster_url, username, TEMP_OUTPUT_FOLDER)\n",
        "    if not is_poster_valid(poster_temp_path) and m3u8_url:\n",
        "        poster_temp_path = generate_poster_with_ffmpeg(\n",
        "            m3u8_url, username, TEMP_OUTPUT_FOLDER, frame_time=poster_frame_time\n",
        "        )\n",
        "\n",
        "    ffmpeg_cmd = [\"ffmpeg\", \"-i\", m3u8_url, \"-t\", str(RECORD_SECONDS), \"-c\", \"copy\", \"-y\", filepath]\n",
        "\n",
        "    start_time_process = time.time()\n",
        "    process = None\n",
        "\n",
        "    try:\n",
        "        process = subprocess.Popen(\n",
        "            ffmpeg_cmd,\n",
        "            stdout=subprocess.PIPE,\n",
        "            stderr=subprocess.STDOUT,\n",
        "            text=True,\n",
        "            bufsize=1,\n",
        "            universal_newlines=True\n",
        "        )\n",
        "        # Monitora o andamento do ffmpeg em tempo real (mantido para logs)\n",
        "        elapsed_seconds = 0\n",
        "        last_log_minute = -1\n",
        "        while True:\n",
        "            line = process.stdout.readline()\n",
        "            if not line and process.poll() is not None:\n",
        "                break\n",
        "            if \"time=\" in line:\n",
        "                try:\n",
        "                    match = re.search(r\"time=(\\d+):(\\d+):(\\d+)\", line)\n",
        "                    if match:\n",
        "                        h, m, s = map(int, match.groups())\n",
        "                        elapsed_seconds = h * 3600 + m * 60 + s\n",
        "                        if elapsed_seconds // 60 != last_log_minute:\n",
        "                            log_progress(username, elapsed_seconds, RECORD_SECONDS)\n",
        "                            last_log_minute = elapsed_seconds // 60\n",
        "                except Exception:\n",
        "                    pass\n",
        "\n",
        "        process.wait()\n",
        "        end_time_process = time.time()\n",
        "        elapsed_seconds_proc = round(end_time_process - start_time_process)\n",
        "        log_progress(username, elapsed_seconds_proc, RECORD_SECONDS)\n",
        "\n",
        "        if process.returncode != 0:\n",
        "            print(f\"❌ FFmpeg falhou para {username}. Código de saída: {process.returncode}\")\n",
        "            return {\n",
        "                'username': username,\n",
        "                'filename': temp_filename,\n",
        "                'filepath': filepath,\n",
        "                'upload_success': False,\n",
        "                'abyss_response': \"Gravação FFmpeg falhou\"\n",
        "            }\n",
        "        else:\n",
        "            elapsed_seconds_real = get_video_duration(filepath)\n",
        "            if elapsed_seconds_real is not None:\n",
        "                print(f\"✅ Duração real do arquivo gravado: {elapsed_seconds_real}s (ffprobe)\")\n",
        "            else:\n",
        "                print(f\"⚠️ Não foi possível aferir duração real, usando a do processo: {elapsed_seconds_proc}s\")\n",
        "                elapsed_seconds_real = elapsed_seconds_proc\n",
        "\n",
        "            # Validação pelo tempo real do arquivo!\n",
        "            if elapsed_seconds_real < RECORD_SECONDS_MIN:\n",
        "                print(f\"⏩ Duração gravada ({elapsed_seconds_real}s) menor que o mínimo ({RECORD_SECONDS_MIN}s). Arquivo descartado.\")\n",
        "                if os.path.exists(filepath): os.remove(filepath)\n",
        "                if poster_temp_path and os.path.exists(poster_temp_path): os.remove(poster_temp_path)\n",
        "                return {\n",
        "                    'username': username,\n",
        "                    'filename': temp_filename,\n",
        "                    'filepath': filepath,\n",
        "                    'upload_success': False,\n",
        "                    'abyss_response': \"Gravação muito curta (descartada)\"\n",
        "                }\n",
        "\n",
        "            tempo_formatado = format_seconds(elapsed_seconds_real)\n",
        "            final_filename = f\"{username}_{data_str}_{horario_str}_{tempo_formatado}.mp4\"\n",
        "            final_filepath = os.path.join(TEMP_OUTPUT_FOLDER, final_filename)\n",
        "\n",
        "            try:\n",
        "                os.rename(filepath, final_filepath)\n",
        "                print(f\"✅ Arquivo renomeado para: {final_filename}\")\n",
        "                filepath_for_upload = final_filepath\n",
        "                filename_for_upload = final_filename\n",
        "            except Exception as e:\n",
        "                print(f\"❌ Erro ao renomear arquivo {temp_filename} para {final_filename}: {e}\")\n",
        "                filepath_for_upload = filepath\n",
        "                filename_for_upload = temp_filename\n",
        "\n",
        "            success, abyss_resp, slug = upload_to_abyss_and_update_json(\n",
        "                filepath_for_upload, username, elapsed_seconds_real,\n",
        "                poster_temp_path=poster_temp_path\n",
        "            )\n",
        "\n",
        "            return {\n",
        "                'username': username,\n",
        "                'filename': filename_for_upload,\n",
        "                'filepath': filepath_for_upload,\n",
        "                'upload_success': success,\n",
        "                'abyss_response': abyss_resp,\n",
        "                'slug': slug\n",
        "            }\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"❌ Erro: Comando 'ffmpeg' não encontrado. Certifique-se de que foi instalado corretamente.\")\n",
        "        return {\n",
        "            'username': username,\n",
        "            'filename': None,\n",
        "            'filepath': None,\n",
        "            'upload_success': False,\n",
        "            'abyss_response': \"Comando FFmpeg não encontrado\"\n",
        "        }\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Erro inesperado durante a execução do FFmpeg para {username}: {e}\")\n",
        "        return {\n",
        "            'username': username,\n",
        "            'filename': None,\n",
        "            'filepath': None,\n",
        "            'upload_success': False,\n",
        "            'abyss_response': f\"Erro inesperado na execução do FFmpeg: {e}\"\n",
        "        }\n",
        "    finally:\n",
        "        # Remove a transmissão do log de transmissões em processamento (robusto e seguro)\n",
        "        try:\n",
        "            if os.path.exists(LOG_PROCESSAMENTO_PATH):\n",
        "                with open(LOG_PROCESSAMENTO_PATH, \"r\") as f:\n",
        "                    linhas = f.readlines()\n",
        "                with open(LOG_PROCESSAMENTO_PATH, \"w\") as f:\n",
        "                    for l in linhas:\n",
        "                        if l.strip() != username:\n",
        "                            f.write(l)\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Erro ao remover transmissão do log de processamento: {e}\")\n",
        "\n",
        "        # Limpa o arquivo de vídeo temporário após upload (para não ocupar espaço no Colab)\n",
        "        if 'filepath_for_upload' in locals() and os.path.exists(filepath_for_upload):\n",
        "            try:\n",
        "                os.remove(filepath_for_upload)\n",
        "                print(f\"🗑️ Arquivo de vídeo removido do Colab: {filepath_for_upload}\")\n",
        "            except Exception as e:\n",
        "                print(f\"⚠️ Não foi possível remover o arquivo de vídeo temporário: {e}\")"
      ],
      "metadata": {
        "id": "eJ_jrfNgKZNr"
      },
      "id": "eJ_jrfNgKZNr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Célula 8: Upload para Abyss.to, Atualização do rec.json, Commit do Poster\n",
        "\n",
        "**Objetivo:**  \n",
        "Faz upload do vídeo para o Abyss.to. Se o upload for bem-sucedido, renomeia/move o poster para a pasta correta do repositório, atualiza ou cria o arquivo rec.json do usuário com todos os metadados (incluindo poster e urlIframe) e realiza o commit/push dos arquivos alterados.  \n",
        "Agora, os commits e pushs são feitos em lote, apenas quando a quantidade de arquivos alterados atinge o valor definido por `COMMIT_PUSH_THRESHOLD`, otimizando o fluxo de trabalho e reduzindo o número de operações no repositório. Também garante que o poster utilizado (baixado ou gerado via ffmpeg) é corretamente movido, registrado e copiado para o Google Drive (se montado).\n",
        "\n",
        "**Como funciona:**\n",
        "\n",
        "*   Preenche todos os campos do JSON conforme seu padrão, incluindo poster e urlIframe.\n",
        "*   Garante que apenas vídeos válidos sejam registrados e compartilha os links corretos.\n",
        "*   Move/renomeia o arquivo do poster utilizado para o local definitivo, sempre associando ao vídeo pelo slug no nome do arquivo.\n",
        "*   Ao invés de commitar/pushar a cada alteração, acumula os arquivos modificados em um buffer e só realiza o commit/push ao atingir o threshold definido (`COMMIT_PUSH_THRESHOLD`). No final do processamento, realiza commit/push dos arquivos restantes, se houver.\n",
        "*   O acesso ao buffer de commit/push é protegido por um lock para garantir segurança em cenários de execução concorrente/processamento paralelo.\n",
        "*   Remove arquivos temporários de poster após mover para o destino final, mantendo o ambiente limpo e eficiente.\n",
        "*   Sempre que salvar ou atualizar rec.json ou poster, faz uma cópia também para a pasta correspondente no Google Drive, garantindo redundância e fácil acesso externo.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "YjGKDlbIKaLs"
      },
      "id": "YjGKDlbIKaLs"
    },
    {
      "cell_type": "code",
      "source": [
        "# Célula 8: Upload para Abyss.to, atualização do rec.json, commit do poster (com cópia p/ Google Drive)\n",
        "# ----------------------------------------------------------------------------------------------------\n",
        "# Esta célula é responsável por:\n",
        "# - Fazer upload do vídeo gravado para Abyss.to.\n",
        "# - Atualizar e registrar os metadados no arquivo rec.json do usuário.\n",
        "# - Mover/renomear o poster (imagem) para o local correto, sempre usando o novo poster (baixado ou gerado via ffmpeg).\n",
        "# - Acumular arquivos para commit/push e executar o envio ao atingir o threshold de alterações, com segurança para concorrência.\n",
        "# - Fazer a limpeza de arquivos temporários após o uso.\n",
        "# - Sempre que salvar/atualizar rec.json ou poster, copia também para o Google Drive (se montado).\n",
        "#\n",
        "# ATENÇÃO: Para processamento paralelo, garante atomicidade do commit_buffer usando lock de threading.\n",
        "\n",
        "import shutil\n",
        "import threading\n",
        "\n",
        "# Caminho base do Drive (ajuste se necessário)\n",
        "DRIVE_USER_BASE = \"/content/drive/MyDrive/XCam.Drive/XCam/xcam-db/user\"\n",
        "\n",
        "# Lock global para garantir atomicidade do commit_buffer em cenários concorrentes\n",
        "commit_lock = threading.Lock()\n",
        "\n",
        "def upload_to_abyss_and_update_json(\n",
        "    filepath, username, duration_seconds, poster_temp_path=None,\n",
        "    commit_buffer=None, commit_threshold=None\n",
        "):\n",
        "    \"\"\"\n",
        "    Faz upload do vídeo, atualiza o rec.json e move o poster.\n",
        "    Acumula arquivos para commit/push e só executa quando atingir o threshold (ou 0).\n",
        "    Sempre salva/atualiza rec.json e poster também no Google Drive.\n",
        "    O acesso ao commit_buffer é protegido por lock para segurança em execução concorrente.\n",
        "    \"\"\"\n",
        "    file_name = os.path.basename(filepath)\n",
        "    file_type = 'video/mp4'\n",
        "    print(f\"⬆️ Upload de: {file_name} para Abyss.to...\")\n",
        "\n",
        "    upload_success = False\n",
        "    abyss_response = \"Upload falhou - Sem resposta\"\n",
        "    uploaded_url = None\n",
        "    video_id = None\n",
        "    slug = None\n",
        "\n",
        "    # Inicializa buffers se não enviados\n",
        "    if commit_buffer is None:\n",
        "        if not hasattr(upload_to_abyss_and_update_json, 'commit_buffer'):\n",
        "            upload_to_abyss_and_update_json.commit_buffer = []\n",
        "        commit_buffer = upload_to_abyss_and_update_json.commit_buffer\n",
        "\n",
        "    if commit_threshold is None:\n",
        "        global COMMIT_PUSH_THRESHOLD\n",
        "        commit_threshold = COMMIT_PUSH_THRESHOLD if 'COMMIT_PUSH_THRESHOLD' in globals() else 100\n",
        "\n",
        "    # ---- Upload do vídeo para Abyss.to ----\n",
        "    try:\n",
        "        with open(filepath, 'rb') as f:\n",
        "            files = { 'file': (file_name, f, file_type) }\n",
        "            response = requests.post(ABYSS_UPLOAD_URL, files=files)\n",
        "            resp_json = response.json()\n",
        "            abyss_response = resp_json\n",
        "            if resp_json.get('status'):\n",
        "                upload_success = True\n",
        "                uploaded_url = resp_json.get('url') or resp_json.get('urlIframe')\n",
        "                video_id = resp_json.get('slug') or resp_json.get('video')\n",
        "                slug = video_id\n",
        "                print(f\"📤 Upload bem-sucedido. URL: {uploaded_url} | SLUG: {slug}\")\n",
        "            else:\n",
        "                print(f\"❌ Falha no upload. Mensagem: {resp_json.get('message','')}\")\n",
        "    except Exception as e:\n",
        "        abyss_response = f\"Erro no upload: {e}\"\n",
        "        print(f\"❌ Erro no upload: {e}\")\n",
        "\n",
        "    poster_final_relpath = None\n",
        "    poster_final_path = None\n",
        "    poster_final_name = None\n",
        "\n",
        "    # ---- Move/renomeia o poster (imagem) para o local correto do usuário ----\n",
        "    if upload_success and poster_temp_path and slug:\n",
        "        try:\n",
        "            user_folder = os.path.join(BASE_REPO_FOLDER, \"xcam-db\", \"user\", username)\n",
        "            os.makedirs(user_folder, exist_ok=True)\n",
        "            poster_final_name = f\"{slug}.jpg\"\n",
        "            poster_final_path = os.path.join(user_folder, poster_final_name)\n",
        "            os.rename(poster_temp_path, poster_final_path)\n",
        "            poster_final_relpath = os.path.relpath(poster_final_path, BASE_REPO_FOLDER)\n",
        "            print(f\"🖼️ Poster movido para {poster_final_path}\")\n",
        "            # Adiciona poster ao buffer de commit (com lock)\n",
        "            with commit_lock:\n",
        "                if poster_final_relpath not in commit_buffer:\n",
        "                    commit_buffer.append(poster_final_relpath)\n",
        "            # ---------- NOVO: Copia poster para o Google Drive ----------\n",
        "            drive_user_dir = os.path.join(DRIVE_USER_BASE, username)\n",
        "            os.makedirs(drive_user_dir, exist_ok=True)\n",
        "            poster_drive_path = os.path.join(drive_user_dir, poster_final_name)\n",
        "            try:\n",
        "                shutil.copy2(poster_final_path, poster_drive_path)\n",
        "                print(f\"🗂️ Poster também salvo no Drive: {poster_drive_path}\")\n",
        "            except Exception as e:\n",
        "                print(f\"⚠️ Falha ao copiar poster para o Drive: {e}\")\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Erro ao mover/renomear poster: {e}\")\n",
        "\n",
        "    # ---- Atualiza/Cria rec.json do usuário com os dados do vídeo ----\n",
        "    if upload_success:\n",
        "        try:\n",
        "            user_folder = os.path.join(BASE_REPO_FOLDER, \"xcam-db\", \"user\", username)\n",
        "            os.makedirs(user_folder, exist_ok=True)\n",
        "            json_filepath = os.path.join(user_folder, \"rec.json\")\n",
        "\n",
        "            file_base = file_name.replace('.mp4', '')\n",
        "            parts = file_base.split('_')\n",
        "            if len(parts) >= 4:\n",
        "                json_data = parts[-3]\n",
        "                json_horario = parts[-2]\n",
        "                json_tempo = parts[-1]\n",
        "            else:\n",
        "                now = datetime.now()\n",
        "                json_data = now.strftime(\"%d-%m-%Y\")\n",
        "                json_horario = now.strftime(\"%H-%M\")\n",
        "                json_tempo = format_seconds(duration_seconds)\n",
        "\n",
        "            poster_url = f\"https://db.xcam.gay/user/{username}/{slug}.jpg\" if slug else \"\"\n",
        "            url_iframe = f\"https://short.icu/{slug}?thumbnail={poster_url}\" if slug else \"\"\n",
        "\n",
        "            new_video_entry = {\n",
        "                \"video\": slug if slug else \"ID_não_retornado\",\n",
        "                \"title\": file_base,\n",
        "                \"file\": file_name,\n",
        "                \"url\": uploaded_url if uploaded_url else \"URL_não_retornada\",\n",
        "                \"poster\": poster_url,\n",
        "                \"urlIframe\": url_iframe,\n",
        "                \"data\": json_data,\n",
        "                \"horario\": json_horario,\n",
        "                \"tempo\": json_tempo\n",
        "            }\n",
        "\n",
        "            def zerar_base(username):\n",
        "                return {\n",
        "                    \"username\": username,\n",
        "                    \"records\": 0,\n",
        "                    \"videos\": []\n",
        "                }\n",
        "\n",
        "            # Carrega ou inicializa rec.json\n",
        "            if not os.path.exists(json_filepath):\n",
        "                rec_data = zerar_base(username)\n",
        "            else:\n",
        "                try:\n",
        "                    with open(json_filepath, 'r', encoding='utf-8') as f:\n",
        "                        loaded = json.load(f)\n",
        "                    valid = (\n",
        "                        isinstance(loaded, dict)\n",
        "                        and \"username\" in loaded\n",
        "                        and \"records\" in loaded\n",
        "                        and \"videos\" in loaded\n",
        "                        and isinstance(loaded[\"videos\"], list)\n",
        "                    )\n",
        "                    rec_data = loaded if valid else zerar_base(username)\n",
        "                except Exception:\n",
        "                    rec_data = zerar_base(username)\n",
        "\n",
        "            # Adiciona novo vídeo ao histórico\n",
        "            rec_data[\"records\"] += 1\n",
        "            rec_data[\"videos\"].append(new_video_entry)\n",
        "            with open(json_filepath, 'w', encoding='utf-8') as f:\n",
        "                json.dump(rec_data, f, indent=2, ensure_ascii=False)\n",
        "            print(f\"✅ rec.json para {username} atualizado em {json_filepath}\")\n",
        "\n",
        "            rel_json_path = os.path.relpath(json_filepath, BASE_REPO_FOLDER)\n",
        "            # Adiciona rec.json ao buffer de commit (com lock)\n",
        "            with commit_lock:\n",
        "                if rel_json_path not in commit_buffer:\n",
        "                    commit_buffer.append(rel_json_path)\n",
        "            # ---------- NOVO: Copia rec.json para o Google Drive ----------\n",
        "            drive_user_dir = os.path.join(DRIVE_USER_BASE, username)\n",
        "            os.makedirs(drive_user_dir, exist_ok=True)\n",
        "            try:\n",
        "                shutil.copy2(json_filepath, os.path.join(drive_user_dir, \"rec.json\"))\n",
        "                print(f\"🗂️ rec.json também salvo no Drive: {os.path.join(drive_user_dir, 'rec.json')}\")\n",
        "            except Exception as e:\n",
        "                print(f\"⚠️ Falha ao copiar rec.json para o Drive: {e}\")\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Erro ao atualizar rec.json: {e}\")\n",
        "            abyss_response = f\"Upload sucesso, erro no JSON: {e}\"\n",
        "\n",
        "    # ---- Commit/push automático ajustado ----\n",
        "    with commit_lock:\n",
        "        # Se threshold for 0, faz commit/push IMEDIATO após cada processamento bem-sucedido\n",
        "        if commit_threshold == 0 and len(commit_buffer) > 0:\n",
        "            print(f\"🚀 Commit/push automático IMEDIATO (threshold=0): {len(commit_buffer)} arquivos\")\n",
        "            try:\n",
        "                git_commit_and_push(commit_buffer, commit_message=\"Commit automático após processamento bem-sucedido\")\n",
        "            except Exception as e:\n",
        "                print(f\"❌ Falha no commit/push automático imediato: {e}\")\n",
        "            commit_buffer.clear()\n",
        "        # Caso threshold > 0, mantém o comportamento em lote\n",
        "        elif commit_threshold > 0 and len(commit_buffer) >= commit_threshold:\n",
        "            print(f\"🚀 Commit/push automático: {len(commit_buffer)} arquivos (threshold: {commit_threshold})\")\n",
        "            try:\n",
        "                git_commit_and_push(commit_buffer, commit_message=\"Atualiza arquivos em lote (threshold automático)\")\n",
        "            except Exception as e:\n",
        "                print(f\"❌ Falha no commit/push em lote: {e}\")\n",
        "            commit_buffer.clear()\n",
        "\n",
        "    # ---- Limpeza do arquivo de poster temporário, se sobrou ----\n",
        "    if poster_temp_path and os.path.exists(poster_temp_path):\n",
        "        try:\n",
        "            os.remove(poster_temp_path)\n",
        "            print(f\"🗑️ Poster temporário removido: {poster_temp_path}\")\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Não foi possível remover o poster temporário: {e}\")\n",
        "\n",
        "    return upload_success, abyss_response, slug\n",
        "\n",
        "# Função auxiliar para garantir commit/push dos arquivos restantes ao final do processamento.\n",
        "def commit_push_restantes():\n",
        "    \"\"\"\n",
        "    Realiza commit/push final de todos os arquivos pendentes no buffer.\n",
        "    O acesso ao buffer é protegido por lock para segurança em execução concorrente.\n",
        "    \"\"\"\n",
        "    buffer = getattr(upload_to_abyss_and_update_json, 'commit_buffer', None)\n",
        "    if buffer and len(buffer) > 0:\n",
        "        print(f\"🚀 Commit/push final de {len(buffer)} arquivos restantes\")\n",
        "        with commit_lock:\n",
        "            try:\n",
        "                git_commit_and_push(buffer, commit_message=\"Atualiza arquivos finais (commit final)\")\n",
        "            except Exception as e:\n",
        "                print(f\"❌ Falha no commit/push final em lote: {e}\")\n",
        "            buffer.clear()"
      ],
      "metadata": {
        "id": "vMTiCrJ5Kp81"
      },
      "id": "vMTiCrJ5Kp81",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Célula 9: Processamento Automático (Paralelo e Supervisor Contínuo)\n",
        "\n",
        "**Objetivo:**  \n",
        "Controla todo o fluxo operacional do notebook, processando transmissões de forma paralela para máxima eficiência. Utiliza as funções das células anteriores para buscar, gravar, processar, fazer upload e registrar os vídeos.  \n",
        "Agora, garante que o lote de transmissões seja sempre preenchido até o `LIMIT_DEFAULT`, controla a unicidade das transmissões em processamento (via log) e gerencia automaticamente o avanço e rotação das páginas.  \n",
        "O loop supervisor contínuo permite que o notebook opere de maneira autônoma, mantendo sempre o máximo de transmissões possíveis processando em paralelo, e faz commit/push dos arquivos pendentes ao término.\n",
        "\n",
        "**Como funciona:**\n",
        "\n",
        "*   Se o usuário informou nomes específicos, busca e grava apenas esses usuários.\n",
        "*   Caso contrário, processa normalmente por páginas, sempre mantendo o lote cheio até `LIMIT_DEFAULT`, pulando transmissões já em processamento ou duplicadas, e utilizando busca inteligente caso necessário para completar o lote.\n",
        "*   Mantém o loop até não encontrar mais transmissões disponíveis para processar.\n",
        "*   Exibe logs detalhados e controla a espera entre páginas para não sobrecarregar a API.\n",
        "*   Faz o controle e rotação das páginas automaticamente, garantindo que todas as transmissões possíveis sejam processadas.\n",
        "*   Ao final, garante commit/push dos arquivos alterados que ainda estejam no buffer, assegurando consistência dos dados e do repositório.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "iwgt8f8iKq4y"
      },
      "id": "iwgt8f8iKq4y"
    },
    {
      "cell_type": "code",
      "source": [
        "# Célula 9: Supervisor dinâmico e processamento automático contínuo (paralelo e interativo) das transmissões\n",
        "# ----------------------------------------------------------------------------------------------------------------\n",
        "# Esta célula implementa um supervisor dinâmico, mantendo o lote sempre cheio em tempo real.\n",
        "# Cada vaga livre é imediatamente preenchida, maximizando o uso do processamento paralelo.\n",
        "# O log do processo inclui informações detalhadas de cada etapa, ajudando no diagnóstico e monitoramento.\n",
        "\n",
        "# Célula 9: Supervisor dinâmico e processamento automático contínuo das transmissões\n",
        "\n",
        "def log_supervisor(msg, level=\"INFO\"):\n",
        "    from datetime import datetime\n",
        "    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "    print(f\"[{timestamp}] [{level}] {msg}\")\n",
        "\n",
        "def worker(username, m3u8_url, poster_url, results):\n",
        "    log_supervisor(f\"Iniciando gravação: {username} | URL: {m3u8_url} | Poster: {poster_url}\", \"WORKER\")\n",
        "    result = gravar_stream(username, m3u8_url, poster_url)\n",
        "    log_supervisor(\n",
        "        f\"Finalizou gravação: {username} | Sucesso: {result.get('upload_success')} | \"\n",
        "        f\"Arquivo: {result.get('filename')} | Abyss: {result.get('abyss_response')}\", \"WORKER\")\n",
        "    results.append(result)\n",
        "\n",
        "def supervisor_dinamico(usuarios_especificos=None):\n",
        "    from multiprocessing import Manager, Process\n",
        "    import time\n",
        "    import os\n",
        "\n",
        "    pool_size = LIMIT_DEFAULT if not usuarios_especificos else API_SEARCH_LIMIT\n",
        "    running = []\n",
        "    results = Manager().list()\n",
        "    seen_usernames = set()\n",
        "    LOG_PROCESSAMENTO_PATH = \"/content/xcam_processing.log\"\n",
        "\n",
        "    log_supervisor(f\"Supervisor dinâmico iniciado | Lote alvo: {pool_size} | Modo: {'específico' if usuarios_especificos else 'automático'}\")\n",
        "\n",
        "    def atualizar_seen_usernames():\n",
        "        # Lê do log para garantir duplicidade robusta mesmo em concorrência\n",
        "        if os.path.exists(LOG_PROCESSAMENTO_PATH):\n",
        "            with open(LOG_PROCESSAMENTO_PATH, \"r\") as f:\n",
        "                log_set = set([line.strip() for line in f if line.strip()])\n",
        "                seen_usernames.update(log_set)\n",
        "\n",
        "    def buscar_nova_transmissao():\n",
        "        atualizar_seen_usernames()  # Atualiza sempre antes de buscar\n",
        "        if usuarios_especificos:\n",
        "            candidatos = buscar_usuarios_especificos(usuarios_especificos)\n",
        "            for s in candidatos:\n",
        "                username = s[\"username\"]\n",
        "                if username not in seen_usernames:\n",
        "                    log_supervisor(f\"Nova transmissão encontrada (específico): {username}\", \"BUSCA\")\n",
        "                    return s\n",
        "            log_supervisor(\"Nenhuma transmissão específica livre encontrada.\", \"BUSCA\")\n",
        "            return None\n",
        "        else:\n",
        "            for tentativa in range(1, 11):\n",
        "                log_supervisor(f\"Buscando próxima transmissão livre: tentativa {tentativa}\", \"BUSCA\")\n",
        "                stream = buscar_proxima_transmissao_livre(pagina_inicial=tentativa, pagina_max=tentativa)\n",
        "                if stream and stream[\"username\"] not in seen_usernames:\n",
        "                    log_supervisor(f\"Nova transmissão encontrada: {stream['username']} (página {tentativa})\", \"BUSCA\")\n",
        "                    return stream\n",
        "            log_supervisor(\"Nenhuma transmissão livre encontrada após tentativas.\", \"BUSCA\")\n",
        "            return None\n",
        "\n",
        "    log_supervisor(f\"Preenchendo lote inicial com até {pool_size} transmissões...\", \"STARTUP\")\n",
        "    tentativas = 0\n",
        "    max_tentativas = 100\n",
        "    while len(running) < pool_size and tentativas < max_tentativas:\n",
        "        stream = buscar_nova_transmissao()\n",
        "        if not stream:\n",
        "            log_supervisor(\"Fim das transmissões disponíveis para preencher lote inicial.\", \"STARTUP\")\n",
        "            break\n",
        "        username = stream[\"username\"]\n",
        "        seen_usernames.add(username)\n",
        "        # Escreve no log imediatamente para evitar duplicidade em concorrência antes do .start()\n",
        "        with open(LOG_PROCESSAMENTO_PATH, \"a\") as f:\n",
        "            f.write(f\"{username}\\n\")\n",
        "        log_supervisor(f\"Lançando processo para: {username} | {len(running)+1}/{pool_size}\", \"STARTUP\")\n",
        "        p = Process(target=worker, args=(username, stream[\"src\"], stream.get(\"poster\"), results))\n",
        "        running.append(p)\n",
        "        p.start()\n",
        "        tentativas += 1\n",
        "\n",
        "    log_supervisor(f\"Lote inicial lançado com {len(running)} transmissões.\", \"STARTUP\")\n",
        "\n",
        "    while True:\n",
        "        antes = len(running)\n",
        "        running = [p for p in running if p.is_alive()]\n",
        "        depois = len(running)\n",
        "        if antes != depois:\n",
        "            log_supervisor(f\"{antes-depois} gravações finalizaram. Vagas livres: {pool_size-len(running)}\", \"LOOP\")\n",
        "        vagas_livres = pool_size - len(running)\n",
        "        if vagas_livres > 0:\n",
        "            for _ in range(vagas_livres):\n",
        "                stream = buscar_nova_transmissao()\n",
        "                if not stream:\n",
        "                    log_supervisor(\"Não há mais transmissões para preencher as vagas livres.\", \"LOOP\")\n",
        "                    break\n",
        "                username = stream[\"username\"]\n",
        "                seen_usernames.add(username)\n",
        "                with open(LOG_PROCESSAMENTO_PATH, \"a\") as f:\n",
        "                    f.write(f\"{username}\\n\")\n",
        "                log_supervisor(f\"Lançando nova gravação: {username} | Vaga preenchida {len(running)+1}/{pool_size}\", \"LOOP\")\n",
        "                p = Process(target=worker, args=(username, stream[\"src\"], stream.get(\"poster\"), results))\n",
        "                running.append(p)\n",
        "                p.start()\n",
        "        if not running:\n",
        "            log_supervisor(\"Todas as transmissões possíveis já foram processadas!\", \"END\")\n",
        "            break\n",
        "        log_supervisor(f\"Transmissões ativas: {len(running)} | Total processadas: {len(seen_usernames)} | Buffer de resultados: {len(results)}\", \"STATUS\")\n",
        "        time.sleep(2)\n",
        "\n",
        "    log_supervisor(f\"Processamento dinâmico concluído! Total de transmissões gravadas/processadas: {len(results)}\", \"RESUMO\")\n",
        "    try:\n",
        "        log_supervisor(\"Realizando commit/push final dos arquivos pendentes...\", \"FINALIZACAO\")\n",
        "        commit_push_restantes()\n",
        "        log_supervisor(\"Commit/push final executado com sucesso.\", \"FINALIZACAO\")\n",
        "    except Exception as e:\n",
        "        log_supervisor(f\"Falha ao tentar commit/push final dos arquivos restantes: {e}\", \"ERRO\")\n",
        "    log_supervisor(\"Supervisor dinâmico finalizado.\", \"END\")\n",
        "\n",
        "def main():\n",
        "    usuarios_especificos = perguntar_transmissoes_especificas()\n",
        "    log_supervisor(\"Iniciando busca e gravação de streams (supervisor dinâmico)...\", \"MAIN\")\n",
        "    supervisor_dinamico(usuarios_especificos=usuarios_especificos)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    try:\n",
        "        if 'google.colab' in str(get_ipython()):\n",
        "            main()\n",
        "        else:\n",
        "            print(\"Execute main() manualmente se desejar rodar fora do Colab.\")\n",
        "    except NameError:\n",
        "        print(\"Não está rodando em Colab/IPython. Execute main() se desejar.\")"
      ],
      "metadata": {
        "id": "5WKQV9g_LB9M"
      },
      "id": "5WKQV9g_LB9M",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Célula extra: Commit final de pendências\n",
        "def commit_final_pendencias():\n",
        "    commit_buffer = getattr(upload_to_abyss_and_update_json, 'commit_buffer', [])\n",
        "    if commit_buffer:\n",
        "        print(f\"🔔 Realizando commit/push final de {len(commit_buffer)} pendências...\")\n",
        "        git_commit_and_push(commit_buffer, commit_message=\"Commit final de pendências\")\n",
        "        commit_buffer.clear()\n",
        "    else:\n",
        "        print(\"✅ Sem pendências para commit final.\")\n",
        "\n",
        "# Execute isto ao final do processamento\n",
        "# commit_final_pendencias()"
      ],
      "metadata": {
        "id": "eXVBhXjsAuAY"
      },
      "id": "eXVBhXjsAuAY",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "c9hve1ySGVAs"
      ],
      "cell_execution_strategy": "setup",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}