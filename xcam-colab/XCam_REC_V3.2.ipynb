{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SamuelPassamani/XCam/blob/main/xcam-colab/XCam_REC_V3.2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# C√©lula 1: Configura√ß√µes Auxiliares e Par√¢metros Gerais\n",
        "\n",
        "**Objetivo:**  \n",
        "Esta c√©lula inicializa e centraliza as vari√°veis globais e par√¢metros de controle essenciais para ajuste r√°pido e seguro do comportamento do notebook, incluindo limites de processamento, controle de grava√ß√£o, e configura√ß√µes de commit autom√°tico.\n",
        "\n",
        "*   Quantidade m√°xima de transmiss√µes processadas em paralelo/lote (`LIMIT_DEFAULT`)\n",
        "*   P√°gina inicial para busca na API (`PAGE_DEFAULT`)\n",
        "*   Tempo m√°ximo de grava√ß√£o de cada v√≠deo em segundos (`RECORD_SECONDS`)\n",
        "*   Tempo m√≠nimo de grava√ß√£o exigido para considerar o v√≠deo v√°lido (`RECORD_SECONDS_MIN`)\n",
        "*   Limite de transmiss√µes retornadas ao buscar usu√°rios espec√≠ficos (`API_SEARCH_LIMIT`)\n",
        "*   Quantidade de transmiss√µes processadas at√© realizar commit/push autom√°tico (`COMMIT_PUSH_THRESHOLD`)\n",
        "    * **Novo:** Pode ser ajustado para controlar a frequ√™ncia com que os arquivos s√£o enviados ao reposit√≥rio (por exemplo, 10 transmiss√µes por commit). Defina como 0 para commit imediato a cada grava√ß√£o.\n",
        "\n",
        "**Interatividade:**  \n",
        "Inclui a fun√ß√£o `perguntar_transmissoes_especificas()` que pergunta ao usu√°rio se deseja gravar transmiss√µes de usu√°rios espec√≠ficos. Caso positivo, solicita os nomes dos usu√°rios (separados por v√≠rgula) e retorna uma lista limpa e pronta para uso.\n",
        "\n",
        "**Funcionamento e Seguran√ßa:**  \n",
        "- Todos os par√¢metros globais s√£o definidos no in√≠cio e propagados para todo o notebook, garantindo consist√™ncia e f√°cil manuten√ß√£o.\n",
        "- Ajuste qualquer valor diretamente nesta c√©lula para alterar o comportamento global do notebook sem risco de inconsist√™ncia.\n",
        "- A fun√ß√£o interativa permite filtrar transmiss√µes espec√≠ficas antes do in√≠cio do processamento.\n",
        "- Os coment√°rios detalhados auxiliam na compreens√£o e ajuste seguro dos par√¢metros, evitando conflitos ou mau funcionamento.\n",
        "\n",
        "**Exemplo de uso interativo:**  \n",
        "Antes de iniciar o processamento, voc√™ pode ajustar qualquer par√¢metro de controle.  \n",
        "O notebook perguntar√° se voc√™ quer gravar transmiss√µes de usu√°rios espec√≠ficos e, se desejar, basta informar os nomes separados por v√≠rgula (ex: \"userNovo234, jovemPT\").\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "c9hve1ySGVAs"
      },
      "id": "c9hve1ySGVAs"
    },
    {
      "cell_type": "code",
      "source": [
        "# C√©lula 1: Configura√ß√µes Auxiliares e Par√¢metros Gerais\n",
        "# ------------------------------------------------------\n",
        "# Esta c√©lula define e documenta todos os principais par√¢metros do sistema,\n",
        "# facilitando o ajuste do comportamento global do notebook de modo seguro e organizado.\n",
        "# Tamb√©m inclui fun√ß√£o para sele√ß√£o opcional de transmiss√µes espec√≠ficas por nome de usu√°rio.\n",
        "#\n",
        "# ATEN√á√ÉO:\n",
        "# - Todos os par√¢metros est√£o centralizados nesta c√©lula.\n",
        "# - Se alterar aqui, o valor refletir√° em todo o notebook.\n",
        "# - Use os coment√°rios para entender facilmente cada par√¢metro antes de ajustar.\n",
        "# - N√£o remova a chamada a 'globals().update()', pois ela garante acesso global seguro.\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "\n",
        "# ============================\n",
        "# PAR√ÇMETROS GLOBAIS EDIT√ÅVEIS\n",
        "# ============================\n",
        "\n",
        "LIMIT_DEFAULT = 25             # Quantidade m√°xima de transmiss√µes processadas em paralelo/lote.\n",
        "PAGE_DEFAULT = 1               # P√°gina inicial para busca na API.\n",
        "RECORD_SECONDS = 420           # Tempo m√°ximo de grava√ß√£o de cada v√≠deo (em segundos).\n",
        "RECORD_SECONDS_MIN = 300       # Tempo m√≠nimo exigido para considerar o v√≠deo v√°lido (em segundos).\n",
        "API_SEARCH_LIMIT = 1000        # Limite de transmiss√µes retornadas ao buscar usu√°rios espec√≠ficos.\n",
        "COMMIT_PUSH_THRESHOLD = 10     # Quantidade de transmiss√µes processadas antes de commit/push autom√°tico (0 = commit imediato a cada v√≠deo).\n",
        "\n",
        "# ============================\n",
        "# ATUALIZA√á√ÉO GLOBAL DOS PAR√ÇMETROS\n",
        "# ============================\n",
        "# Isto garante que todos os scripts e fun√ß√µes do notebook possam acessar os par√¢metros acima\n",
        "# como vari√°veis globais, evitando conflitos ou inconsist√™ncia de valores.\n",
        "globals().update({\n",
        "    'LIMIT_DEFAULT': LIMIT_DEFAULT,\n",
        "    'PAGE_DEFAULT': PAGE_DEFAULT,\n",
        "    'RECORD_SECONDS': RECORD_SECONDS,\n",
        "    'RECORD_SECONDS_MIN': RECORD_SECONDS_MIN,\n",
        "    'API_SEARCH_LIMIT': API_SEARCH_LIMIT,\n",
        "    'COMMIT_PUSH_THRESHOLD': COMMIT_PUSH_THRESHOLD\n",
        "})\n",
        "\n",
        "# ============================\n",
        "# FUN√á√ÉO INTERATIVA (opcional)\n",
        "# ============================\n",
        "def perguntar_transmissoes_especificas():\n",
        "    \"\"\"\n",
        "    Pergunta ao usu√°rio se deseja informar transmiss√µes espec√≠ficas para gravar,\n",
        "    recebendo nomes de usu√°rio separados por v√≠rgula e retornando lista limpa.\n",
        "    Retorna lista vazia caso n√£o deseje selecionar usu√°rios.\n",
        "    \"\"\"\n",
        "    resp = input('Deseja gravar alguma transmiss√£o espec√≠fica? (sim/n√£o): ').strip().lower()\n",
        "    if resp.startswith('s'):\n",
        "        usuarios = input('Informe o(s) nome(s) de usu√°rio, separados por v√≠rgula (ex: userNovo234, jovemPT): ')\n",
        "        usuarios_lista = [u.strip() for u in usuarios.split(',') if u.strip()]\n",
        "        return usuarios_lista\n",
        "    return []"
      ],
      "metadata": {
        "id": "j5pPh353GLMD"
      },
      "id": "j5pPh353GLMD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# C√©lula 2: Instala√ß√£o do ffmpeg\n",
        "\n",
        "**Objetivo:**\n",
        "Garante que o ffmpeg esteja instalado no ambiente do Google Colab. O ffmpeg √© fundamental para gravar os v√≠deos das transmiss√µes.\n",
        "\n",
        "**Como funciona:**\n",
        "Executa comandos de instala√ß√£o do ffmpeg, necess√°rios para o funcionamento correto das pr√≥ximas etapas."
      ],
      "metadata": {
        "id": "WXs0o6OPHXbi"
      },
      "id": "WXs0o6OPHXbi"
    },
    {
      "cell_type": "code",
      "source": [
        "# C√©lula 2: Instala√ß√£o do ffmpeg\n",
        "# ------------------------------\n",
        "# Garante que o ffmpeg est√° instalado no ambiente Colab.\n",
        "\n",
        "!apt-get update -y\n",
        "!apt-get install -y ffmpeg"
      ],
      "metadata": {
        "id": "vIODn0c2HiHz"
      },
      "id": "vIODn0c2HiHz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# C√©lula 3: Imports Essenciais e Fun√ß√µes Utilit√°rias\n",
        "\n",
        "**Objetivo:**  \n",
        "Importa todas as bibliotecas do Python necess√°rias para o funcionamento do notebook, incluindo m√≥dulos para requisi√ß√µes HTTP, processamento paralelo, manipula√ß√£o de data/hora, controle de subprocessos e exibi√ß√£o interativa.  \n",
        "Tamb√©m define fun√ß√µes utilit√°rias robustas para:\n",
        "\n",
        "*   Formatar o tempo de grava√ß√£o (`format_seconds`)\n",
        "*   Exibir logs de progresso do processamento (`log_progress`)\n",
        "*   Baixar e salvar a imagem de poster de cada transmiss√£o (`download_and_save_poster`)\n",
        "*   Gerar poster automaticamente com ffmpeg a partir da transmiss√£o ao vivo caso o poster esteja ausente ou inv√°lido (`generate_poster_with_ffmpeg`)\n",
        "*   Validar se o poster √© v√°lido (`is_poster_valid`)\n",
        "*   **Concorr√™ncia/Log:** Garante a cria√ß√£o do arquivo de log tempor√°rio para controlar transmiss√µes atualmente em processamento e j√° inclui, de forma opcional, um lock global para garantir escrita thread-safe em cen√°rios de execu√ß√£o paralela.\n",
        "\n",
        "**Como funciona:**  \n",
        "Essas fun√ß√µes s√£o usadas em v√°rias partes do notebook para:\n",
        "- Manipular e exibir tempos de grava√ß√£o de forma amig√°vel.\n",
        "- Acompanhar e reportar o progresso de grava√ß√µes em tempo real.\n",
        "- Garantir que cada transmiss√£o tenha sempre um poster v√°lido, seja baixando da API, seja gerando automaticamente com ffmpeg.\n",
        "- Manter o controle das transmiss√µes em processamento por meio do arquivo de log tempor√°rio, auxiliando na preven√ß√£o de duplicidade e facilitando o processamento paralelo cont√≠nuo e seguro.\n",
        "- Os coment√°rios detalhados facilitam a manuten√ß√£o e o entendimento para futuras adapta√ß√µes do notebook.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "90qvXC0rHtWb"
      },
      "id": "90qvXC0rHtWb"
    },
    {
      "cell_type": "code",
      "source": [
        "# C√©lula 3: Imports essenciais e utilit√°rios\n",
        "# ------------------------------------------\n",
        "# Importa√ß√£o de bibliotecas e fun√ß√µes auxiliares de formata√ß√£o e download.\n",
        "# Tamb√©m garante a cria√ß√£o do arquivo de log tempor√°rio para controle de transmiss√µes em processamento.\n",
        "# ADI√á√ÉO: Fun√ß√£o para gerar poster com ffmpeg caso n√£o haja poster v√°lido na API.\n",
        "# CORRE√á√ÉO: Antes de rodar ffmpeg, testa se a URL do stream est√° acess√≠vel (HEAD).\n",
        "# Se n√£o estiver, retorna None e faz o tratamento do erro de stream offline.\n",
        "\n",
        "import os\n",
        "import requests\n",
        "import multiprocessing\n",
        "from datetime import datetime\n",
        "import json\n",
        "import time\n",
        "import subprocess\n",
        "import math\n",
        "import re\n",
        "\n",
        "from IPython import get_ipython\n",
        "from IPython.display import display\n",
        "\n",
        "# Caminho do arquivo de log tempor√°rio\n",
        "LOG_PROCESSAMENTO_PATH = \"/content/xcam_processing.log\"\n",
        "\n",
        "# Garante que o arquivo de log tempor√°rio exista ao iniciar o notebook\n",
        "if not os.path.exists(LOG_PROCESSAMENTO_PATH):\n",
        "    with open(LOG_PROCESSAMENTO_PATH, \"w\") as f:\n",
        "        f.write(\"\")  # Cria arquivo vazio\n",
        "\n",
        "def format_seconds(seconds):\n",
        "    total_seconds = int(seconds)\n",
        "    hours = total_seconds // 3600\n",
        "    minutes = (total_seconds % 3600) // 60\n",
        "    seconds = total_seconds % 60\n",
        "    parts = []\n",
        "    if hours > 0: parts.append(f\"{hours}h\")\n",
        "    if minutes > 0 or (hours == 0 and seconds > 0): parts.append(f\"{minutes}m\")\n",
        "    if seconds > 0 or total_seconds == 0: parts.append(f\"{seconds}s\")\n",
        "    return \"\".join(parts) if parts else \"0s\"\n",
        "\n",
        "def log_progress(username, elapsed_seconds, total_seconds):\n",
        "    percent = min((elapsed_seconds / total_seconds) * 100, 100)\n",
        "    tempo = format_seconds(elapsed_seconds)\n",
        "    minutos_gravados = math.floor(elapsed_seconds / 60)\n",
        "    minutos_restantes = max(0, math.ceil((total_seconds - elapsed_seconds) / 60))\n",
        "    print(f\"‚è±Ô∏è [{username}] Gravados: {minutos_gravados} min | Restantes: {minutos_restantes} min | Tempo total: {tempo} ‚Äî üìä {percent:.1f}% conclu√≠do\")\n",
        "\n",
        "def download_and_save_poster(poster_url, username, temp_folder):\n",
        "    \"\"\"\n",
        "    Baixa e salva o poster a partir de uma URL HTTP/HTTPS.\n",
        "    Ou, se receber um caminho local existente, apenas retorna esse caminho.\n",
        "    Retorna o caminho do arquivo salvo, ou None em caso de erro.\n",
        "    \"\"\"\n",
        "    # Se for um caminho local j√° existente, apenas retorna\n",
        "    if os.path.exists(poster_url):\n",
        "        return poster_url\n",
        "    # Se for uma URL HTTP/HTTPS, faz o download normalmente\n",
        "    if isinstance(poster_url, str) and (poster_url.startswith(\"http://\") or poster_url.startswith(\"https://\")):\n",
        "        try:\n",
        "            response = requests.get(poster_url, timeout=15)\n",
        "            response.raise_for_status()\n",
        "            ext = os.path.splitext(poster_url)[1].lower()\n",
        "            if ext not in [\".jpg\", \".jpeg\", \".png\"]:\n",
        "                ext = \".jpg\"\n",
        "            poster_temp_path = os.path.join(temp_folder, f\"{username}_poster_temp{ext}\")\n",
        "            with open(poster_temp_path, \"wb\") as f:\n",
        "                f.write(response.content)\n",
        "            print(f\"üñºÔ∏è Poster baixado em: {poster_temp_path}\")\n",
        "            return poster_temp_path\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Erro ao baixar poster {poster_url}: {e}\")\n",
        "            return None\n",
        "    else:\n",
        "        print(f\"‚ùå poster_url inv√°lido ou n√£o encontrado: {poster_url}\")\n",
        "        return None\n",
        "\n",
        "def generate_poster_with_ffmpeg(m3u8_url, username, temp_folder, frame_time=7, timeout=20):\n",
        "    \"\"\"\n",
        "    Gera um poster (screenshot) usando ffmpeg a partir da URL .m3u8 da transmiss√£o.\n",
        "    Retorna o caminho do arquivo gerado ou None em caso de erro.\n",
        "    frame_time: segundo do v√≠deo em que o poster ser√° capturado (padr√£o: 7s para evitar frame preto).\n",
        "    Antes de rodar o ffmpeg, faz uma checagem HTTP HEAD para saber se a URL do stream est√° ativa.\n",
        "    \"\"\"\n",
        "    # Checa se a URL est√° acess√≠vel antes de rodar ffmpeg\n",
        "    try:\n",
        "        head_resp = requests.head(m3u8_url, timeout=5)\n",
        "        if not head_resp.ok:\n",
        "            print(f\"‚ö†Ô∏è Stream offline ou n√£o dispon√≠vel para {username} (status {head_resp.status_code})\")\n",
        "            return None\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Erro de conex√£o ao acessar stream de {username}: {e}\")\n",
        "        return None\n",
        "\n",
        "    poster_ffmpeg_path = os.path.join(temp_folder, f\"{username}_poster_ffmpeg.jpg\")\n",
        "    # Comando ffmpeg: captura 1 frame ap√≥s frame_time segundos de v√≠deo\n",
        "    command = [\n",
        "        \"ffmpeg\",\n",
        "        \"-y\",  # sobrescreve arquivo se j√° existir\n",
        "        \"-ss\", str(frame_time),  # avan√ßa para frame_time segundos antes de capturar\n",
        "        \"-i\", m3u8_url,\n",
        "        \"-vframes\", \"1\",\n",
        "        \"-q:v\", \"2\",  # qualidade alta\n",
        "        poster_ffmpeg_path\n",
        "    ]\n",
        "    try:\n",
        "        print(f\"üé¨ Gerando poster com ffmpeg para {username} no segundo {frame_time}...\")\n",
        "        # subprocess.run com timeout para evitar travamento caso a URL esteja offline/inv√°lida\n",
        "        result = subprocess.run(\n",
        "            command,\n",
        "            stdout=subprocess.PIPE,\n",
        "            stderr=subprocess.PIPE,\n",
        "            timeout=timeout\n",
        "        )\n",
        "        if result.returncode == 0 and os.path.exists(poster_ffmpeg_path):\n",
        "            print(f\"üñºÔ∏è Poster gerado via ffmpeg: {poster_ffmpeg_path}\")\n",
        "            return poster_ffmpeg_path\n",
        "        else:\n",
        "            print(f\"‚ùå ffmpeg n√£o conseguiu gerar poster para {username}. Sa√≠da: {result.stderr.decode(errors='ignore')}\")\n",
        "            return None\n",
        "    except subprocess.TimeoutExpired:\n",
        "        print(f\"‚è∞ Tempo excedido ao tentar gerar poster para {username} via ffmpeg.\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Erro inesperado ao gerar poster via ffmpeg: {e}\")\n",
        "        return None\n",
        "\n",
        "def is_poster_valid(poster_path):\n",
        "    \"\"\"\n",
        "    Verifica se o poster existe e n√£o est√° vazio.\n",
        "    \"\"\"\n",
        "    return poster_path and os.path.exists(poster_path) and os.path.getsize(poster_path) > 0"
      ],
      "metadata": {
        "id": "hOetz0nGICkz"
      },
      "id": "hOetz0nGICkz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# C√©lula 4: Clonagem do Reposit√≥rio GitHub para o Colab\n",
        "\n",
        "**Objetivo:**\n",
        "Clona o reposit√≥rio do GitHub para o ambiente local do Colab, garantindo que o ambiente sempre esteja atualizado e pronto para armazenar os arquivos gerados.\n",
        "\n",
        "**Como funciona:**\n",
        "Remove qualquer reposit√≥rio anterior para evitar conflitos, clona o novo, prepara pastas tempor√°rias e define a URL de upload para o Abyss.to."
      ],
      "metadata": {
        "id": "hpRIMtyFIY0q"
      },
      "id": "hpRIMtyFIY0q"
    },
    {
      "cell_type": "code",
      "source": [
        "# C√©lula 4: Clonagem do reposit√≥rio GitHub para o Colab e para o Drive\n",
        "# --------------------------------------------------------------------\n",
        "# Clona o reposit√≥rio para o ambiente Colab E tamb√©m para o Google Drive (se montado),\n",
        "# garantindo ambiente limpo, persist√™ncia e sincroniza√ß√£o para futuras execu√ß√µes.\n",
        "\n",
        "GITHUB_USER = \"SamuelPassamani\"\n",
        "GITHUB_REPO = \"XCam\"\n",
        "GITHUB_BRANCH = \"main\"\n",
        "GITHUB_TOKEN = \"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\"\n",
        "\n",
        "repo_url = f\"https://{GITHUB_USER}:{GITHUB_TOKEN}@github.com/{GITHUB_USER}/{GITHUB_REPO}.git\"\n",
        "\n",
        "# Clona para o ambiente Colab\n",
        "!rm -rf {GITHUB_REPO}\n",
        "!git clone -b {GITHUB_BRANCH} {repo_url}\n",
        "\n",
        "# Caminhos locais\n",
        "TEMP_OUTPUT_FOLDER = \"/content/temp_recordings\"\n",
        "os.makedirs(TEMP_OUTPUT_FOLDER, exist_ok=True)\n",
        "BASE_REPO_FOLDER = f\"/content/{GITHUB_REPO}\"\n",
        "\n",
        "# Caminho para o Drive (se montado)\n",
        "DRIVE_MOUNT = \"/content/drive/MyDrive/XCam.Drive\"\n",
        "DRIVE_REPO_FOLDER = f\"{DRIVE_MOUNT}/{GITHUB_REPO}\"\n",
        "\n",
        "# Clona tamb√©m para o Drive, se estiver montado\n",
        "import os\n",
        "if os.path.exists(DRIVE_MOUNT):\n",
        "    # Remove reposit√≥rio antigo no Drive (se existir), depois clona\n",
        "    !rm -rf \"{DRIVE_REPO_FOLDER}\"\n",
        "    !git clone -b {GITHUB_BRANCH} {repo_url} \"{DRIVE_REPO_FOLDER}\"\n",
        "    print(f\"‚úÖ Reposit√≥rio tamb√©m clonado no Drive: {DRIVE_REPO_FOLDER}\")\n",
        "else:\n",
        "    print(f\"‚ö†Ô∏è Google Drive n√£o est√° montado em {DRIVE_MOUNT}.\")\n",
        "\n",
        "ABYSS_UPLOAD_URL = 'http://up.hydrax.net/0128263f78f0b426d617bb61c2a8ff43'"
      ],
      "metadata": {
        "id": "Uof_0QCrIlf7"
      },
      "id": "Uof_0QCrIlf7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# C√©lula 5: Commit e Push Autom√°ticos (rec.json e poster)\n",
        "\n",
        "---\n",
        "\n",
        "**Objetivo:**\n",
        "Define a fun√ß√£o git_commit_and_push() para garantir que apenas arquivos importantes (JSON de grava√ß√£o e posters de imagem) sejam adicionados, commitados e enviados ao reposit√≥rio.\n",
        "\n",
        "**Como funciona:**\n",
        "Configura o git, adiciona o arquivo desejado, faz commit e push para o reposit√≥rio remoto."
      ],
      "metadata": {
        "id": "M5iL_9BoIoj7"
      },
      "id": "M5iL_9BoIoj7"
    },
    {
      "cell_type": "code",
      "source": [
        "# C√©lula 5: Commit e Push autom√°ticos (rec.json e poster)\n",
        "# -------------------------------------------------------\n",
        "# Esta fun√ß√£o agora aceita tanto um caminho √∫nico (str) quanto uma lista de caminhos (list) para realizar commit e push.\n",
        "# O comportamento original para um √∫nico arquivo √© preservado, mas agora √© poss√≠vel realizar commit em lote,\n",
        "# conforme necess√°rio para a estrat√©gia de batch commit com threshold.\n",
        "\n",
        "def git_commit_and_push(file_paths, commit_message=\"Atualiza rec.json\"):\n",
        "    \"\"\"\n",
        "    Realiza git add, commit e push dos arquivos especificados.\n",
        "    - file_paths pode ser uma string (arquivo √∫nico) ou uma lista de arquivos.\n",
        "    - commit_message √© a mensagem de commit utilizada.\n",
        "    \"\"\"\n",
        "    repo_dir = f\"/content/{GITHUB_REPO}\"\n",
        "    os.chdir(repo_dir)\n",
        "    subprocess.run([\"git\", \"config\", \"user.email\", \"contato@aserio.work\"])\n",
        "    subprocess.run([\"git\", \"config\", \"user.name\", \"SamuelPassamani\"])\n",
        "\n",
        "    # Permite tanto um arquivo √∫nico quanto uma lista de arquivos\n",
        "    if isinstance(file_paths, str):\n",
        "        file_paths = [file_paths]\n",
        "\n",
        "    # Adiciona cada arquivo ao staging do git\n",
        "    for file_path in file_paths:\n",
        "        subprocess.run([\"git\", \"add\", file_path])\n",
        "\n",
        "    # Realiza o commit (permite commit vazio por seguran√ßa)\n",
        "    subprocess.run([\"git\", \"commit\", \"-m\", commit_message, \"--allow-empty\"], check=False)\n",
        "\n",
        "    # Push para o reposit√≥rio remoto usando autentica√ß√£o via token\n",
        "    subprocess.run([\n",
        "        \"git\", \"push\", f\"https://{GITHUB_USER}:{GITHUB_TOKEN}@github.com/{GITHUB_USER}/{GITHUB_REPO}.git\"\n",
        "    ])"
      ],
      "metadata": {
        "id": "1aQn1G6yI6Gz"
      },
      "id": "1aQn1G6yI6Gz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# C√©lula 6: Busca de Transmiss√µes na API XCam, com Fallback via liveInfo e Busca Inteligente/Unit√°ria\n",
        "\n",
        "**Objetivo:**  \n",
        "Busca as transmiss√µes ativas na API principal da XCam, garantindo que o lote retornado esteja sempre completo at√© `LIMIT_DEFAULT` e que n√£o haja duplicidade, consultando o log de transmiss√µes em processamento.  \n",
        "Al√©m disso, inclui uma fun√ß√£o de busca unit√°ria/inteligente de transmiss√µes livres, fundamental para manter o processamento cont√≠nuo e o ‚Äúlote cheio‚Äù conforme a l√≥gica moderna do notebook.  \n",
        "Tamb√©m assegura que cada transmiss√£o tenha um poster v√°lido: se o poster n√£o estiver presente, for nulo ou inv√°lido, o notebook gera automaticamente uma imagem de poster usando ffmpeg a partir da URL da transmiss√£o ao vivo (.m3u8).\n",
        "\n",
        "**Como funciona:**\n",
        "\n",
        "* Para cada transmiss√£o encontrada, retorna um dicion√°rio com username, src (endere√ßo do stream) e poster (imagem local gerada ou baixada).\n",
        "* Se for solicitado buscar usu√°rios espec√≠ficos, s√≥ retorna esses.\n",
        "* Caso algum usu√°rio n√£o tenha src na API principal, faz nova chamada √† API `/liveInfo` para tentar encontrar o link da transmiss√£o.\n",
        "* Caso o poster esteja ausente, vazio, nulo ou inv√°lido (tanto na API principal quanto na liveInfo), o notebook gera e salva automaticamente uma imagem de poster via ffmpeg no momento do processamento.\n",
        "* Antes de adicionar uma transmiss√£o ao lote, verifica se ela j√° est√° em processamento (consultando o log tempor√°rio) e se n√£o h√° duplicidade na sele√ß√£o.\n",
        "* O lote final respeita sempre o `LIMIT_DEFAULT` de transmiss√µes v√°lidas, preenchendo com fallback se necess√°rio.\n",
        "\n",
        "**Atualiza√ß√µes e melhorias recentes:**\n",
        "\n",
        "- **Busca em lote otimizada:** Agora, ao buscar transmiss√µes para preencher o lote, a fun√ß√£o utiliza um `limit` alto (ex: 1500) e `page=1`, recebendo todas as transmiss√µes online de uma s√≥ vez. Isso reduz o n√∫mero de requisi√ß√µes, acelera o preenchimento do lote e melhora a efici√™ncia de todo o processamento.\n",
        "- **Busca unit√°ria otimizada:** A busca unit√°ria (`buscar_proxima_transmissao_livre`) tamb√©m foi ajustada para buscar todas as transmiss√µes online em uma √∫nica chamada (limit alto, page=1), retornando rapidamente a pr√≥xima transmiss√£o livre e v√°lida, sem precisar varrer p√°gina por p√°gina.\n",
        "- **Efici√™ncia e paralelismo:** Essas melhorias garantem que o supervisor consiga manter o lote sempre cheio, caso existam transmiss√µes dispon√≠veis, e que o uso de processamento paralelo seja maximizado.\n",
        "- **Controle de duplicidade robusto:** O sistema continua consultando o log de transmiss√µes em processamento, garantindo que transmiss√µes j√° processadas ou em andamento n√£o sejam selecionadas novamente.\n",
        "- **Compatibilidade mantida:** O comportamento para busca de usu√°rios espec√≠ficos permanece inalterado e totalmente compat√≠vel com as demais fun√ß√µes do notebook.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "BZ4c3Uk1I7AK"
      },
      "id": "BZ4c3Uk1I7AK"
    },
    {
      "cell_type": "code",
      "source": [
        "# C√©lula 6: Busca de transmiss√µes na API XCam, com fallback via liveInfo e busca unit√°ria/inteligente (OTIMIZADA)\n",
        "# ----------------------------------------------------------------------------------------------------------------\n",
        "# Nesta vers√£o, tanto a busca em lote quanto a busca unit√°ria buscam TODAS as transmiss√µes online de uma vez s√≥ (limit alto, page=1).\n",
        "# Isso garante m√°xima efici√™ncia, reduz o n√∫mero de requisi√ß√µes √† API e mant√©m o lote sempre cheio, respeitando LIMIT_DEFAULT.\n",
        "# Os coment√°rios detalham cada etapa para facilitar manuten√ß√£o, depura√ß√£o e entendimento do fluxo.\n",
        "\n",
        "def get_broadcasts(limit=LIMIT_DEFAULT, page=PAGE_DEFAULT, usuarios_especificos=None, temp_folder=\"/content\"):\n",
        "    \"\"\"\n",
        "    Busca transmiss√µes ao vivo via API principal da XCam.\n",
        "    Se usuarios_especificos for fornecido (lista), retorna apenas essas transmiss√µes.\n",
        "    Caso contr√°rio, busca todas as transmiss√µes online em uma √∫nica chamada (limit alto, page=1),\n",
        "    preenchendo o lote at√© o m√°ximo permitido por 'limit' (ex: 25).\n",
        "    Faz fallback via liveInfo para transmiss√µes sem src.\n",
        "    Garante poster v√°lido: se ausente, gera com ffmpeg a partir do src/m3u8.\n",
        "    Evita duplicidade (checa log de transmiss√µes em processamento) e respeita LIMIT_DEFAULT.\n",
        "    \"\"\"\n",
        "    LOG_PROCESSAMENTO_PATH = \"/content/xcam_processing.log\"\n",
        "\n",
        "    # Carrega transmiss√µes j√° em processamento para evitar duplicidade\n",
        "    transmissao_em_proc = set()\n",
        "    if os.path.exists(LOG_PROCESSAMENTO_PATH):\n",
        "        with open(LOG_PROCESSAMENTO_PATH, \"r\") as f:\n",
        "            transmissao_em_proc = set([line.strip() for line in f if line.strip()])\n",
        "\n",
        "    # Escolhe a URL da API conforme o modo (usu√°rios espec√≠ficos ou todos)\n",
        "    if usuarios_especificos:\n",
        "        api_url_main = f\"https://api.xcam.gay/?limit={API_SEARCH_LIMIT}&page=1\"\n",
        "        print(f\"üåê Acessando API principal (usu√°rios espec√≠ficos): {api_url_main}\")\n",
        "    else:\n",
        "        api_url_main = f\"https://api.xcam.gay/?limit=1500&page=1\"\n",
        "        print(f\"üåê Acessando API principal (todas transmiss√µes online): {api_url_main}\")\n",
        "\n",
        "    streams_from_main = []\n",
        "    streams_without_preview = []\n",
        "\n",
        "    try:\n",
        "        response_main = requests.get(api_url_main)\n",
        "        response_main.raise_for_status()\n",
        "        data_main = response_main.json()\n",
        "        broadcasts_data = data_main.get(\"broadcasts\")\n",
        "        if not broadcasts_data:\n",
        "            print(\"‚ö†Ô∏è Chave 'broadcasts' n√£o encontrada na resposta da API principal.\")\n",
        "            return []\n",
        "        items = broadcasts_data.get(\"items\")\n",
        "        if not isinstance(items, list):\n",
        "            print(f\"‚ö†Ô∏è Chave 'items' n√£o encontrada ou n√£o √© uma lista em 'broadcasts'.\")\n",
        "            return []\n",
        "\n",
        "        # Percorre todas as transmiss√µes retornadas pela API principal\n",
        "        for item in items:\n",
        "            preview = item.get(\"preview\") or {}\n",
        "            src = preview.get(\"src\")\n",
        "            poster = preview.get(\"poster\")\n",
        "            username = item.get(\"username\", \"desconhecido\")\n",
        "            # Evita duplicidade: s√≥ adiciona se n√£o estiver em processamento\n",
        "            if username in transmissao_em_proc:\n",
        "                continue\n",
        "            if usuarios_especificos and username not in usuarios_especificos:\n",
        "                continue\n",
        "            if src:\n",
        "                poster_path = None\n",
        "                if poster and isinstance(poster, str) and poster.strip():\n",
        "                    poster_path = download_and_save_poster(poster, username, temp_folder)\n",
        "                if not is_poster_valid(poster_path):\n",
        "                    poster_path = generate_poster_with_ffmpeg(src, username, temp_folder)\n",
        "                streams_from_main.append({\n",
        "                    \"username\": username,\n",
        "                    \"src\": src,\n",
        "                    \"poster\": poster_path\n",
        "                })\n",
        "            else:\n",
        "                streams_without_preview.append({\"username\": username})\n",
        "\n",
        "        print(f\"‚úÖ {len(streams_from_main)} transmiss√µes com URL na API principal (total consultado).\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Erro ao acessar API principal: {e}\")\n",
        "        return []\n",
        "\n",
        "    # Fallback: busca via liveInfo para streams sem URL na API principal\n",
        "    streams_from_liveinfo = []\n",
        "    if streams_without_preview:\n",
        "        print(f\"üîÅ Buscando liveInfo para {len(streams_without_preview)} streams sem URL na API principal...\")\n",
        "        for stream_info in streams_without_preview:\n",
        "            username = stream_info[\"username\"]\n",
        "            if username in transmissao_em_proc:\n",
        "                continue\n",
        "            if usuarios_especificos and username not in usuarios_especificos:\n",
        "                continue\n",
        "            api_url_liveinfo = f\"https://api.xcam.gay/user/{username}/liveInfo\"\n",
        "            try:\n",
        "                response_liveinfo = requests.get(api_url_liveinfo)\n",
        "                response_liveinfo.raise_for_status()\n",
        "                data_liveinfo = response_liveinfo.json()\n",
        "                m3u8_url = data_liveinfo.get(\"cdnURL\") or data_liveinfo.get(\"edgeURL\")\n",
        "                poster_path = None\n",
        "                if m3u8_url:\n",
        "                    poster_path = generate_poster_with_ffmpeg(m3u8_url, username, temp_folder)\n",
        "                    streams_from_liveinfo.append({\n",
        "                        \"username\": username,\n",
        "                        \"src\": m3u8_url,\n",
        "                        \"poster\": poster_path\n",
        "                    })\n",
        "                else:\n",
        "                    print(f\"‚ö†Ô∏è liveInfo de {username} n√£o retornou cdnURL/edgeURL (usu√°rio possivelmente offline).\")\n",
        "            except Exception as ex:\n",
        "                print(f\"‚ùå Erro ao buscar liveInfo para {username}: {ex}\")\n",
        "            time.sleep(0.5)\n",
        "\n",
        "    # Junta, evita duplicidade de usu√°rio e respeita 'limit' FINAL\n",
        "    final_streams_list = []\n",
        "    seen_usernames = set()\n",
        "    for stream in streams_from_main + streams_from_liveinfo:\n",
        "        username = stream[\"username\"]\n",
        "        if username in seen_usernames or username in transmissao_em_proc:\n",
        "            continue\n",
        "        final_streams_list.append(stream)\n",
        "        seen_usernames.add(username)\n",
        "        if len(final_streams_list) >= limit:\n",
        "            break\n",
        "\n",
        "    print(f\"üîé Selecionadas {len(final_streams_list)} streams v√°lidas ap√≥s fallback (respeitando limit={limit}).\")\n",
        "    return final_streams_list\n",
        "\n",
        "def buscar_usuarios_especificos(usuarios_lista, temp_folder=\"/content\"):\n",
        "    \"\"\"\n",
        "    Busca usu√°rios espec√≠ficos via API, utilizando um limit alto.\n",
        "    Fallback via liveInfo para usu√°rios sem src.\n",
        "    Garante poster v√°lido: se ausente, gera com ffmpeg a partir do src/m3u8.\n",
        "    Considera log de transmiss√µes em processamento para evitar duplicidade.\n",
        "    \"\"\"\n",
        "    LOG_PROCESSAMENTO_PATH = \"/content/xcam_processing.log\"\n",
        "    transmissao_em_proc = set()\n",
        "    if os.path.exists(LOG_PROCESSAMENTO_PATH):\n",
        "        with open(LOG_PROCESSAMENTO_PATH, \"r\") as f:\n",
        "            transmissao_em_proc = set([line.strip() for line in f if line.strip()])\n",
        "\n",
        "    api_url = f\"https://api.xcam.gay/?limit={API_SEARCH_LIMIT}&page=1\"\n",
        "    print(f\"üîç Buscando usu√°rios espec√≠ficos em {api_url}\")\n",
        "    try:\n",
        "        response = requests.get(api_url)\n",
        "        response.raise_for_status()\n",
        "        data = response.json()\n",
        "        items = data.get(\"broadcasts\", {}).get(\"items\", [])\n",
        "        encontrados = []\n",
        "        sem_src = []\n",
        "        for item in items:\n",
        "            username = item.get(\"username\", \"\")\n",
        "            if username in usuarios_lista and username not in transmissao_em_proc:\n",
        "                preview = item.get(\"preview\") or {}\n",
        "                src = preview.get(\"src\")\n",
        "                poster = preview.get(\"poster\")\n",
        "                poster_path = None\n",
        "                if src:\n",
        "                    if poster and isinstance(poster, str) and poster.strip():\n",
        "                        poster_path = download_and_save_poster(poster, username, temp_folder)\n",
        "                    if not is_poster_valid(poster_path):\n",
        "                        poster_path = generate_poster_with_ffmpeg(src, username, temp_folder)\n",
        "                    encontrados.append({\n",
        "                        \"username\": username,\n",
        "                        \"src\": src,\n",
        "                        \"poster\": poster_path\n",
        "                    })\n",
        "                else:\n",
        "                    sem_src.append(username)\n",
        "        for username in sem_src:\n",
        "            if username in transmissao_em_proc:\n",
        "                continue\n",
        "            api_url_liveinfo = f\"https://api.xcam.gay/user/{username}/liveInfo\"\n",
        "            try:\n",
        "                response_liveinfo = requests.get(api_url_liveinfo)\n",
        "                response_liveinfo.raise_for_status()\n",
        "                data_liveinfo = response_liveinfo.json()\n",
        "                m3u8_url = data_liveinfo.get(\"cdnURL\") or data_liveinfo.get(\"edgeURL\")\n",
        "                poster_path = None\n",
        "                if m3u8_url:\n",
        "                    poster_path = generate_poster_with_ffmpeg(m3u8_url, username, temp_folder)\n",
        "                    encontrados.append({\n",
        "                        \"username\": username,\n",
        "                        \"src\": m3u8_url,\n",
        "                        \"poster\": poster_path\n",
        "                    })\n",
        "                else:\n",
        "                    print(f\"‚ö†Ô∏è liveInfo de {username} n√£o retornou cdnURL/edgeURL (usu√°rio possivelmente offline).\")\n",
        "            except Exception as ex:\n",
        "                print(f\"‚ùå Erro ao buscar liveInfo para {username}: {ex}\")\n",
        "            time.sleep(0.5)\n",
        "        print(f\"Encontrados {len(encontrados)} dos {len(usuarios_lista)} usu√°rios procurados (incluindo fallback).\")\n",
        "        return encontrados\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Erro ao buscar usu√°rios espec√≠ficos: {e}\")\n",
        "        return []\n",
        "\n",
        "def buscar_proxima_transmissao_livre(temp_folder=\"/content\"):\n",
        "    \"\"\"\n",
        "    Busca unit√°ria/inteligente: retorna a PR√ìXIMA transmiss√£o AO VIVO n√£o processada e j√° com poster v√°lido.\n",
        "    Agora otimizada: em vez de varrer p√°gina por p√°gina, busca todas as transmiss√µes online de uma vez s√≥ (limit alto, page=1).\n",
        "    Assim, reduz n√∫mero de requisi√ß√µes, encontra rapidamente a pr√≥xima vaga dispon√≠vel e evita downloads desnecess√°rios.\n",
        "    \"\"\"\n",
        "    LOG_PROCESSAMENTO_PATH = \"/content/xcam_processing.log\"\n",
        "    transmissao_em_proc = set()\n",
        "    if os.path.exists(LOG_PROCESSAMENTO_PATH):\n",
        "        with open(LOG_PROCESSAMENTO_PATH, \"r\") as f:\n",
        "            transmissao_em_proc = set([line.strip() for line in f if line.strip()])\n",
        "\n",
        "    api_url_main = f\"https://api.xcam.gay/?limit=1500&page=1\"\n",
        "    print(f\"üîé Buscando pr√≥xima transmiss√£o livre (todas de uma vez): {api_url_main}\")\n",
        "    try:\n",
        "        response_main = requests.get(api_url_main)\n",
        "        response_main.raise_for_status()\n",
        "        data_main = response_main.json()\n",
        "        items = data_main.get(\"broadcasts\", {}).get(\"items\", [])\n",
        "        for item in items:\n",
        "            username = item.get(\"username\", \"desconhecido\")\n",
        "            if username in transmissao_em_proc:\n",
        "                continue\n",
        "            preview = item.get(\"preview\") or {}\n",
        "            src = preview.get(\"src\")\n",
        "            poster = preview.get(\"poster\")\n",
        "            # S√≥ seleciona se houver src v√°lido\n",
        "            if src:\n",
        "                poster_path = None\n",
        "                if poster and isinstance(poster, str) and poster.strip():\n",
        "                    poster_path = download_and_save_poster(poster, username, temp_folder)\n",
        "                if not is_poster_valid(poster_path):\n",
        "                    poster_path = generate_poster_with_ffmpeg(src, username, temp_folder)\n",
        "                print(f\"üéØ Transmiss√£o livre encontrada: {username}\")\n",
        "                return {\n",
        "                    \"username\": username,\n",
        "                    \"src\": src,\n",
        "                    \"poster\": poster_path\n",
        "                }\n",
        "            else:\n",
        "                # Fallback para o PRIMEIRO candidato sem src\n",
        "                api_url_liveinfo = f\"https://api.xcam.gay/user/{username}/liveInfo\"\n",
        "                try:\n",
        "                    response_liveinfo = requests.get(api_url_liveinfo)\n",
        "                    response_liveinfo.raise_for_status()\n",
        "                    data_liveinfo = response_liveinfo.json()\n",
        "                    m3u8_url = data_liveinfo.get(\"cdnURL\") or data_liveinfo.get(\"edgeURL\")\n",
        "                    poster_path = None\n",
        "                    if m3u8_url:\n",
        "                        poster_path = generate_poster_with_ffmpeg(m3u8_url, username, temp_folder)\n",
        "                        print(f\"üéØ Transmiss√£o livre (pelo liveInfo) encontrada: {username}\")\n",
        "                        return {\n",
        "                            \"username\": username,\n",
        "                            \"src\": m3u8_url,\n",
        "                            \"poster\": poster_path\n",
        "                        }\n",
        "                except Exception as ex:\n",
        "                    print(f\"‚ùå Erro ao buscar liveInfo para {username}: {ex}\")\n",
        "                time.sleep(0.5)\n",
        "        print(\"üö´ Nenhuma transmiss√£o livre encontrada ap√≥s varrer todas online.\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Erro ao buscar transmiss√µes online: {e}\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "h1jr7D0pJ7jS"
      },
      "id": "h1jr7D0pJ7jS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# C√©lula 7: Grava√ß√£o da Stream, Download/Gera√ß√£o do Poster, Controle de Tempo M√≠nimo e Gerenciamento de Log\n",
        "\n",
        "**Objetivo:**  \n",
        "Grava a transmiss√£o ao vivo do usu√°rio usando ffmpeg. Durante a grava√ß√£o, baixa o poster da transmiss√£o ou, caso ele esteja ausente, inv√°lido ou n√£o possa ser baixado, gera automaticamente uma imagem de poster utilizando ffmpeg a partir da pr√≥pria stream. Ao final, verifica se o tempo de grava√ß√£o atingiu o m√≠nimo desejado para ser considerado v√°lido.  \n",
        "Agora, al√©m disso, atualiza o log de transmiss√µes em processamento ao iniciar e sempre remove ao finalizar a grava√ß√£o (com sucesso ou erro), garantindo o controle, a unicidade e evitando vazamento de processamento no sistema.\n",
        "\n",
        "**Como funciona:**\n",
        "\n",
        "*  Se o v√≠deo gravado for muito curto, descarta imediatamente o v√≠deo e o poster associado.\n",
        "*  Se atingir o tempo m√≠nimo, renomeia o v√≠deo, faz upload, renomeia o poster e chama a fun√ß√£o de atualiza√ß√£o de JSON.\n",
        "*  Antes de iniciar a grava√ß√£o, registra o usu√°rio no log de transmiss√µes em processamento; ao finalizar (com sucesso ou erro/exception), remove o usu√°rio desse log para liberar espa√ßo para novas transmiss√µes.\n",
        "*  Garante que sempre haver√° um poster v√°lido para cada transmiss√£o, baixando da API quando poss√≠vel ou gerando automaticamente com ffmpeg caso necess√°rio.\n",
        "*  Inclui limpeza de arquivos tempor√°rios ap√≥s upload para otimizar o uso de espa√ßo e manter o ambiente Colab organizado.\n",
        "*  A manipula√ß√£o do log √© feita de modo robusto, mesmo em situa√ß√µes de erro ou interrup√ß√£o, evitando inconsist√™ncias no processamento cont√≠nuo/paralelo.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "jGFyqOUoKEF7"
      },
      "id": "jGFyqOUoKEF7"
    },
    {
      "cell_type": "code",
      "source": [
        "# C√©lula 7: Grava√ß√£o de stream, download/gera√ß√£o do poster, atualiza√ß√£o e remo√ß√£o do log ao finalizar\n",
        "# -------------------------------------------------------------------------------------------------\n",
        "# Esta c√©lula garante controle rigoroso do log de transmiss√µes em processamento:\n",
        "# - Adiciona o usu√°rio ao log no in√≠cio da grava√ß√£o.\n",
        "# - Remove do log assim que a grava√ß√£o encerra (com sucesso ou erro), mesmo em caso de exce√ß√£o.\n",
        "# - Manipula√ß√£o do log √© robusta, evitando duplicidade e vazamentos.\n",
        "# - Garante limpeza de arquivos tempor√°rios ap√≥s uso.\n",
        "# - Calcula a dura√ß√£o real do arquivo usando ffprobe para garantir a validade da grava√ß√£o.\n",
        "\n",
        "def get_video_duration(filepath):\n",
        "    \"\"\"\n",
        "    Utiliza ffprobe para obter a dura√ß√£o real do arquivo mp4, em segundos.\n",
        "    Retorna None em caso de erro.\n",
        "    \"\"\"\n",
        "    import subprocess\n",
        "    import json\n",
        "    try:\n",
        "        cmd = [\n",
        "            \"ffprobe\", \"-v\", \"error\",\n",
        "            \"-show_entries\", \"format=duration\",\n",
        "            \"-of\", \"json\",\n",
        "            filepath\n",
        "        ]\n",
        "        result = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
        "        info = json.loads(result.stdout)\n",
        "        duration = float(info[\"format\"][\"duration\"])\n",
        "        return int(round(duration))\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è N√£o foi poss√≠vel obter dura√ß√£o via ffprobe: {e}\")\n",
        "        return None\n",
        "\n",
        "def gravar_stream(username, m3u8_url, poster_url=None, poster_frame_time=7):\n",
        "    \"\"\"\n",
        "    Grava a transmiss√£o ao vivo do usu√°rio usando ffmpeg.\n",
        "    - Garante poster v√°lido: baixa da poster_url, ou gera automaticamente com ffmpeg se ausente/inv√°lido.\n",
        "    - Controla o tempo m√≠nimo de grava√ß√£o e gerencia o log de transmiss√µes em processamento.\n",
        "    - Remove do log ao finalizar a grava√ß√£o, independentemente do resultado.\n",
        "    - Limpa arquivos tempor√°rios ao final.\n",
        "    poster_frame_time: tempo (em segundos) do v√≠deo onde a captura do poster ser√° feita, se gerado via ffmpeg.\n",
        "    \"\"\"\n",
        "    LOG_PROCESSAMENTO_PATH = \"/content/xcam_processing.log\"\n",
        "\n",
        "    # Adiciona a transmiss√£o ao log de transmiss√µes em processamento (thread-safe se usar lock)\n",
        "    try:\n",
        "        with open(LOG_PROCESSAMENTO_PATH, \"a\") as f:\n",
        "            f.write(f\"{username}\\n\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Erro ao registrar transmiss√£o em processamento no log: {e}\")\n",
        "\n",
        "    start_time_dt = datetime.now()\n",
        "    data_str = start_time_dt.strftime(\"%d-%m-%Y\")\n",
        "    horario_str = start_time_dt.strftime(\"%H-%M\")\n",
        "    temp_filename = f\"{username}_{start_time_dt.strftime('%Y%m%d_%H%M%S')}_temp.mp4\"\n",
        "    filepath = os.path.join(TEMP_OUTPUT_FOLDER, temp_filename)\n",
        "\n",
        "    print(f\"\\nüé¨ Iniciando grava√ß√£o de: {username} (URL: {m3u8_url}) em {filepath}\")\n",
        "\n",
        "    # Garantia de poster v√°lido:\n",
        "    poster_temp_path = None\n",
        "    if poster_url:\n",
        "        poster_temp_path = download_and_save_poster(poster_url, username, TEMP_OUTPUT_FOLDER)\n",
        "    if not is_poster_valid(poster_temp_path) and m3u8_url:\n",
        "        poster_temp_path = generate_poster_with_ffmpeg(\n",
        "            m3u8_url, username, TEMP_OUTPUT_FOLDER, frame_time=poster_frame_time\n",
        "        )\n",
        "\n",
        "    ffmpeg_cmd = [\"ffmpeg\", \"-i\", m3u8_url, \"-t\", str(RECORD_SECONDS), \"-c\", \"copy\", \"-y\", filepath]\n",
        "\n",
        "    start_time_process = time.time()\n",
        "    process = None\n",
        "\n",
        "    try:\n",
        "        process = subprocess.Popen(\n",
        "            ffmpeg_cmd,\n",
        "            stdout=subprocess.PIPE,\n",
        "            stderr=subprocess.STDOUT,\n",
        "            text=True,\n",
        "            bufsize=1,\n",
        "            universal_newlines=True\n",
        "        )\n",
        "        # Monitora o andamento do ffmpeg em tempo real (mantido para logs)\n",
        "        elapsed_seconds = 0\n",
        "        last_log_minute = -1\n",
        "        while True:\n",
        "            line = process.stdout.readline()\n",
        "            if not line and process.poll() is not None:\n",
        "                break\n",
        "            if \"time=\" in line:\n",
        "                try:\n",
        "                    match = re.search(r\"time=(\\d+):(\\d+):(\\d+)\", line)\n",
        "                    if match:\n",
        "                        h, m, s = map(int, match.groups())\n",
        "                        elapsed_seconds = h * 3600 + m * 60 + s\n",
        "                        if elapsed_seconds // 60 != last_log_minute:\n",
        "                            log_progress(username, elapsed_seconds, RECORD_SECONDS)\n",
        "                            last_log_minute = elapsed_seconds // 60\n",
        "                except Exception:\n",
        "                    pass\n",
        "\n",
        "        process.wait()\n",
        "        end_time_process = time.time()\n",
        "        elapsed_seconds_proc = round(end_time_process - start_time_process)\n",
        "        log_progress(username, elapsed_seconds_proc, RECORD_SECONDS)\n",
        "\n",
        "        if process.returncode != 0:\n",
        "            print(f\"‚ùå FFmpeg falhou para {username}. C√≥digo de sa√≠da: {process.returncode}\")\n",
        "            return {\n",
        "                'username': username,\n",
        "                'filename': temp_filename,\n",
        "                'filepath': filepath,\n",
        "                'upload_success': False,\n",
        "                'abyss_response': \"Grava√ß√£o FFmpeg falhou\"\n",
        "            }\n",
        "        else:\n",
        "            elapsed_seconds_real = get_video_duration(filepath)\n",
        "            if elapsed_seconds_real is not None:\n",
        "                print(f\"‚úÖ Dura√ß√£o real do arquivo gravado: {elapsed_seconds_real}s (ffprobe)\")\n",
        "            else:\n",
        "                print(f\"‚ö†Ô∏è N√£o foi poss√≠vel aferir dura√ß√£o real, usando a do processo: {elapsed_seconds_proc}s\")\n",
        "                elapsed_seconds_real = elapsed_seconds_proc\n",
        "\n",
        "            # Valida√ß√£o pelo tempo real do arquivo!\n",
        "            if elapsed_seconds_real < RECORD_SECONDS_MIN:\n",
        "                print(f\"‚è© Dura√ß√£o gravada ({elapsed_seconds_real}s) menor que o m√≠nimo ({RECORD_SECONDS_MIN}s). Arquivo descartado.\")\n",
        "                if os.path.exists(filepath): os.remove(filepath)\n",
        "                if poster_temp_path and os.path.exists(poster_temp_path): os.remove(poster_temp_path)\n",
        "                return {\n",
        "                    'username': username,\n",
        "                    'filename': temp_filename,\n",
        "                    'filepath': filepath,\n",
        "                    'upload_success': False,\n",
        "                    'abyss_response': \"Grava√ß√£o muito curta (descartada)\"\n",
        "                }\n",
        "\n",
        "            tempo_formatado = format_seconds(elapsed_seconds_real)\n",
        "            final_filename = f\"{username}_{data_str}_{horario_str}_{tempo_formatado}.mp4\"\n",
        "            final_filepath = os.path.join(TEMP_OUTPUT_FOLDER, final_filename)\n",
        "\n",
        "            try:\n",
        "                os.rename(filepath, final_filepath)\n",
        "                print(f\"‚úÖ Arquivo renomeado para: {final_filename}\")\n",
        "                filepath_for_upload = final_filepath\n",
        "                filename_for_upload = final_filename\n",
        "            except Exception as e:\n",
        "                print(f\"‚ùå Erro ao renomear arquivo {temp_filename} para {final_filename}: {e}\")\n",
        "                filepath_for_upload = filepath\n",
        "                filename_for_upload = temp_filename\n",
        "\n",
        "            success, abyss_resp, slug = upload_to_abyss_and_update_json(\n",
        "                filepath_for_upload, username, elapsed_seconds_real,\n",
        "                poster_temp_path=poster_temp_path\n",
        "            )\n",
        "\n",
        "            return {\n",
        "                'username': username,\n",
        "                'filename': filename_for_upload,\n",
        "                'filepath': filepath_for_upload,\n",
        "                'upload_success': success,\n",
        "                'abyss_response': abyss_resp,\n",
        "                'slug': slug\n",
        "            }\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"‚ùå Erro: Comando 'ffmpeg' n√£o encontrado. Certifique-se de que foi instalado corretamente.\")\n",
        "        return {\n",
        "            'username': username,\n",
        "            'filename': None,\n",
        "            'filepath': None,\n",
        "            'upload_success': False,\n",
        "            'abyss_response': \"Comando FFmpeg n√£o encontrado\"\n",
        "        }\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Erro inesperado durante a execu√ß√£o do FFmpeg para {username}: {e}\")\n",
        "        return {\n",
        "            'username': username,\n",
        "            'filename': None,\n",
        "            'filepath': None,\n",
        "            'upload_success': False,\n",
        "            'abyss_response': f\"Erro inesperado na execu√ß√£o do FFmpeg: {e}\"\n",
        "        }\n",
        "    finally:\n",
        "        # Remove a transmiss√£o do log de transmiss√µes em processamento (robusto e seguro)\n",
        "        try:\n",
        "            if os.path.exists(LOG_PROCESSAMENTO_PATH):\n",
        "                with open(LOG_PROCESSAMENTO_PATH, \"r\") as f:\n",
        "                    linhas = f.readlines()\n",
        "                with open(LOG_PROCESSAMENTO_PATH, \"w\") as f:\n",
        "                    for l in linhas:\n",
        "                        if l.strip() != username:\n",
        "                            f.write(l)\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Erro ao remover transmiss√£o do log de processamento: {e}\")\n",
        "\n",
        "        # Limpa o arquivo de v√≠deo tempor√°rio ap√≥s upload (para n√£o ocupar espa√ßo no Colab)\n",
        "        if 'filepath_for_upload' in locals() and os.path.exists(filepath_for_upload):\n",
        "            try:\n",
        "                os.remove(filepath_for_upload)\n",
        "                print(f\"üóëÔ∏è Arquivo de v√≠deo removido do Colab: {filepath_for_upload}\")\n",
        "            except Exception as e:\n",
        "                print(f\"‚ö†Ô∏è N√£o foi poss√≠vel remover o arquivo de v√≠deo tempor√°rio: {e}\")"
      ],
      "metadata": {
        "id": "eJ_jrfNgKZNr"
      },
      "id": "eJ_jrfNgKZNr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# C√©lula 8: Upload para Abyss.to, Atualiza√ß√£o do rec.json, Commit do Poster\n",
        "\n",
        "**Objetivo:**  \n",
        "Faz upload do v√≠deo para o Abyss.to. Se o upload for bem-sucedido, renomeia/move o poster para a pasta correta do reposit√≥rio, atualiza ou cria o arquivo rec.json do usu√°rio com todos os metadados (incluindo poster e urlIframe) e realiza o commit/push dos arquivos alterados.  \n",
        "Agora, os commits e pushs s√£o feitos em lote, apenas quando a quantidade de arquivos alterados atinge o valor definido por `COMMIT_PUSH_THRESHOLD`, otimizando o fluxo de trabalho e reduzindo o n√∫mero de opera√ß√µes no reposit√≥rio. Tamb√©m garante que o poster utilizado (baixado ou gerado via ffmpeg) √© corretamente movido, registrado e copiado para o Google Drive (se montado).\n",
        "\n",
        "**Como funciona:**\n",
        "\n",
        "*   Preenche todos os campos do JSON conforme seu padr√£o, incluindo poster e urlIframe.\n",
        "*   Garante que apenas v√≠deos v√°lidos sejam registrados e compartilha os links corretos.\n",
        "*   Move/renomeia o arquivo do poster utilizado para o local definitivo, sempre associando ao v√≠deo pelo slug no nome do arquivo.\n",
        "*   Ao inv√©s de commitar/pushar a cada altera√ß√£o, acumula os arquivos modificados em um buffer e s√≥ realiza o commit/push ao atingir o threshold definido (`COMMIT_PUSH_THRESHOLD`). No final do processamento, realiza commit/push dos arquivos restantes, se houver.\n",
        "*   O acesso ao buffer de commit/push √© protegido por um lock para garantir seguran√ßa em cen√°rios de execu√ß√£o concorrente/processamento paralelo.\n",
        "*   Remove arquivos tempor√°rios de poster ap√≥s mover para o destino final, mantendo o ambiente limpo e eficiente.\n",
        "*   Sempre que salvar ou atualizar rec.json ou poster, faz uma c√≥pia tamb√©m para a pasta correspondente no Google Drive, garantindo redund√¢ncia e f√°cil acesso externo.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "YjGKDlbIKaLs"
      },
      "id": "YjGKDlbIKaLs"
    },
    {
      "cell_type": "code",
      "source": [
        "# C√©lula 8: Upload para Abyss.to, atualiza√ß√£o do rec.json, commit do poster (com c√≥pia p/ Google Drive)\n",
        "# ----------------------------------------------------------------------------------------------------\n",
        "# Esta c√©lula √© respons√°vel por:\n",
        "# - Fazer upload do v√≠deo gravado para Abyss.to.\n",
        "# - Atualizar e registrar os metadados no arquivo rec.json do usu√°rio.\n",
        "# - Mover/renomear o poster (imagem) para o local correto, sempre usando o novo poster (baixado ou gerado via ffmpeg).\n",
        "# - Acumular arquivos para commit/push e executar o envio ao atingir o threshold de altera√ß√µes, com seguran√ßa para concorr√™ncia.\n",
        "# - Fazer a limpeza de arquivos tempor√°rios ap√≥s o uso.\n",
        "# - Sempre que salvar/atualizar rec.json ou poster, copia tamb√©m para o Google Drive (se montado).\n",
        "#\n",
        "# ATEN√á√ÉO: Para processamento paralelo, garante atomicidade do commit_buffer usando lock de threading.\n",
        "\n",
        "import shutil\n",
        "import threading\n",
        "\n",
        "# Caminho base do Drive (ajuste se necess√°rio)\n",
        "DRIVE_USER_BASE = \"/content/drive/MyDrive/XCam.Drive/XCam/xcam-db/user\"\n",
        "\n",
        "# Lock global para garantir atomicidade do commit_buffer em cen√°rios concorrentes\n",
        "commit_lock = threading.Lock()\n",
        "\n",
        "def upload_to_abyss_and_update_json(\n",
        "    filepath, username, duration_seconds, poster_temp_path=None,\n",
        "    commit_buffer=None, commit_threshold=None\n",
        "):\n",
        "    \"\"\"\n",
        "    Faz upload do v√≠deo, atualiza o rec.json e move o poster.\n",
        "    Acumula arquivos para commit/push e s√≥ executa quando atingir o threshold (ou 0).\n",
        "    Sempre salva/atualiza rec.json e poster tamb√©m no Google Drive.\n",
        "    O acesso ao commit_buffer √© protegido por lock para seguran√ßa em execu√ß√£o concorrente.\n",
        "    \"\"\"\n",
        "    file_name = os.path.basename(filepath)\n",
        "    file_type = 'video/mp4'\n",
        "    print(f\"‚¨ÜÔ∏è Upload de: {file_name} para Abyss.to...\")\n",
        "\n",
        "    upload_success = False\n",
        "    abyss_response = \"Upload falhou - Sem resposta\"\n",
        "    uploaded_url = None\n",
        "    video_id = None\n",
        "    slug = None\n",
        "\n",
        "    # Inicializa buffers se n√£o enviados\n",
        "    if commit_buffer is None:\n",
        "        if not hasattr(upload_to_abyss_and_update_json, 'commit_buffer'):\n",
        "            upload_to_abyss_and_update_json.commit_buffer = []\n",
        "        commit_buffer = upload_to_abyss_and_update_json.commit_buffer\n",
        "\n",
        "    if commit_threshold is None:\n",
        "        global COMMIT_PUSH_THRESHOLD\n",
        "        commit_threshold = COMMIT_PUSH_THRESHOLD if 'COMMIT_PUSH_THRESHOLD' in globals() else 100\n",
        "\n",
        "    # ---- Upload do v√≠deo para Abyss.to ----\n",
        "    try:\n",
        "        with open(filepath, 'rb') as f:\n",
        "            files = { 'file': (file_name, f, file_type) }\n",
        "            response = requests.post(ABYSS_UPLOAD_URL, files=files)\n",
        "            resp_json = response.json()\n",
        "            abyss_response = resp_json\n",
        "            if resp_json.get('status'):\n",
        "                upload_success = True\n",
        "                uploaded_url = resp_json.get('url') or resp_json.get('urlIframe')\n",
        "                video_id = resp_json.get('slug') or resp_json.get('video')\n",
        "                slug = video_id\n",
        "                print(f\"üì§ Upload bem-sucedido. URL: {uploaded_url} | SLUG: {slug}\")\n",
        "            else:\n",
        "                print(f\"‚ùå Falha no upload. Mensagem: {resp_json.get('message','')}\")\n",
        "    except Exception as e:\n",
        "        abyss_response = f\"Erro no upload: {e}\"\n",
        "        print(f\"‚ùå Erro no upload: {e}\")\n",
        "\n",
        "    poster_final_relpath = None\n",
        "    poster_final_path = None\n",
        "    poster_final_name = None\n",
        "\n",
        "    # ---- Move/renomeia o poster (imagem) para o local correto do usu√°rio ----\n",
        "    if upload_success and poster_temp_path and slug:\n",
        "        try:\n",
        "            user_folder = os.path.join(BASE_REPO_FOLDER, \"xcam-db\", \"user\", username)\n",
        "            os.makedirs(user_folder, exist_ok=True)\n",
        "            poster_final_name = f\"{slug}.jpg\"\n",
        "            poster_final_path = os.path.join(user_folder, poster_final_name)\n",
        "            os.rename(poster_temp_path, poster_final_path)\n",
        "            poster_final_relpath = os.path.relpath(poster_final_path, BASE_REPO_FOLDER)\n",
        "            print(f\"üñºÔ∏è Poster movido para {poster_final_path}\")\n",
        "            # Adiciona poster ao buffer de commit (com lock)\n",
        "            with commit_lock:\n",
        "                if poster_final_relpath not in commit_buffer:\n",
        "                    commit_buffer.append(poster_final_relpath)\n",
        "            # ---------- NOVO: Copia poster para o Google Drive ----------\n",
        "            drive_user_dir = os.path.join(DRIVE_USER_BASE, username)\n",
        "            os.makedirs(drive_user_dir, exist_ok=True)\n",
        "            poster_drive_path = os.path.join(drive_user_dir, poster_final_name)\n",
        "            try:\n",
        "                shutil.copy2(poster_final_path, poster_drive_path)\n",
        "                print(f\"üóÇÔ∏è Poster tamb√©m salvo no Drive: {poster_drive_path}\")\n",
        "            except Exception as e:\n",
        "                print(f\"‚ö†Ô∏è Falha ao copiar poster para o Drive: {e}\")\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Erro ao mover/renomear poster: {e}\")\n",
        "\n",
        "    # ---- Atualiza/Cria rec.json do usu√°rio com os dados do v√≠deo ----\n",
        "    if upload_success:\n",
        "        try:\n",
        "            user_folder = os.path.join(BASE_REPO_FOLDER, \"xcam-db\", \"user\", username)\n",
        "            os.makedirs(user_folder, exist_ok=True)\n",
        "            json_filepath = os.path.join(user_folder, \"rec.json\")\n",
        "\n",
        "            file_base = file_name.replace('.mp4', '')\n",
        "            parts = file_base.split('_')\n",
        "            if len(parts) >= 4:\n",
        "                json_data = parts[-3]\n",
        "                json_horario = parts[-2]\n",
        "                json_tempo = parts[-1]\n",
        "            else:\n",
        "                now = datetime.now()\n",
        "                json_data = now.strftime(\"%d-%m-%Y\")\n",
        "                json_horario = now.strftime(\"%H-%M\")\n",
        "                json_tempo = format_seconds(duration_seconds)\n",
        "\n",
        "            poster_url = f\"https://db.xcam.gay/user/{username}/{slug}.jpg\" if slug else \"\"\n",
        "            url_iframe = f\"https://short.icu/{slug}?thumbnail={poster_url}\" if slug else \"\"\n",
        "\n",
        "            new_video_entry = {\n",
        "                \"video\": slug if slug else \"ID_n√£o_retornado\",\n",
        "                \"title\": file_base,\n",
        "                \"file\": file_name,\n",
        "                \"url\": uploaded_url if uploaded_url else \"URL_n√£o_retornada\",\n",
        "                \"poster\": poster_url,\n",
        "                \"urlIframe\": url_iframe,\n",
        "                \"data\": json_data,\n",
        "                \"horario\": json_horario,\n",
        "                \"tempo\": json_tempo\n",
        "            }\n",
        "\n",
        "            def zerar_base(username):\n",
        "                return {\n",
        "                    \"username\": username,\n",
        "                    \"records\": 0,\n",
        "                    \"videos\": []\n",
        "                }\n",
        "\n",
        "            # Carrega ou inicializa rec.json\n",
        "            if not os.path.exists(json_filepath):\n",
        "                rec_data = zerar_base(username)\n",
        "            else:\n",
        "                try:\n",
        "                    with open(json_filepath, 'r', encoding='utf-8') as f:\n",
        "                        loaded = json.load(f)\n",
        "                    valid = (\n",
        "                        isinstance(loaded, dict)\n",
        "                        and \"username\" in loaded\n",
        "                        and \"records\" in loaded\n",
        "                        and \"videos\" in loaded\n",
        "                        and isinstance(loaded[\"videos\"], list)\n",
        "                    )\n",
        "                    rec_data = loaded if valid else zerar_base(username)\n",
        "                except Exception:\n",
        "                    rec_data = zerar_base(username)\n",
        "\n",
        "            # Adiciona novo v√≠deo ao hist√≥rico\n",
        "            rec_data[\"records\"] += 1\n",
        "            rec_data[\"videos\"].append(new_video_entry)\n",
        "            with open(json_filepath, 'w', encoding='utf-8') as f:\n",
        "                json.dump(rec_data, f, indent=2, ensure_ascii=False)\n",
        "            print(f\"‚úÖ rec.json para {username} atualizado em {json_filepath}\")\n",
        "\n",
        "            rel_json_path = os.path.relpath(json_filepath, BASE_REPO_FOLDER)\n",
        "            # Adiciona rec.json ao buffer de commit (com lock)\n",
        "            with commit_lock:\n",
        "                if rel_json_path not in commit_buffer:\n",
        "                    commit_buffer.append(rel_json_path)\n",
        "            # ---------- NOVO: Copia rec.json para o Google Drive ----------\n",
        "            drive_user_dir = os.path.join(DRIVE_USER_BASE, username)\n",
        "            os.makedirs(drive_user_dir, exist_ok=True)\n",
        "            try:\n",
        "                shutil.copy2(json_filepath, os.path.join(drive_user_dir, \"rec.json\"))\n",
        "                print(f\"üóÇÔ∏è rec.json tamb√©m salvo no Drive: {os.path.join(drive_user_dir, 'rec.json')}\")\n",
        "            except Exception as e:\n",
        "                print(f\"‚ö†Ô∏è Falha ao copiar rec.json para o Drive: {e}\")\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Erro ao atualizar rec.json: {e}\")\n",
        "            abyss_response = f\"Upload sucesso, erro no JSON: {e}\"\n",
        "\n",
        "    # ---- Commit/push autom√°tico ajustado ----\n",
        "    with commit_lock:\n",
        "        # Se threshold for 0, faz commit/push IMEDIATO ap√≥s cada processamento bem-sucedido\n",
        "        if commit_threshold == 0 and len(commit_buffer) > 0:\n",
        "            print(f\"üöÄ Commit/push autom√°tico IMEDIATO (threshold=0): {len(commit_buffer)} arquivos\")\n",
        "            try:\n",
        "                git_commit_and_push(commit_buffer, commit_message=\"Commit autom√°tico ap√≥s processamento bem-sucedido\")\n",
        "            except Exception as e:\n",
        "                print(f\"‚ùå Falha no commit/push autom√°tico imediato: {e}\")\n",
        "            commit_buffer.clear()\n",
        "        # Caso threshold > 0, mant√©m o comportamento em lote\n",
        "        elif commit_threshold > 0 and len(commit_buffer) >= commit_threshold:\n",
        "            print(f\"üöÄ Commit/push autom√°tico: {len(commit_buffer)} arquivos (threshold: {commit_threshold})\")\n",
        "            try:\n",
        "                git_commit_and_push(commit_buffer, commit_message=\"Atualiza arquivos em lote (threshold autom√°tico)\")\n",
        "            except Exception as e:\n",
        "                print(f\"‚ùå Falha no commit/push em lote: {e}\")\n",
        "            commit_buffer.clear()\n",
        "\n",
        "    # ---- Limpeza do arquivo de poster tempor√°rio, se sobrou ----\n",
        "    if poster_temp_path and os.path.exists(poster_temp_path):\n",
        "        try:\n",
        "            os.remove(poster_temp_path)\n",
        "            print(f\"üóëÔ∏è Poster tempor√°rio removido: {poster_temp_path}\")\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è N√£o foi poss√≠vel remover o poster tempor√°rio: {e}\")\n",
        "\n",
        "    return upload_success, abyss_response, slug\n",
        "\n",
        "# Fun√ß√£o auxiliar para garantir commit/push dos arquivos restantes ao final do processamento.\n",
        "def commit_push_restantes():\n",
        "    \"\"\"\n",
        "    Realiza commit/push final de todos os arquivos pendentes no buffer.\n",
        "    O acesso ao buffer √© protegido por lock para seguran√ßa em execu√ß√£o concorrente.\n",
        "    \"\"\"\n",
        "    buffer = getattr(upload_to_abyss_and_update_json, 'commit_buffer', None)\n",
        "    if buffer and len(buffer) > 0:\n",
        "        print(f\"üöÄ Commit/push final de {len(buffer)} arquivos restantes\")\n",
        "        with commit_lock:\n",
        "            try:\n",
        "                git_commit_and_push(buffer, commit_message=\"Atualiza arquivos finais (commit final)\")\n",
        "            except Exception as e:\n",
        "                print(f\"‚ùå Falha no commit/push final em lote: {e}\")\n",
        "            buffer.clear()"
      ],
      "metadata": {
        "id": "vMTiCrJ5Kp81"
      },
      "id": "vMTiCrJ5Kp81",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# C√©lula 9: Processamento Autom√°tico (Paralelo e Supervisor Cont√≠nuo)\n",
        "\n",
        "**Objetivo:**  \n",
        "Controla todo o fluxo operacional do notebook, processando transmiss√µes de forma paralela para m√°xima efici√™ncia. Utiliza as fun√ß√µes das c√©lulas anteriores para buscar, gravar, processar, fazer upload e registrar os v√≠deos.  \n",
        "Agora, garante que o lote de transmiss√µes seja sempre preenchido at√© o `LIMIT_DEFAULT`, controla a unicidade das transmiss√µes em processamento (via log) e gerencia automaticamente o avan√ßo e rota√ß√£o das p√°ginas.  \n",
        "O loop supervisor cont√≠nuo permite que o notebook opere de maneira aut√¥noma, mantendo sempre o m√°ximo de transmiss√µes poss√≠veis processando em paralelo, e faz commit/push dos arquivos pendentes ao t√©rmino.\n",
        "\n",
        "**Como funciona:**\n",
        "\n",
        "*   Se o usu√°rio informou nomes espec√≠ficos, busca e grava apenas esses usu√°rios.\n",
        "*   Caso contr√°rio, processa normalmente por p√°ginas, sempre mantendo o lote cheio at√© `LIMIT_DEFAULT`, pulando transmiss√µes j√° em processamento ou duplicadas, e utilizando busca inteligente caso necess√°rio para completar o lote.\n",
        "*   Mant√©m o loop at√© n√£o encontrar mais transmiss√µes dispon√≠veis para processar.\n",
        "*   Exibe logs detalhados e controla a espera entre p√°ginas para n√£o sobrecarregar a API.\n",
        "*   Faz o controle e rota√ß√£o das p√°ginas automaticamente, garantindo que todas as transmiss√µes poss√≠veis sejam processadas.\n",
        "*   Ao final, garante commit/push dos arquivos alterados que ainda estejam no buffer, assegurando consist√™ncia dos dados e do reposit√≥rio.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "iwgt8f8iKq4y"
      },
      "id": "iwgt8f8iKq4y"
    },
    {
      "cell_type": "code",
      "source": [
        "# C√©lula 9: Supervisor din√¢mico e processamento autom√°tico cont√≠nuo (paralelo e interativo) das transmiss√µes\n",
        "# ----------------------------------------------------------------------------------------------------------------\n",
        "# Esta c√©lula implementa um supervisor din√¢mico, mantendo o lote sempre cheio em tempo real.\n",
        "# Cada vaga livre √© imediatamente preenchida, maximizando o uso do processamento paralelo.\n",
        "# O log do processo inclui informa√ß√µes detalhadas de cada etapa, ajudando no diagn√≥stico e monitoramento.\n",
        "\n",
        "# C√©lula 9: Supervisor din√¢mico e processamento autom√°tico cont√≠nuo das transmiss√µes\n",
        "\n",
        "def log_supervisor(msg, level=\"INFO\"):\n",
        "    from datetime import datetime\n",
        "    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "    print(f\"[{timestamp}] [{level}] {msg}\")\n",
        "\n",
        "def worker(username, m3u8_url, poster_url, results):\n",
        "    log_supervisor(f\"Iniciando grava√ß√£o: {username} | URL: {m3u8_url} | Poster: {poster_url}\", \"WORKER\")\n",
        "    result = gravar_stream(username, m3u8_url, poster_url)\n",
        "    log_supervisor(\n",
        "        f\"Finalizou grava√ß√£o: {username} | Sucesso: {result.get('upload_success')} | \"\n",
        "        f\"Arquivo: {result.get('filename')} | Abyss: {result.get('abyss_response')}\", \"WORKER\")\n",
        "    results.append(result)\n",
        "\n",
        "def supervisor_dinamico(usuarios_especificos=None):\n",
        "    from multiprocessing import Manager, Process\n",
        "    import time\n",
        "    import os\n",
        "\n",
        "    pool_size = LIMIT_DEFAULT if not usuarios_especificos else API_SEARCH_LIMIT\n",
        "    running = []\n",
        "    results = Manager().list()\n",
        "    seen_usernames = set()\n",
        "    LOG_PROCESSAMENTO_PATH = \"/content/xcam_processing.log\"\n",
        "\n",
        "    log_supervisor(f\"Supervisor din√¢mico iniciado | Lote alvo: {pool_size} | Modo: {'espec√≠fico' if usuarios_especificos else 'autom√°tico'}\")\n",
        "\n",
        "    def atualizar_seen_usernames():\n",
        "        # L√™ do log para garantir duplicidade robusta mesmo em concorr√™ncia\n",
        "        if os.path.exists(LOG_PROCESSAMENTO_PATH):\n",
        "            with open(LOG_PROCESSAMENTO_PATH, \"r\") as f:\n",
        "                log_set = set([line.strip() for line in f if line.strip()])\n",
        "                seen_usernames.update(log_set)\n",
        "\n",
        "    def buscar_nova_transmissao():\n",
        "        atualizar_seen_usernames()  # Atualiza sempre antes de buscar\n",
        "        if usuarios_especificos:\n",
        "            candidatos = buscar_usuarios_especificos(usuarios_especificos)\n",
        "            for s in candidatos:\n",
        "                username = s[\"username\"]\n",
        "                if username not in seen_usernames:\n",
        "                    log_supervisor(f\"Nova transmiss√£o encontrada (espec√≠fico): {username}\", \"BUSCA\")\n",
        "                    return s\n",
        "            log_supervisor(\"Nenhuma transmiss√£o espec√≠fica livre encontrada.\", \"BUSCA\")\n",
        "            return None\n",
        "        else:\n",
        "            for tentativa in range(1, 11):\n",
        "                log_supervisor(f\"Buscando pr√≥xima transmiss√£o livre: tentativa {tentativa}\", \"BUSCA\")\n",
        "                stream = buscar_proxima_transmissao_livre(pagina_inicial=tentativa, pagina_max=tentativa)\n",
        "                if stream and stream[\"username\"] not in seen_usernames:\n",
        "                    log_supervisor(f\"Nova transmiss√£o encontrada: {stream['username']} (p√°gina {tentativa})\", \"BUSCA\")\n",
        "                    return stream\n",
        "            log_supervisor(\"Nenhuma transmiss√£o livre encontrada ap√≥s tentativas.\", \"BUSCA\")\n",
        "            return None\n",
        "\n",
        "    log_supervisor(f\"Preenchendo lote inicial com at√© {pool_size} transmiss√µes...\", \"STARTUP\")\n",
        "    tentativas = 0\n",
        "    max_tentativas = 100\n",
        "    while len(running) < pool_size and tentativas < max_tentativas:\n",
        "        stream = buscar_nova_transmissao()\n",
        "        if not stream:\n",
        "            log_supervisor(\"Fim das transmiss√µes dispon√≠veis para preencher lote inicial.\", \"STARTUP\")\n",
        "            break\n",
        "        username = stream[\"username\"]\n",
        "        seen_usernames.add(username)\n",
        "        # Escreve no log imediatamente para evitar duplicidade em concorr√™ncia antes do .start()\n",
        "        with open(LOG_PROCESSAMENTO_PATH, \"a\") as f:\n",
        "            f.write(f\"{username}\\n\")\n",
        "        log_supervisor(f\"Lan√ßando processo para: {username} | {len(running)+1}/{pool_size}\", \"STARTUP\")\n",
        "        p = Process(target=worker, args=(username, stream[\"src\"], stream.get(\"poster\"), results))\n",
        "        running.append(p)\n",
        "        p.start()\n",
        "        tentativas += 1\n",
        "\n",
        "    log_supervisor(f\"Lote inicial lan√ßado com {len(running)} transmiss√µes.\", \"STARTUP\")\n",
        "\n",
        "    while True:\n",
        "        antes = len(running)\n",
        "        running = [p for p in running if p.is_alive()]\n",
        "        depois = len(running)\n",
        "        if antes != depois:\n",
        "            log_supervisor(f\"{antes-depois} grava√ß√µes finalizaram. Vagas livres: {pool_size-len(running)}\", \"LOOP\")\n",
        "        vagas_livres = pool_size - len(running)\n",
        "        if vagas_livres > 0:\n",
        "            for _ in range(vagas_livres):\n",
        "                stream = buscar_nova_transmissao()\n",
        "                if not stream:\n",
        "                    log_supervisor(\"N√£o h√° mais transmiss√µes para preencher as vagas livres.\", \"LOOP\")\n",
        "                    break\n",
        "                username = stream[\"username\"]\n",
        "                seen_usernames.add(username)\n",
        "                with open(LOG_PROCESSAMENTO_PATH, \"a\") as f:\n",
        "                    f.write(f\"{username}\\n\")\n",
        "                log_supervisor(f\"Lan√ßando nova grava√ß√£o: {username} | Vaga preenchida {len(running)+1}/{pool_size}\", \"LOOP\")\n",
        "                p = Process(target=worker, args=(username, stream[\"src\"], stream.get(\"poster\"), results))\n",
        "                running.append(p)\n",
        "                p.start()\n",
        "        if not running:\n",
        "            log_supervisor(\"Todas as transmiss√µes poss√≠veis j√° foram processadas!\", \"END\")\n",
        "            break\n",
        "        log_supervisor(f\"Transmiss√µes ativas: {len(running)} | Total processadas: {len(seen_usernames)} | Buffer de resultados: {len(results)}\", \"STATUS\")\n",
        "        time.sleep(2)\n",
        "\n",
        "    log_supervisor(f\"Processamento din√¢mico conclu√≠do! Total de transmiss√µes gravadas/processadas: {len(results)}\", \"RESUMO\")\n",
        "    try:\n",
        "        log_supervisor(\"Realizando commit/push final dos arquivos pendentes...\", \"FINALIZACAO\")\n",
        "        commit_push_restantes()\n",
        "        log_supervisor(\"Commit/push final executado com sucesso.\", \"FINALIZACAO\")\n",
        "    except Exception as e:\n",
        "        log_supervisor(f\"Falha ao tentar commit/push final dos arquivos restantes: {e}\", \"ERRO\")\n",
        "    log_supervisor(\"Supervisor din√¢mico finalizado.\", \"END\")\n",
        "\n",
        "def main():\n",
        "    usuarios_especificos = perguntar_transmissoes_especificas()\n",
        "    log_supervisor(\"Iniciando busca e grava√ß√£o de streams (supervisor din√¢mico)...\", \"MAIN\")\n",
        "    supervisor_dinamico(usuarios_especificos=usuarios_especificos)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    try:\n",
        "        if 'google.colab' in str(get_ipython()):\n",
        "            main()\n",
        "        else:\n",
        "            print(\"Execute main() manualmente se desejar rodar fora do Colab.\")\n",
        "    except NameError:\n",
        "        print(\"N√£o est√° rodando em Colab/IPython. Execute main() se desejar.\")"
      ],
      "metadata": {
        "id": "5WKQV9g_LB9M"
      },
      "id": "5WKQV9g_LB9M",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# C√©lula extra: Commit final de pend√™ncias\n",
        "def commit_final_pendencias():\n",
        "    commit_buffer = getattr(upload_to_abyss_and_update_json, 'commit_buffer', [])\n",
        "    if commit_buffer:\n",
        "        print(f\"üîî Realizando commit/push final de {len(commit_buffer)} pend√™ncias...\")\n",
        "        git_commit_and_push(commit_buffer, commit_message=\"Commit final de pend√™ncias\")\n",
        "        commit_buffer.clear()\n",
        "    else:\n",
        "        print(\"‚úÖ Sem pend√™ncias para commit final.\")\n",
        "\n",
        "# Execute isto ao final do processamento\n",
        "# commit_final_pendencias()"
      ],
      "metadata": {
        "id": "eXVBhXjsAuAY"
      },
      "id": "eXVBhXjsAuAY",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "c9hve1ySGVAs"
      ],
      "cell_execution_strategy": "setup",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}