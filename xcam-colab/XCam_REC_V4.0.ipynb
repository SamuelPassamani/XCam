{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SamuelPassamani/XCam/blob/main/xcam-colab/XCam_REC_V4.0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# C√©lula 1: Configura√ß√µes Auxiliares, Par√¢metros Globais e Log Centralizado\n",
        "\n",
        "**Objetivo:**  \n",
        "Esta c√©lula inicializa e centraliza todas as vari√°veis globais, par√¢metros essenciais e agora tamb√©m fornece um utilit√°rio robusto para o log √∫nico do notebook XCam.  \n",
        "Permite ajuste r√°pido e seguro do comportamento do notebook, incluindo limites de processamento, controle de grava√ß√£o, commit autom√°tico e mecanismos de resili√™ncia contra transmiss√µes problem√°ticas.\n",
        "\n",
        "## Principais pontos e melhorias implementadas\n",
        "\n",
        "- **Centraliza√ß√£o dos par√¢metros globais:**  \n",
        "  Todos os valores cr√≠ticos (limites, thresholds, caminhos) s√£o definidos e propagados como globais pelo notebook.\n",
        "- **Log √∫nico modular e estruturado (`xcam_master.log`):**  \n",
        "  Todas as opera√ß√µes relevantes (busca, grava√ß√£o, blacklist, commit, erros, etc.) agora s√£o registradas em um √∫nico arquivo JSON Lines.  \n",
        "  Cada entrada inclui sess√£o, evento, id, username, id_username, timestamps, status e detalhes.\n",
        "- **Fun√ß√µes utilit√°rias para o log:**  \n",
        "  Adi√ß√£o, busca, remo√ß√£o e atualiza√ß√£o de eventos s√£o facilitadas por fun√ß√µes modulares (CRUD), promovendo robustez, rastreabilidade e f√°cil manuten√ß√£o.\n",
        "- **Blacklist, falhas e processamento padronizados por `id`:**  \n",
        "  Toda l√≥gica de controle √© feita via identificador √∫nico (`id`) e refer√™ncia `{id}:{username}` (`id_username`), garantindo unicidade e eliminando inconsist√™ncias.\n",
        "- **Uso consistente do campo `sessao`:**  \n",
        "  Todos os registros s√£o organizados por sess√µes l√≥gicas, facilitando filtros, relat√≥rios e auditoria.\n",
        "- **Fun√ß√£o interativa para sele√ß√£o de transmiss√µes espec√≠ficas:**  \n",
        "  Permite ao usu√°rio informar nomes de usu√°rios para filtrar transmiss√µes antes do processamento.\n",
        "- **Coment√°rios detalhados:**  \n",
        "  Cada etapa do c√≥digo est√° documentada para orientar ajustes, manuten√ß√£o e integra√ß√£o por toda a equipe.\n",
        "\n",
        "---\n",
        "\n",
        "## Par√¢metros globais controlados nesta c√©lula\n",
        "\n",
        "- **`LIMIT_DEFAULT`**: Quantidade m√°xima de transmiss√µes processadas em paralelo/lote.\n",
        "- **`PAGE_DEFAULT`**: P√°gina inicial para busca na API.\n",
        "- **`RECORD_SECONDS`**: Tempo m√°ximo de grava√ß√£o de cada v√≠deo (em segundos).\n",
        "- **`RECORD_SECONDS_MIN`**: Tempo m√≠nimo exigido para considerar o v√≠deo v√°lido (em segundos).\n",
        "- **`API_SEARCH_LIMIT`**: Limite de transmiss√µes retornadas ao buscar usu√°rios espec√≠ficos.\n",
        "- **`COMMIT_PUSH_THRESHOLD`**: Quantidade de transmiss√µes processadas at√© realizar commit/push autom√°tico (0 = commit imediato a cada grava√ß√£o).\n",
        "- **`LOG_PATH`**: Caminho do arquivo √∫nico de log (JSONL).\n",
        "- **`BLACKLIST_TIMEOUT`**: Tempo de expira√ß√£o da blacklist (em segundos).\n",
        "- **`BLACKLIST_MAX_FAILURES`**: Quantidade de falhas consecutivas antes de banir temporariamente o usu√°rio.\n",
        "\n",
        "---\n",
        "\n",
        "## Estrutura do log √∫nico (`xcam_master.log`)\n",
        "\n",
        "Cada entrada segue o modelo:\n",
        "```json\n",
        "{\n",
        "  \"timestamp\": \"2025-06-06T06:15:00Z\",\n",
        "  \"sessao\": \"busca|grava√ß√£o|blacklist|processing|failure|success|commit|erro|...\",\n",
        "  \"evento\": \"...\",\n",
        "  \"id\": \"...\",           // identificador √∫nico (prim√°rio)\n",
        "  \"username\": \"...\",     // nome do usu√°rio para exibi√ß√£o\n",
        "  \"id_username\": \"...\",  // refer√™ncia padr√£o \"{id}:{username}\" para consultas e auditoria\n",
        "  \"status\": \"...\",       // ok|erro|blacklisted|expirado|...\n",
        "  \"detalhes\": \"...\",     // informa√ß√µes adicionais (motivo, paths, etc)\n",
        "}\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Fun√ß√µes utilit√°rias para o log\n",
        "\n",
        "- **`append_log(entry, log_path=LOG_PATH)`**: Adiciona uma nova entrada ao log central (gera campo `id_username` automaticamente).\n",
        "- **`read_logs(log_path=LOG_PATH)`**: L√™ todas as entradas do log.\n",
        "- **`query_logs(...)`**: Consulta entradas do log por filtros opcionais (sess√£o, id, id_username, status, etc).\n",
        "- **`remove_logs(condition_fn, log_path=LOG_PATH)`**: Remove todas as entradas que satisfa√ßam a condi√ß√£o.\n",
        "- **`update_log_entry(match_fn, update_fn, log_path=LOG_PATH)`**: Atualiza entradas do log conforme regra.\n",
        "\n",
        "---\n",
        "\n",
        "## Exemplo de uso das fun√ß√µes (a serem aplicadas nas pr√≥ximas c√©lulas)\n",
        "\n",
        "```python\n",
        "append_log({\n",
        "    \"sessao\": \"processing\",\n",
        "    \"evento\": \"iniciado\",\n",
        "    \"id\": \"abc123\",\n",
        "    \"username\": \"Manugic_\",\n",
        "    \"status\": \"ok\",\n",
        "    \"detalhes\": \"URL v√°lida\"\n",
        "})\n",
        "\n",
        "# Consultar blacklist:\n",
        "logs_blacklist = query_logs(sessao=\"blacklist\", status=\"blacklisted\")\n",
        "\n",
        "# Remover registros expirados:\n",
        "remove_logs(lambda entry: entry[\"sessao\"] == \"processing\" and expirou(entry), log_path=LOG_PATH)\n",
        "\n",
        "# Atualizar status:\n",
        "update_log_entry(lambda e: e[\"id\"]==\"abc123\" and e[\"sessao\"]==\"processing\", lambda e: e.update({\"status\":\"ok\"}))\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Fun√ß√£o interativa\n",
        "\n",
        "Permite ao usu√°rio informar transmiss√µes espec√≠ficas a serem gravadas antes de iniciar o processamento.\n",
        "\n",
        "---\n",
        "\n",
        "## Seguran√ßa, rastreabilidade e manuten√ß√£o\n",
        "\n",
        "- Todos os par√¢metros globais s√£o definidos no in√≠cio e propagados para todo o notebook, garantindo consist√™ncia.\n",
        "- O log √∫nico fornece rastreabilidade detalhada e elimina arquivos dispersos (blacklist, falha, etc).\n",
        "- Uso do padr√£o `{id}:{username}` para refer√™ncia e auditoria.\n",
        "- Ajuste qualquer valor diretamente nesta c√©lula para alterar o comportamento global do notebook de forma segura.\n",
        "- Coment√°rios detalhados auxiliam a compreens√£o, integra√ß√£o e manuten√ß√£o por toda a equipe.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "c9hve1ySGVAs"
      },
      "id": "c9hve1ySGVAs"
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================\n",
        "# C√©lula 1: Configura√ß√£o Global, Par√¢metros e Log √önico Estruturado\n",
        "# ================================================================\n",
        "# Objetivo:\n",
        "# - Centralizar configura√ß√µes globais e thresholds\n",
        "# - Definir e montar caminhos do notebook\n",
        "# - Fornecer utilit√°rio robusto para LOG √öNICO MODULAR (JSONL)\n",
        "#   => Todas as c√©lulas e fun√ß√µes usar√£o este log para registrar, consultar e manipular eventos\n",
        "# - Garantir padroniza√ß√£o, rastreabilidade, unicidade e f√°cil manuten√ß√£o futura\n",
        "#\n",
        "# Estrat√©gia:\n",
        "# - Log √∫nico estruturado (JSONL): sess√£o, evento, id, username, id_username, timestamps, status, detalhes\n",
        "# - Fun√ß√µes CRUD para log: adicionar, buscar, atualizar, remover (para blacklist, processing, falhas, auditoria)\n",
        "# - Blacklist e controles baseados em id (com username apenas para exibi√ß√£o)\n",
        "# - Par√¢metros globais facilmente edit√°veis e propagados via globals()\n",
        "# - Uso consistente de \"sessao\" para diferenciar tipos de registros\n",
        "# ================================================================\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "import json\n",
        "\n",
        "# ============================\n",
        "# PAR√ÇMETROS GLOBAIS EDIT√ÅVEIS\n",
        "# ============================\n",
        "# Modifique abaixo conforme necessidade do ambiente ou processamento\n",
        "\n",
        "# Limites e thresholds principais de processamento\n",
        "LIMIT_DEFAULT = 50             # M√°ximo de transmiss√µes processadas por rodada\n",
        "PAGE_DEFAULT = 1               # P√°gina padr√£o para busca na API\n",
        "RECORD_SECONDS = 12780         # Dura√ß√£o m√°xima da grava√ß√£o (em segundos)\n",
        "RECORD_SECONDS_MIN = 660       # Dura√ß√£o m√≠nima v√°lida (em segundos)\n",
        "API_SEARCH_LIMIT = 1500        # Limite ao buscar usu√°rios espec√≠ficos\n",
        "COMMIT_PUSH_THRESHOLD = 25     # Quantidade de transmiss√µes at√© commit/push autom√°tico (0 = commit imediato)\n",
        "\n",
        "# Caminhos de arquivos principais\n",
        "BASE_PATH = '/content'\n",
        "LOG_PATH = f\"{BASE_PATH}/xcam_master.log\"          # Arquivo √∫nico de log central\n",
        "BLACKLIST_TIMEOUT = 15 * 60                        # Blacklist: tempo de expira√ß√£o (segundos)\n",
        "BLACKLIST_MAX_FAILURES = 3                         # Blacklist: falhas para banimento tempor√°rio\n",
        "\n",
        "# ============================\n",
        "# ATUALIZA√á√ÉO GLOBAL DOS PAR√ÇMETROS\n",
        "# ============================\n",
        "# Propaga par√¢metros como globais do notebook\n",
        "globals().update({\n",
        "    'LIMIT_DEFAULT': LIMIT_DEFAULT,\n",
        "    'PAGE_DEFAULT': PAGE_DEFAULT,\n",
        "    'RECORD_SECONDS': RECORD_SECONDS,\n",
        "    'RECORD_SECONDS_MIN': RECORD_SECONDS_MIN,\n",
        "    'API_SEARCH_LIMIT': API_SEARCH_LIMIT,\n",
        "    'COMMIT_PUSH_THRESHOLD': COMMIT_PUSH_THRESHOLD,\n",
        "    'LOG_PATH': LOG_PATH,\n",
        "    'BLACKLIST_TIMEOUT': BLACKLIST_TIMEOUT,\n",
        "    'BLACKLIST_MAX_FAILURES': BLACKLIST_MAX_FAILURES\n",
        "})\n",
        "\n",
        "# =============================================================================\n",
        "# UTILIT√ÅRIO DE LOG √öNICO MODULAR (JSONL) ‚Äî Clean Architecture\n",
        "# -----------------------------------------------------------------------------\n",
        "# Cada entrada: {\n",
        "#   \"timestamp\": \"2025-06-06T06:15:00Z\",\n",
        "#   \"sessao\": \"busca|grava√ß√£o|blacklist|processing|failure|commit|erro|...\",\n",
        "#   \"evento\": \"...\",\n",
        "#   \"id\": \"...\",               # identificador prim√°rio (ex: id da transmiss√£o)\n",
        "#   \"username\": \"...\",         # apenas refer√™ncia humana\n",
        "#   \"id_username\": \"...\",      # padr√£o \"{id}:{username}\" para f√°cil leitura/humano\n",
        "#   \"status\": \"...\",           # ok|erro|blacklisted|expirado|...\n",
        "#   \"detalhes\": \"...\",         # informa√ß√µes adicionais/motivo/paths\n",
        "# }\n",
        "# =============================================================================\n",
        "\n",
        "from datetime import datetime\n",
        "\n",
        "def now_iso():\n",
        "    \"\"\"Retorna timestamp UTC em formato ISO.\"\"\"\n",
        "    return datetime.utcnow().isoformat() + \"Z\"\n",
        "\n",
        "def make_id_username(id, username):\n",
        "    \"\"\"Gera o identificador de refer√™ncia padr√£o para logs: '{id}:{username}'.\"\"\"\n",
        "    return f\"{id}:{username}\"\n",
        "\n",
        "def append_log(entry, log_path=LOG_PATH):\n",
        "    \"\"\"\n",
        "    Adiciona uma nova entrada ao log central (JSONL).\n",
        "    Campos obrigat√≥rios: sessao, evento, id, username, status.\n",
        "    - 'id' DEVE ser chave prim√°ria (√∫nico por transmiss√£o/processo).\n",
        "    - 'username' √© apenas refer√™ncia humana.\n",
        "    - 'id_username' sempre gerado para facilitar auditoria/consulta.\n",
        "    - 'sessao' obrigat√≥rio e padronizado para facilitar filtros e consultas.\n",
        "    \"\"\"\n",
        "    entry.setdefault(\"timestamp\", now_iso())\n",
        "    for field in [\"sessao\", \"evento\", \"id\", \"username\", \"status\"]:\n",
        "        entry.setdefault(field, \"\")\n",
        "    # Padr√£o de refer√™ncia √∫nico e f√°cil busca\n",
        "    entry[\"id_username\"] = make_id_username(entry[\"id\"], entry[\"username\"])\n",
        "    # Evitar duplicidade de id+sessao+evento (unicidade l√≥gica)\n",
        "    logs = []\n",
        "    if os.path.exists(log_path):\n",
        "        with open(log_path, \"r\", encoding=\"utf-8\") as f:\n",
        "            logs = [json.loads(line) for line in f if line.strip()]\n",
        "    # Checa unicidade apenas para eventos que n√£o podem ser duplicados (ex: processing, blacklist, etc)\n",
        "    if entry[\"sessao\"] in {\"processing\", \"blacklist\", \"failure\", \"success\"}:\n",
        "        key = (entry[\"id\"], entry[\"sessao\"], entry[\"evento\"])\n",
        "        for e in logs:\n",
        "            if (e.get(\"id\"), e.get(\"sessao\"), e.get(\"evento\")) == key:\n",
        "                # Atualiza o registro existente ao inv√©s de duplicar\n",
        "                e.update(entry)\n",
        "                with open(log_path, \"w\", encoding=\"utf-8\") as f:\n",
        "                    for l in logs:\n",
        "                        f.write(json.dumps(l, ensure_ascii=False) + \"\\n\")\n",
        "                return\n",
        "    # Se n√£o existe, apenas append\n",
        "    with open(log_path, \"a\", encoding=\"utf-8\") as f:\n",
        "        f.write(json.dumps(entry, ensure_ascii=False) + \"\\n\")\n",
        "\n",
        "def read_logs(log_path=LOG_PATH):\n",
        "    \"\"\"L√™ todas as entradas do log central.\"\"\"\n",
        "    if not os.path.exists(log_path):\n",
        "        return []\n",
        "    with open(log_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        return [json.loads(line) for line in f if line.strip()]\n",
        "\n",
        "def query_logs(sessao=None, id=None, username=None, id_username=None, evento=None, status=None, after=None, before=None, log_path=LOG_PATH):\n",
        "    \"\"\"\n",
        "    Consulta entradas do log por filtros opcionais.\n",
        "    Filtros dispon√≠veis: sessao, id, username, id_username, evento, status, after, before.\n",
        "    - after/before: string ISO ou datetime\n",
        "    \"\"\"\n",
        "    logs = read_logs(log_path)\n",
        "    result = []\n",
        "    for entry in logs:\n",
        "        if sessao and entry.get(\"sessao\") != sessao:\n",
        "            continue\n",
        "        if id and entry.get(\"id\") != id:\n",
        "            continue\n",
        "        if username and entry.get(\"username\") != username:\n",
        "            continue\n",
        "        if id_username and entry.get(\"id_username\") != id_username:\n",
        "            continue\n",
        "        if evento and entry.get(\"evento\") != evento:\n",
        "            continue\n",
        "        if status and entry.get(\"status\") != status:\n",
        "            continue\n",
        "        ts = entry.get(\"timestamp\")\n",
        "        if after:\n",
        "            after_val = after if isinstance(after, str) else after.isoformat()\n",
        "            if ts < after_val:\n",
        "                continue\n",
        "        if before:\n",
        "            before_val = before if isinstance(before, str) else before.isoformat()\n",
        "            if ts > before_val:\n",
        "                continue\n",
        "        result.append(entry)\n",
        "    return result\n",
        "\n",
        "def remove_logs(condition_fn, log_path=LOG_PATH):\n",
        "    \"\"\"\n",
        "    Remove do log central todas as entradas que satisfa√ßam condition_fn(entry).\n",
        "    √ötil para expurgar logs expirados, blacklists vencidas, eventos processados, etc.\n",
        "    \"\"\"\n",
        "    logs = read_logs(log_path)\n",
        "    kept = [entry for entry in logs if not condition_fn(entry)]\n",
        "    with open(log_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        for entry in kept:\n",
        "            f.write(json.dumps(entry, ensure_ascii=False) + \"\\n\")\n",
        "    return len(logs) - len(kept)\n",
        "\n",
        "def update_log_entry(match_fn, update_fn, log_path=LOG_PATH):\n",
        "    \"\"\"\n",
        "    Atualiza entradas do log central: se match_fn(entry)==True, aplica update_fn(entry).\n",
        "    Exemplo: promover status de \"pending\" para \"ok\".\n",
        "    \"\"\"\n",
        "    logs = read_logs(log_path)\n",
        "    updated = 0\n",
        "    for entry in logs:\n",
        "        if match_fn(entry):\n",
        "            update_fn(entry)\n",
        "            updated += 1\n",
        "    with open(log_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        for entry in logs:\n",
        "            f.write(json.dumps(entry, ensure_ascii=False) + \"\\n\")\n",
        "    return updated\n",
        "\n",
        "# Exemplos de uso (para as pr√≥ximas c√©lulas):\n",
        "# append_log({\"sessao\":\"processing\", \"evento\":\"iniciado\", \"id\":\"123456\", \"username\":\"Manugic_\", \"status\":\"ok\", \"detalhes\":\"URL v√°lida\"})\n",
        "# logs_blacklist = query_logs(sessao=\"blacklist\", status=\"blacklisted\")\n",
        "# remove_logs(lambda entry: entry[\"sessao\"]==\"processing\" and expirou(entry), log_path=LOG_PATH)\n",
        "# update_log_entry(lambda e: e[\"id\"]==\"123456\" and e[\"sessao\"]==\"processing\", lambda e: e.update({\"status\":\"ok\"}))\n",
        "\n",
        "# =============================================================================\n",
        "# FUN√á√ÉO INTERATIVA (opcional) PARA ESCOLHA DE TRANSMISS√ïES ESPEC√çFICAS\n",
        "# =============================================================================\n",
        "def perguntar_transmissoes_especificas():\n",
        "    \"\"\"\n",
        "    Pergunta ao usu√°rio se deseja informar transmiss√µes espec√≠ficas para gravar,\n",
        "    recebendo nomes de usu√°rio separados por v√≠rgula e retornando lista limpa.\n",
        "    Retorna lista vazia caso n√£o deseje selecionar usu√°rios.\n",
        "    \"\"\"\n",
        "    resp = input('Deseja gravar alguma transmiss√£o espec√≠fica? (sim/n√£o): ').strip().lower()\n",
        "    if resp.startswith('s'):\n",
        "        usuarios = input('Informe o(s) nome(s) de usu√°rio, separados por v√≠rgula (ex: userNovo234, jovemPT): ')\n",
        "        usuarios_lista = [u.strip() for u in usuarios.split(',') if u.strip()]\n",
        "        return usuarios_lista\n",
        "    return []\n",
        "\n",
        "# =============================================================================\n",
        "# DICAS DE USO EM OUTRAS C√âLULAS:\n",
        "# - Para registrar evento: append_log({...})\n",
        "# - Para consultar blacklist: query_logs(sessao=\"blacklist\", status=\"blacklisted\")\n",
        "# - Para remover registros expirados: remove_logs(lambda e: ...)\n",
        "# - Para atualizar status: update_log_entry(lambda e: ..., lambda e: ...)\n",
        "# - Sempre use o id como chave prim√°ria e id_username para refer√™ncia em relat√≥rios/auditoria\n",
        "# =============================================================================\n",
        "\n",
        "# ============================\n",
        "# FIM DA C√âLULA 1\n",
        "# ============================"
      ],
      "metadata": {
        "id": "j5pPh353GLMD"
      },
      "id": "j5pPh353GLMD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# C√©lula 2: Instala√ß√£o e Valida√ß√£o do ffmpeg\n",
        "\n",
        "**Objetivo:**  \n",
        "Esta c√©lula garante que o utilit√°rio `ffmpeg` esteja instalado e dispon√≠vel no ambiente Google Colab. O ffmpeg √© indispens√°vel para a grava√ß√£o dos v√≠deos das transmiss√µes e para o processamento de m√≠dia ao longo do pipeline do notebook XCam.\n",
        "\n",
        "## Pontos principais e melhorias implementadas\n",
        "\n",
        "- **Verifica√ß√£o pr√©-instala√ß√£o:**  \n",
        "  Antes de instalar, verifica se o ffmpeg j√° est√° dispon√≠vel no ambiente, tornando o processo idempotente e eficiente.\n",
        "- **Instala√ß√£o automatizada:**  \n",
        "  Efetua a instala√ß√£o via `apt-get` apenas se necess√°rio, reduzindo o tempo de setup em execu√ß√µes futuras.\n",
        "- **Valida√ß√£o p√≥s-instala√ß√£o:**  \n",
        "  Exibe a vers√£o instalada do ffmpeg, garantindo transpar√™ncia e rastreabilidade.\n",
        "- **Mensagens detalhadas:**  \n",
        "  O usu√°rio recebe logs informativos sobre cada etapa, facilitando o diagn√≥stico em caso de erros.\n",
        "- **Design modular:**  \n",
        "  Estrutura pronta para ser utilizada em outros ambientes (Colab, local, server) com pequenas adapta√ß√µes.\n",
        "\n",
        "---\n",
        "\n",
        "## Como funciona a c√©lula\n",
        "\n",
        "- **Verifica se o ffmpeg est√° instalado (no PATH do sistema).**\n",
        "- **Se n√£o estiver, instala automaticamente via apt-get.**\n",
        "- **Valida e exibe a vers√£o instalada ap√≥s o processo.**\n",
        "- **Em caso de falha, exibe erro detalhado e interrompe o fluxo para evitar inconsist√™ncias futuras.**\n",
        "\n",
        "---\n",
        "\n",
        "## Exemplo de uso das fun√ß√µes nesta c√©lula\n",
        "\n",
        "```python\n",
        "if not is_ffmpeg_installed():\n",
        "    install_ffmpeg()\n",
        "show_ffmpeg_version()\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Seguran√ßa, rastreabilidade e manuten√ß√£o\n",
        "\n",
        "- A c√©lula torna o setup do ambiente mais robusto, impedindo falhas silenciosas relacionadas √† aus√™ncia de ffmpeg.\n",
        "- Mensagens e valida√ß√µes ajudam a equipe a identificar rapidamente problemas de ambiente ou permiss√µes.\n",
        "- O padr√£o modular facilita a reutiliza√ß√£o do c√≥digo em diferentes notebooks ou pipelines do projeto XCam.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "WXs0o6OPHXbi"
      },
      "id": "WXs0o6OPHXbi"
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================\n",
        "# C√©lula 2: Instala√ß√£o e Valida√ß√£o do FFMPEG no Colab\n",
        "# ================================================================\n",
        "# Objetivo:\n",
        "# - Garantir que o utilit√°rio ffmpeg est√° instalado e dispon√≠vel no ambiente\n",
        "# - Validar a instala√ß√£o e exibir a vers√£o instalada\n",
        "# - Tornar a etapa idempotente, evitando instala√ß√µes desnecess√°rias\n",
        "# - Fornecer feedback claro e orienta√ß√µes em caso de erro\n",
        "#\n",
        "# Estrat√©gia aplicada:\n",
        "# - Instala√ß√£o via apt-get apenas se ffmpeg n√£o estiver dispon√≠vel\n",
        "# - Valida√ß√£o p√≥s-instala√ß√£o\n",
        "# - Logs claros e coment√°rios detalhados para rastreabilidade\n",
        "# ================================================================\n",
        "\n",
        "def is_ffmpeg_installed():\n",
        "    \"\"\"\n",
        "    Verifica se o ffmpeg est√° instalado e dispon√≠vel no PATH do sistema.\n",
        "    Retorna True se estiver, False caso contr√°rio.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        result = subprocess.run([\"ffmpeg\", \"-version\"], capture_output=True, text=True)\n",
        "        return result.returncode == 0\n",
        "    except FileNotFoundError:\n",
        "        return False\n",
        "\n",
        "def install_ffmpeg():\n",
        "    \"\"\"\n",
        "    Instala o ffmpeg via apt-get caso n√£o esteja presente.\n",
        "    \"\"\"\n",
        "    print(\"[INFO] Instalando ffmpeg via apt-get...\")\n",
        "    # Atualiza pacotes e instala ffmpeg silenciosamente\n",
        "    !apt-get update -y > /dev/null\n",
        "    !apt-get install -y ffmpeg > /dev/null\n",
        "    print(\"[INFO] ffmpeg instalado com sucesso.\")\n",
        "\n",
        "def show_ffmpeg_version():\n",
        "    \"\"\"\n",
        "    Exibe a vers√£o instalada do ffmpeg.\n",
        "    \"\"\"\n",
        "    print(\"[INFO] Vers√£o do ffmpeg instalada:\")\n",
        "    !ffmpeg -version | head -n 2\n",
        "\n",
        "# ============================\n",
        "# EXECU√á√ÉO DA ETAPA DE SETUP\n",
        "# ============================\n",
        "\n",
        "if not is_ffmpeg_installed():\n",
        "    print(\"[WARN] ffmpeg n√£o encontrado no ambiente.\")\n",
        "    install_ffmpeg()\n",
        "    if not is_ffmpeg_installed():\n",
        "        raise RuntimeError(\"[ERRO] Falha ao instalar o ffmpeg. Verifique permiss√µes ou tente novamente.\")\n",
        "else:\n",
        "    print(\"[OK] ffmpeg j√° est√° instalado no ambiente.\")\n",
        "\n",
        "# Valida√ß√£o final e exibi√ß√£o da vers√£o\n",
        "show_ffmpeg_version()\n",
        "\n",
        "# ============================\n",
        "# FIM DA C√âLULA 2\n",
        "# ============================\n",
        "\n",
        "# Dica: ffmpeg deve estar dispon√≠vel para todas as c√©lulas subsequentes.\n",
        "# Se precisar de um caminho espec√≠fico, utilize `which ffmpeg` para obter o path absoluto."
      ],
      "metadata": {
        "id": "vIODn0c2HiHz"
      },
      "id": "vIODn0c2HiHz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# C√©lula 3: Imports Essenciais, Utilit√°rios e Prepara√ß√£o do Ambiente\n",
        "\n",
        "**Objetivo:**  \n",
        "Importa todas as bibliotecas essenciais do Python necess√°rias para o funcionamento do notebook, incluindo m√≥dulos para requisi√ß√µes HTTP, processamento paralelo, manipula√ß√£o de datas, controle de subprocessos e exibi√ß√£o interativa.  \n",
        "Centraliza fun√ß√µes utilit√°rias robustas e padronizadas para processamento, download de poster, gera√ß√£o autom√°tica de poster com ffmpeg e exibi√ß√£o de progresso, totalmente integradas ao log √∫nico centralizado definido na C√©lula 1.\n",
        "\n",
        "## Principais pontos e melhorias implementadas\n",
        "\n",
        "- **Centraliza√ß√£o de imports essenciais:**  \n",
        "  Todos os m√≥dulos fundamentais (os, requests, multiprocessing, datetime, json, time, subprocess, math, re, IPython) est√£o dispon√≠veis e prontos para uso global.\n",
        "- **Fun√ß√µes utilit√°rias padronizadas:**  \n",
        "  Fun√ß√µes para formata√ß√£o de segundos, exibi√ß√£o de progresso, download e valida√ß√£o de poster, gera√ß√£o de poster via ffmpeg (com fallback e m√∫ltiplas tentativas) e integra√ß√£o direta ao log centralizado, seguindo Clean Architecture.\n",
        "- **Remo√ß√£o de logs tempor√°rios dispersos:**  \n",
        "  Toda rastreabilidade de eventos (incluindo processamento, blacklist, falhas e auditoria) agora √© feita apenas pelo log √∫nico centralizado (LOG_PATH), eliminando arquivos dispersos como LOG_PROCESSAMENTO_PATH, BLACKLIST_PATH ou FAILURE_LOG_PATH.\n",
        "- **Robustez, clareza e modularidade:**  \n",
        "  As fun√ß√µes possuem tratamento de erros, s√£o preparadas para uso concorrente, possuem fallback inteligente (poster placeholder) e integra√ß√£o autom√°tica com o pipeline e o log centralizado.\n",
        "- **Pronto para uso em todo o notebook:**  \n",
        "  Todas as fun√ß√µes aqui definidas s√£o utilizadas em toda a automa√ß√£o, promovendo reuso, legibilidade e manuten√ß√£o facilitada em pipelines concorrentes ou distribu√≠dos.\n",
        "\n",
        "---\n",
        "\n",
        "## Fun√ß√µes utilit√°rias dispon√≠veis nesta c√©lula\n",
        "\n",
        "- **`format_seconds(seconds)`**: Formata um valor em segundos para string leg√≠vel (ex: \"1h23m45s\").\n",
        "- **`log_progress(username, elapsed_seconds, total_seconds)`**: Exibe o progresso da grava√ß√£o de cada transmiss√£o.\n",
        "- **`download_and_save_poster(poster_url, username, temp_folder)`**: Baixa e salva o poster da transmiss√£o a partir de uma URL remota ou retorna se for um caminho local.\n",
        "- **`generate_poster_with_ffmpeg(m3u8_url, username, temp_folder, tries=(7,1,15,30), timeout=30)`**: Gera automaticamente um poster usando ffmpeg, tentando m√∫ltiplos pontos e, em caso de falha, gera um placeholder e registra o erro no log centralizado.\n",
        "- **`is_poster_valid(poster_path)`**: Verifica se o arquivo de poster √© v√°lido (existe e n√£o est√° vazio).\n",
        "\n",
        "---\n",
        "\n",
        "## Exemplo de uso das fun√ß√µes\n",
        "\n",
        "```python\n",
        "# Formatar segundos em string leg√≠vel\n",
        "tempo = format_seconds(385)\n",
        "\n",
        "# Exibir progresso\n",
        "log_progress(\"userNovo234\", 385, 12780)\n",
        "\n",
        "# Download do poster\n",
        "poster_path = download_and_save_poster(url_poster, \"userNovo234\", \"/content/temp\")\n",
        "\n",
        "# Gera√ß√£o autom√°tica de poster via ffmpeg (com fallback e registro no log)\n",
        "if not is_poster_valid(poster_path):\n",
        "    poster_path = generate_poster_with_ffmpeg(m3u8_url, \"userNovo234\", \"/content/temp\")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Seguran√ßa, rastreabilidade e manuten√ß√£o\n",
        "\n",
        "- Todas as fun√ß√µes s√£o preparadas para tratamento de erros, integra√ß√£o com processos concorrentes e fallback inteligente.\n",
        "- O log tempor√°rio de processamento foi removido, garantindo que todo o rastreio e auditoria sejam feitos via log √∫nico centralizado da C√©lula 1.\n",
        "- Fun√ß√µes de gera√ß√£o de poster integram fallback (placeholder) e registro detalhado de falhas no log central.\n",
        "- Coment√°rios detalhados facilitam manuten√ß√£o, entendimento e evolu√ß√£o do notebook para toda a equipe.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "90qvXC0rHtWb"
      },
      "id": "90qvXC0rHtWb"
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================\n",
        "# C√©lula 3: Imports Essenciais, Utilit√°rios e Prepara√ß√£o do Ambiente\n",
        "# ================================================================\n",
        "# Objetivo:\n",
        "# - Importar bibliotecas essenciais para todo o notebook\n",
        "# - Centralizar fun√ß√µes auxiliares de formata√ß√£o, download e gera√ß√£o de poster\n",
        "# - Remover depend√™ncias de logs tempor√°rios dispersos, integrando ao log √∫nico do sistema (LOG_PATH)\n",
        "# - Garantir robustez, clareza e modularidade para as pr√≥ximas c√©lulas\n",
        "#\n",
        "# Estrat√©gia aplicada:\n",
        "# - Apenas os imports necess√°rios para o funcionamento do notebook\n",
        "# - Fun√ß√µes auxiliares adaptadas para Clean Architecture e integra√ß√£o com o log centralizado (C√©lula 1)\n",
        "# - Fun√ß√£o de gera√ß√£o de poster com ffmpeg robusta, com m√∫ltiplas tentativas e fallback\n",
        "# - Modularidade: fun√ß√µes isoladas, reus√°veis, prontas para testes e integra√ß√£o\n",
        "# ================================================================\n",
        "\n",
        "import os\n",
        "import requests\n",
        "from multiprocessing import Manager, Process\n",
        "from datetime import datetime\n",
        "import json\n",
        "import time\n",
        "import subprocess\n",
        "import math\n",
        "import re\n",
        "import shutil\n",
        "import threading\n",
        "\n",
        "from IPython import get_ipython\n",
        "from IPython.display import display\n",
        "\n",
        "# ============================\n",
        "# UTILIT√ÅRIOS DE FORMATA√á√ÉO E PROGRESSO\n",
        "# ============================\n",
        "\n",
        "def format_seconds(seconds):\n",
        "    \"\"\"\n",
        "    Formata segundos em string leg√≠vel (e.g., 1h23m45s).\n",
        "    \"\"\"\n",
        "    total_seconds = int(seconds)\n",
        "    hours = total_seconds // 3600\n",
        "    minutes = (total_seconds % 3600) // 60\n",
        "    seconds = total_seconds % 60\n",
        "    parts = []\n",
        "    if hours > 0:\n",
        "        parts.append(f\"{hours}h\")\n",
        "    if minutes > 0 or (hours == 0 and seconds > 0):\n",
        "        parts.append(f\"{minutes}m\")\n",
        "    if seconds > 0 or total_seconds == 0:\n",
        "        parts.append(f\"{seconds}s\")\n",
        "    return \"\".join(parts) if parts else \"0s\"\n",
        "\n",
        "def log_progress(username, elapsed_seconds, total_seconds):\n",
        "    \"\"\"\n",
        "    Exibe progresso da grava√ß√£o de cada transmiss√£o em tempo real.\n",
        "    \"\"\"\n",
        "    percent = min((elapsed_seconds / total_seconds) * 100, 100)\n",
        "    tempo = format_seconds(elapsed_seconds)\n",
        "    minutos_gravados = math.floor(elapsed_seconds / 60)\n",
        "    minutos_restantes = max(0, math.ceil((total_seconds - elapsed_seconds) / 60))\n",
        "    print(f\"‚è±Ô∏è [{username}] Gravados: {minutos_gravados} min | Restantes: {minutos_restantes} min | Tempo total: {tempo} ‚Äî üìä {percent:.1f}% conclu√≠do\")\n",
        "\n",
        "# ============================\n",
        "# UTILIT√ÅRIO PARA DOWNLOAD DE POSTER\n",
        "# ============================\n",
        "\n",
        "def download_and_save_poster(poster_url, username, temp_folder):\n",
        "    \"\"\"\n",
        "    Baixa e salva o poster (thumbnail) a partir de uma URL HTTP/HTTPS.\n",
        "    Se for um caminho local existente, retorna esse caminho.\n",
        "    Retorna o caminho do arquivo salvo, ou None em caso de erro.\n",
        "    \"\"\"\n",
        "    # Se for um caminho local v√°lido, retorna diretamente\n",
        "    if os.path.exists(poster_url):\n",
        "        return poster_url\n",
        "    # Download de URL HTTP/HTTPS\n",
        "    if isinstance(poster_url, str) and (poster_url.startswith(\"http://\") or poster_url.startswith(\"https://\")):\n",
        "        try:\n",
        "            response = requests.get(poster_url, timeout=15)\n",
        "            response.raise_for_status()\n",
        "            ext = os.path.splitext(poster_url)[1].lower()\n",
        "            if ext not in [\".jpg\", \".jpeg\", \".png\"]:\n",
        "                ext = \".jpg\"\n",
        "            poster_temp_path = os.path.join(temp_folder, f\"{username}_poster_temp{ext}\")\n",
        "            with open(poster_temp_path, \"wb\") as f:\n",
        "                f.write(response.content)\n",
        "            print(f\"üñºÔ∏è Poster baixado em: {poster_temp_path}\")\n",
        "            return poster_temp_path\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Erro ao baixar poster {poster_url}: {e}\")\n",
        "            return None\n",
        "    else:\n",
        "        print(f\"‚ùå poster_url inv√°lido ou n√£o encontrado: {poster_url}\")\n",
        "        return None\n",
        "\n",
        "# ============================\n",
        "# UTILIT√ÅRIO PARA GERAR POSTER COM FFMPEG (com fallback e log central)\n",
        "# ============================\n",
        "\n",
        "def generate_poster_with_ffmpeg(m3u8_url, username, temp_folder, tries=(7, 1, 15, 30), timeout=30):\n",
        "    \"\"\"\n",
        "    Gera um poster (screenshot) usando ffmpeg a partir da URL .m3u8 da transmiss√£o.\n",
        "    Tenta m√∫ltiplos pontos no v√≠deo caso haja erro (robustez).\n",
        "    Integra ao log centralizado via append_log em caso de falha.\n",
        "    Retorna o caminho do arquivo gerado ou None em caso de erro.\n",
        "    \"\"\"\n",
        "    from IPython.display import clear_output\n",
        "\n",
        "    # Checa se a URL est√° acess√≠vel antes de rodar ffmpeg\n",
        "    try:\n",
        "        head_resp = requests.head(m3u8_url, timeout=5)\n",
        "        if not head_resp.ok:\n",
        "            print(f\"‚ö†Ô∏è Stream offline ou n√£o dispon√≠vel para {username} (status {head_resp.status_code})\")\n",
        "            return None\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Erro de conex√£o ao acessar stream de {username}: {e}\")\n",
        "        return None\n",
        "\n",
        "    for frame_time in tries:\n",
        "        poster_ffmpeg_path = os.path.join(temp_folder, f\"{username}_poster_ffmpeg_{frame_time}.jpg\")\n",
        "        command = [\n",
        "            \"ffmpeg\",\n",
        "            \"-y\",\n",
        "            \"-analyzeduration\", \"10M\",\n",
        "            \"-probesize\", \"50M\",\n",
        "            \"-ss\", str(frame_time),\n",
        "            \"-i\", m3u8_url,\n",
        "            \"-vframes\", \"1\",\n",
        "            \"-q:v\", \"2\",\n",
        "            poster_ffmpeg_path\n",
        "        ]\n",
        "        try:\n",
        "            print(f\"üé¨ Tentando gerar poster para {username} com ffmpeg no segundo {frame_time}...\")\n",
        "            result = subprocess.run(\n",
        "                command,\n",
        "                stdout=subprocess.PIPE,\n",
        "                stderr=subprocess.PIPE,\n",
        "                timeout=timeout\n",
        "            )\n",
        "            if result.returncode == 0 and os.path.exists(poster_ffmpeg_path) and os.path.getsize(poster_ffmpeg_path) > 0:\n",
        "                print(f\"üñºÔ∏è Poster gerado via ffmpeg: {poster_ffmpeg_path}\")\n",
        "                return poster_ffmpeg_path\n",
        "            else:\n",
        "                print(f\"‚ùå ffmpeg n√£o conseguiu gerar poster para {username} no segundo {frame_time}.\\nSTDOUT:\\n{result.stdout.decode(errors='ignore')}\\nSTDERR:\\n{result.stderr.decode(errors='ignore')}\")\n",
        "        except subprocess.TimeoutExpired:\n",
        "            print(f\"‚è∞ Tempo excedido ao tentar gerar poster para {username} via ffmpeg (segundo {frame_time}).\")\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Erro inesperado ao gerar poster via ffmpeg: {e}\")\n",
        "\n",
        "    # Fallback: gera um poster placeholder se todas as tentativas falharem\n",
        "    placeholder_path = os.path.join(temp_folder, f\"{username}_placeholder.jpg\")\n",
        "    try:\n",
        "        from PIL import Image, ImageDraw\n",
        "        img = Image.new('RGB', (640, 360), color=(80, 80, 80))\n",
        "        d = ImageDraw.Draw(img)\n",
        "        d.text((10, 150), f\"Poster indispon√≠vel\\n{username}\", fill=(255, 255, 255))\n",
        "        img.save(placeholder_path)\n",
        "        print(f\"‚ö†Ô∏è Poster placeholder gerado para {username}: {placeholder_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Erro ao gerar placeholder: {e}\")\n",
        "        placeholder_path = None\n",
        "\n",
        "    # Registro detalhado no log central, se definido\n",
        "    if \"append_log\" in globals():\n",
        "        append_log({\n",
        "            \"sessao\": \"poster\",\n",
        "            \"evento\": \"erro_ffmpeg\",\n",
        "            \"id\": username,\n",
        "            \"username\": username,\n",
        "            \"status\": \"erro\",\n",
        "            \"detalhes\": f\"Falha ao gerar poster com ffmpeg em todos tempos testados. √öltimo frame: {frame_time}s\"\n",
        "        })\n",
        "    return placeholder_path\n",
        "\n",
        "# ============================\n",
        "# VALIDA√á√ÉO DE POSTER\n",
        "# ============================\n",
        "\n",
        "def is_poster_valid(poster_path):\n",
        "    \"\"\"\n",
        "    Verifica se o poster existe e n√£o est√° vazio.\n",
        "    \"\"\"\n",
        "    return poster_path and os.path.exists(poster_path) and os.path.getsize(poster_path) > 0\n",
        "\n",
        "# ============================\n",
        "# FIM DA C√âLULA 3\n",
        "# ============================\n",
        "\n",
        "# Observa√ß√µes:\n",
        "# - Todas as fun√ß√µes de logging, blacklist, falha e auditoria devem ser feitas via utilit√°rio de log centralizado (C√©lula 1).\n",
        "# - LOG_PROCESSAMENTO_PATH, BLACKLIST_PATH, FAILURE_LOG_PATH e outros logs dispersos n√£o devem mais ser usados.\n",
        "# - O pipeline est√° pronto para Clean Architecture, m√°xima rastreabilidade e integra√ß√£o.\n",
        "# - Fun√ß√µes aqui s√£o modulares, reus√°veis e preparadas para tratamento de exce√ß√µes e logging detalhado."
      ],
      "metadata": {
        "id": "hOetz0nGICkz"
      },
      "id": "hOetz0nGICkz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# C√©lula 4: Clonagem do Reposit√≥rio GitHub no Colab e Google Drive\n",
        "\n",
        "**Objetivo:**  \n",
        "Esta c√©lula garante que o reposit√≥rio do projeto XCam seja sempre clonado de forma limpa e sincronizada no ambiente local do Colab e, se dispon√≠vel, tamb√©m no Google Drive para persist√™ncia.  \n",
        "Assegura ambiente pronto, atualizado, seguro para grava√ß√µes e processamento, e prepara diret√≥rios padronizados para integra√ß√£o com o restante do pipeline.\n",
        "\n",
        "## Principais pontos e melhorias implementadas\n",
        "\n",
        "- **Clonagem idempotente e limpa:**  \n",
        "  Remove reposit√≥rios antigos antes de clonar para evitar conflitos, arquivos √≥rf√£os ou problemas de sincroniza√ß√£o.\n",
        "- **Clonagem para ambiente tempor√°rio e persistente:**  \n",
        "  O reposit√≥rio √© clonado tanto para `/content` (Colab) quanto para o Drive (`/content/drive/MyDrive/XCam.Drive`) se o Drive estiver montado.\n",
        "- **Prepara√ß√£o de diret√≥rios de grava√ß√£o e processamento:**  \n",
        "  Estrutura de diret√≥rios tempor√°rios criada automaticamente, garantindo organiza√ß√£o dos dados.\n",
        "- **Exporta√ß√£o de vari√°veis globais:**  \n",
        "  Todos os caminhos, URLs e configura√ß√µes relevantes s√£o disponibilizados via `globals().update()` para uso em todo o notebook.\n",
        "- **Mensagens e valida√ß√µes detalhadas:**  \n",
        "  Feedback informativo sobre o status de cada etapa, facilitando o diagn√≥stico e a manuten√ß√£o.\n",
        "- **Pronto para CI/CD e integra√ß√µes futuras:**  \n",
        "  Token e URLs preparados para automa√ß√µes, integra√ß√µes externas e uploads (Abyss.to, etc).\n",
        "\n",
        "---\n",
        "\n",
        "## Par√¢metros globais definidos nesta c√©lula\n",
        "\n",
        "- **`GITHUB_USER`**, **`GITHUB_REPO`**, **`GITHUB_BRANCH`**, **`GITHUB_TOKEN`**: Configura√ß√µes do reposit√≥rio e autentica√ß√£o.\n",
        "- **`repo_url`**: URL do reposit√≥rio autenticada para clone/push.\n",
        "- **`TEMP_OUTPUT_FOLDER`**: Pasta para grava√ß√µes tempor√°rias.\n",
        "- **`BASE_REPO_FOLDER`**: Localiza√ß√£o do reposit√≥rio no ambiente Colab.\n",
        "- **`DRIVE_MOUNT`**, **`DRIVE_REPO_FOLDER`**: Caminhos no Google Drive para persist√™ncia (se montado).\n",
        "- **`ABYSS_UPLOAD_URL`**: URL de upload para integra√ß√£o com sistemas externos.\n",
        "\n",
        "---\n",
        "\n",
        "## Como funciona a c√©lula\n",
        "\n",
        "- **Remove reposit√≥rios antigos e diret√≥rios tempor√°rios**, evitando res√≠duos de execu√ß√µes anteriores.\n",
        "- **Clona o reposit√≥rio do GitHub** para `/content` (Colab).\n",
        "- **Se o Google Drive estiver montado**, faz o mesmo clone no diret√≥rio persistente do Drive.\n",
        "- **Cria diret√≥rios tempor√°rios necess√°rios** para grava√ß√µes e arquivos intermedi√°rios.\n",
        "- **Exporta todas as vari√°veis configuradas** para uso global no notebook.\n",
        "- **Exibe mensagens informativas** sobre cada etapa e alerta caso o Drive n√£o esteja dispon√≠vel.\n",
        "\n",
        "---\n",
        "\n",
        "## Exemplo de uso das vari√°veis globais\n",
        "\n",
        "```python\n",
        "print(BASE_REPO_FOLDER)        # Caminho do reposit√≥rio clonado no Colab\n",
        "print(DRIVE_REPO_FOLDER)      # Caminho do reposit√≥rio no Drive (se montado)\n",
        "print(TEMP_OUTPUT_FOLDER)     # Pasta tempor√°ria para grava√ß√µes\n",
        "print(ABYSS_UPLOAD_URL)       # URL de upload para integra√ß√£o externa\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Seguran√ßa, rastreabilidade e manuten√ß√£o\n",
        "\n",
        "- Garantia de ambiente limpo a cada execu√ß√£o, evitando conflitos de arquivos e branches.\n",
        "- Persist√™ncia dos dados no Drive (se montado), evitando perda de grava√ß√µes em caso de reinicializa√ß√£o do Colab.\n",
        "- Coment√°rios detalhados e estrutura modular facilitam a manuten√ß√£o, integra√ß√£o com CI/CD e futuras expans√µes no pipeline do XCam.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "hpRIMtyFIY0q"
      },
      "id": "hpRIMtyFIY0q"
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================\n",
        "# C√©lula 4: Clonagem do Reposit√≥rio GitHub no Colab e no Google Drive\n",
        "# ================================================================\n",
        "# Objetivo:\n",
        "# - Garantir ambiente limpo e sincronizado para o reposit√≥rio XCam em todas as execu√ß√µes\n",
        "# - Clonar o reposit√≥rio tanto para o ambiente ef√™mero do Colab quanto para o Google Drive (persist√™ncia)\n",
        "# - Preparar diret√≥rios de trabalho para grava√ß√µes e processamento tempor√°rio\n",
        "# - Fornecer feedback claro sobre o status da opera√ß√£o\n",
        "#\n",
        "# Estrat√©gia aplicada:\n",
        "# - Remove reposit√≥rios antigos antes de clonar (evita conflitos e arquivos √≥rf√£os)\n",
        "# - Utiliza token pessoal para autentica√ß√£o segura e push futuro (CI/CD)\n",
        "# - Cria estrutura de diret√≥rios padronizada (m√≥dulos, grava√ß√µes, cache, etc.)\n",
        "# - Valida se o Drive est√° montado antes de tentar opera√ß√µes persistentes\n",
        "# - Coment√°rios detalhados para f√°cil manuten√ß√£o e evolu√ß√£o\n",
        "# ================================================================\n",
        "\n",
        "# ============================\n",
        "# CONFIGURA√á√ïES DO GITHUB\n",
        "# ============================\n",
        "GITHUB_USER = \"SamuelPassamani\"\n",
        "GITHUB_REPO = \"XCam\"\n",
        "GITHUB_BRANCH = \"main\"\n",
        "GITHUB_TOKEN = \"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\"\n",
        "\n",
        "repo_url = f\"https://{GITHUB_USER}:{GITHUB_TOKEN}@github.com/{GITHUB_USER}/{GITHUB_REPO}.git\"\n",
        "\n",
        "# ============================\n",
        "# CLONAGEM PARA O COLAB\n",
        "# ============================\n",
        "print(f\"‚è≥ Limpando ambiente e clonando '{GITHUB_REPO}' para o Colab...\")\n",
        "!rm -rf {GITHUB_REPO}\n",
        "!git clone -b {GITHUB_BRANCH} {repo_url}\n",
        "print(f\"‚úÖ Reposit√≥rio clonado em /content/{GITHUB_REPO}\")\n",
        "\n",
        "# ============================\n",
        "# ESTRUTURA DE DIRET√ìRIOS TEMPOR√ÅRIOS\n",
        "# ============================\n",
        "TEMP_OUTPUT_FOLDER = \"/content/temp_recordings\"  # Para grava√ß√µes tempor√°rias\n",
        "os.makedirs(TEMP_OUTPUT_FOLDER, exist_ok=True)\n",
        "BASE_REPO_FOLDER = f\"/content/{GITHUB_REPO}\"\n",
        "\n",
        "# ============================\n",
        "# CLONAGEM PARA O GOOGLE DRIVE (PERSIST√äNCIA)\n",
        "# ============================\n",
        "DRIVE_MOUNT = \"/content/drive/MyDrive/XCam.Drive\"\n",
        "DRIVE_REPO_FOLDER = f\"{DRIVE_MOUNT}/{GITHUB_REPO}\"\n",
        "\n",
        "if os.path.exists(DRIVE_MOUNT):\n",
        "    print(f\"‚è≥ Limpando reposit√≥rio antigo no Drive (se existir)...\")\n",
        "    !rm -rf \"{DRIVE_REPO_FOLDER}\"\n",
        "    print(f\"‚è≥ Clonando '{GITHUB_REPO}' para o Drive em {DRIVE_REPO_FOLDER} ...\")\n",
        "    !git clone -b {GITHUB_BRANCH} {repo_url} \"{DRIVE_REPO_FOLDER}\"\n",
        "    print(f\"‚úÖ Reposit√≥rio tamb√©m clonado no Drive: {DRIVE_REPO_FOLDER}\")\n",
        "else:\n",
        "    print(f\"‚ö†Ô∏è Google Drive n√£o est√° montado em {DRIVE_MOUNT}.\\n‚ÑπÔ∏è Use a c√©lula de montagem antes de prosseguir para garantir persist√™ncia.\")\n",
        "\n",
        "# ============================\n",
        "# CONFIGURA√á√ÉO DE ENDPOINTS DE UPLOAD/INTEGRA√á√ÉO\n",
        "# ============================\n",
        "ABYSS_UPLOAD_URL = 'http://up.hydrax.net/0128263f78f0b426d617bb61c2a8ff43'\n",
        "globals().update({\n",
        "    'GITHUB_USER': GITHUB_USER,\n",
        "    'GITHUB_REPO': GITHUB_REPO,\n",
        "    'GITHUB_BRANCH': GITHUB_BRANCH,\n",
        "    'GITHUB_TOKEN': GITHUB_TOKEN,\n",
        "    'repo_url': repo_url,\n",
        "    'TEMP_OUTPUT_FOLDER': TEMP_OUTPUT_FOLDER,\n",
        "    'BASE_REPO_FOLDER': BASE_REPO_FOLDER,\n",
        "    'DRIVE_MOUNT': DRIVE_MOUNT,\n",
        "    'DRIVE_REPO_FOLDER': DRIVE_REPO_FOLDER,\n",
        "    'ABYSS_UPLOAD_URL': ABYSS_UPLOAD_URL\n",
        "})\n",
        "\n",
        "# ============================\n",
        "# FIM DA C√âLULA 4\n",
        "# ============================\n",
        "\n",
        "# Observa√ß√µes:\n",
        "# - Os caminhos globais s√£o exportados via globals().update() para uso em todo o notebook.\n",
        "# - Recomenda-se sempre rodar esta c√©lula ap√≥s alterar tokens ou trocar branches para garantir ambiente limpo e sincronizado.\n",
        "# - O endpoint ABYSS_UPLOAD_URL pode ser atualizado conforme integra√ß√µes futuras."
      ],
      "metadata": {
        "id": "Uof_0QCrIlf7"
      },
      "id": "Uof_0QCrIlf7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# C√©lula 5: Commit e Push Autom√°ticos (rec.json, posters, etc.)\n",
        "\n",
        "**Objetivo:**  \n",
        "Automatiza o processo de commit e push dos arquivos modificados (ex: rec.json, posters e demais artefatos importantes) para o reposit√≥rio GitHub, garantindo rastreabilidade, atomicidade e integra√ß√£o cont√≠nua (CI/CD) do pipeline XCam.\n",
        "\n",
        "## Principais pontos e melhorias implementadas\n",
        "\n",
        "- **Fun√ß√£o robusta e modular:**  \n",
        "  A fun√ß√£o `git_commit_and_push()` aceita um caminho √∫nico (string) ou uma lista de arquivos, permitindo commit em lote e integra√ß√£o com estrat√©gias de batch commit (threshold).\n",
        "- **Configura√ß√£o automatizada de usu√°rio e e-mail do git:**  \n",
        "  Garante commits v√°lidos para rastreabilidade, auditoria e integra√ß√£o com pipelines autom√°ticos.\n",
        "- **Valida√ß√£o de caminhos e mensagens informativas:**  \n",
        "  Apenas arquivos existentes s√£o adicionados. Mensagens de sucesso, erro ou aviso detalhadas facilitam troubleshooting e manuten√ß√£o.\n",
        "- **Compat√≠vel com commit vazio:**  \n",
        "  Permite o uso do par√¢metro `--allow-empty` para garantir que o pipeline siga mesmo sem altera√ß√µes detectadas, √∫til para sincroniza√ß√£o e CI/CD.\n",
        "- **Push autenticado via token:**  \n",
        "  Utiliza o token pessoal fornecido nas vari√°veis globais para garantir push seguro e sem interven√ß√£o manual.\n",
        "- **Design pronto para integra√ß√£o com logs centralizados:**  \n",
        "  Recomenda-se registrar todas as a√ß√µes relevantes de commit/push utilizando o log √∫nico modular definido na C√©lula 1.\n",
        "\n",
        "---\n",
        "\n",
        "## Par√¢metros e vari√°veis globais utilizados\n",
        "\n",
        "- **`GITHUB_USER`**, **`GITHUB_REPO`**, **`GITHUB_TOKEN`**: Definidos nas c√©lulas anteriores para autentica√ß√£o e configura√ß√£o do reposit√≥rio.\n",
        "- **`repo_dir`**: Caminho absoluto do reposit√≥rio clonado no ambiente Colab.\n",
        "- **`file_paths`**: String ou lista de arquivos a serem commitados e enviados.\n",
        "- **`commit_message`**: Mensagem do commit, customiz√°vel conforme a opera√ß√£o realizada.\n",
        "\n",
        "---\n",
        "\n",
        "## Como funciona a fun√ß√£o principal\n",
        "\n",
        "- **Valida a exist√™ncia do reposit√≥rio local** antes de prosseguir.\n",
        "- **Aceita arquivos √∫nicos ou m√∫ltiplos** para commit (string ou lista).\n",
        "- **Adiciona apenas arquivos existentes** ao staging, com avisos para arquivos n√£o encontrados.\n",
        "- **Realiza commit (mesmo vazio) e push autenticado** para o reposit√≥rio remoto.\n",
        "- **Emite mensagens claras** de sucesso, erro ou aviso ao longo do processo.\n",
        "\n",
        "---\n",
        "\n",
        "## Exemplo de uso t√≠pico\n",
        "\n",
        "```python\n",
        "# Commit e push de um √∫nico arquivo\n",
        "git_commit_and_push(\"data/rec.json\", \"Atualiza rec.json de grava√ß√£o\")\n",
        "\n",
        "# Commit e push em lote (lista de arquivos)\n",
        "git_commit_and_push([\n",
        "    \"data/rec.json\",\n",
        "    \"posters/user1_poster.jpg\",\n",
        "    \"posters/user2_poster.jpg\"\n",
        "], \"Batch commit de m√∫ltiplos arquivos\")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Seguran√ßa, rastreabilidade e manuten√ß√£o\n",
        "\n",
        "- **Rastreabilidade garantida** por mensagens de commit claras e integra√ß√£o recomendada com o log modular (C√©lula 1).\n",
        "- **Atomicidade** em opera√ß√µes batch, evitando inconsist√™ncias de dados no reposit√≥rio.\n",
        "- **Pronto para integra√ß√£o com pipelines CI/CD**, webhooks e controles de auditoria.\n",
        "- **Mensagens e tratamento de erros detalhados** facilitam o diagn√≥stico e a evolu√ß√£o do sistema.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "M5iL_9BoIoj7"
      },
      "id": "M5iL_9BoIoj7"
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================\n",
        "# C√©lula 5: Commit e Push Autom√°ticos (rec.json, posters, etc.)\n",
        "# ================================================================\n",
        "# Objetivo:\n",
        "# - Automatizar o processo de commit e push dos arquivos modificados (rec.json, posters, etc.) para o reposit√≥rio GitHub\n",
        "# - Suportar tanto commit de arquivo √∫nico como em lote, permitindo estrat√©gia de batch commit baseada em thresholds\n",
        "# - Garantir rastreabilidade, atomicidade e integra√ß√£o segura (CI/CD)\n",
        "#\n",
        "# Estrat√©gia aplicada:\n",
        "# - Fun√ß√£o modular e robusta, preparada para integra√ß√£o com logs e auditoria\n",
        "# - Permite commit vazio por seguran√ßa, evitando falhas em pipelines sincronizados\n",
        "# - Mensagens e tratamento de erros detalhados para facilitar troubleshooting\n",
        "# - Utiliza√ß√£o de vari√°veis globais para caminhos, usu√°rio e token definidos nas c√©lulas anteriores\n",
        "# - Design pronto para evolu√ß√£o, reuso e integra√ß√£o com ferramentas externas (ex: webhooks, jobs, etc.)\n",
        "# ================================================================\n",
        "\n",
        "def git_commit_and_push(file_paths, commit_message=\"Atualiza rec.json\"):\n",
        "    \"\"\"\n",
        "    Realiza git add, commit e push dos arquivos especificados.\n",
        "    - file_paths pode ser uma string (arquivo √∫nico) ou uma lista de arquivos.\n",
        "    - commit_message √© a mensagem de commit utilizada.\n",
        "\n",
        "    Estrat√©gia:\n",
        "    - Ajusta diret√≥rio para o reposit√≥rio local clonado no Colab\n",
        "    - Configura usu√°rio e e-mail do git (necess√°rios para CI/CD)\n",
        "    - Adiciona arquivos ao staging (aceita m√∫ltiplos arquivos)\n",
        "    - Realiza commit (permite commit vazio)\n",
        "    - Realiza push autenticado via token\n",
        "    \"\"\"\n",
        "    # ============================\n",
        "    # VALIDA√á√ÉO E AJUSTE DE ENTRADAS\n",
        "    # ============================\n",
        "    repo_dir = f\"/content/{GITHUB_REPO}\"\n",
        "    if not os.path.exists(repo_dir):\n",
        "        raise FileNotFoundError(f\"Reposit√≥rio '{repo_dir}' n√£o encontrado. Verifique se a c√©lula de clonagem foi executada.\")\n",
        "    os.chdir(repo_dir)\n",
        "\n",
        "    # Aceita string ou lista de arquivos\n",
        "    if isinstance(file_paths, str):\n",
        "        file_paths = [file_paths]\n",
        "    elif not isinstance(file_paths, list):\n",
        "        raise ValueError(\"file_paths deve ser uma string ou uma lista de caminhos.\")\n",
        "\n",
        "    # ============================\n",
        "    # CONFIGURA√á√ÉO DO USU√ÅRIO GIT (CI/CD)\n",
        "    # ============================\n",
        "    subprocess.run([\"git\", \"config\", \"user.email\", \"contato@aserio.work\"], check=True)\n",
        "    subprocess.run([\"git\", \"config\", \"user.name\", \"SamuelPassamani\"], check=True)\n",
        "\n",
        "    # ============================\n",
        "    # ADI√á√ÉO DOS ARQUIVOS AO STAGING\n",
        "    # ============================\n",
        "    for file_path in file_paths:\n",
        "        # Verifica se o arquivo existe antes de adicionar\n",
        "        if not os.path.exists(file_path):\n",
        "            print(f\"‚ö†Ô∏è Aviso: arquivo '{file_path}' n√£o existe e ser√° ignorado no commit.\")\n",
        "            continue\n",
        "        subprocess.run([\"git\", \"add\", file_path], check=True)\n",
        "\n",
        "    # ============================\n",
        "    # COMMIT (PERMITE COMMIT VAZIO)\n",
        "    # ============================\n",
        "    try:\n",
        "        subprocess.run(\n",
        "            [\"git\", \"commit\", \"-m\", commit_message, \"--allow-empty\"],\n",
        "            check=False  # N√£o for√ßa erro se n√£o houver mudan√ßas\n",
        "        )\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Erro ao tentar realizar commit: {e}\")\n",
        "\n",
        "    # ============================\n",
        "    # PUSH PARA O REPOSIT√ìRIO REMOTO (AUTENTICADO)\n",
        "    # ============================\n",
        "    try:\n",
        "        remote_url = f\"https://{GITHUB_USER}:{GITHUB_TOKEN}@github.com/{GITHUB_USER}/{GITHUB_REPO}.git\"\n",
        "        subprocess.run(\n",
        "            [\"git\", \"push\", remote_url],\n",
        "            check=True\n",
        "        )\n",
        "        print(f\"‚úÖ Push realizado com sucesso! ({commit_message})\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Erro ao tentar realizar push: {e}\")\n",
        "\n",
        "# ============================\n",
        "# FIM DA C√âLULA 5\n",
        "# ============================\n",
        "\n",
        "# Dicas e melhores pr√°ticas:\n",
        "# - Use commit_messages claros e informativos para facilitar a auditoria.\n",
        "# - Utilize a fun√ß√£o dentro de loops ou triggers de batch para commit em lote.\n",
        "# - Integre logs das a√ß√µes de commit/push usando o log √∫nico centralizado (C√©lula 1).\n",
        "# - Em caso de erro de autentica√ß√£o, revise o token e as permiss√µes do GitHub."
      ],
      "metadata": {
        "id": "1aQn1G6yI6Gz"
      },
      "id": "1aQn1G6yI6Gz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# C√©lula 6: Busca de Transmiss√µes na API XCam, Blacklist Tempor√°ria, Fallback via liveInfo e Busca Inteligente/Unit√°ria ‚Äî Centraliza√ß√£o no Log √önico\n",
        "\n",
        "**Objetivo:**  \n",
        "Realizar a busca das transmiss√µes ativas na API principal da XCam, mantendo o lote de transmiss√µes sempre completo at√© o `LIMIT_DEFAULT` e sem duplicidades, utilizando agora o controle de blacklist tempor√°ria, falhas e transmiss√µes em processamento **totalmente centralizados no log √∫nico** (`xcam_master.log`).  \n",
        "Inclui fun√ß√µes de busca unit√°ria/inteligente (para manter ‚Äúlote cheio‚Äù continuamente), gerenciamento autom√°tico de poster com gera√ß√£o via ffmpeg e rastreabilidade m√°xima para auditoria e manuten√ß√£o.\n",
        "\n",
        "## Estrat√©gia e melhorias implementadas\n",
        "\n",
        "- **Blacklist e controle de falhas centralizados:**  \n",
        "  Usu√°rios problem√°ticos s√£o bloqueados temporariamente ap√≥s atingirem o limite de falhas (`BLACKLIST_MAX_FAILURES`), com todos os eventos registrados via sess√µes (`sessao`) no log √∫nico.  \n",
        "  N√£o h√° mais leitura ou escrita em arquivos dispersos de blacklist/falha ‚Äî toda consulta e registro √© feita por fun√ß√µes do log central (`append_log`, `query_logs`, `remove_logs`).\n",
        "- **Busca em lote e unit√°ria com fallback:**  \n",
        "  Consulta a API principal com limite alto para preencher o lote rapidamente; fallback autom√°tico via `/liveInfo` para usu√°rios sem `src`.\n",
        "- **Controle de duplicidade e fila inteligente:**  \n",
        "  Antes de incluir qualquer transmiss√£o, verifica no log central se j√° est√° em processamento (`sessao=\"processing\"`), al√©m de checar blacklist, evitando tentativas repetidas ou travamento em streams problem√°ticos.\n",
        "- **Poster garantido:**  \n",
        "  Se o poster estiver ausente, inv√°lido ou nulo, gera automaticamente uma imagem via ffmpeg a partir do stream, garantindo sempre um arquivo v√°lido para cada transmiss√£o.\n",
        "- **Efici√™ncia, paralelismo e rastreabilidade:**  \n",
        "  Fun√ß√µes preparadas para execu√ß√£o concorrente e integra√ß√£o CI/CD, com toda a rastreabilidade poss√≠vel (inclusive limpeza autom√°tica de eventos expirados).\n",
        "- **Compatibilidade com busca de usu√°rios espec√≠ficos:**  \n",
        "  Busca protegida por blacklist/falhas, fallback via `/liveInfo` e controle de processamento j√° em lote.\n",
        "- **Design modular e Clean Architecture:**  \n",
        "  Fun√ß√µes separadas para busca em lote (`get_broadcasts`), busca por usu√°rios (`buscar_usuarios_especificos`) e busca unit√°ria/primeira transmiss√£o livre (`buscar_proxima_transmissao_livre`), todas com integra√ß√£o nativa ao log centralizado.\n",
        "\n",
        "---\n",
        "\n",
        "## Como funciona cada fun√ß√£o\n",
        "\n",
        "- **get_broadcasts:**  \n",
        "  Retorna um lote de transmiss√µes v√°lidas, sempre checando blacklist, log de processamento e gerando poster se necess√°rio. Realiza fallback autom√°tico para `/liveInfo` se n√£o encontrar o src na API principal. Todos os eventos de falha, blacklist ou sucesso s√£o registrados no log √∫nico.\n",
        "- **buscar_usuarios_especificos:**  \n",
        "  Busca apenas os usu√°rios informados, respeitando sempre o controle centralizado de blacklist/falhas, com fallback via `/liveInfo` quando necess√°rio.\n",
        "- **buscar_proxima_transmissao_livre:**  \n",
        "  Busca rapidamente a pr√≥xima transmiss√£o livre para processamento, sempre utilizando os mesmos crit√©rios de controle, garantindo agilidade na fila e efici√™ncia m√°xima ‚Äî tudo com rastreabilidade total no log.\n",
        "\n",
        "---\n",
        "\n",
        "## Detalhes t√©cnicos e recomenda√ß√µes\n",
        "\n",
        "- **Blacklist e falhas totalmente centralizados:**  \n",
        "  Fun√ß√µes `register_failure`, `clear_failure`, `add_to_blacklist`, `is_in_blacklist`, `get_failures` operam exclusivamente sobre o log √∫nico, eliminando arquivos auxiliares e promovendo rastreabilidade, auditoria e manuten√ß√£o facilitada.\n",
        "- **Arquitetura limpa e modular:**  \n",
        "  C√≥digo 100% integrado ao log centralizado, pronto para execu√ß√£o concorrente, CI/CD e manuten√ß√£o.\n",
        "- **Poster sempre v√°lido:**  \n",
        "  Fun√ß√µes utilit√°rias garantem que cada transmiss√£o s√≥ √© liberada para grava√ß√£o se houver poster v√°lido (baixado ou gerado).\n",
        "- **Tratamento de erros robusto e logging autom√°tico:**  \n",
        "  Toda etapa cr√≠tica possui tratamento de exce√ß√µes, registro detalhado de eventos e mensagens claras para facilitar monitoramento e evolu√ß√£o.\n",
        "- **Limpeza autom√°tica de eventos expirados:**  \n",
        "  Sempre que uma blacklist ou falha expira, o log √© automaticamente limpo, garantindo performance e precis√£o.\n",
        "\n",
        "---\n",
        "\n",
        "## Exemplo de uso das fun√ß√µes\n",
        "\n",
        "```python\n",
        "# Buscar lote completo de transmiss√µes v√°lidas (integrado ao log central)\n",
        "streams = get_broadcasts(limit=LIMIT_DEFAULT)\n",
        "\n",
        "# Buscar apenas usu√°rios espec√≠ficos (com prote√ß√£o centralizada)\n",
        "streams_especificos = buscar_usuarios_especificos([\"user1\", \"user2\"])\n",
        "\n",
        "# Buscar a pr√≥xima transmiss√£o livre dispon√≠vel (total rastreabilidade)\n",
        "proxima_stream = buscar_proxima_transmissao_livre()\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Rastreabilidade, manuten√ß√£o e integra√ß√£o\n",
        "\n",
        "- **Toda blacklist, falha, evento de processamento e sucesso √© registrado no log √∫nico centralizado (`xcam_master.log`).**\n",
        "- **Fun√ß√µes compat√≠veis com execu√ß√£o paralela, CI/CD e auditoria.**\n",
        "- **Mensagens detalhadas e arquitetura modular facilitam manuten√ß√£o, entendimento e futuras expans√µes no pipeline XCam.**\n",
        "- **Elimina√ß√£o completa de arquivos dispersos como BLACKLIST_PATH, FAILURE_LOG_PATH ou xcam_processing.log.**\n",
        "- **Uso consistente dos campos `sessao`, `id`, `username`, `status`, `detalhes` e timestamps ISO, conforme padr√£o global do notebook.**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "BZ4c3Uk1I7AK"
      },
      "id": "BZ4c3Uk1I7AK"
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================\n",
        "# C√©lula 6: Busca de Transmiss√µes com Blacklist Tempor√°ria e Controle de Falhas Centralizados\n",
        "# ================================================================\n",
        "# Objetivo:\n",
        "# - Buscar transmiss√µes ao vivo na API XCam, considerando blacklist e controle de falhas por usu√°rio, ambos centralizados no log √∫nico (xcam_master.log)\n",
        "# - Evitar loops infinitos e tentativas repetidas em usu√°rios problem√°ticos via sess√µes de blacklist/falha no log √∫nico\n",
        "# - Garantir sempre poster v√°lido (via download ou ffmpeg) antes de liberar qualquer transmiss√£o para processamento\n",
        "# - Modulariza√ß√£o robusta, integra√ß√£o total com log √∫nico, sem leitura/escrita direta em arquivos dispersos\n",
        "#\n",
        "# Estrat√©gia aplicada:\n",
        "# - Toda a l√≥gica de blacklist e falhas opera via fun√ß√µes utilit√°rias do log centralizado (C√©lula 1)\n",
        "# - Sess√µes do log: \"blacklist\" (usu√°rios banidos temporariamente), \"failure\" (falhas por usu√°rio), \"processing\" (transmiss√£o em processamento)\n",
        "# - Cada evento registrado no log cont√©m: sessao, evento, id (username), username, status, detalhes, timestamp\n",
        "# - N√£o existe mais uso de arquivos como BLACKLIST_PATH, FAILURE_LOG_PATH ou LOG_PROCESSAMENTO_PATH\n",
        "# ================================================================\n",
        "\n",
        "# ============================\n",
        "# FUN√á√ïES DE BLACKLIST E FALHAS CENTRALIZADAS NO LOG\n",
        "# ============================\n",
        "\n",
        "def is_in_blacklist(username, now=None):\n",
        "    \"\"\"\n",
        "    Verifica se o usu√°rio est√° atualmente na blacklist (sessao='blacklist' e status='blacklisted' e n√£o expirado).\n",
        "    Remove automaticamente entradas expiradas.\n",
        "    \"\"\"\n",
        "    now = now or time.time()\n",
        "    # Busca todos eventos atuais de blacklist desse usu√°rio\n",
        "    entries = query_logs(sessao=\"blacklist\", username=username, status=\"blacklisted\")\n",
        "    for entry in entries:\n",
        "        ts_log = entry.get(\"timestamp\")\n",
        "        # timestamp ISO para epoch\n",
        "        ts_epoch = datetime.fromisoformat(ts_log.replace(\"Z\", \"+00:00\")).timestamp() if ts_log else 0\n",
        "        # Verifica expira√ß√£o\n",
        "        if now - ts_epoch < BLACKLIST_TIMEOUT:\n",
        "            return True\n",
        "        else:\n",
        "            # Remove entrada expirada\n",
        "            remove_logs(lambda e: e.get(\"sessao\") == \"blacklist\" and e.get(\"username\") == username and e.get(\"timestamp\") == ts_log)\n",
        "    return False\n",
        "\n",
        "def add_to_blacklist(username):\n",
        "    \"\"\"\n",
        "    Adiciona usu√°rio √† blacklist tempor√°ria via log central.\n",
        "    \"\"\"\n",
        "    entry = {\n",
        "        \"sessao\": \"blacklist\",\n",
        "        \"evento\": \"add_blacklist\",\n",
        "        \"id\": username,\n",
        "        \"username\": username,\n",
        "        \"status\": \"blacklisted\",\n",
        "        \"detalhes\": f\"Banido temporariamente por atingir o limite de falhas ({BLACKLIST_MAX_FAILURES})\"\n",
        "    }\n",
        "    append_log(entry)\n",
        "    print(f\"‚ö†Ô∏è Usu√°rio '{username}' adicionado √† blacklist tempor√°ria (registrado no log centralizado).\")\n",
        "\n",
        "def get_failures(username):\n",
        "    \"\"\"\n",
        "    Conta o n√∫mero de falhas registradas para o usu√°rio (sessao='failure' e status='erro' n√£o expiradas).\n",
        "    \"\"\"\n",
        "    # Busca falhas nos √∫ltimos BLACKLIST_TIMEOUT segundos (expira junto com blacklist)\n",
        "    now = time.time()\n",
        "    entries = query_logs(sessao=\"failure\", username=username, status=\"erro\")\n",
        "    valid_failures = []\n",
        "    for entry in entries:\n",
        "        ts_log = entry.get(\"timestamp\")\n",
        "        ts_epoch = datetime.fromisoformat(ts_log.replace(\"Z\", \"+00:00\")).timestamp() if ts_log else 0\n",
        "        if now - ts_epoch < BLACKLIST_TIMEOUT:\n",
        "            valid_failures.append(entry)\n",
        "        else:\n",
        "            # Remove entrada expirada\n",
        "            remove_logs(lambda e: e.get(\"sessao\") == \"failure\" and e.get(\"username\") == username and e.get(\"timestamp\") == ts_log)\n",
        "    return len(valid_failures)\n",
        "\n",
        "def register_failure(username, details=\"\"):\n",
        "    \"\"\"\n",
        "    Registra uma falha para o usu√°rio. Move para blacklist se exceder o limite.\n",
        "    \"\"\"\n",
        "    append_log({\n",
        "        \"sessao\": \"failure\",\n",
        "        \"evento\": \"registrar_falha\",\n",
        "        \"id\": username,\n",
        "        \"username\": username,\n",
        "        \"status\": \"erro\",\n",
        "        \"detalhes\": details\n",
        "    })\n",
        "    failures = get_failures(username)\n",
        "    if failures >= BLACKLIST_MAX_FAILURES:\n",
        "        add_to_blacklist(username)\n",
        "        # Limpa falhas ap√≥s blacklisting\n",
        "        remove_logs(lambda e: e.get(\"sessao\") == \"failure\" and e.get(\"username\") == username)\n",
        "    print(f\"‚ùå Falha registrada para '{username}' ({failures}/{BLACKLIST_MAX_FAILURES})\")\n",
        "\n",
        "def clear_failure(username):\n",
        "    \"\"\"\n",
        "    Limpa todas as falhas registradas para o usu√°rio.\n",
        "    \"\"\"\n",
        "    removed = remove_logs(lambda e: e.get(\"sessao\") == \"failure\" and e.get(\"username\") == username)\n",
        "    if removed > 0:\n",
        "        print(f\"‚úÖ Falhas limpas para '{username}'.\")\n",
        "\n",
        "def is_processing(username):\n",
        "    \"\"\"\n",
        "    Verifica se o usu√°rio est√° marcado como em processamento ativo.\n",
        "    \"\"\"\n",
        "    entries = query_logs(sessao=\"processing\", username=username, status=\"in_progress\")\n",
        "    return len(entries) > 0\n",
        "\n",
        "def mark_processing(username):\n",
        "    \"\"\"\n",
        "    Marca o usu√°rio/transmiss√£o como em processamento ativo via log central.\n",
        "    \"\"\"\n",
        "    append_log({\n",
        "        \"sessao\": \"processing\",\n",
        "        \"evento\": \"iniciar\",\n",
        "        \"id\": username,\n",
        "        \"username\": username,\n",
        "        \"status\": \"in_progress\",\n",
        "        \"detalhes\": \"\"\n",
        "    })\n",
        "\n",
        "def unmark_processing(username):\n",
        "    \"\"\"\n",
        "    Remove marca√ß√£o de processamento ativo para o usu√°rio.\n",
        "    \"\"\"\n",
        "    remove_logs(lambda e: e.get(\"sessao\") == \"processing\" and e.get(\"username\") == username and e.get(\"status\") == \"in_progress\")\n",
        "\n",
        "# ============================\n",
        "# BUSCA DE TRANSMISS√ïES NA API XCAM (INTEGRADO AO LOG CENTRALIZADO)\n",
        "# ============================\n",
        "\n",
        "def get_broadcasts(limit=LIMIT_DEFAULT, page=PAGE_DEFAULT, usuarios_especificos=None, temp_folder=\"/content\"):\n",
        "    \"\"\"\n",
        "    Busca transmiss√µes ao vivo, respeitando blacklist, falhas e log de processamento via log centralizado.\n",
        "    Garante poster v√°lido (download ou ffmpeg) e faz fallback autom√°tico.\n",
        "    \"\"\"\n",
        "    # Coleta usu√°rios atualmente em processamento\n",
        "    usuarios_em_proc = {e[\"username\"] for e in query_logs(sessao=\"processing\", status=\"in_progress\")}\n",
        "    if usuarios_especificos:\n",
        "        api_url_main = f\"https://api.xcam.gay/?limit={API_SEARCH_LIMIT}&page=1\"\n",
        "        print(f\"üåê Acessando API principal (usu√°rios espec√≠ficos): {api_url_main}\")\n",
        "    else:\n",
        "        api_url_main = f\"https://api.xcam.gay/?limit=1500&page=1\"\n",
        "        print(f\"üåê Acessando API principal (todas transmiss√µes online): {api_url_main}\")\n",
        "\n",
        "    streams_from_main = []\n",
        "    streams_without_preview = []\n",
        "\n",
        "    try:\n",
        "        response_main = requests.get(api_url_main)\n",
        "        response_main.raise_for_status()\n",
        "        data_main = response_main.json()\n",
        "        broadcasts_data = data_main.get(\"broadcasts\")\n",
        "        if not broadcasts_data:\n",
        "            print(\"‚ö†Ô∏è Chave 'broadcasts' n√£o encontrada na resposta da API principal.\")\n",
        "            return []\n",
        "        items = broadcasts_data.get(\"items\")\n",
        "        if not isinstance(items, list):\n",
        "            print(f\"‚ö†Ô∏è Chave 'items' n√£o encontrada ou n√£o √© uma lista em 'broadcasts'.\")\n",
        "            return []\n",
        "\n",
        "        for item in items:\n",
        "            preview = item.get(\"preview\") or {}\n",
        "            src = preview.get(\"src\")\n",
        "            poster = preview.get(\"poster\")\n",
        "            username = item.get(\"username\", \"desconhecido\")\n",
        "            if username in usuarios_em_proc or is_in_blacklist(username):\n",
        "                continue\n",
        "            if usuarios_especificos and username not in usuarios_especificos:\n",
        "                continue\n",
        "            if src:\n",
        "                poster_path = None\n",
        "                try:\n",
        "                    if poster and isinstance(poster, str) and poster.strip():\n",
        "                        poster_path = download_and_save_poster(poster, username, temp_folder)\n",
        "                    if not is_poster_valid(poster_path):\n",
        "                        poster_path = generate_poster_with_ffmpeg(src, username, temp_folder)\n",
        "                    if not is_poster_valid(poster_path):\n",
        "                        register_failure(username, \"Poster inv√°lido ap√≥s todas tentativas.\")\n",
        "                        continue\n",
        "                    else:\n",
        "                        clear_failure(username)\n",
        "                except Exception as e:\n",
        "                    print(f\"‚ùå Falha ao gerar poster para {username}: {e}\")\n",
        "                    register_failure(username, f\"Exce√ß√£o ao gerar poster: {e}\")\n",
        "                    continue\n",
        "                streams_from_main.append({\n",
        "                    \"username\": username,\n",
        "                    \"src\": src,\n",
        "                    \"poster\": poster_path\n",
        "                })\n",
        "            else:\n",
        "                streams_without_preview.append({\"username\": username})\n",
        "\n",
        "        print(f\"‚úÖ {len(streams_from_main)} transmiss√µes com URL na API principal (total consultado).\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Erro ao acessar API principal: {e}\")\n",
        "        return []\n",
        "\n",
        "    # Fallback: busca via liveInfo para streams sem URL na API principal\n",
        "    streams_from_liveinfo = []\n",
        "    if streams_without_preview:\n",
        "        print(f\"üîÅ Buscando liveInfo para {len(streams_without_preview)} streams sem URL na API principal...\")\n",
        "        for stream_info in streams_without_preview:\n",
        "            username = stream_info[\"username\"]\n",
        "            if username in usuarios_em_proc or is_in_blacklist(username):\n",
        "                continue\n",
        "            if usuarios_especificos and username not in usuarios_especificos:\n",
        "                continue\n",
        "            api_url_liveinfo = f\"https://api.xcam.gay/user/{username}/liveInfo\"\n",
        "            try:\n",
        "                response_liveinfo = requests.get(api_url_liveinfo)\n",
        "                response_liveinfo.raise_for_status()\n",
        "                data_liveinfo = response_liveinfo.json()\n",
        "                m3u8_url = data_liveinfo.get(\"cdnURL\") or data_liveinfo.get(\"edgeURL\")\n",
        "                poster_path = None\n",
        "                if m3u8_url:\n",
        "                    poster_path = generate_poster_with_ffmpeg(m3u8_url, username, temp_folder)\n",
        "                    if not is_poster_valid(poster_path):\n",
        "                        register_failure(username, \"Poster inv√°lido (liveInfo).\")\n",
        "                        continue\n",
        "                    else:\n",
        "                        clear_failure(username)\n",
        "                    streams_from_liveinfo.append({\n",
        "                        \"username\": username,\n",
        "                        \"src\": m3u8_url,\n",
        "                        \"poster\": poster_path\n",
        "                    })\n",
        "                else:\n",
        "                    print(f\"‚ö†Ô∏è liveInfo de {username} n√£o retornou cdnURL/edgeURL (usu√°rio possivelmente offline).\")\n",
        "                    register_failure(username, \"liveInfo sem cdnURL/edgeURL.\")\n",
        "            except Exception as ex:\n",
        "                print(f\"‚ùå Erro ao buscar liveInfo para {username}: {ex}\")\n",
        "                register_failure(username, f\"Erro ao buscar liveInfo: {ex}\")\n",
        "            time.sleep(0.5)\n",
        "\n",
        "    # Junta, evita duplicidade de usu√°rio, blacklist e respeita 'limit' FINAL\n",
        "    final_streams_list = []\n",
        "    seen_usernames = set()\n",
        "    for stream in streams_from_main + streams_from_liveinfo:\n",
        "        username = stream[\"username\"]\n",
        "        if username in seen_usernames or username in usuarios_em_proc or is_in_blacklist(username):\n",
        "            continue\n",
        "        final_streams_list.append(stream)\n",
        "        seen_usernames.add(username)\n",
        "        if len(final_streams_list) >= limit:\n",
        "            break\n",
        "\n",
        "    print(f\"üîé Selecionadas {len(final_streams_list)} streams v√°lidas ap√≥s fallback (respeitando limit={limit}).\")\n",
        "    return final_streams_list\n",
        "\n",
        "# ============================\n",
        "# BUSCA DE USU√ÅRIOS ESPEC√çFICOS (COM BLACKLIST CENTRALIZADA)\n",
        "# ============================\n",
        "\n",
        "def buscar_usuarios_especificos(usuarios_lista, temp_folder=\"/content\"):\n",
        "    \"\"\"\n",
        "    Busca usu√°rios espec√≠ficos via API, agora respeitando blacklist e controle de falhas via log central.\n",
        "    \"\"\"\n",
        "    usuarios_em_proc = {e[\"username\"] for e in query_logs(sessao=\"processing\", status=\"in_progress\")}\n",
        "\n",
        "    api_url = f\"https://api.xcam.gay/?limit={API_SEARCH_LIMIT}&page=1\"\n",
        "    print(f\"üîç Buscando usu√°rios espec√≠ficos em {api_url}\")\n",
        "    try:\n",
        "        response = requests.get(api_url)\n",
        "        response.raise_for_status()\n",
        "        data = response.json()\n",
        "        items = data.get(\"broadcasts\", {}).get(\"items\", [])\n",
        "        encontrados = []\n",
        "        sem_src = []\n",
        "        for item in items:\n",
        "            username = item.get(\"username\", \"\")\n",
        "            if username in usuarios_lista and username not in usuarios_em_proc and not is_in_blacklist(username):\n",
        "                preview = item.get(\"preview\") or {}\n",
        "                src = preview.get(\"src\")\n",
        "                poster = preview.get(\"poster\")\n",
        "                poster_path = None\n",
        "                try:\n",
        "                    if src:\n",
        "                        if poster and isinstance(poster, str) and poster.strip():\n",
        "                            poster_path = download_and_save_poster(poster, username, temp_folder)\n",
        "                        if not is_poster_valid(poster_path):\n",
        "                            poster_path = generate_poster_with_ffmpeg(src, username, temp_folder)\n",
        "                        if not is_poster_valid(poster_path):\n",
        "                            register_failure(username, \"Poster inv√°lido (usu√°rios espec√≠ficos).\")\n",
        "                            continue\n",
        "                        else:\n",
        "                            clear_failure(username)\n",
        "                        encontrados.append({\n",
        "                            \"username\": username,\n",
        "                            \"src\": src,\n",
        "                            \"poster\": poster_path\n",
        "                        })\n",
        "                    else:\n",
        "                        sem_src.append(username)\n",
        "                except Exception as e:\n",
        "                    print(f\"‚ùå Falha ao gerar poster para {username}: {e}\")\n",
        "                    register_failure(username, f\"Exce√ß√£o ao gerar poster: {e}\")\n",
        "        for username in sem_src:\n",
        "            if username in usuarios_em_proc or is_in_blacklist(username):\n",
        "                continue\n",
        "            api_url_liveinfo = f\"https://api.xcam.gay/user/{username}/liveInfo\"\n",
        "            try:\n",
        "                response_liveinfo = requests.get(api_url_liveinfo)\n",
        "                response_liveinfo.raise_for_status()\n",
        "                data_liveinfo = response_liveinfo.json()\n",
        "                m3u8_url = data_liveinfo.get(\"cdnURL\") or data_liveinfo.get(\"edgeURL\")\n",
        "                poster_path = None\n",
        "                if m3u8_url:\n",
        "                    poster_path = generate_poster_with_ffmpeg(m3u8_url, username, temp_folder)\n",
        "                    if not is_poster_valid(poster_path):\n",
        "                        register_failure(username, \"Poster inv√°lido (usu√°rios espec√≠ficos/liveInfo).\")\n",
        "                        continue\n",
        "                    else:\n",
        "                        clear_failure(username)\n",
        "                    encontrados.append({\n",
        "                        \"username\": username,\n",
        "                        \"src\": m3u8_url,\n",
        "                        \"poster\": poster_path\n",
        "                    })\n",
        "                else:\n",
        "                    print(f\"‚ö†Ô∏è liveInfo de {username} n√£o retornou cdnURL/edgeURL (usu√°rio possivelmente offline).\")\n",
        "                    register_failure(username, \"liveInfo sem cdnURL/edgeURL.\")\n",
        "            except Exception as ex:\n",
        "                print(f\"‚ùå Erro ao buscar liveInfo para {username}: {ex}\")\n",
        "                register_failure(username, f\"Erro ao buscar liveInfo: {ex}\")\n",
        "            time.sleep(0.5)\n",
        "        print(f\"Encontrados {len(encontrados)} dos {len(usuarios_lista)} usu√°rios procurados (incluindo fallback).\")\n",
        "        return encontrados\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Erro ao buscar usu√°rios espec√≠ficos: {e}\")\n",
        "        return []\n",
        "\n",
        "# ============================\n",
        "# BUSCA DA PR√ìXIMA TRANSMISS√ÉO DISPON√çVEL (COM BLACKLIST CENTRALIZADA)\n",
        "# ============================\n",
        "\n",
        "def buscar_proxima_transmissao_livre(temp_folder=\"/content\"):\n",
        "    \"\"\"\n",
        "    Busca a pr√≥xima transmiss√£o ao vivo n√£o processada, com poster v√°lido e ignorando blacklist, tudo centralizado no log.\n",
        "    \"\"\"\n",
        "    usuarios_em_proc = {e[\"username\"] for e in query_logs(sessao=\"processing\", status=\"in_progress\")}\n",
        "\n",
        "    api_url_main = f\"https://api.xcam.gay/?limit=1500&page=1\"\n",
        "    print(f\"üîé Buscando pr√≥xima transmiss√£o livre: {api_url_main}\")\n",
        "    try:\n",
        "        response_main = requests.get(api_url_main)\n",
        "        response_main.raise_for_status()\n",
        "        data_main = response_main.json()\n",
        "        items = data_main.get(\"broadcasts\", {}).get(\"items\", [])\n",
        "        for item in items:\n",
        "            username = item.get(\"username\", \"desconhecido\")\n",
        "            if username in usuarios_em_proc or is_in_blacklist(username):\n",
        "                continue\n",
        "            preview = item.get(\"preview\") or {}\n",
        "            src = preview.get(\"src\")\n",
        "            poster = preview.get(\"poster\")\n",
        "            try:\n",
        "                if src:\n",
        "                    poster_path = None\n",
        "                    if poster and isinstance(poster, str) and poster.strip():\n",
        "                        poster_path = download_and_save_poster(poster, username, temp_folder)\n",
        "                    if not is_poster_valid(poster_path):\n",
        "                        poster_path = generate_poster_with_ffmpeg(src, username, temp_folder)\n",
        "                    if not is_poster_valid(poster_path):\n",
        "                        register_failure(username, \"Poster inv√°lido (proxima transmiss√£o).\")\n",
        "                        continue\n",
        "                    else:\n",
        "                        clear_failure(username)\n",
        "                    print(f\"üéØ Transmiss√£o livre encontrada: {username}\")\n",
        "                    return {\n",
        "                        \"username\": username,\n",
        "                        \"src\": src,\n",
        "                        \"poster\": poster_path\n",
        "                    }\n",
        "                else:\n",
        "                    api_url_liveinfo = f\"https://api.xcam.gay/user/{username}/liveInfo\"\n",
        "                    try:\n",
        "                        response_liveinfo = requests.get(api_url_liveinfo)\n",
        "                        response_liveinfo.raise_for_status()\n",
        "                        data_liveinfo = response_liveinfo.json()\n",
        "                        m3u8_url = data_liveinfo.get(\"cdnURL\") or data_liveinfo.get(\"edgeURL\")\n",
        "                        poster_path = None\n",
        "                        if m3u8_url:\n",
        "                            poster_path = generate_poster_with_ffmpeg(m3u8_url, username, temp_folder)\n",
        "                            if not is_poster_valid(poster_path):\n",
        "                                register_failure(username, \"Poster inv√°lido (proxima transmiss√£o liveInfo).\")\n",
        "                                continue\n",
        "                            else:\n",
        "                                clear_failure(username)\n",
        "                            print(f\"üéØ Transmiss√£o livre (pelo liveInfo) encontrada: {username}\")\n",
        "                            return {\n",
        "                                \"username\": username,\n",
        "                                \"src\": m3u8_url,\n",
        "                                \"poster\": poster_path\n",
        "                            }\n",
        "                        else:\n",
        "                            register_failure(username, \"liveInfo sem cdnURL/edgeURL.\")\n",
        "                    except Exception as ex:\n",
        "                        print(f\"‚ùå Erro ao buscar liveInfo para {username}: {ex}\")\n",
        "                        register_failure(username, f\"Erro ao buscar liveInfo: {ex}\")\n",
        "                    time.sleep(0.5)\n",
        "            except Exception as e:\n",
        "                print(f\"‚ùå Falha ao processar transmiss√£o {username}: {e}\")\n",
        "                register_failure(username, f\"Erro ao processar transmiss√£o: {e}\")\n",
        "        print(\"üö´ Nenhuma transmiss√£o livre encontrada ap√≥s varrer todas online.\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Erro ao buscar transmiss√µes online: {e}\")\n",
        "        return None\n",
        "\n",
        "# ================================================================\n",
        "# FIM DA C√âLULA 6 ‚Äî BUSCA, BLACKLIST E CONTROLE DE FALHAS CENTRALIZADOS\n",
        "# ================================================================\n",
        "\n",
        "# Observa√ß√µes:\n",
        "# - Toda manipula√ß√£o de blacklist, falha e processamento agora √© feita via log centralizado da C√©lula 1 (JSONL).\n",
        "# - Nenhum uso de arquivos dispersos. Consultas e remo√ß√µes s√£o sempre via query_logs, append_log, remove_logs.\n",
        "# - username √© usado como id prim√°rio (consist√™ncia com padr√£o {id}:{username} do log).\n",
        "# - Para m√°xima rastreabilidade, todos os eventos relevantes est√£o registrados no log √∫nico."
      ],
      "metadata": {
        "id": "h1jr7D0pJ7jS"
      },
      "id": "h1jr7D0pJ7jS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# C√©lula 7: Grava√ß√£o da Stream, Poster Autom√°tico, Controle de Falhas, Log Centralizado Seguro e Blacklist Inteligente\n",
        "\n",
        "**Objetivo:**  \n",
        "Automatizar a grava√ß√£o de transmiss√µes ao vivo com ffmpeg, garantindo robustez, rastreabilidade e integra√ß√£o total com a l√≥gica de blacklist tempor√°ria e controle de falhas **centralizados no log √∫nico** (`xcam_master.log`).  \n",
        "Esta c√©lula assegura o gerenciamento seguro do log de transmiss√µes em processamento, registro de sucesso/erro, integra√ß√£o direta com CI/CD, e a limpeza de arquivos tempor√°rios.\n",
        "\n",
        "## Estrat√©gia e melhorias implementadas\n",
        "\n",
        "- **Gerenciamento seguro e centralizado de log:**  \n",
        "  O usu√°rio √© registrado no log centralizado (`sessao=\"processing\"`, `status=\"in_progress\"`) antes da grava√ß√£o e removido ao final (sucesso ou erro), evitando duplicidade e permitindo paralelismo seguro. Todos os eventos (sucesso, erro, exce√ß√£o, dura√ß√£o insuficiente, etc.) s√£o registrados com rastreabilidade completa.\n",
        "- **Poster sempre v√°lido:**  \n",
        "  O sistema tenta baixar o poster da API. Se o poster estiver ausente, inv√°lido ou nulo, gera automaticamente uma imagem via ffmpeg, assegurando que toda transmiss√£o tenha um poster associado e v√°lido.\n",
        "- **Controle de tempo m√≠nimo e valida√ß√£o robusta:**  \n",
        "  Se a grava√ß√£o resultar em v√≠deo muito curto, tanto o arquivo de v√≠deo quanto o poster s√£o descartados imediatamente, e uma falha √© registrada para o usu√°rio no log central. O contador de falhas √© limpo automaticamente em caso de sucesso.\n",
        "- **Tratamento robusto de falhas e blacklist:**  \n",
        "  Qualquer falha (ffmpeg, exceptions, etc.) √© registrada no log √∫nico, e o usu√°rio √© escalado para a blacklist tempor√°ria quando atinge o limite configurado (`BLACKLIST_MAX_FAILURES`), evitando tentativas infinitas e desperd√≠cio de recursos.\n",
        "- **Limpeza automatizada:**  \n",
        "  Ap√≥s upload ou erro, todos os arquivos tempor√°rios (v√≠deo e poster) s√£o removidos, otimizando o uso do disco e mantendo o ambiente do Colab limpo.\n",
        "- **Feedback e rastreabilidade detalhados:**  \n",
        "  Todas as etapas cr√≠ticas s√£o registradas no log √∫nico e exibidas no console, facilitando diagn√≥stico, manuten√ß√£o e integra√ß√£o com pipelines CI/CD.\n",
        "- **C√≥digo modular e altamente documentado:**  \n",
        "  Todo o fluxo √© comentado passo a passo, pronto para manuten√ß√£o, revis√£o e entendimento por toda a equipe.\n",
        "\n",
        "---\n",
        "\n",
        "## Fluxo resumido da fun√ß√£o principal\n",
        "\n",
        "1. **Registra o usu√°rio** no log centralizado como processamento ativo (sessao=\"processing\", status=\"in_progress\").\n",
        "2. **Garante um poster v√°lido** (download ou gera√ß√£o autom√°tica).\n",
        "3. **Executa o ffmpeg** para gravar a transmiss√£o e monitora o progresso em tempo real.\n",
        "4. **Valida a grava√ß√£o**:\n",
        "   - Se falhar, registra no log central e trata blacklist/falhas.\n",
        "   - Se for curta demais, descarta e registra falha no log.\n",
        "   - Se for v√°lida, limpa contador de falhas no log e prossegue normalmente.\n",
        "5. **Ap√≥s upload ou erro**, remove o usu√°rio do log central e limpa arquivos tempor√°rios.\n",
        "\n",
        "---\n",
        "\n",
        "## Exemplo de uso\n",
        "\n",
        "```python\n",
        "resultado = gravar_stream(username=\"user123\", m3u8_url=\"https://cdn.xcam.gay/m3u8/...\", poster_url=\"https://api.xcam.gay/poster/...\")\n",
        "if resultado['upload_success']:\n",
        "    print(\"Grava√ß√£o e upload realizados com sucesso!\")\n",
        "else:\n",
        "    print(\"Falha na grava√ß√£o ou upload:\", resultado['abyss_response'])\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Seguran√ßa, rastreabilidade e integra√ß√£o\n",
        "\n",
        "- **Pronto para CI/CD e execu√ß√£o paralela:**  \n",
        "  O controle rigoroso de log centralizado e blacklist garante execu√ß√£o concorrente, segura e rastre√°vel por todo o pipeline XCam.\n",
        "- **Integra√ß√£o total com as fun√ß√µes globais:**  \n",
        "  Utiliza fun√ß√µes de blacklist e falha da C√©lula 6, promovendo rastreabilidade e controle centralizado, sem depend√™ncia de arquivos dispersos.\n",
        "- **Diagn√≥stico facilitado:**  \n",
        "  Mensagens e logs detalhados em cada etapa do processo, todos acess√≠veis via consulta ao log √∫nico (`xcam_master.log`).\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "jGFyqOUoKEF7"
      },
      "id": "jGFyqOUoKEF7"
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================\n",
        "# C√©lula 7: Grava√ß√£o Autom√°tica de Transmiss√£o, Controle de Log Centralizado, Limpeza e Blacklist Inteligente\n",
        "# ================================================================\n",
        "# Objetivo:\n",
        "# - Gravar transmiss√µes ao vivo utilizando ffmpeg, com controle rigoroso e centralizado de log de processamento, tratamento de falhas e integra√ß√£o com blacklist tempor√°ria (log √∫nico).\n",
        "# - Garantir que cada transmiss√£o seja registrada no log central no in√≠cio e removida ao final (sucesso ou erro), evitando duplicidade/processamento concorrente (sessao=\"processing\").\n",
        "# - Registrar falhas (ffmpeg, dura√ß√£o insuficiente, poster inv√°lido), escalando usu√°rios para a blacklist tempor√°ria via log central ao atingir o limite de tentativas.\n",
        "# - Assegurar limpeza robusta de arquivos tempor√°rios e rastreabilidade total via eventos no log √∫nico e mensagens detalhadas.\n",
        "# - Modular, preparado para integra√ß√£o com pipelines CI/CD, paralelismo e auditoria centralizada.\n",
        "# ================================================================\n",
        "\n",
        "def get_video_duration(filepath):\n",
        "    \"\"\"\n",
        "    Retorna a dura√ß√£o real do arquivo mp4, em segundos, utilizando ffprobe.\n",
        "    Retorna None em caso de erro ou se o arquivo n√£o existir.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        if not os.path.exists(filepath):\n",
        "            print(f\"‚ö†Ô∏è Arquivo para ffprobe n√£o encontrado: {filepath}\")\n",
        "            return None\n",
        "        cmd = [\n",
        "            \"ffprobe\", \"-v\", \"error\",\n",
        "            \"-show_entries\", \"format=duration\",\n",
        "            \"-of\", \"json\",\n",
        "            filepath\n",
        "        ]\n",
        "        result = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
        "        info = json.loads(result.stdout)\n",
        "        duration = float(info[\"format\"][\"duration\"])\n",
        "        return int(round(duration))\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è N√£o foi poss√≠vel obter dura√ß√£o via ffprobe para {filepath}: {e}\")\n",
        "        return None\n",
        "\n",
        "def gravar_stream(username, m3u8_url, poster_url=None, poster_frame_time=7):\n",
        "    \"\"\"\n",
        "    Grava a transmiss√£o ao vivo do usu√°rio usando ffmpeg, com controle de erros, log centralizado e integra√ß√£o √† blacklist.\n",
        "    - Registra no log centralizado (sessao=\"processing\") no in√≠cio (status=\"in_progress\").\n",
        "    - Remove do log ao finalizar, independentemente do resultado.\n",
        "    - Em caso de falha do ffmpeg ou grava√ß√£o muito curta, registra falha do usu√°rio no log (sessao=\"failure\").\n",
        "    - Ao atingir N falhas consecutivas, usu√°rio entra na blacklist (fun√ß√µes de log centralizado).\n",
        "    - Limpa arquivos tempor√°rios ao final.\n",
        "    - Garante poster v√°lido: baixa da poster_url ou gera automaticamente com ffmpeg.\n",
        "    - poster_frame_time: segundo do v√≠deo onde a captura do poster ser√° feita, se necess√°rio.\n",
        "    \"\"\"\n",
        "    # --- Registro no log centralizado: PROCESSAMENTO INICIADO ---\n",
        "    mark_processing(username)\n",
        "\n",
        "    start_time_dt = datetime.now()\n",
        "    data_str = start_time_dt.strftime(\"%d-%m-%Y\")\n",
        "    horario_str = start_time_dt.strftime(\"%H-%M\")\n",
        "    temp_filename = f\"{username}_{start_time_dt.strftime('%Y%m%d_%H%M%S')}_temp.mp4\"\n",
        "    filepath = os.path.join(TEMP_OUTPUT_FOLDER, temp_filename)\n",
        "    append_log({\n",
        "        \"sessao\": \"processing\",\n",
        "        \"evento\": \"iniciar_gravacao\",\n",
        "        \"id\": username,\n",
        "        \"username\": username,\n",
        "        \"status\": \"in_progress\",\n",
        "        \"detalhes\": f\"Grava√ß√£o iniciada para {username} em {filepath}\"\n",
        "    })\n",
        "\n",
        "    print(f\"\\nüé¨ Iniciando grava√ß√£o de: {username} (URL: {m3u8_url}) em {filepath}\")\n",
        "\n",
        "    # --- Garante poster v√°lido ---\n",
        "    poster_temp_path = None\n",
        "    if poster_url:\n",
        "        poster_temp_path = download_and_save_poster(poster_url, username, TEMP_OUTPUT_FOLDER)\n",
        "    if not is_poster_valid(poster_temp_path) and m3u8_url:\n",
        "        poster_temp_path = generate_poster_with_ffmpeg(m3u8_url, username, TEMP_OUTPUT_FOLDER, frame_time=poster_frame_time)\n",
        "\n",
        "    ffmpeg_cmd = [\n",
        "        \"ffmpeg\", \"-i\", m3u8_url,\n",
        "        \"-t\", str(RECORD_SECONDS),\n",
        "        \"-c\", \"copy\", \"-y\", filepath\n",
        "    ]\n",
        "\n",
        "    start_time_process = time.time()\n",
        "    process = None\n",
        "\n",
        "    try:\n",
        "        process = subprocess.Popen(\n",
        "            ffmpeg_cmd,\n",
        "            stdout=subprocess.PIPE,\n",
        "            stderr=subprocess.STDOUT,\n",
        "            text=True,\n",
        "            bufsize=1,\n",
        "            universal_newlines=True\n",
        "        )\n",
        "\n",
        "        # --- Monitoramento de progresso do ffmpeg (logs em tempo real) ---\n",
        "        elapsed_seconds = 0\n",
        "        last_log_minute = -1\n",
        "        while True:\n",
        "            line = process.stdout.readline()\n",
        "            if not line and process.poll() is not None:\n",
        "                break\n",
        "            if \"time=\" in line:\n",
        "                try:\n",
        "                    match = re.search(r\"time=(\\d+):(\\d+):(\\d+)\", line)\n",
        "                    if match:\n",
        "                        h, m, s = map(int, match.groups())\n",
        "                        elapsed_seconds = h * 3600 + m * 60 + s\n",
        "                        if elapsed_seconds // 60 != last_log_minute:\n",
        "                            log_progress(username, elapsed_seconds, RECORD_SECONDS)\n",
        "                            last_log_minute = elapsed_seconds // 60\n",
        "                except Exception:\n",
        "                    pass\n",
        "\n",
        "        process.wait()\n",
        "        end_time_process = time.time()\n",
        "        elapsed_seconds_proc = round(end_time_process - start_time_process)\n",
        "        log_progress(username, elapsed_seconds_proc, RECORD_SECONDS)\n",
        "\n",
        "        # --- Se FFmpeg falhou, registra no log central e retorna erro ---\n",
        "        if process.returncode != 0:\n",
        "            msg = f\"FFmpeg falhou para {username}. C√≥digo de sa√≠da: {process.returncode}\"\n",
        "            print(f\"‚ùå {msg}\")\n",
        "            append_log({\n",
        "                \"sessao\": \"processing\",\n",
        "                \"evento\": \"erro_ffmpeg\",\n",
        "                \"id\": username,\n",
        "                \"username\": username,\n",
        "                \"status\": \"erro\",\n",
        "                \"detalhes\": msg\n",
        "            })\n",
        "            register_failure(username, \"Erro FFmpeg\")\n",
        "            return {\n",
        "                'username': username,\n",
        "                'filename': temp_filename,\n",
        "                'filepath': filepath,\n",
        "                'upload_success': False,\n",
        "                'abyss_response': msg\n",
        "            }\n",
        "\n",
        "        # --- Valida√ß√£o pelo tempo real do arquivo gravado (robusta) ---\n",
        "        elapsed_seconds_real = get_video_duration(filepath)\n",
        "        if elapsed_seconds_real is not None:\n",
        "            print(f\"‚úÖ Dura√ß√£o real do arquivo gravado: {elapsed_seconds_real}s (ffprobe)\")\n",
        "        else:\n",
        "            print(f\"‚ö†Ô∏è N√£o foi poss√≠vel aferir dura√ß√£o real, usando a do processo: {elapsed_seconds_proc}s\")\n",
        "            elapsed_seconds_real = elapsed_seconds_proc\n",
        "\n",
        "        if elapsed_seconds_real < RECORD_SECONDS_MIN:\n",
        "            msg = f\"Dura√ß√£o gravada ({elapsed_seconds_real}s) menor que o m√≠nimo ({RECORD_SECONDS_MIN}s). Arquivo descartado.\"\n",
        "            print(f\"‚è© {msg}\")\n",
        "            append_log({\n",
        "                \"sessao\": \"processing\",\n",
        "                \"evento\": \"erro_duracao\",\n",
        "                \"id\": username,\n",
        "                \"username\": username,\n",
        "                \"status\": \"erro\",\n",
        "                \"detalhes\": msg\n",
        "            })\n",
        "            register_failure(username, \"Grava√ß√£o muito curta\")\n",
        "            if os.path.exists(filepath): os.remove(filepath)\n",
        "            if poster_temp_path and os.path.exists(poster_temp_path): os.remove(poster_temp_path)\n",
        "            return {\n",
        "                'username': username,\n",
        "                'filename': temp_filename,\n",
        "                'filepath': filepath,\n",
        "                'upload_success': False,\n",
        "                'abyss_response': \"Grava√ß√£o muito curta (descartada)\"\n",
        "            }\n",
        "\n",
        "        # --- Sucesso: limpa falhas acumuladas do usu√°rio no log central ---\n",
        "        clear_failure(username)\n",
        "        tempo_formatado = format_seconds(elapsed_seconds_real)\n",
        "        final_filename = f\"{username}_{data_str}_{horario_str}_{tempo_formatado}.mp4\"\n",
        "        final_filepath = os.path.join(TEMP_OUTPUT_FOLDER, final_filename)\n",
        "\n",
        "        try:\n",
        "            os.rename(filepath, final_filepath)\n",
        "            print(f\"‚úÖ Arquivo renomeado para: {final_filename}\")\n",
        "            filepath_for_upload = final_filepath\n",
        "            filename_for_upload = final_filename\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Erro ao renomear arquivo {temp_filename} para {final_filename}: {e}\")\n",
        "            filepath_for_upload = filepath\n",
        "            filename_for_upload = temp_filename\n",
        "\n",
        "        # --- Realiza upload e atualiza√ß√£o do banco de dados (json) ---\n",
        "        success, abyss_resp, slug = upload_to_abyss_and_update_json(\n",
        "            filepath_for_upload, username, elapsed_seconds_real,\n",
        "            poster_temp_path=poster_temp_path\n",
        "        )\n",
        "\n",
        "        # --- Loga sucesso de grava√ß√£o no log central ---\n",
        "        append_log({\n",
        "            \"sessao\": \"processing\",\n",
        "            \"evento\": \"sucesso_gravacao\",\n",
        "            \"id\": username,\n",
        "            \"username\": username,\n",
        "            \"status\": \"ok\",\n",
        "            \"detalhes\": f\"Arquivo {filename_for_upload} gravado e enviado com sucesso. Dura√ß√£o: {elapsed_seconds_real}s\"\n",
        "        })\n",
        "\n",
        "        return {\n",
        "            'username': username,\n",
        "            'filename': filename_for_upload,\n",
        "            'filepath': filepath_for_upload,\n",
        "            'upload_success': success,\n",
        "            'abyss_response': abyss_resp,\n",
        "            'slug': slug\n",
        "        }\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        msg = \"Comando 'ffmpeg' n√£o encontrado. Certifique-se de que foi instalado corretamente.\"\n",
        "        print(f\"‚ùå {msg}\")\n",
        "        append_log({\n",
        "            \"sessao\": \"processing\",\n",
        "            \"evento\": \"erro_ffmpeg_nao_encontrado\",\n",
        "            \"id\": username,\n",
        "            \"username\": username,\n",
        "            \"status\": \"erro\",\n",
        "            \"detalhes\": msg\n",
        "        })\n",
        "        register_failure(username, msg)\n",
        "        return {\n",
        "            'username': username,\n",
        "            'filename': None,\n",
        "            'filepath': None,\n",
        "            'upload_success': False,\n",
        "            'abyss_response': msg\n",
        "        }\n",
        "    except Exception as e:\n",
        "        msg = f\"Erro inesperado durante a execu√ß√£o do FFmpeg para {username}: {e}\"\n",
        "        print(f\"‚ùå {msg}\")\n",
        "        append_log({\n",
        "            \"sessao\": \"processing\",\n",
        "            \"evento\": \"erro_execucao_ffmpeg\",\n",
        "            \"id\": username,\n",
        "            \"username\": username,\n",
        "            \"status\": \"erro\",\n",
        "            \"detalhes\": msg\n",
        "        })\n",
        "        register_failure(username, msg)\n",
        "        return {\n",
        "            'username': username,\n",
        "            'filename': None,\n",
        "            'filepath': None,\n",
        "            'upload_success': False,\n",
        "            'abyss_response': msg\n",
        "        }\n",
        "    finally:\n",
        "        # --- Remove marca√ß√£o de processamento ativo no log central ---\n",
        "        unmark_processing(username)\n",
        "\n",
        "        # --- Limpeza do arquivo de v√≠deo p√≥s-upload ---\n",
        "        if 'filepath_for_upload' in locals() and os.path.exists(filepath_for_upload):\n",
        "            try:\n",
        "                os.remove(filepath_for_upload)\n",
        "                print(f\"üóëÔ∏è Arquivo de v√≠deo removido do Colab: {filepath_for_upload}\")\n",
        "            except Exception as e:\n",
        "                print(f\"‚ö†Ô∏è N√£o foi poss√≠vel remover o arquivo de v√≠deo tempor√°rio: {e}\")\n",
        "\n",
        "        # --- Limpeza do poster tempor√°rio ---\n",
        "        if poster_temp_path and os.path.exists(poster_temp_path):\n",
        "            try:\n",
        "                os.remove(poster_temp_path)\n",
        "                print(f\"üóëÔ∏è Poster tempor√°rio removido: {poster_temp_path}\")\n",
        "            except Exception as e:\n",
        "                print(f\"‚ö†Ô∏è N√£o foi poss√≠vel remover o poster tempor√°rio: {e}\")\n",
        "\n",
        "# ================================================================\n",
        "# Fim da C√©lula 7 ‚Äî Grava√ß√£o, Log Centralizado e Blacklist Inteligente\n",
        "# ================================================================\n",
        "\n",
        "# Observa√ß√µes e recomenda√ß√µes:\n",
        "# - Toda manipula√ß√£o de status, falha, blacklist e processamento √© feita via fun√ß√µes do log centralizado (C√©lulas 1 e 6).\n",
        "# - Mensagens claras e detalhadas e logging estruturado garantem rastreabilidade, CI/CD e manuten√ß√£o.\n",
        "# - Pronto para execu√ß√£o concorrente, pipelines e auditoria centralizada no XCam."
      ],
      "metadata": {
        "id": "eJ_jrfNgKZNr"
      },
      "id": "eJ_jrfNgKZNr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# C√©lula 8: Upload para Abyss.to, Atualiza√ß√£o do rec.json, Commit Poster, Sincroniza√ß√£o com Google Drive ‚Äî Log Centralizado\n",
        "\n",
        "**Objetivo:**  \n",
        "Realizar upload do v√≠deo gravado para Abyss.to, registrar e atualizar todos os metadados relevantes no arquivo `rec.json` do usu√°rio, garantir a movimenta√ß√£o/renomea√ß√£o adequada do poster e executar o commit/push automatizado de arquivos alterados, sincronizando tamb√©m com o Google Drive e **registrando todas as a√ß√µes relevantes no log centralizado (`xcam_master.log`)**.  \n",
        "O processo √© otimizado para processamento em lote: os arquivos modificados s√≥ s√£o enviados quando o n√∫mero atingir o limiar (`COMMIT_PUSH_THRESHOLD`), promovendo efici√™ncia, rastreabilidade e integridade do reposit√≥rio, mesmo em execu√ß√£o paralela.\n",
        "\n",
        "---\n",
        "\n",
        "## Estrat√©gia e melhorias implementadas\n",
        "\n",
        "- **Commit/push em lote otimizado e rastre√°vel:**  \n",
        "  Arquivos alterados s√£o acumulados em um buffer protegido por lock. O commit e push s√£o executados automaticamente quando a quantidade de arquivos atinge o threshold configurado, reduzindo conflitos e otimizando o workflow CI/CD. Todas as a√ß√µes de commit s√£o registradas no log central para auditoria.\n",
        "- **Sincroniza√ß√£o autom√°tica com o Google Drive:**  \n",
        "  Sempre que `rec.json` ou poster s√£o atualizados, uma c√≥pia √© feita para o diret√≥rio correspondente do usu√°rio no Google Drive (se dispon√≠vel), garantindo redund√¢ncia, persist√™ncia e f√°cil acesso externo aos metadados e imagens. Falhas na sincroniza√ß√£o tamb√©m s√£o logadas.\n",
        "- **Atomicidade, concorr√™ncia e log centralizado:**  \n",
        "  O acesso ao buffer de commit √© protegido por lock (`threading.Lock`), assegurando integridade mesmo em processamento paralelo ou m√∫ltiplos workers. Cada etapa cr√≠tica (upload, poster, commit, rec.json) √© registrada via `append_log` para rastreabilidade total.\n",
        "- **Poster sempre correto e rastre√°vel:**  \n",
        "  O poster utilizado √© sempre movido/renomeado para o local definitivo e associado ao v√≠deo pelo nome (`slug`). O caminho √© sincronizado tanto no reposit√≥rio quanto no Drive, e o evento √© registrado no log.\n",
        "- **Atualiza√ß√£o robusta do rec.json:**  \n",
        "  O hist√≥rico do usu√°rio √© preenchido com todos os campos, incluindo poster, urlIframe, data, hor√°rio e tempo formatado. O padr√£o da estrutura JSON √© rigorosamente seguido, facilitando a integra√ß√£o, an√°lise e exporta√ß√£o dos dados. Atualiza√ß√µes e falhas s√£o sempre logadas.\n",
        "- **Limpeza autom√°tica de arquivos tempor√°rios:**  \n",
        "  Ap√≥s mover, copiar e commitar os arquivos, os tempor√°rios s√£o removidos, mantendo o ambiente Colab limpo e eficiente, com logs de sucesso ou falha de limpeza.\n",
        "\n",
        "---\n",
        "\n",
        "## Como funciona o fluxo principal\n",
        "\n",
        "1. **Faz upload do v√≠deo para Abyss.to** e recebe a confirma√ß√£o (slug, url, urlIframe). Evento de sucesso ou falha registrado no log.\n",
        "2. **Move/renomeia o poster** para o local definitivo no reposit√≥rio, associando ao v√≠deo pelo slug. Evento registrado no log.\n",
        "3. **Atualiza ou cria `rec.json`** do usu√°rio, preenchendo todos os metadados da grava√ß√£o. Evento registrado no log.\n",
        "4. **Adiciona arquivos alterados ao buffer de commit** (com lock para evitar concorr√™ncia) e registra a√ß√£o no log.\n",
        "5. **Sincroniza** `rec.json` e poster no Google Drive, mantendo redund√¢ncia e facilidade de acesso. Falhas de sync s√£o logadas.\n",
        "6. **Executa commit/push autom√°tico em lote** ao atingir o limiar definido; ao final do processamento faz o commit/push dos arquivos restantes, sempre registrando eventos no log central.\n",
        "7. **Limpa arquivos tempor√°rios** garantindo efici√™ncia, organiza√ß√£o do ambiente e registro de sucesso/falha no log.\n",
        "\n",
        "---\n",
        "\n",
        "## Exemplo de uso recomendado\n",
        "\n",
        "```python\n",
        "# Ap√≥s concluir o upload e gerar poster:\n",
        "upload_success, abyss_response, slug = upload_to_abyss_and_update_json(\n",
        "    filepath=arquivo_video,\n",
        "    username=\"usuario\",\n",
        "    duration_seconds=duracao,\n",
        "    poster_temp_path=caminho_poster_temp\n",
        ")\n",
        "\n",
        "# Ao final do processamento, para garantir commit dos arquivos restantes:\n",
        "commit_push_restantes()\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Seguran√ßa, rastreabilidade e integra√ß√£o\n",
        "\n",
        "- **Processo compat√≠vel com execu√ß√£o concorrente** e pipelines CI/CD.\n",
        "- **Commit/push protegido contra condi√ß√µes de corrida**, garantindo atomicidade dos dados no reposit√≥rio.\n",
        "- **Sincroniza√ß√£o Drive robusta**, ideal para ambientes colaborativos ou para garantir backup.\n",
        "- **Toda a√ß√£o relevante registrada no log centralizado**: upload, poster, commit, rec.json, limpeza e falhas.\n",
        "- **Mensagens e logs claros** facilitam manuten√ß√£o, auditoria e diagn√≥stico r√°pido em todo o pipeline XCam.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "YjGKDlbIKaLs"
      },
      "id": "YjGKDlbIKaLs"
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================\n",
        "# C√©lula 8: Upload para Abyss.to, Atualiza√ß√£o do rec.json, Commit Poster, Sincroniza√ß√£o com Google Drive\n",
        "# ================================================================\n",
        "# Objetivo:\n",
        "# - Fazer upload do v√≠deo gravado para Abyss.to e registrar corretamente os metadados.\n",
        "# - Atualizar/registrar informa√ß√µes no rec.json do usu√°rio (hist√≥rico).\n",
        "# - Mover/renomear o poster para o local definitivo, sempre usando o novo poster v√°lido (baixado ou gerado via ffmpeg).\n",
        "# - Acumular arquivos para commit/push e executar o envio ao atingir o threshold configurado, com seguran√ßa para execu√ß√£o concorrente (lock).\n",
        "# - Sincronizar rec.json e poster para o Google Drive (se montado).\n",
        "# - Limpar arquivos tempor√°rios ap√≥s uso.\n",
        "# - Modular, preparado para CI/CD, concorr√™ncia e integra√ß√£o total ao pipeline XCam.\n",
        "# ================================================================\n",
        "\n",
        "# Caminho base do Drive (ajuste se necess√°rio)\n",
        "DRIVE_USER_BASE = \"/content/drive/MyDrive/XCam.Drive/user\"\n",
        "\n",
        "# Lock global para garantir atomicidade do commit_buffer em cen√°rios concorrentes\n",
        "commit_lock = threading.Lock()\n",
        "\n",
        "def upload_to_abyss_and_update_json(\n",
        "    filepath, username, duration_seconds, poster_temp_path=None,\n",
        "    commit_buffer=None, commit_threshold=None\n",
        "):\n",
        "    \"\"\"\n",
        "    Realiza upload do v√≠deo, atualiza rec.json do usu√°rio, move/copia poster e organiza commit/push autom√°tico.\n",
        "    - Acumula arquivos para commit/push; executa envio quando atingir o threshold (ou imediatamente se threshold=0).\n",
        "    - Sincroniza rec.json e poster com o Google Drive.\n",
        "    - Limpa arquivos tempor√°rios ap√≥s uso.\n",
        "    - Protege commit_buffer com lock para execu√ß√£o concorrente.\n",
        "    - Toda a√ß√£o relevante √© registrada no log centralizado via append_log().\n",
        "    \"\"\"\n",
        "    file_name = os.path.basename(filepath)\n",
        "    file_type = 'video/mp4'\n",
        "    print(f\"‚¨ÜÔ∏è Upload de: {file_name} para Abyss.to...\")\n",
        "\n",
        "    upload_success = False\n",
        "    abyss_response = \"Upload falhou - Sem resposta\"\n",
        "    uploaded_url = None\n",
        "    video_id = None\n",
        "    slug = None\n",
        "\n",
        "    # Inicializa buffers se n√£o enviados\n",
        "    if commit_buffer is None:\n",
        "        if not hasattr(upload_to_abyss_and_update_json, 'commit_buffer'):\n",
        "            upload_to_abyss_and_update_json.commit_buffer = []\n",
        "        commit_buffer = upload_to_abyss_and_update_json.commit_buffer\n",
        "\n",
        "    if commit_threshold is None:\n",
        "        global COMMIT_PUSH_THRESHOLD\n",
        "        commit_threshold = COMMIT_PUSH_THRESHOLD if 'COMMIT_PUSH_THRESHOLD' in globals() else 100\n",
        "\n",
        "    # ---- Upload do v√≠deo para Abyss.to ----\n",
        "    try:\n",
        "        with open(filepath, 'rb') as f:\n",
        "            files = { 'file': (file_name, f, file_type) }\n",
        "            response = requests.post(ABYSS_UPLOAD_URL, files=files)\n",
        "            resp_json = response.json()\n",
        "            abyss_response = resp_json\n",
        "            if resp_json.get('status'):\n",
        "                upload_success = True\n",
        "                uploaded_url = resp_json.get('url') or resp_json.get('urlIframe')\n",
        "                video_id = resp_json.get('slug') or resp_json.get('video')\n",
        "                slug = video_id\n",
        "                print(f\"üì§ Upload bem-sucedido. URL: {uploaded_url} | SLUG: {slug}\")\n",
        "                append_log({\n",
        "                    \"sessao\": \"upload\",\n",
        "                    \"evento\": \"upload_sucesso\",\n",
        "                    \"id\": username,\n",
        "                    \"username\": username,\n",
        "                    \"status\": \"ok\",\n",
        "                    \"detalhes\": f\"Arquivo {file_name} enviado para Abyss.to. URL: {uploaded_url}, SLUG: {slug}\"\n",
        "                })\n",
        "            else:\n",
        "                print(f\"‚ùå Falha no upload. Mensagem: {resp_json.get('message','')}\")\n",
        "                append_log({\n",
        "                    \"sessao\": \"upload\",\n",
        "                    \"evento\": \"upload_falhou\",\n",
        "                    \"id\": username,\n",
        "                    \"username\": username,\n",
        "                    \"status\": \"erro\",\n",
        "                    \"detalhes\": f\"Falha no upload. Mensagem: {resp_json.get('message','')}\"\n",
        "                })\n",
        "    except Exception as e:\n",
        "        abyss_response = f\"Erro no upload: {e}\"\n",
        "        print(f\"‚ùå Erro no upload: {e}\")\n",
        "        append_log({\n",
        "            \"sessao\": \"upload\",\n",
        "            \"evento\": \"upload_falhou\",\n",
        "            \"id\": username,\n",
        "            \"username\": username,\n",
        "            \"status\": \"erro\",\n",
        "            \"detalhes\": f\"Exce√ß√£o no upload: {e}\"\n",
        "        })\n",
        "\n",
        "    poster_final_relpath = None\n",
        "    poster_final_path = None\n",
        "    poster_final_name = None\n",
        "\n",
        "    # ---- Move/renomeia o poster para o local correto do usu√°rio ----\n",
        "    if upload_success and poster_temp_path and slug:\n",
        "        try:\n",
        "            user_folder = os.path.join(BASE_REPO_FOLDER, \"xcam-db\", \"user\", username)\n",
        "            os.makedirs(user_folder, exist_ok=True)\n",
        "            poster_final_name = f\"{slug}.jpg\"\n",
        "            poster_final_path = os.path.join(user_folder, poster_final_name)\n",
        "            os.rename(poster_temp_path, poster_final_path)\n",
        "            poster_final_relpath = os.path.relpath(poster_final_path, BASE_REPO_FOLDER)\n",
        "            print(f\"üñºÔ∏è Poster movido para {poster_final_path}\")\n",
        "            append_log({\n",
        "                \"sessao\": \"poster\",\n",
        "                \"evento\": \"poster_salvo\",\n",
        "                \"id\": username,\n",
        "                \"username\": username,\n",
        "                \"status\": \"ok\",\n",
        "                \"detalhes\": f\"Poster salvo em {poster_final_path}\"\n",
        "            })\n",
        "            # Adiciona poster ao buffer de commit (com lock)\n",
        "            with commit_lock:\n",
        "                if poster_final_relpath not in commit_buffer:\n",
        "                    commit_buffer.append(poster_final_relpath)\n",
        "            # Copia poster para o Google Drive (opcional)\n",
        "            drive_user_dir = os.path.join(DRIVE_USER_BASE, username)\n",
        "            os.makedirs(drive_user_dir, exist_ok=True)\n",
        "            poster_drive_path = os.path.join(drive_user_dir, poster_final_name)\n",
        "            try:\n",
        "                shutil.copy2(poster_final_path, poster_drive_path)\n",
        "                print(f\"üóÇÔ∏è Poster tamb√©m salvo no Drive: {poster_drive_path}\")\n",
        "            except Exception as e:\n",
        "                print(f\"‚ö†Ô∏è Falha ao copiar poster para o Drive: {e}\")\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Erro ao mover/renomear poster: {e}\")\n",
        "            append_log({\n",
        "                \"sessao\": \"poster\",\n",
        "                \"evento\": \"erro_salvar_poster\",\n",
        "                \"id\": username,\n",
        "                \"username\": username,\n",
        "                \"status\": \"erro\",\n",
        "                \"detalhes\": f\"Erro ao salvar/mover poster: {e}\"\n",
        "            })\n",
        "\n",
        "    # ---- Atualiza/Cria rec.json do usu√°rio com os dados do v√≠deo ----\n",
        "    if upload_success:\n",
        "        try:\n",
        "            user_folder = os.path.join(BASE_REPO_FOLDER, \"xcam-db\", \"user\", username)\n",
        "            os.makedirs(user_folder, exist_ok=True)\n",
        "            json_filepath = os.path.join(user_folder, \"rec.json\")\n",
        "\n",
        "            file_base = file_name.replace('.mp4', '')\n",
        "            parts = file_base.split('_')\n",
        "            if len(parts) >= 4:\n",
        "                json_data = parts[-3]\n",
        "                json_horario = parts[-2]\n",
        "                json_tempo = parts[-1]\n",
        "            else:\n",
        "                now = datetime.now()\n",
        "                json_data = now.strftime(\"%d-%m-%Y\")\n",
        "                json_horario = now.strftime(\"%H-%M\")\n",
        "                json_tempo = format_seconds(duration_seconds)\n",
        "\n",
        "            poster_url = f\"https://db.xcam.gay/user/{username}/{slug}.jpg\" if slug else \"\"\n",
        "            url_iframe = f\"https://short.icu/{slug}?thumbnail={poster_url}\" if slug else \"\"\n",
        "\n",
        "            new_video_entry = {\n",
        "                \"video\": slug if slug else \"ID_n√£o_retornado\",\n",
        "                \"title\": file_base,\n",
        "                \"file\": file_name,\n",
        "                \"url\": uploaded_url if uploaded_url else \"URL_n√£o_retornada\",\n",
        "                \"poster\": poster_url,\n",
        "                \"urlIframe\": url_iframe,\n",
        "                \"data\": json_data,\n",
        "                \"horario\": json_horario,\n",
        "                \"tempo\": json_tempo\n",
        "            }\n",
        "\n",
        "            def zerar_base(username):\n",
        "                return {\n",
        "                    \"username\": username,\n",
        "                    \"records\": 0,\n",
        "                    \"videos\": []\n",
        "                }\n",
        "\n",
        "            # Carrega ou inicializa rec.json\n",
        "            if not os.path.exists(json_filepath):\n",
        "                rec_data = zerar_base(username)\n",
        "            else:\n",
        "                try:\n",
        "                    with open(json_filepath, 'r', encoding='utf-8') as f:\n",
        "                        loaded = json.load(f)\n",
        "                    valid = (\n",
        "                        isinstance(loaded, dict)\n",
        "                        and \"username\" in loaded\n",
        "                        and \"records\" in loaded\n",
        "                        and \"videos\" in loaded\n",
        "                        and isinstance(loaded[\"videos\"], list)\n",
        "                    )\n",
        "                    rec_data = loaded if valid else zerar_base(username)\n",
        "                except Exception:\n",
        "                    rec_data = zerar_base(username)\n",
        "\n",
        "            # Adiciona novo v√≠deo ao hist√≥rico\n",
        "            rec_data[\"records\"] += 1\n",
        "            rec_data[\"videos\"].append(new_video_entry)\n",
        "            with open(json_filepath, 'w', encoding='utf-8') as f:\n",
        "                json.dump(rec_data, f, indent=2, ensure_ascii=False)\n",
        "            print(f\"‚úÖ rec.json para {username} atualizado em {json_filepath}\")\n",
        "\n",
        "            append_log({\n",
        "                \"sessao\": \"recjson\",\n",
        "                \"evento\": \"recjson_atualizado\",\n",
        "                \"id\": username,\n",
        "                \"username\": username,\n",
        "                \"status\": \"ok\",\n",
        "                \"detalhes\": f\"rec.json atualizado em {json_filepath}\"\n",
        "            })\n",
        "\n",
        "            rel_json_path = os.path.relpath(json_filepath, BASE_REPO_FOLDER)\n",
        "            with commit_lock:\n",
        "                if rel_json_path not in commit_buffer:\n",
        "                    commit_buffer.append(rel_json_path)\n",
        "            # Copia rec.json para o Google Drive (opcional)\n",
        "            drive_user_dir = os.path.join(DRIVE_USER_BASE, username)\n",
        "            os.makedirs(drive_user_dir, exist_ok=True)\n",
        "            try:\n",
        "                shutil.copy2(json_filepath, os.path.join(drive_user_dir, \"rec.json\"))\n",
        "                print(f\"üóÇÔ∏è rec.json tamb√©m salvo no Drive: {os.path.join(drive_user_dir, 'rec.json')}\")\n",
        "            except Exception as e:\n",
        "                print(f\"‚ö†Ô∏è Falha ao copiar rec.json para o Drive: {e}\")\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Erro ao atualizar rec.json: {e}\")\n",
        "            abyss_response = f\"Upload sucesso, erro no JSON: {e}\"\n",
        "            append_log({\n",
        "                \"sessao\": \"recjson\",\n",
        "                \"evento\": \"erro_atualizar_recjson\",\n",
        "                \"id\": username,\n",
        "                \"username\": username,\n",
        "                \"status\": \"erro\",\n",
        "                \"detalhes\": f\"Erro ao atualizar rec.json: {e}\"\n",
        "            })\n",
        "\n",
        "    # ---- Commit/push autom√°tico ajustado ----\n",
        "    with commit_lock:\n",
        "        # Commit imediato se threshold for 0\n",
        "        if commit_threshold == 0 and len(commit_buffer) > 0:\n",
        "            print(f\"üöÄ Commit/push autom√°tico IMEDIATO (threshold=0): {len(commit_buffer)} arquivos\")\n",
        "            try:\n",
        "                git_commit_and_push(commit_buffer, commit_message=\"Commit autom√°tico ap√≥s processamento bem-sucedido\")\n",
        "                append_log({\n",
        "                    \"sessao\": \"commit\",\n",
        "                    \"evento\": \"commit_push_imediato\",\n",
        "                    \"id\": username,\n",
        "                    \"username\": username,\n",
        "                    \"status\": \"ok\",\n",
        "                    \"detalhes\": f\"Commit autom√°tico imediato realizado ({len(commit_buffer)} arquivos)\"\n",
        "                })\n",
        "            except Exception as e:\n",
        "                print(f\"‚ùå Falha no commit/push autom√°tico imediato: {e}\")\n",
        "                append_log({\n",
        "                    \"sessao\": \"commit\",\n",
        "                    \"evento\": \"erro_commit_imediato\",\n",
        "                    \"id\": username,\n",
        "                    \"username\": username,\n",
        "                    \"status\": \"erro\",\n",
        "                    \"detalhes\": f\"Erro no commit/push imediato: {e}\"\n",
        "                })\n",
        "            commit_buffer.clear()\n",
        "        # Commit em lote se threshold > 0\n",
        "        elif commit_threshold > 0 and len(commit_buffer) >= commit_threshold:\n",
        "            print(f\"üöÄ Commit/push autom√°tico: {len(commit_buffer)} arquivos (threshold: {commit_threshold})\")\n",
        "            try:\n",
        "                git_commit_and_push(commit_buffer, commit_message=\"Atualiza arquivos em lote (threshold autom√°tico)\")\n",
        "                append_log({\n",
        "                    \"sessao\": \"commit\",\n",
        "                    \"evento\": \"commit_push_lote\",\n",
        "                    \"id\": username,\n",
        "                    \"username\": username,\n",
        "                    \"status\": \"ok\",\n",
        "                    \"detalhes\": f\"Commit autom√°tico em lote realizado ({len(commit_buffer)} arquivos)\"\n",
        "                })\n",
        "            except Exception as e:\n",
        "                print(f\"‚ùå Falha no commit/push em lote: {e}\")\n",
        "                append_log({\n",
        "                    \"sessao\": \"commit\",\n",
        "                    \"evento\": \"erro_commit_lote\",\n",
        "                    \"id\": username,\n",
        "                    \"username\": username,\n",
        "                    \"status\": \"erro\",\n",
        "                    \"detalhes\": f\"Erro no commit/push em lote: {e}\"\n",
        "                })\n",
        "            commit_buffer.clear()\n",
        "\n",
        "    # ---- Limpeza do arquivo de poster tempor√°rio, se sobrou ----\n",
        "    if poster_temp_path and os.path.exists(poster_temp_path):\n",
        "        try:\n",
        "            os.remove(poster_temp_path)\n",
        "            print(f\"üóëÔ∏è Poster tempor√°rio removido: {poster_temp_path}\")\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è N√£o foi poss√≠vel remover o poster tempor√°rio: {e}\")\n",
        "\n",
        "    return upload_success, abyss_response, slug\n",
        "\n",
        "def commit_push_restantes():\n",
        "    \"\"\"\n",
        "    Realiza commit/push final de todos os arquivos pendentes no buffer.\n",
        "    O acesso ao buffer √© protegido por lock para seguran√ßa em execu√ß√£o concorrente.\n",
        "    Registra sucesso/erro no log centralizado.\n",
        "    \"\"\"\n",
        "    buffer = getattr(upload_to_abyss_and_update_json, 'commit_buffer', None)\n",
        "    if buffer and len(buffer) > 0:\n",
        "        print(f\"üöÄ Commit/push final de {len(buffer)} arquivos restantes\")\n",
        "        with commit_lock:\n",
        "            try:\n",
        "                git_commit_and_push(buffer, commit_message=\"Atualiza arquivos finais (commit final)\")\n",
        "                append_log({\n",
        "                    \"sessao\": \"commit\",\n",
        "                    \"evento\": \"commit_push_final\",\n",
        "                    \"id\": \"global\",\n",
        "                    \"username\": \"global\",\n",
        "                    \"status\": \"ok\",\n",
        "                    \"detalhes\": f\"Commit final realizado ({len(buffer)} arquivos)\"\n",
        "                })\n",
        "            except Exception as e:\n",
        "                print(f\"‚ùå Falha no commit/push final em lote: {e}\")\n",
        "                append_log({\n",
        "                    \"sessao\": \"commit\",\n",
        "                    \"evento\": \"erro_commit_final\",\n",
        "                    \"id\": \"global\",\n",
        "                    \"username\": \"global\",\n",
        "                    \"status\": \"erro\",\n",
        "                    \"detalhes\": f\"Erro no commit/push final: {e}\"\n",
        "                })\n",
        "            buffer.clear()\n",
        "\n",
        "# ================================================================\n",
        "# FIM DA C√âLULA 8 ‚Äî Upload, Metadados, Commit e Sincroniza√ß√£o Drive (com log centralizado)\n",
        "# ================================================================\n",
        "\n",
        "# Observa√ß√µes:\n",
        "# - Fun√ß√µes projetadas para execu√ß√£o concorrente, CI/CD e automa√ß√£o robusta.\n",
        "# - Commit/push autom√°tico e seguro, com threshold customiz√°vel (lote ou imediato).\n",
        "# - Toda a√ß√£o relevante registrada no log centralizado para total rastreabilidade/auditoria.\n",
        "# - Sincroniza√ß√£o transparente com Google Drive quando dispon√≠vel.\n",
        "# - Modularidade e coment√°rios garantem f√°cil manuten√ß√£o e evolu√ß√£o."
      ],
      "metadata": {
        "id": "vMTiCrJ5Kp81"
      },
      "id": "vMTiCrJ5Kp81",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# C√©lula 9: Processamento Autom√°tico, Paralelismo e Supervisor Din√¢mico com Blacklist\n",
        "\n",
        "**Objetivo:**  \n",
        "Controlar e orquestrar todo o pipeline do notebook, garantindo processamento cont√≠nuo, paralelo, eficiente e seguro de transmiss√µes ao vivo. O supervisor din√¢mico mant√©m o lote sempre cheio, respeita a blacklist tempor√°ria e o log central, e integra todas as fun√ß√µes cr√≠ticas das c√©lulas anteriores, garantindo m√°xima resili√™ncia e rastreabilidade.\n",
        "\n",
        "---\n",
        "\n",
        "## Estrat√©gia e melhorias implementadas\n",
        "\n",
        "- **Paralelismo seguro e eficiente:**  \n",
        "  Utiliza m√∫ltiplos processos para gravar e processar transmiss√µes simultaneamente, otimizando o uso de recursos e acelerando o processamento em lote.\n",
        "- **Supervisor din√¢mico e lote sempre cheio:**  \n",
        "  O supervisor monitora constantemente as vagas livres no lote e preenche em tempo real com novas transmiss√µes v√°lidas, evitando ociosidade e maximizando a efici√™ncia.\n",
        "- **Controle centralizado de duplicidade:**  \n",
        "  Antes de processar qualquer transmiss√£o, consulta o log central de processamento para evitar duplicidade, mesmo em ambientes concorrentes ou paralelos.\n",
        "- **Respeito integral √† blacklist tempor√°ria:**  \n",
        "  Transmiss√µes de usu√°rios em blacklist n√£o s√£o tentadas novamente durante o ciclo vigente, economizando recursos e evitando loops problem√°ticos.\n",
        "- **Logs robustos e detalhados:**  \n",
        "  Cada etapa do processamento √© registrada com timestamp, status e contexto, facilitando auditoria, troubleshooting e acompanhamento em produ√ß√£o.\n",
        "- **Commit/push autom√°tico e seguro:**  \n",
        "  Ao final do ciclo (ou quando atingido o threshold), todos os arquivos alterados s√£o enviados ao reposit√≥rio, garantindo consist√™ncia e persist√™ncia dos dados.\n",
        "- **Design modular e Clean Architecture:**  \n",
        "  Fun√ß√µes separadas para supervis√£o, workers, busca, commit, log, etc., facilitando manuten√ß√£o, reuso e integra√ß√£o com CI/CD.\n",
        "\n",
        "---\n",
        "\n",
        "## Como funciona o fluxo principal\n",
        "\n",
        "1. **Inicializa√ß√£o:**  \n",
        "   - Determina o modo de opera√ß√£o: grava√ß√£o de usu√°rios espec√≠ficos ou busca autom√°tica.\n",
        "   - Calcula o tamanho do lote alvo (`LIMIT_DEFAULT` ou `API_SEARCH_LIMIT`).\n",
        "\n",
        "2. **Preenchimento do lote:**  \n",
        "   - Busca transmiss√µes v√°lidas (n√£o duplicadas, n√£o em blacklist) e lan√ßa workers para cada uma, registrando no log de processamento.\n",
        "   - Utiliza fun√ß√µes otimizadas de busca (`buscar_proxima_transmissao_livre` e `buscar_usuarios_especificos`), integradas √† blacklist e ao log.\n",
        "\n",
        "3. **Supervis√£o din√¢mica:**  \n",
        "   - Monitora o ciclo de vida dos workers/processos.\n",
        "   - Preenche imediatamente cada vaga livre com nova transmiss√£o dispon√≠vel, at√© esgotar as op√ß√µes v√°lidas.\n",
        "\n",
        "4. **Respeito √† blacklist:**  \n",
        "   - Antes de qualquer grava√ß√£o, verifica se o usu√°rio est√° em blacklist tempor√°ria.\n",
        "   - Usu√°rios problem√°ticos nunca s√£o tentados duas vezes no mesmo ciclo.\n",
        "\n",
        "5. **Logs detalhados:**  \n",
        "   - Todas as opera√ß√µes geram logs padronizados com n√≠vel (INFO, WORKER, BUSCA, ERRO, etc.) e timestamp.\n",
        "\n",
        "6. **Finaliza√ß√£o segura:**  \n",
        "   - Ao final do processamento, executa commit/push dos arquivos pendentes, garantindo persist√™ncia e integridade do reposit√≥rio.\n",
        "\n",
        "---\n",
        "\n",
        "## Exemplo de uso recomendado\n",
        "\n",
        "```python\n",
        "# Fun√ß√£o principal do notebook: dispara o supervisor din√¢mico\n",
        "main()\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Seguran√ßa, rastreabilidade e integra√ß√£o\n",
        "\n",
        "- **Pronto para execu√ß√£o concorrente e ambientes CI/CD.**\n",
        "- **A l√≥gica de blacklist e commit est√° totalmente integrada ao fluxo, garantindo m√°xima resili√™ncia.**\n",
        "- **Logs detalhados e arquitetura modular facilitam diagn√≥stico, manuten√ß√£o e evolu√ß√£o do pipeline XCam.**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "iwgt8f8iKq4y"
      },
      "id": "iwgt8f8iKq4y"
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================\n",
        "# C√©lula 9: Supervisor Din√¢mico ‚Äî Execu√ß√£o Paralela, Lote Sempre Cheio, Blacklist e Log Centralizado\n",
        "# ================================================================\n",
        "# Objetivo:\n",
        "# - Manter o lote de grava√ß√µes sempre cheio, preenchendo vagas em tempo real com m√°xima efici√™ncia e seguran√ßa.\n",
        "# - Garantir que usu√°rios problem√°ticos (em blacklist) n√£o sejam tentados novamente no ciclo vigente.\n",
        "# - Prevenir duplicidade consultando log central de processamento antes de iniciar qualquer grava√ß√£o.\n",
        "# - Integrar-se com a l√≥gica de blacklist, commit/push autom√°tico, limpeza de recursos e log robusto.\n",
        "# - Modularidade e clareza, pronta para integra√ß√£o com pipelines CI/CD, execu√ß√£o concorrente e ambientes colaborativos.\n",
        "# ================================================================\n",
        "\n",
        "def log_supervisor(msg, level=\"INFO\"):\n",
        "    \"\"\"\n",
        "    Log supervisor padronizado para todas as etapas do pipeline.\n",
        "    Tamb√©m registra cada evento relevante no log centralizado.\n",
        "    \"\"\"\n",
        "    from datetime import datetime\n",
        "    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "    print(f\"[{timestamp}] [{level}] {msg}\")\n",
        "    # Registro tamb√©m no log central (sessao supervisor)\n",
        "    append_log({\n",
        "        \"sessao\": \"supervisor\",\n",
        "        \"evento\": level,\n",
        "        \"id\": \"global\",\n",
        "        \"username\": \"global\",\n",
        "        \"status\": \"info\" if level != \"ERRO\" else \"erro\",\n",
        "        \"detalhes\": msg\n",
        "    })\n",
        "\n",
        "def worker(username, m3u8_url, poster_url, results):\n",
        "    \"\"\"\n",
        "    Worker dedicado: grava a stream, faz upload, atualiza rec.json/poster, integra ao log.\n",
        "    O processamento √© rastreado via log central, e o status final √© adicionado √† lista de resultados.\n",
        "    \"\"\"\n",
        "    log_supervisor(f\"Iniciando grava√ß√£o: {username} | URL: {m3u8_url} | Poster: {poster_url}\", \"WORKER\")\n",
        "    result = gravar_stream(username, m3u8_url, poster_url)\n",
        "    log_supervisor(\n",
        "        f\"Finalizou grava√ß√£o: {username} | Sucesso: {result.get('upload_success')} | \"\n",
        "        f\"Arquivo: {result.get('filename')} | Abyss: {result.get('abyss_response')}\", \"WORKER\")\n",
        "    results.append(result)\n",
        "    # Registro do resultado no log central\n",
        "    append_log({\n",
        "        \"sessao\": \"supervisor\",\n",
        "        \"evento\": \"worker_result\",\n",
        "        \"id\": username,\n",
        "        \"username\": username,\n",
        "        \"status\": \"ok\" if result.get(\"upload_success\") else \"erro\",\n",
        "        \"detalhes\": str(result)\n",
        "    })\n",
        "\n",
        "def supervisor_dinamico(usuarios_especificos=None):\n",
        "    \"\"\"\n",
        "    Supervisor din√¢mico de transmiss√µes ao vivo:\n",
        "    - Mant√©m o lote de grava√ß√µes sempre cheio, preenchendo vagas em tempo real.\n",
        "    - Evita duplicidade e concorr√™ncia consultando log central (sessao=\"processing\", status=\"in_progress\").\n",
        "    - Respeita blacklist centralizada, n√£o processando usu√°rios bloqueados no ciclo vigente.\n",
        "    - Log detalhado e modular para diagn√≥stico, CI/CD e rastreabilidade.\n",
        "    \"\"\"\n",
        "\n",
        "    # Determina o tamanho do lote com base no modo operacional\n",
        "    pool_size = LIMIT_DEFAULT if not usuarios_especificos else API_SEARCH_LIMIT\n",
        "    running = []\n",
        "    results = Manager().list()\n",
        "    seen_usernames = set()\n",
        "\n",
        "    log_supervisor(f\"Supervisor din√¢mico iniciado | Lote alvo: {pool_size} | Modo: {'espec√≠fico' if usuarios_especificos else 'autom√°tico'}\")\n",
        "\n",
        "    def atualizar_seen_usernames():\n",
        "        \"\"\"\n",
        "        Atualiza o conjunto de usernames j√° processados diretamente do log central (sessao='processing').\n",
        "        Garante robustez em ambientes concorrentes e previne duplicidade.\n",
        "        \"\"\"\n",
        "        entries = query_logs(sessao=\"processing\", status=\"in_progress\")\n",
        "        seen_usernames.update([e[\"username\"] for e in entries])\n",
        "\n",
        "    def buscar_nova_transmissao():\n",
        "        \"\"\"\n",
        "        Busca uma nova transmiss√£o livre para preencher o lote:\n",
        "        - Modo espec√≠fico: busca em lista fornecida.\n",
        "        - Modo autom√°tico: busca pr√≥xima transmiss√£o livre dispon√≠vel.\n",
        "        - Sempre consulta blacklist e log central antes de lan√ßar.\n",
        "        \"\"\"\n",
        "        atualizar_seen_usernames()  # Sempre atualiza antes de buscar\n",
        "        if usuarios_especificos:\n",
        "            candidatos = buscar_usuarios_especificos(usuarios_especificos)\n",
        "            for s in candidatos:\n",
        "                username = s[\"username\"]\n",
        "                if username not in seen_usernames and not is_in_blacklist(username) and not is_processing(username):\n",
        "                    log_supervisor(f\"Nova transmiss√£o encontrada (espec√≠fico): {username}\", \"BUSCA\")\n",
        "                    return s\n",
        "            log_supervisor(\"Nenhuma transmiss√£o espec√≠fica livre encontrada (todos em blacklist/log ou offline).\", \"BUSCA\")\n",
        "            return None\n",
        "        else:\n",
        "            # Busca otimizada: tenta at√© 10 vezes buscar pr√≥xima transmiss√£o livre\n",
        "            for tentativa in range(1, 11):\n",
        "                log_supervisor(f\"Buscando pr√≥xima transmiss√£o livre: tentativa {tentativa}\", \"BUSCA\")\n",
        "                stream = buscar_proxima_transmissao_livre()\n",
        "                if stream:\n",
        "                    username = stream[\"username\"]\n",
        "                    if username not in seen_usernames and not is_in_blacklist(username) and not is_processing(username):\n",
        "                        log_supervisor(f\"Nova transmiss√£o encontrada: {username}\", \"BUSCA\")\n",
        "                        return stream\n",
        "                    else:\n",
        "                        log_supervisor(f\"Usu√°rio {username} j√° processado/em blacklist/processing, ignorando.\", \"BUSCA\")\n",
        "            log_supervisor(\"Nenhuma transmiss√£o livre encontrada ap√≥s tentativas (todos em blacklist/log ou offline).\", \"BUSCA\")\n",
        "            return None\n",
        "\n",
        "    # ========== Fase 1: Preenchimento do lote inicial ==========\n",
        "    log_supervisor(f\"Preenchendo lote inicial com at√© {pool_size} transmiss√µes...\", \"STARTUP\")\n",
        "    tentativas = 0\n",
        "    max_tentativas = 100\n",
        "    while len(running) < pool_size and tentativas < max_tentativas:\n",
        "        stream = buscar_nova_transmissao()\n",
        "        if not stream:\n",
        "            log_supervisor(\"Fim das transmiss√µes dispon√≠veis para preencher lote inicial.\", \"STARTUP\")\n",
        "            break\n",
        "        username = stream[\"username\"]\n",
        "        seen_usernames.add(username)\n",
        "        # Marca no log central como em processamento para evitar duplicidade\n",
        "        mark_processing(username)\n",
        "        log_supervisor(f\"Lan√ßando processo para: {username} | {len(running)+1}/{pool_size}\", \"STARTUP\")\n",
        "        p = Process(target=worker, args=(username, stream[\"src\"], stream.get(\"poster\"), results))\n",
        "        running.append(p)\n",
        "        p.start()\n",
        "        tentativas += 1\n",
        "\n",
        "    log_supervisor(f\"Lote inicial lan√ßado com {len(running)} transmiss√µes.\", \"STARTUP\")\n",
        "\n",
        "    # ========== Fase 2: Loop din√¢mico de preenchimento cont√≠nuo ==========\n",
        "    while True:\n",
        "        antes = len(running)\n",
        "        running = [p for p in running if p.is_alive()]\n",
        "        depois = len(running)\n",
        "        if antes != depois:\n",
        "            log_supervisor(f\"{antes-depois} grava√ß√µes finalizaram. Vagas livres: {pool_size-len(running)}\", \"LOOP\")\n",
        "        vagas_livres = pool_size - len(running)\n",
        "        if vagas_livres > 0:\n",
        "            for _ in range(vagas_livres):\n",
        "                stream = buscar_nova_transmissao()\n",
        "                if not stream:\n",
        "                    log_supervisor(\"N√£o h√° mais transmiss√µes para preencher as vagas livres.\", \"LOOP\")\n",
        "                    break\n",
        "                username = stream[\"username\"]\n",
        "                seen_usernames.add(username)\n",
        "                mark_processing(username)\n",
        "                log_supervisor(f\"Lan√ßando nova grava√ß√£o: {username} | Vaga preenchida {len(running)+1}/{pool_size}\", \"LOOP\")\n",
        "                p = Process(target=worker, args=(username, stream[\"src\"], stream.get(\"poster\"), results))\n",
        "                running.append(p)\n",
        "                p.start()\n",
        "        if not running:\n",
        "            log_supervisor(\"Todas as transmiss√µes poss√≠veis j√° foram processadas!\", \"END\")\n",
        "            break\n",
        "        log_supervisor(\n",
        "            f\"Transmiss√µes ativas: {len(running)} | Total processadas: {len(seen_usernames)} | Buffer de resultados: {len(results)}\",\n",
        "            \"STATUS\"\n",
        "        )\n",
        "        time.sleep(2)\n",
        "\n",
        "    # ========== Fase 3: Commit/push final e encerramento ==========\n",
        "    log_supervisor(f\"Processamento din√¢mico conclu√≠do! Total de transmiss√µes gravadas/processadas: {len(results)}\", \"RESUMO\")\n",
        "    try:\n",
        "        log_supervisor(\"Realizando commit/push final dos arquivos pendentes...\", \"FINALIZACAO\")\n",
        "        commit_push_restantes()\n",
        "        log_supervisor(\"Commit/push final executado com sucesso.\", \"FINALIZACAO\")\n",
        "    except Exception as e:\n",
        "        log_supervisor(f\"Falha ao tentar commit/push final dos arquivos restantes: {e}\", \"ERRO\")\n",
        "    log_supervisor(\"Supervisor din√¢mico finalizado.\", \"END\")\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Fun√ß√£o principal: inicia o notebook perguntando se o usu√°rio quer gravar transmiss√µes espec√≠ficas ou autom√°ticas.\n",
        "    Dispara o supervisor din√¢mico na modalidade selecionada.\n",
        "    \"\"\"\n",
        "    usuarios_especificos = perguntar_transmissoes_especificas()\n",
        "    log_supervisor(\"Iniciando busca e grava√ß√£o de streams (supervisor din√¢mico)...\", \"MAIN\")\n",
        "    supervisor_dinamico(usuarios_especificos=usuarios_especificos)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    try:\n",
        "        if 'google.colab' in str(get_ipython()):\n",
        "            main()\n",
        "        else:\n",
        "            print(\"Execute main() manualmente se desejar rodar fora do Colab.\")\n",
        "    except NameError:\n",
        "        print(\"N√£o est√° rodando em Colab/IPython. Execute main() se desejar.\")\n",
        "\n",
        "# ================================================================\n",
        "# FIM DA C√âLULA 9 ‚Äî Supervisor Din√¢mico, Lote Cheio e Blacklist Centralizados\n",
        "# ================================================================\n",
        "\n",
        "# Observa√ß√µes e recomenda√ß√µes:\n",
        "# - Toda l√≥gica de blacklist, commit e status de processamento est√° integrada ao log centralizado para m√°xima rastreabilidade.\n",
        "# - O log central √© a fonte de verdade para sincroniza√ß√£o entre workers/processos.\n",
        "# - Modularidade, logs claros e tratamento de erro garantem manuten√ß√£o e evolu√ß√£o seguras.\n",
        "# - Pronto para ambientes colaborativos (Colab, CI/CD, pipelines paralelos)."
      ],
      "metadata": {
        "id": "5WKQV9g_LB9M"
      },
      "id": "5WKQV9g_LB9M",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# C√©lula extra: Commit final de pend√™ncias\n",
        "def commit_final_pendencias():\n",
        "    commit_buffer = getattr(upload_to_abyss_and_update_json, 'commit_buffer', [])\n",
        "    if commit_buffer:\n",
        "        print(f\"üîî Realizando commit/push final de {len(commit_buffer)} pend√™ncias...\")\n",
        "        git_commit_and_push(commit_buffer, commit_message=\"Commit final de pend√™ncias\")\n",
        "        commit_buffer.clear()\n",
        "    else:\n",
        "        print(\"‚úÖ Sem pend√™ncias para commit final.\")\n",
        "\n",
        "# Execute isto ao final do processamento\n",
        "# commit_final_pendencias()"
      ],
      "metadata": {
        "id": "eXVBhXjsAuAY"
      },
      "id": "eXVBhXjsAuAY",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "c9hve1ySGVAs"
      ],
      "cell_execution_strategy": "setup",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}