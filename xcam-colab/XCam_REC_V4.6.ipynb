{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SamuelPassamani/XCam/blob/main/xcam-colab/XCam_REC_V4.6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c9hve1ySGVAs",
      "metadata": {
        "id": "c9hve1ySGVAs"
      },
      "source": [
        "# C√©lula 1: Configura√ß√µes Auxiliares, Par√¢metros Globais e Log Centralizado\n",
        "\n",
        "**Objetivo:**  \n",
        "Esta c√©lula inicializa e centraliza todas as vari√°veis globais, par√¢metros essenciais e agora tamb√©m fornece um utilit√°rio robusto para o log √∫nico do notebook XCam.  \n",
        "Permite ajuste r√°pido e seguro do comportamento do notebook, incluindo limites de processamento, controle de grava√ß√£o, commit autom√°tico e mecanismos de resili√™ncia contra transmiss√µes problem√°ticas.\n",
        "\n",
        "## Principais pontos e melhorias implementadas\n",
        "\n",
        "- **Centraliza√ß√£o dos par√¢metros globais:**  \n",
        "  Todos os valores cr√≠ticos (limites, thresholds, caminhos) s√£o definidos e propagados como globais pelo notebook.\n",
        "- **Log √∫nico modular e estruturado (`xcam_master.log`):**  \n",
        "  Todas as opera√ß√µes relevantes (busca, grava√ß√£o, blacklist, commit, erros, etc.) agora s√£o registradas em um √∫nico arquivo JSON Lines.  \n",
        "  Cada entrada inclui sess√£o, evento, id, username, timestamps, status e detalhes.\n",
        "- **Fun√ß√µes utilit√°rias para o log:**  \n",
        "  Adi√ß√£o, busca, remo√ß√£o e atualiza√ß√£o de eventos s√£o facilitadas por fun√ß√µes modulares (CRUD), promovendo robustez, rastreabilidade e f√°cil manuten√ß√£o.\n",
        "- **Blacklist, falhas e processamento padronizados por `id`:**  \n",
        "  Toda l√≥gica de controle √© feita via identificador √∫nico, com `username` para exibi√ß√£o, garantindo unicidade e eliminando inconsist√™ncias.\n",
        "- **Fun√ß√£o interativa para sele√ß√£o de transmiss√µes espec√≠ficas:**  \n",
        "  Permite ao usu√°rio informar nomes de usu√°rios para filtrar transmiss√µes antes do processamento.\n",
        "- **Coment√°rios detalhados:**  \n",
        "  Cada etapa do c√≥digo est√° documentada para orientar ajustes, manuten√ß√£o e integra√ß√£o por toda a equipe.\n",
        "\n",
        "---\n",
        "\n",
        "## Par√¢metros globais controlados nesta c√©lula\n",
        "\n",
        "- **`LIMIT_DEFAULT`**: Quantidade m√°xima de transmiss√µes processadas em paralelo/lote.\n",
        "- **`PAGE_DEFAULT`**: P√°gina inicial para busca na API.\n",
        "- **`RECORD_SECONDS`**: Tempo m√°ximo de grava√ß√£o de cada v√≠deo (em segundos).\n",
        "- **`RECORD_SECONDS_MIN`**: Tempo m√≠nimo exigido para considerar o v√≠deo v√°lido (em segundos).\n",
        "- **`API_SEARCH_LIMIT`**: Limite de transmiss√µes retornadas ao buscar usu√°rios espec√≠ficos.\n",
        "- **`COMMIT_PUSH_THRESHOLD`**: Quantidade de transmiss√µes processadas at√© realizar commit/push autom√°tico (0 = commit imediato a cada grava√ß√£o).\n",
        "- **`LOG_PATH`**: Caminho do arquivo √∫nico de log (JSONL).\n",
        "- **`BLACKLIST_TIMEOUT`**: Tempo de expira√ß√£o da blacklist (em segundos).\n",
        "- **`BLACKLIST_MAX_FAILURES`**: Quantidade de falhas consecutivas antes de banir temporariamente o usu√°rio.\n",
        "\n",
        "---\n",
        "\n",
        "## Estrutura do log √∫nico (`xcam_master.log`)\n",
        "\n",
        "Cada entrada segue o modelo:\n",
        "```json\n",
        "{\n",
        "  \"timestamp\": \"2025-06-06T06:15:00Z\",\n",
        "  \"sessao\": \"busca|grava√ß√£o|blacklist|commit|erro|...\",\n",
        "  \"evento\": \"...\",\n",
        "  \"id\": \"...\",         // identificador √∫nico (prim√°rio)\n",
        "  \"username\": \"...\",   // nome do usu√°rio para exibi√ß√£o\n",
        "  \"status\": \"...\",     // ok|erro|blacklisted|expirado|...\n",
        "  \"detalhes\": \"...\",   // informa√ß√µes adicionais\n",
        "}\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Fun√ß√µes utilit√°rias para o log\n",
        "\n",
        "- **`append_log(entry, log_path=LOG_PATH)`**: Adiciona uma nova entrada ao log central.\n",
        "- **`read_logs(log_path=LOG_PATH)`**: L√™ todas as entradas do log.\n",
        "- **`query_logs(...)`**: Consulta entradas do log por filtros opcionais (sess√£o, id, status, etc).\n",
        "- **`remove_logs(condition_fn, log_path=LOG_PATH)`**: Remove todas as entradas que satisfa√ßam a condi√ß√£o.\n",
        "- **`update_log_entry(match_fn, update_fn, log_path=LOG_PATH)`**: Atualiza entradas do log conforme regra.\n",
        "\n",
        "---\n",
        "\n",
        "## Exemplo de uso das fun√ß√µes (a serem aplicadas nas pr√≥ximas c√©lulas)\n",
        "\n",
        "```python\n",
        "append_log({\n",
        "    \"sessao\": \"busca\",\n",
        "    \"evento\": \"encontrado\",\n",
        "    \"id\": \"abc123\",\n",
        "    \"username\": \"Manugic_\",\n",
        "    \"status\": \"ok\",\n",
        "    \"detalhes\": \"URL v√°lida\"\n",
        "})\n",
        "\n",
        "# Consultar blacklist:\n",
        "logs_blacklist = query_logs(sessao=\"blacklist\", status=\"blacklisted\")\n",
        "\n",
        "# Remover registros expirados:\n",
        "remove_logs(lambda entry: entry[\"sessao\"] == \"processing\" and expirou(entry), log_path=LOG_PATH)\n",
        "\n",
        "# Atualizar status:\n",
        "update_log_entry(lambda e: e[\"id\"]==\"abc123\", lambda e: e.update({\"status\":\"ok\"}))\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Fun√ß√£o interativa\n",
        "\n",
        "Permite ao usu√°rio informar transmiss√µes espec√≠ficas a serem gravadas antes de iniciar o processamento.\n",
        "\n",
        "---\n",
        "\n",
        "## Seguran√ßa, rastreabilidade e manuten√ß√£o\n",
        "\n",
        "- Todos os par√¢metros globais s√£o definidos no in√≠cio e propagados para todo o notebook, garantindo consist√™ncia.\n",
        "- O log √∫nico fornece rastreabilidade detalhada e elimina arquivos dispersos (blacklist, falha, etc).\n",
        "- Ajuste qualquer valor diretamente nesta c√©lula para alterar o comportamento global do notebook de forma segura.\n",
        "- Coment√°rios detalhados auxiliam a compreens√£o, integra√ß√£o e manuten√ß√£o por toda a equipe.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "j5pPh353GLMD",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5pPh353GLMD",
        "outputId": "44655413-5f22-4c54-9d44-2a2fc00f759c"
      },
      "outputs": [],
      "source": [
        "# =====================================================================================\n",
        "# XCam REC - C√©lula de Configura√ß√£o Global e Logs\n",
        "# =====================================================================================\n",
        "# [@author]      Samuel Passamani / Um Projeto do Estudio A.S√©rio [AllS Company]\n",
        "# [@info]        https://aserio.work/\n",
        "# [@version]     4.6.2\n",
        "# [@lastupdate]  2025-07-01\n",
        "#\n",
        "# [@description]\n",
        "# Esta c√©lula √© o n√∫cleo de configura√ß√£o e controle para todo o notebook de grava√ß√£o.\n",
        "# Ela centraliza todos os par√¢metros, limites, timeouts e caminhos de arquivos,\n",
        "# garantindo que todas as opera√ß√µes subsequentes sejam consistentes e facilmente ajust√°veis.\n",
        "# Al√©m disso, implementa um sistema de logging robusto e centralizado em um √∫nico\n",
        "# arquivo (JSONL), com fun√ß√µes utilit√°rias para manipula√ß√£o (CRUD), promovendo\n",
        "# m√°xima rastreabilidade e facilitando a depura√ß√£o.\n",
        "#\n",
        "# [@mode]\n",
        "# Esta c√©lula funciona como a base de setup para todos os modos de opera√ß√£o do\n",
        "# notebook, seja em modo de busca autom√°tica ou grava√ß√£o de usu√°rios espec√≠ficos.\n",
        "# =====================================================================================\n",
        "\n",
        "# =====================================================================================\n",
        "# 2. Configura√ß√µes & Vari√°veis Globais\n",
        "# =====================================================================================\n",
        "\n",
        "# --- Imports Essenciais ---\n",
        "from google.colab import drive  # M√≥dulo para interagir com o Google Drive\n",
        "import os                       # M√≥dulo para intera√ß√µes com o sistema operacional (pastas, arquivos)\n",
        "import json                     # M√≥dulo para manipula√ß√£o de dados no formato JSON\n",
        "from datetime import datetime   # M√≥dulo para trabalhar com datas e horas\n",
        "import time                     # M√≥dulo para fun√ß√µes relacionadas a tempo (ex: sleep, timestamps)\n",
        "\n",
        "# --- Montagem do Google Drive ---\n",
        "# Garante que o Google Drive esteja acess√≠vel para persist√™ncia dos dados.\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# --- Par√¢metros Globais Edit√°veis ---\n",
        "# Ajuste estes valores para controlar o comportamento de todo o notebook.\n",
        "\n",
        "# Limites e thresholds de processamento\n",
        "LIMIT_DEFAULT = 50              # Define a quantidade m√°xima de grava√ß√µes que podem ocorrer em paralelo.\n",
        "PAGE_DEFAULT = 1                # Define a p√°gina inicial para buscas na API do XCam.\n",
        "RECORD_SECONDS = 12780          # Define o tempo m√°ximo de grava√ß√£o de cada v√≠deo, em segundos (aprox. 3.5 horas).\n",
        "RECORD_SECONDS_MIN = 660        # Define o tempo m√≠nimo que um v√≠deo precisa ter para ser considerado v√°lido.\n",
        "API_SEARCH_LIMIT = 1500         # Limite de resultados ao buscar por usu√°rios espec√≠ficos na API.\n",
        "COMMIT_PUSH_THRESHOLD = 25      # N√∫mero de grava√ß√µes conclu√≠das para disparar um commit autom√°tico para o GitHub.\n",
        "\n",
        "# Configura√ß√µes da Blacklist\n",
        "BLACKLIST_TIMEOUT = 15 * 60     # Tempo que um usu√°rio permanece na blacklist, em segundos (15 minutos).\n",
        "BLACKLIST_MAX_FAILURES = 3      # N√∫mero de falhas consecutivas de grava√ß√£o para um usu√°rio ser adicionado √† blacklist.\n",
        "\n",
        "# --- Caminhos Centralizados (Google Drive) ---\n",
        "# Define todos os caminhos de forma centralizada para f√°cil manuten√ß√£o.\n",
        "DRIVE_BASE_PATH = \"/content/drive/MyDrive/XCam.Drive/src\"               # Pasta raiz do projeto no Drive.\n",
        "DRIVE_LOGS_PATH = os.path.join(DRIVE_BASE_PATH, \"logs\")                 # Pasta para todos os arquivos de log.\n",
        "DRIVE_POSTERS_TEMP_PATH = os.path.join(DRIVE_BASE_PATH, \"temp\", \"posters\") # Pasta para p√¥steres tempor√°rios.\n",
        "DRIVE_RECORDS_TEMP_PATH = os.path.join(DRIVE_BASE_PATH, \"temp\", \"records\") # Pasta para v√≠deos tempor√°rios.\n",
        "DRIVE_ARCHIVE_BASE_PATH = \"/content/drive/MyDrive/XCam.Drive/user\"      # Pasta de arquivamento final dos dados por usu√°rio.\n",
        "\n",
        "# --- Nomes de Arquivos de Log Espec√≠ficos ---\n",
        "# Define os nomes dos arquivos de log que ser√£o criados dentro de DRIVE_LOGS_PATH.\n",
        "MASTER_LOG_FILE = os.path.join(DRIVE_LOGS_PATH, \"xcam_master.log\")         # Log principal com todos os eventos.\n",
        "BLACKLIST_LOG_FILE = os.path.join(DRIVE_LOGS_PATH, \"xcam_blacklist.log\")   # Log de usu√°rios em blacklist.\n",
        "FAILURE_LOG_FILE = os.path.join(DRIVE_LOGS_PATH, \"xcam_failures.log\")     # Log de contagem de falhas.\n",
        "PROCESSING_LOG_FILE = os.path.join(DRIVE_LOGS_PATH, \"xcam_processing.log\")  # Log de usu√°rios em processamento.\n",
        "\n",
        "# --- Verifica√ß√£o e Cria√ß√£o de Diret√≥rios ---\n",
        "# Garante que as pastas de destino existam para evitar erros de \"Arquivo n√£o encontrado\".\n",
        "os.makedirs(DRIVE_LOGS_PATH, exist_ok=True)\n",
        "os.makedirs(DRIVE_POSTERS_TEMP_PATH, exist_ok=True)\n",
        "os.makedirs(DRIVE_RECORDS_TEMP_PATH, exist_ok=True)\n",
        "os.makedirs(DRIVE_ARCHIVE_BASE_PATH, exist_ok=True)\n",
        "print(\"‚úÖ Pastas do Google Drive verificadas/criadas com sucesso.\")\n",
        "\n",
        "# --- Propaga√ß√£o de Vari√°veis Globais ---\n",
        "# Torna todas as configura√ß√µes acima acess√≠veis em qualquer outra c√©lula do notebook.\n",
        "globals().update({\n",
        "    'LIMIT_DEFAULT': LIMIT_DEFAULT,\n",
        "    'PAGE_DEFAULT': PAGE_DEFAULT,\n",
        "    'RECORD_SECONDS': RECORD_SECONDS,\n",
        "    'RECORD_SECONDS_MIN': RECORD_SECONDS_MIN,\n",
        "    'API_SEARCH_LIMIT': API_SEARCH_LIMIT,\n",
        "    'COMMIT_PUSH_THRESHOLD': COMMIT_PUSH_THRESHOLD,\n",
        "    'BLACKLIST_TIMEOUT': BLACKLIST_TIMEOUT,\n",
        "    'BLACKLIST_MAX_FAILURES': BLACKLIST_MAX_FAILURES,\n",
        "    'DRIVE_LOGS_PATH': DRIVE_LOGS_PATH,\n",
        "    'DRIVE_POSTERS_TEMP_PATH': DRIVE_POSTERS_TEMP_PATH,\n",
        "    'DRIVE_RECORDS_TEMP_PATH': DRIVE_RECORDS_TEMP_PATH,\n",
        "    'DRIVE_ARCHIVE_BASE_PATH': DRIVE_ARCHIVE_BASE_PATH,\n",
        "    'MASTER_LOG_FILE': MASTER_LOG_FILE,\n",
        "    'BLACKLIST_LOG_FILE': BLACKLIST_LOG_FILE,\n",
        "    'FAILURE_LOG_FILE': FAILURE_LOG_FILE,\n",
        "    'PROCESSING_LOG_FILE': PROCESSING_LOG_FILE\n",
        "})\n",
        "\n",
        "\n",
        "# =====================================================================================\n",
        "# 3. Corpo\n",
        "# =====================================================================================\n",
        "\n",
        "# --- Fun√ß√µes Utilit√°rias para Log Centralizado (JSONL) ---\n",
        "\n",
        "def now_iso():\n",
        "    \"\"\"Retorna o timestamp atual em formato UTC ISO 8601, padr√£o para logs.\"\"\"\n",
        "    return datetime.utcnow().isoformat() + \"Z\"\n",
        "\n",
        "def append_log(entry, log_path=MASTER_LOG_FILE):\n",
        "    \"\"\"Adiciona uma nova entrada ao arquivo de log especificado.\"\"\"\n",
        "    # Garante que toda entrada de log tenha um timestamp.\n",
        "    entry.setdefault(\"timestamp\", now_iso())\n",
        "    # Garante que os campos essenciais para rastreabilidade existam na entrada.\n",
        "    for field in [\"sessao\", \"evento\", \"id\", \"username\", \"status\"]:\n",
        "        entry.setdefault(field, \"\")\n",
        "    # Abre o arquivo em modo 'append' (a) e escreve a nova entrada como uma linha JSON.\n",
        "    with open(log_path, \"a\", encoding=\"utf-8\") as f:\n",
        "        f.write(json.dumps(entry, ensure_ascii=False) + \"\\\\n\")\n",
        "\n",
        "def read_logs(log_path=MASTER_LOG_FILE):\n",
        "    \"\"\"L√™ e retorna todas as entradas de um arquivo de log JSONL.\"\"\"\n",
        "    # Se o arquivo n√£o existir, retorna uma lista vazia para evitar erros.\n",
        "    if not os.path.exists(log_path):\n",
        "        return []\n",
        "    # Abre o arquivo para leitura e converte cada linha de JSON para um dicion√°rio Python.\n",
        "    with open(log_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        return [json.loads(line) for line in f if line.strip()]\n",
        "\n",
        "def query_logs(sessao=None, id=None, username=None, evento=None, status=None, after=None, before=None, log_path=MASTER_LOG_FILE):\n",
        "    \"\"\"Consulta entradas de log com base em m√∫ltiplos filtros opcionais.\"\"\"\n",
        "    # L√™ todos os logs do arquivo.\n",
        "    logs = read_logs(log_path)\n",
        "    filtered_logs = []\n",
        "    # Itera sobre cada entrada de log para aplicar os filtros.\n",
        "    for entry in logs:\n",
        "        if sessao and entry.get(\"sessao\") != sessao: continue\n",
        "        if id and entry.get(\"id\") != id: continue\n",
        "        if username and entry.get(\"username\") != username: continue\n",
        "        if evento and entry.get(\"evento\") != evento: continue\n",
        "        if status and entry.get(\"status\") != status: continue\n",
        "        # Filtra por intervalo de tempo, se especificado.\n",
        "        ts = entry.get(\"timestamp\")\n",
        "        if after and ts < (after.isoformat() if isinstance(after, datetime) else after): continue\n",
        "        if before and ts > (before.isoformat() if isinstance(before, datetime) else before): continue\n",
        "        filtered_logs.append(entry)\n",
        "    return filtered_logs\n",
        "\n",
        "def remove_logs(condition_fn, log_path=MASTER_LOG_FILE):\n",
        "    \"\"\"Remove entradas de um log que satisfa√ßam uma fun√ß√£o de condi√ß√£o.\"\"\"\n",
        "    logs = read_logs(log_path)\n",
        "    # Cria uma nova lista apenas com os logs que devem ser mantidos.\n",
        "    kept_logs = [entry for entry in logs if not condition_fn(entry)]\n",
        "    # Reescreve o arquivo de log com a lista filtrada.\n",
        "    with open(log_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        for entry in kept_logs:\n",
        "            f.write(json.dumps(entry, ensure_ascii=False) + \"\\\\n\")\n",
        "    # Retorna o n√∫mero de entradas removidas.\n",
        "    return len(logs) - len(kept_logs)\n",
        "\n",
        "def update_log_entry(match_fn, update_fn, log_path=MASTER_LOG_FILE):\n",
        "    \"\"\"Atualiza uma ou mais entradas de log que correspondam a uma fun√ß√£o de busca.\"\"\"\n",
        "    logs = read_logs(log_path)\n",
        "    updated_count = 0\n",
        "    # Itera sobre os logs e aplica a fun√ß√£o de atualiza√ß√£o.\n",
        "    for entry in logs:\n",
        "        if match_fn(entry):\n",
        "            update_fn(entry)\n",
        "            updated_count += 1\n",
        "    # Reescreve o arquivo com os logs atualizados.\n",
        "    with open(log_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        for entry in logs:\n",
        "            f.write(json.dumps(entry, ensure_ascii=False) + \"\\\\n\")\n",
        "    return updated_count\n",
        "\n",
        "# --- Fun√ß√£o Interativa para Sele√ß√£o de Usu√°rios ---\n",
        "\n",
        "def perguntar_transmissoes_especificas():\n",
        "    \"\"\"Pergunta ao usu√°rio se deseja gravar transmiss√µes espec√≠ficas.\"\"\"\n",
        "    # Captura a resposta do usu√°rio.\n",
        "    resp = input('Deseja gravar alguma transmiss√£o espec√≠fica? (sim/n√£o): ').strip().lower()\n",
        "    # Se a resposta for afirmativa, solicita a lista de usu√°rios.\n",
        "    if resp.startswith('s'):\n",
        "        usuarios_input = input('Informe o(s) nome(s) de usu√°rio, separados por v√≠rgula: ')\n",
        "        # Limpa e formata a entrada do usu√°rio em uma lista de nomes.\n",
        "        return [u.strip() for u in usuarios_input.split(',') if u.strip()]\n",
        "    # Retorna uma lista vazia se a resposta for negativa.\n",
        "    return []\n",
        "\n",
        "# =====================================================================================\n",
        "# 4. Rodap√© / Fim do C√≥digo\n",
        "# =====================================================================================\n",
        "# @log de mudan√ßas\n",
        "# - v4.6.2 (01/07/2025): Refatora√ß√£o para o padr√£o de documenta√ß√£o XCam. Adi√ß√£o de\n",
        "#   coment√°rios detalhados, centraliza√ß√£o de caminhos do Drive e organiza√ß√£o\n",
        "#   estrutural para melhor clareza e manuten√ß√£o.\n",
        "# - v4.6.1 (01/07/2025): Centraliza√ß√£o dos caminhos de arquivos tempor√°rios e logs\n",
        "#   para subpastas dedicadas no Google Drive, melhorando a organiza√ß√£o.\n",
        "# - v4.6.0: Vers√£o inicial da C√©lula 1 com sistema de log centralizado.\n",
        "#\n",
        "# @roadmap futuro\n",
        "# - Migrar a l√≥gica de controle de blacklist e falhas (atualmente em arquivos\n",
        "#   separados na C√©lula 6) para usar exclusivamente o MASTER_LOG_FILE,\n",
        "#   centralizando 100% da l√≥gica de estado.\n",
        "# - Refatorar as fun√ß√µes de log para uma classe `Logger` dedicada, melhorando\n",
        "#   o encapsulamento e a organiza√ß√£o do c√≥digo.\n",
        "# ====================================================================================="
      ]
    },
    {
      "cell_type": "markdown",
      "id": "WXs0o6OPHXbi",
      "metadata": {
        "id": "WXs0o6OPHXbi"
      },
      "source": [
        "# C√©lula 2: Instala√ß√£o e Valida√ß√£o do ffmpeg\n",
        "\n",
        "**Objetivo:**  \n",
        "Esta c√©lula garante que o utilit√°rio `ffmpeg` esteja instalado e dispon√≠vel no ambiente Google Colab. O ffmpeg √© indispens√°vel para a grava√ß√£o dos v√≠deos das transmiss√µes e para o processamento de m√≠dia ao longo do pipeline do notebook XCam.\n",
        "\n",
        "## Pontos principais e melhorias implementadas\n",
        "\n",
        "- **Verifica√ß√£o pr√©-instala√ß√£o:**  \n",
        "  Antes de instalar, verifica se o ffmpeg j√° est√° dispon√≠vel no ambiente, tornando o processo idempotente e eficiente.\n",
        "- **Instala√ß√£o automatizada:**  \n",
        "  Efetua a instala√ß√£o via `apt-get` apenas se necess√°rio, reduzindo o tempo de setup em execu√ß√µes futuras.\n",
        "- **Valida√ß√£o p√≥s-instala√ß√£o:**  \n",
        "  Exibe a vers√£o instalada do ffmpeg, garantindo transpar√™ncia e rastreabilidade.\n",
        "- **Mensagens detalhadas:**  \n",
        "  O usu√°rio recebe logs informativos sobre cada etapa, facilitando o diagn√≥stico em caso de erros.\n",
        "- **Design modular:**  \n",
        "  Estrutura pronta para ser utilizada em outros ambientes (Colab, local, server) com pequenas adapta√ß√µes.\n",
        "\n",
        "---\n",
        "\n",
        "## Como funciona a c√©lula\n",
        "\n",
        "- **Verifica se o ffmpeg est√° instalado (no PATH do sistema).**\n",
        "- **Se n√£o estiver, instala automaticamente via apt-get.**\n",
        "- **Valida e exibe a vers√£o instalada ap√≥s o processo.**\n",
        "- **Em caso de falha, exibe erro detalhado e interrompe o fluxo para evitar inconsist√™ncias futuras.**\n",
        "\n",
        "---\n",
        "\n",
        "## Exemplo de uso das fun√ß√µes nesta c√©lula\n",
        "\n",
        "```python\n",
        "if not is_ffmpeg_installed():\n",
        "    install_ffmpeg()\n",
        "show_ffmpeg_version()\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Seguran√ßa, rastreabilidade e manuten√ß√£o\n",
        "\n",
        "- A c√©lula torna o setup do ambiente mais robusto, impedindo falhas silenciosas relacionadas √† aus√™ncia de ffmpeg.\n",
        "- Mensagens e valida√ß√µes ajudam a equipe a identificar rapidamente problemas de ambiente ou permiss√µes.\n",
        "- O padr√£o modular facilita a reutiliza√ß√£o do c√≥digo em diferentes notebooks ou pipelines do projeto XCam.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "vIODn0c2HiHz",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vIODn0c2HiHz",
        "outputId": "8461c69a-d669-487a-d6be-095e29eaccdb"
      },
      "outputs": [],
      "source": [
        "# ================================================================\n",
        "# C√©lula 2: Instala√ß√£o e Valida√ß√£o do FFMPEG no Colab\n",
        "# ================================================================\n",
        "# Objetivo:\n",
        "# - Garantir que o utilit√°rio ffmpeg est√° instalado e dispon√≠vel no ambiente\n",
        "# - Validar a instala√ß√£o e exibir a vers√£o instalada\n",
        "# - Tornar a etapa idempotente, evitando instala√ß√µes desnecess√°rias\n",
        "# - Fornecer feedback claro e orienta√ß√µes em caso de erro\n",
        "#\n",
        "# Estrat√©gia aplicada:\n",
        "# - Instala√ß√£o via apt-get apenas se ffmpeg n√£o estiver dispon√≠vel\n",
        "# - Valida√ß√£o p√≥s-instala√ß√£o\n",
        "# - Logs claros e coment√°rios detalhados para rastreabilidade\n",
        "# ================================================================\n",
        "\n",
        "import subprocess\n",
        "\n",
        "def is_ffmpeg_installed():\n",
        "    \"\"\"\n",
        "    Verifica se o ffmpeg est√° instalado e dispon√≠vel no PATH do sistema.\n",
        "    Retorna True se estiver, False caso contr√°rio.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        result = subprocess.run([\"ffmpeg\", \"-version\"], capture_output=True, text=True)\n",
        "        return result.returncode == 0\n",
        "    except FileNotFoundError:\n",
        "        return False\n",
        "\n",
        "def install_ffmpeg():\n",
        "    \"\"\"\n",
        "    Instala o ffmpeg via apt-get caso n√£o esteja presente.\n",
        "    \"\"\"\n",
        "    print(\"[INFO] Instalando ffmpeg via apt-get...\")\n",
        "    # Atualiza pacotes e instala ffmpeg silenciosamente\n",
        "    !apt-get update -y > /dev/null\n",
        "    !apt-get install -y ffmpeg > /dev/null\n",
        "    print(\"[INFO] ffmpeg instalado com sucesso.\")\n",
        "\n",
        "def show_ffmpeg_version():\n",
        "    \"\"\"\n",
        "    Exibe a vers√£o instalada do ffmpeg.\n",
        "    \"\"\"\n",
        "    print(\"[INFO] Vers√£o do ffmpeg instalada:\")\n",
        "    !ffmpeg -version | head -n 2\n",
        "\n",
        "# ============================\n",
        "# EXECU√á√ÉO DA ETAPA DE SETUP\n",
        "# ============================\n",
        "\n",
        "if not is_ffmpeg_installed():\n",
        "    print(\"[WARN] ffmpeg n√£o encontrado no ambiente.\")\n",
        "    install_ffmpeg()\n",
        "    if not is_ffmpeg_installed():\n",
        "        raise RuntimeError(\"[ERRO] Falha ao instalar o ffmpeg. Verifique permiss√µes ou tente novamente.\")\n",
        "else:\n",
        "    print(\"[OK] ffmpeg j√° est√° instalado no ambiente.\")\n",
        "\n",
        "# Valida√ß√£o final e exibi√ß√£o da vers√£o\n",
        "show_ffmpeg_version()\n",
        "\n",
        "# ============================\n",
        "# FIM DA C√âLULA 2\n",
        "# ============================\n",
        "\n",
        "# Dica: ffmpeg deve estar dispon√≠vel para todas as c√©lulas subsequentes.\n",
        "# Se precisar de um caminho espec√≠fico, utilize `which ffmpeg` para obter o path absoluto."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "90qvXC0rHtWb",
      "metadata": {
        "id": "90qvXC0rHtWb"
      },
      "source": [
        "# C√©lula 3: Imports Essenciais, Utilit√°rios e Prepara√ß√£o do Ambiente\n",
        "\n",
        "**Objetivo:**  \n",
        "Importa todas as bibliotecas essenciais do Python necess√°rias para o funcionamento do notebook, incluindo m√≥dulos para requisi√ß√µes HTTP, processamento paralelo, manipula√ß√£o de datas, controle de subprocessos e exibi√ß√£o interativa.  \n",
        "Centraliza fun√ß√µes utilit√°rias robustas e padronizadas para processamento, download de poster, gera√ß√£o autom√°tica de poster com ffmpeg e exibi√ß√£o de progresso.  \n",
        "\n",
        "## Principais pontos e melhorias implementadas\n",
        "\n",
        "- **Centraliza√ß√£o de imports essenciais:**  \n",
        "  Todos os m√≥dulos fundamentais (os, requests, multiprocessing, datetime, json, time, subprocess, math, re, IPython) est√£o dispon√≠veis e prontos para uso global.\n",
        "- **Fun√ß√µes utilit√°rias padronizadas:**  \n",
        "  Fun√ß√µes para formata√ß√£o de segundos, exibi√ß√£o de progresso, download e valida√ß√£o de poster e gera√ß√£o de poster via ffmpeg foram refatoradas e documentadas, seguindo arquitetura modular e Clean Architecture.\n",
        "- **Remo√ß√£o de logs tempor√°rios dispersos:**  \n",
        "  O antigo arquivo de log de processamento tempor√°rio foi descontinuado em favor do log √∫nico centralizado definido na C√©lula 1, promovendo rastreabilidade e controle total.\n",
        "- **Robustez e clareza:**  \n",
        "  Todas as fun√ß√µes possuem tratamento de erros, mensagens amig√°veis e s√£o preparadas para uso concorrente e integra√ß√£o com as pr√≥ximas etapas do pipeline.\n",
        "- **Pronto para uso em todo o notebook:**  \n",
        "  As fun√ß√µes aqui definidas s√£o utilizadas em toda a automa√ß√£o, garantindo reuso, legibilidade e manuten√ß√£o facilitada.\n",
        "\n",
        "---\n",
        "\n",
        "## Fun√ß√µes utilit√°rias dispon√≠veis nesta c√©lula\n",
        "\n",
        "- **`format_seconds(seconds)`**: Formata um valor em segundos para string leg√≠vel (ex: \"1h23m45s\").\n",
        "- **`log_progress(username, elapsed_seconds, total_seconds)`**: Exibe o progresso da grava√ß√£o de cada transmiss√£o.\n",
        "- **`download_and_save_poster(poster_url, username, temp_folder)`**: Baixa e salva o poster da transmiss√£o a partir de uma URL remota ou retorna se for um caminho local.\n",
        "- **`generate_poster_with_ffmpeg(m3u8_url, username, temp_folder, frame_time=7, timeout=20)`**: Gera automaticamente um poster usando ffmpeg, ap√≥s validar a disponibilidade do stream.\n",
        "- **`is_poster_valid(poster_path)`**: Verifica se o arquivo de poster √© v√°lido (existe e n√£o est√° vazio).\n",
        "\n",
        "---\n",
        "\n",
        "## Exemplo de uso das fun√ß√µes\n",
        "\n",
        "```python\n",
        "# Formatar segundos em string leg√≠vel\n",
        "tempo = format_seconds(385)\n",
        "# Exibir progresso\n",
        "log_progress(\"userNovo234\", 385, 12780)\n",
        "# Download do poster\n",
        "poster_path = download_and_save_poster(url_poster, \"userNovo234\", \"/content/temp\")\n",
        "# Gera√ß√£o autom√°tica de poster via ffmpeg (se necess√°rio)\n",
        "if not is_poster_valid(poster_path):\n",
        "    poster_path = generate_poster_with_ffmpeg(m3u8_url, \"userNovo234\", \"/content/temp\")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Seguran√ßa, rastreabilidade e manuten√ß√£o\n",
        "\n",
        "- Todas as fun√ß√µes s√£o preparadas para tratamento de erros e integra√ß√£o com processos concorrentes.\n",
        "- O log tempor√°rio de processamento foi removido, garantindo que todo o rastreio e auditoria sejam feitos via log √∫nico centralizado da C√©lula 1.\n",
        "- Coment√°rios detalhados facilitam manuten√ß√£o, entendimento e evolu√ß√£o do notebook.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hOetz0nGICkz",
      "metadata": {
        "id": "hOetz0nGICkz"
      },
      "outputs": [],
      "source": [
        "# =====================================================================================\n",
        "# XCam REC - C√©lula 3: Utilit√°rios Essenciais e Prepara√ß√£o do Ambiente\n",
        "# =====================================================================================\n",
        "# [@author]      Samuel Passamani / Um Projeto do Estudio A.S√©rio [AllS Company]\n",
        "# [@info]        https://aserio.work/\n",
        "# [@version]     4.6.1\n",
        "# [@lastupdate]  2025-07-01\n",
        "#\n",
        "# [@description]\n",
        "# Esta c√©lula √© respons√°vel por importar todas as bibliotecas Python essenciais para\n",
        "# a execu√ß√£o do pipeline de grava√ß√£o e por definir um conjunto de fun√ß√µes\n",
        "# utilit√°rias robustas e padronizadas. As fun√ß√µes aqui presentes s√£o usadas\n",
        "# em todo o notebook para tarefas como formata√ß√£o de tempo, exibi√ß√£o de progresso,\n",
        "# download de p√¥steres e gera√ß√£o autom√°tica de thumbnails via ffmpeg, garantindo\n",
        "# modularidade, reuso de c√≥digo e f√°cil manuten√ß√£o.\n",
        "#\n",
        "# [@mode]\n",
        "# As fun√ß√µes e imports definidos nesta c√©lula s√£o de prop√≥sito geral e servem de\n",
        "# base para todas as opera√ß√µes do notebook, independentemente do modo de execu√ß√£o.\n",
        "# =====================================================================================\n",
        "\n",
        "# =====================================================================================\n",
        "# 2. Configura√ß√µes & Vari√°veis Globais (Imports)\n",
        "# =====================================================================================\n",
        "\n",
        "# --- Imports Essenciais ---\n",
        "import os                          # M√≥dulo para intera√ß√µes com o sistema operacional (pastas, arquivos).\n",
        "import requests                    # Biblioteca para fazer requisi√ß√µes HTTP de forma simples e elegante.\n",
        "from multiprocessing import Manager, Process # M√≥dulos para habilitar o processamento paralelo e acelerar as grava√ß√µes.\n",
        "from datetime import datetime      # M√≥dulo para trabalhar com datas e horas.\n",
        "import json                        # M√≥dulo para manipula√ß√£o de dados no formato JSON.\n",
        "import time                        # M√≥dulo para fun√ß√µes relacionadas a tempo (ex: sleep, timestamps).\n",
        "import subprocess                  # M√≥dulo para executar processos externos, como o ffmpeg.\n",
        "import math                        # M√≥dulo com fun√ß√µes matem√°ticas (ex: arredondamento).\n",
        "import re                          # M√≥dulo para trabalhar com express√µes regulares, √∫til para extrair dados de texto.\n",
        "import shutil                      # M√≥dulo com opera√ß√µes de alto n√≠vel em arquivos e cole√ß√µes de arquivos.\n",
        "import threading                   # M√≥dulo para trabalhar com threads, usado para controle de concorr√™ncia (locks).\n",
        "\n",
        "# --- Imports Espec√≠ficos do Ambiente (IPython/Colab) ---\n",
        "from IPython import get_ipython    # Fun√ß√£o para obter a inst√¢ncia atual do IPython (√∫til para detectar o ambiente).\n",
        "from IPython.display import display # Fun√ß√£o para renderizar objetos de forma rica no notebook.\n",
        "\n",
        "\n",
        "# =====================================================================================\n",
        "# 3. Corpo\n",
        "# =====================================================================================\n",
        "\n",
        "# --- Fun√ß√µes Utilit√°rias de Formata√ß√£o e Progresso ---\n",
        "\n",
        "def format_seconds(seconds):\n",
        "    \"\"\"\n",
        "    Converte um n√∫mero total de segundos em uma string de formato amig√°vel (ex: \"1h23m45s\").\n",
        "    Ideal para logs e exibi√ß√£o de dura√ß√£o de v√≠deos.\n",
        "    \"\"\"\n",
        "    total_seconds = int(seconds)  # Garante que estamos trabalhando com um n√∫mero inteiro.\n",
        "    # Usa divmod para obter horas e o resto da divis√£o.\n",
        "    hours, remainder = divmod(total_seconds, 3600)\n",
        "    # Usa divmod novamente no resto para obter minutos e segundos.\n",
        "    minutes, seconds = divmod(remainder, 60)\n",
        "    \n",
        "    parts = [] # Lista para armazenar as partes do tempo formatado.\n",
        "    if hours > 0: parts.append(f\"{hours}h\")\n",
        "    if minutes > 0: parts.append(f\"{minutes}m\")\n",
        "    # Adiciona os segundos se houver, ou se for a √∫nica unidade de tempo.\n",
        "    if seconds > 0 or not parts: parts.append(f\"{seconds}s\")\n",
        "    \n",
        "    return \"\".join(parts) # Junta as partes em uma √∫nica string.\n",
        "\n",
        "def log_progress(username, elapsed_seconds, total_seconds):\n",
        "    \"\"\"\n",
        "    Imprime uma linha de progresso formatada para uma grava√ß√£o em andamento.\n",
        "    Inclui nome de usu√°rio, tempo decorrido, tempo restante e porcentagem.\n",
        "    \"\"\"\n",
        "    # Calcula a porcentagem, garantindo que n√£o ultrapasse 100%.\n",
        "    percent = min((elapsed_seconds / total_seconds) * 100, 100)\n",
        "    # Formata o tempo decorrido.\n",
        "    tempo = format_seconds(elapsed_seconds)\n",
        "    # Calcula os minutos gravados e restantes para uma vis√£o r√°pida.\n",
        "    minutos_gravados = math.floor(elapsed_seconds / 60)\n",
        "    minutos_restantes = max(0, math.ceil((total_seconds - elapsed_seconds) / 60))\n",
        "    # Imprime a linha de log formatada.\n",
        "    print(f\"‚è±Ô∏è [{username}] Gravados: {minutos_gravados} min | Restantes: {minutos_restantes} min | Tempo total: {tempo} ‚Äî üìä {percent:.1f}% conclu√≠do\")\n",
        "\n",
        "# --- Fun√ß√µes Utilit√°rias para Manipula√ß√£o de P√¥steres ---\n",
        "\n",
        "def download_and_save_poster(poster_url, username, temp_folder=DRIVE_POSTERS_TEMP_PATH):\n",
        "    \"\"\"\n",
        "    Baixa um p√¥ster de uma URL e o salva em uma pasta tempor√°ria.\n",
        "    Retorna o caminho do arquivo salvo ou None em caso de falha.\n",
        "    \"\"\"\n",
        "    # Se a URL j√° for um caminho de arquivo local existente, apenas o retorna.\n",
        "    if os.path.exists(poster_url):\n",
        "        return poster_url\n",
        "    \n",
        "    # Verifica se a URL √© uma string e come√ßa com \"http\".\n",
        "    if isinstance(poster_url, str) and poster_url.startswith(\"http\"):\n",
        "        try:\n",
        "            # Faz a requisi√ß√£o GET para a URL do p√¥ster com um timeout.\n",
        "            response = requests.get(poster_url, timeout=15)\n",
        "            # Levanta um erro se a resposta n√£o for bem-sucedida (status code n√£o for 2xx).\n",
        "            response.raise_for_status()\n",
        "            \n",
        "            # Padroniza a extens√£o do arquivo para .jpg para consist√™ncia.\n",
        "            ext = \".jpg\"\n",
        "            # Constr√≥i o caminho completo para o arquivo tempor√°rio.\n",
        "            poster_temp_path = os.path.join(temp_folder, f\"{username}_poster_temp{ext}\")\n",
        "            \n",
        "            # Salva o conte√∫do da resposta no arquivo.\n",
        "            with open(poster_temp_path, \"wb\") as f:\n",
        "                f.write(response.content)\n",
        "            \n",
        "            print(f\"üñºÔ∏è Poster baixado em: {poster_temp_path}\")\n",
        "            return poster_temp_path\n",
        "        except Exception as e:\n",
        "            # Em caso de qualquer erro (timeout, status ruim, etc.), loga e retorna None.\n",
        "            print(f\"‚ùå Erro ao baixar poster {poster_url}: {e}\")\n",
        "            return None\n",
        "    else:\n",
        "        # Se a URL n√£o for v√°lida, loga o erro e retorna None.\n",
        "        print(f\"‚ùå poster_url inv√°lido: {poster_url}\")\n",
        "        return None\n",
        "\n",
        "def generate_poster_with_ffmpeg(m3u8_url, username, temp_folder=DRIVE_POSTERS_TEMP_PATH, frame_time=7, timeout=20):\n",
        "    \"\"\"\n",
        "    Gera um p√¥ster (thumbnail) a partir de um stream de v√≠deo usando o ffmpeg.\n",
        "    Primeiro, verifica se o stream est√° online para evitar chamadas desnecess√°rias ao ffmpeg.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Faz uma requisi√ß√£o HEAD (mais leve) para verificar a disponibilidade do stream.\n",
        "        head_resp = requests.head(m3u8_url, timeout=5)\n",
        "        if not head_resp.ok:\n",
        "            # Se o stream n√£o estiver acess√≠vel, loga e retorna None.\n",
        "            print(f\"‚ö†Ô∏è Stream offline para {username} (status {head_resp.status_code})\")\n",
        "            return None\n",
        "    except Exception as e:\n",
        "        # Se houver um erro de conex√£o, loga e retorna None.\n",
        "        print(f\"‚ö†Ô∏è Erro de conex√£o ao stream de {username}: {e}\")\n",
        "        return None\n",
        "\n",
        "    # Define o caminho de sa√≠da para o p√¥ster gerado.\n",
        "    poster_ffmpeg_path = os.path.join(temp_folder, f\"{username}_poster_ffmpeg.jpg\")\n",
        "    # Constr√≥i o comando ffmpeg para capturar um √∫nico frame do v√≠deo.\n",
        "    command = [\"ffmpeg\", \"-y\", \"-ss\", str(frame_time), \"-i\", m3u8_url, \"-vframes\", \"1\", \"-q:v\", \"2\", poster_ffmpeg_path]\n",
        "    \n",
        "    try:\n",
        "        print(f\"üé¨ Gerando poster com ffmpeg para {username}...\")\n",
        "        # Executa o comando ffmpeg com um timeout para evitar que o processo trave.\n",
        "        result = subprocess.run(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, timeout=timeout)\n",
        "        # Se o comando foi bem-sucedido e o arquivo foi criado...\n",
        "        if result.returncode == 0 and os.path.exists(poster_ffmpeg_path):\n",
        "            print(f\"üñºÔ∏è Poster gerado via ffmpeg: {poster_ffmpeg_path}\")\n",
        "            return poster_ffmpeg_path\n",
        "        else:\n",
        "            # Caso contr√°rio, loga a sa√≠da de erro do ffmpeg.\n",
        "            print(f\"‚ùå ffmpeg falhou para {username}. STDERR: {result.stderr.decode(errors='ignore')}\")\n",
        "            return None\n",
        "    except subprocess.TimeoutExpired:\n",
        "        # Se o comando demorar demais, loga o timeout.\n",
        "        print(f\"‚è∞ Tempo excedido ao gerar poster para {username}.\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        # Lida com outros erros inesperados.\n",
        "        print(f\"‚ùå Erro inesperado ao gerar poster: {e}\")\n",
        "        return None\n",
        "\n",
        "def is_poster_valid(poster_path):\n",
        "    \"\"\"\n",
        "    Verifica se um caminho de p√¥ster √© v√°lido, ou seja, se o arquivo existe e n√£o est√° vazio.\n",
        "    \"\"\"\n",
        "    return poster_path and os.path.exists(poster_path) and os.path.getsize(poster_path) > 0\n",
        "\n",
        "\n",
        "# =====================================================================================\n",
        "# 4. Rodap√© / Fim do C√≥digo\n",
        "# =====================================================================================\n",
        "# @log de mudan√ßas\n",
        "# - v4.6.1 (01/07/2025): Refatora√ß√£o completa da c√©lula para o padr√£o de documenta√ß√£o\n",
        "#   XCam, com adi√ß√£o de coment√°rios detalhados e organiza√ß√£o estrutural.\n",
        "#   Os caminhos tempor√°rios foram atualizados para usar as vari√°veis globais do Drive.\n",
        "# - v4.6.0: Vers√£o inicial da C√©lula 3 com fun√ß√µes utilit√°rias.\n",
        "#\n",
        "# @roadmap futuro\n",
        "# - Refatorar as fun√ß√µes utilit√°rias em classes dedicadas (ex: `class VideoUtils`,\n",
        "#   `class PosterManager`) para melhorar o encapsulamento e a testabilidade.\n",
        "# - Integrar um sistema de cache para os p√¥steres para reduzir o n√∫mero de downloads\n",
        "#   e gera√ß√µes via ffmpeg em execu√ß√µes repetidas.\n",
        "# ====================================================================================="
      ]
    },
    {
      "cell_type": "markdown",
      "id": "hpRIMtyFIY0q",
      "metadata": {
        "id": "hpRIMtyFIY0q"
      },
      "source": [
        "# C√©lula 4: Clonagem do Reposit√≥rio GitHub no Colab e Google Drive\n",
        "\n",
        "**Objetivo:**  \n",
        "Esta c√©lula garante que o reposit√≥rio do projeto XCam seja sempre clonado de forma limpa e sincronizada no ambiente local do Colab e, se dispon√≠vel, tamb√©m no Google Drive para persist√™ncia.  \n",
        "Assegura ambiente pronto, atualizado, seguro para grava√ß√µes e processamento, e prepara diret√≥rios padronizados para integra√ß√£o com o restante do pipeline.\n",
        "\n",
        "## Principais pontos e melhorias implementadas\n",
        "\n",
        "- **Clonagem idempotente e limpa:**  \n",
        "  Remove reposit√≥rios antigos antes de clonar para evitar conflitos, arquivos √≥rf√£os ou problemas de sincroniza√ß√£o.\n",
        "- **Clonagem para ambiente tempor√°rio e persistente:**  \n",
        "  O reposit√≥rio √© clonado tanto para `/content` (Colab) quanto para o Drive (`/content/drive/MyDrive/XCam.Drive`) se o Drive estiver montado.\n",
        "- **Prepara√ß√£o de diret√≥rios de grava√ß√£o e processamento:**  \n",
        "  Estrutura de diret√≥rios tempor√°rios criada automaticamente, garantindo organiza√ß√£o dos dados.\n",
        "- **Exporta√ß√£o de vari√°veis globais:**  \n",
        "  Todos os caminhos, URLs e configura√ß√µes relevantes s√£o disponibilizados via `globals().update()` para uso em todo o notebook.\n",
        "- **Mensagens e valida√ß√µes detalhadas:**  \n",
        "  Feedback informativo sobre o status de cada etapa, facilitando o diagn√≥stico e a manuten√ß√£o.\n",
        "- **Pronto para CI/CD e integra√ß√µes futuras:**  \n",
        "  Token e URLs preparados para automa√ß√µes, integra√ß√µes externas e uploads (Abyss.to, etc).\n",
        "\n",
        "---\n",
        "\n",
        "## Par√¢metros globais definidos nesta c√©lula\n",
        "\n",
        "- **`GITHUB_USER`**, **`GITHUB_REPO`**, **`GITHUB_BRANCH`**, **`GITHUB_TOKEN`**: Configura√ß√µes do reposit√≥rio e autentica√ß√£o.\n",
        "- **`repo_url`**: URL do reposit√≥rio autenticada para clone/push.\n",
        "- **`TEMP_OUTPUT_FOLDER`**: Pasta para grava√ß√µes tempor√°rias.\n",
        "- **`BASE_REPO_FOLDER`**: Localiza√ß√£o do reposit√≥rio no ambiente Colab.\n",
        "- **`DRIVE_MOUNT`**, **`DRIVE_REPO_FOLDER`**: Caminhos no Google Drive para persist√™ncia (se montado).\n",
        "- **`ABYSS_UPLOAD_URL`**: URL de upload para integra√ß√£o com sistemas externos.\n",
        "\n",
        "---\n",
        "\n",
        "## Como funciona a c√©lula\n",
        "\n",
        "- **Remove reposit√≥rios antigos e diret√≥rios tempor√°rios**, evitando res√≠duos de execu√ß√µes anteriores.\n",
        "- **Clona o reposit√≥rio do GitHub** para `/content` (Colab).\n",
        "- **Se o Google Drive estiver montado**, faz o mesmo clone no diret√≥rio persistente do Drive.\n",
        "- **Cria diret√≥rios tempor√°rios necess√°rios** para grava√ß√µes e arquivos intermedi√°rios.\n",
        "- **Exporta todas as vari√°veis configuradas** para uso global no notebook.\n",
        "- **Exibe mensagens informativas** sobre cada etapa e alerta caso o Drive n√£o esteja dispon√≠vel.\n",
        "\n",
        "---\n",
        "\n",
        "## Exemplo de uso das vari√°veis globais\n",
        "\n",
        "```python\n",
        "print(BASE_REPO_FOLDER)        # Caminho do reposit√≥rio clonado no Colab\n",
        "print(DRIVE_REPO_FOLDER)      # Caminho do reposit√≥rio no Drive (se montado)\n",
        "print(TEMP_OUTPUT_FOLDER)     # Pasta tempor√°ria para grava√ß√µes\n",
        "print(ABYSS_UPLOAD_URL)       # URL de upload para integra√ß√£o externa\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Seguran√ßa, rastreabilidade e manuten√ß√£o\n",
        "\n",
        "- Garantia de ambiente limpo a cada execu√ß√£o, evitando conflitos de arquivos e branches.\n",
        "- Persist√™ncia dos dados no Drive (se montado), evitando perda de grava√ß√µes em caso de reinicializa√ß√£o do Colab.\n",
        "- Coment√°rios detalhados e estrutura modular facilitam a manuten√ß√£o, integra√ß√£o com CI/CD e futuras expans√µes no pipeline do XCam.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Uof_0QCrIlf7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uof_0QCrIlf7",
        "outputId": "8c4fec8f-25ce-4649-a429-2a239eef6c23"
      },
      "outputs": [],
      "source": [
        "# =====================================================================================\n",
        "# XCam REC - C√©lula 4: Sincroniza√ß√£o de Reposit√≥rio (Git)\n",
        "# =====================================================================================\n",
        "# [@author]      Samuel Passamani / Um Projeto do Estudio A.S√©rio [AllS Company]\n",
        "# [@info]        https://aserio.work/\n",
        "# [@version]     4.6.2\n",
        "# [@lastupdate]  2025-07-01\n",
        "#\n",
        "# [@description]\n",
        "# Esta c√©lula √© respons√°vel por preparar o ambiente de trabalho, garantindo que o\n",
        "# reposit√≥rio do projeto XCam esteja sempre sincronizado e dispon√≠vel. Ela realiza\n",
        "# uma clonagem limpa (removendo vers√µes antigas para evitar conflitos) do\n",
        "# reposit√≥rio do GitHub para dois locais estrat√©gicos:\n",
        "#   1. O ambiente ef√™mero do Google Colab (/content) para execu√ß√£o r√°pida.\n",
        "#   2. O Google Drive do usu√°rio para persist√™ncia de dados e metadados.\n",
        "# A c√©lula tamb√©m configura endpoints externos e propaga todas as vari√°veis de\n",
        "# caminho e configura√ß√£o para o restante do notebook.\n",
        "#\n",
        "# [@mode]\n",
        "# Esta √© uma c√©lula de setup fundamental e deve ser executada antes de qualquer\n",
        "# outra c√©lula de processamento, pois ela constr√≥i a base do ambiente de execu√ß√£o.\n",
        "# =====================================================================================\n",
        "\n",
        "\n",
        "# =====================================================================================\n",
        "# 2. Configura√ß√µes & Vari√°veis Globais\n",
        "# =====================================================================================\n",
        "\n",
        "# --- Configura√ß√µes do Reposit√≥rio GitHub ---\n",
        "# Define as credenciais e informa√ß√µes do reposit√≥rio a ser clonado.\n",
        "GITHUB_USER = \"SamuelPassamani\"\n",
        "GITHUB_REPO = \"XCam\"\n",
        "GITHUB_BRANCH = \"main\"\n",
        "# NOTA DE SEGURAN√áA: O token est√° hardcoded para facilitar. Em produ√ß√£o,\n",
        "# √© recomendado usar os \"Secrets\" do Google Colab para armazen√°-lo com mais seguran√ßa.\n",
        "GITHUB_TOKEN = \"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\"\n",
        "\n",
        "# --- URL do Reposit√≥rio com Autentica√ß√£o ---\n",
        "# Constr√≥i a URL de clonagem que inclui o token de acesso para permitir opera√ß√µes de push.\n",
        "repo_url = f\"https://{GITHUB_USER}:{GITHUB_TOKEN}@github.com/{GITHUB_USER}/{GITHUB_REPO}.git\"\n",
        "\n",
        "\n",
        "# =====================================================================================\n",
        "# 3. Corpo\n",
        "# =====================================================================================\n",
        "\n",
        "# --- Defini√ß√£o de Caminhos do Reposit√≥rio ---\n",
        "# Caminho para o reposit√≥rio no ambiente local e vol√°til do Colab.\n",
        "BASE_REPO_FOLDER = f\"/content/{GITHUB_REPO}\"\n",
        "# Caminho para o reposit√≥rio no Google Drive, usando a vari√°vel definida na C√©lula 1 para persist√™ncia.\n",
        "DRIVE_REPO_FOLDER = f\"{DRIVE_BASE_PATH}/{GITHUB_REPO}\"\n",
        "\n",
        "# --- Bloco de Sincroniza√ß√£o com o Ambiente Colab ---\n",
        "# Garante um ambiente limpo e atualizado a cada execu√ß√£o.\n",
        "print(f\"‚è≥ Limpando ambiente e clonando '{GITHUB_REPO}' para o Colab...\")\n",
        "# Remove qualquer pasta do reposit√≥rio que possa ter sobrado de uma execu√ß√£o anterior.\n",
        "# Isso previne conflitos de git e garante uma c√≥pia nova.\n",
        "!rm -rf {BASE_REPO_FOLDER}\n",
        "# Clona o branch especificado do reposit√≥rio para a pasta base do Colab.\n",
        "!git clone -b {GITHUB_BRANCH} {repo_url} {BASE_REPO_FOLDER}\n",
        "print(f\"‚úÖ Reposit√≥rio clonado com sucesso em: {BASE_REPO_FOLDER}\")\n",
        "\n",
        "# --- Bloco de Sincroniza√ß√£o com o Google Drive (Persist√™ncia) ---\n",
        "# Executa a mesma l√≥gica de clonagem para o Google Drive, se estiver montado.\n",
        "if os.path.exists(DRIVE_BASE_PATH):\n",
        "    print(f\"‚è≥ Limpando e clonando '{GITHUB_REPO}' para o Google Drive para garantir persist√™ncia...\")\n",
        "    # Remove a vers√£o antiga do reposit√≥rio no Drive.\n",
        "    !rm -rf \"{DRIVE_REPO_FOLDER}\"\n",
        "    # Clona a nova vers√£o para o Drive.\n",
        "    !git clone -b {GITHUB_BRANCH} {repo_url} \"{DRIVE_REPO_FOLDER}\"\n",
        "    print(f\"‚úÖ Reposit√≥rio tamb√©m clonado no Drive: {DRIVE_REPO_FOLDER}\")\n",
        "else:\n",
        "    # Alerta o usu√°rio caso o Drive n√£o esteja montado, o que comprometeria a persist√™ncia.\n",
        "    print(f\"‚ö†Ô∏è Google Drive n√£o est√° montado em {DRIVE_BASE_PATH}. A persist√™ncia do reposit√≥rio no Drive est√° desativada.\")\n",
        "\n",
        "# --- Configura√ß√£o de Endpoints Externos ---\n",
        "# Define a URL para o servi√ßo de upload de v√≠deos.\n",
        "ABYSS_UPLOAD_URL = 'http://up.hydrax.net/0128263f78f0b426d617bb61c2a8ff43'\n",
        "\n",
        "# --- Propaga√ß√£o de Vari√°veis Globais ---\n",
        "# Torna todas as vari√°veis e caminhos definidos nesta c√©lula acess√≠veis globalmente.\n",
        "globals().update({\n",
        "    'GITHUB_USER': GITHUB_USER,\n",
        "    'GITHUB_REPO': GITHUB_REPO,\n",
        "    'GITHUB_BRANCH': GITHUB_BRANCH,\n",
        "    'GITHUB_TOKEN': GITHUB_TOKEN,\n",
        "    'repo_url': repo_url,\n",
        "    'BASE_REPO_FOLDER': BASE_REPO_FOLDER,\n",
        "    'DRIVE_REPO_FOLDER': DRIVE_REPO_FOLDER,\n",
        "    'ABYSS_UPLOAD_URL': ABYSS_UPLOAD_URL\n",
        "})\n",
        "\n",
        "\n",
        "# =====================================================================================\n",
        "# 4. Rodap√© / Fim do C√≥digo\n",
        "# =====================================================================================\n",
        "# @log de mudan√ßas\n",
        "# - v4.6.2 (01/07/2025): Refatora√ß√£o completa para o padr√£o de documenta√ß√£o XCam.\n",
        "#   Adi√ß√£o de coment√°rios detalhados e organiza√ß√£o estrutural. Removida a\n",
        "#   defini√ß√£o de TEMP_OUTPUT_FOLDER, que agora √© gerenciada na C√©lula 1.\n",
        "# - v4.6.1: C√≥digo original da c√©lula de clonagem.\n",
        "#\n",
        "# @roadmap futuro\n",
        "# - Mover a vari√°vel GITHUB_TOKEN para o sistema de \"Secrets\" do Google Colab para\n",
        "#   aumentar a seguran√ßa e evitar a exposi√ß√£o do token diretamente no c√≥digo.\n",
        "# - Adicionar um bloco try/except para os comandos `git clone` para capturar\n",
        "#   poss√≠veis erros de autentica√ß√£o ou de rede e interromper a execu√ß√£o de forma\n",
        "#   controlada caso a clonagem falhe.\n",
        "# ====================================================================================="
      ]
    },
    {
      "cell_type": "markdown",
      "id": "M5iL_9BoIoj7",
      "metadata": {
        "id": "M5iL_9BoIoj7"
      },
      "source": [
        "# C√©lula 5: Commit e Push Autom√°ticos (rec.json, posters, etc.)\n",
        "\n",
        "**Objetivo:**  \n",
        "Automatiza o processo de commit e push dos arquivos modificados (ex: rec.json, posters e demais artefatos importantes) para o reposit√≥rio GitHub, garantindo rastreabilidade, atomicidade e integra√ß√£o cont√≠nua (CI/CD) do pipeline XCam.\n",
        "\n",
        "## Principais pontos e melhorias implementadas\n",
        "\n",
        "- **Fun√ß√£o robusta e modular:**  \n",
        "  A fun√ß√£o `git_commit_and_push()` aceita um caminho √∫nico (string) ou uma lista de arquivos, permitindo commit em lote e integra√ß√£o com estrat√©gias de batch commit (threshold).\n",
        "- **Configura√ß√£o automatizada de usu√°rio e e-mail do git:**  \n",
        "  Garante commits v√°lidos para rastreabilidade, auditoria e integra√ß√£o com pipelines autom√°ticos.\n",
        "- **Valida√ß√£o de caminhos e mensagens informativas:**  \n",
        "  Apenas arquivos existentes s√£o adicionados. Mensagens de sucesso, erro ou aviso detalhadas facilitam troubleshooting e manuten√ß√£o.\n",
        "- **Compat√≠vel com commit vazio:**  \n",
        "  Permite o uso do par√¢metro `--allow-empty` para garantir que o pipeline siga mesmo sem altera√ß√µes detectadas, √∫til para sincroniza√ß√£o e CI/CD.\n",
        "- **Push autenticado via token:**  \n",
        "  Utiliza o token pessoal fornecido nas vari√°veis globais para garantir push seguro e sem interven√ß√£o manual.\n",
        "- **Design pronto para integra√ß√£o com logs centralizados:**  \n",
        "  Recomenda-se registrar todas as a√ß√µes relevantes de commit/push utilizando o log √∫nico modular definido na C√©lula 1.\n",
        "\n",
        "---\n",
        "\n",
        "## Par√¢metros e vari√°veis globais utilizados\n",
        "\n",
        "- **`GITHUB_USER`**, **`GITHUB_REPO`**, **`GITHUB_TOKEN`**: Definidos nas c√©lulas anteriores para autentica√ß√£o e configura√ß√£o do reposit√≥rio.\n",
        "- **`repo_dir`**: Caminho absoluto do reposit√≥rio clonado no ambiente Colab.\n",
        "- **`file_paths`**: String ou lista de arquivos a serem commitados e enviados.\n",
        "- **`commit_message`**: Mensagem do commit, customiz√°vel conforme a opera√ß√£o realizada.\n",
        "\n",
        "---\n",
        "\n",
        "## Como funciona a fun√ß√£o principal\n",
        "\n",
        "- **Valida a exist√™ncia do reposit√≥rio local** antes de prosseguir.\n",
        "- **Aceita arquivos √∫nicos ou m√∫ltiplos** para commit (string ou lista).\n",
        "- **Adiciona apenas arquivos existentes** ao staging, com avisos para arquivos n√£o encontrados.\n",
        "- **Realiza commit (mesmo vazio) e push autenticado** para o reposit√≥rio remoto.\n",
        "- **Emite mensagens claras** de sucesso, erro ou aviso ao longo do processo.\n",
        "\n",
        "---\n",
        "\n",
        "## Exemplo de uso t√≠pico\n",
        "\n",
        "```python\n",
        "# Commit e push de um √∫nico arquivo\n",
        "git_commit_and_push(\"data/rec.json\", \"Atualiza rec.json de grava√ß√£o\")\n",
        "\n",
        "# Commit e push em lote (lista de arquivos)\n",
        "git_commit_and_push([\n",
        "    \"data/rec.json\",\n",
        "    \"posters/user1_poster.jpg\",\n",
        "    \"posters/user2_poster.jpg\"\n",
        "], \"Batch commit de m√∫ltiplos arquivos\")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Seguran√ßa, rastreabilidade e manuten√ß√£o\n",
        "\n",
        "- **Rastreabilidade garantida** por mensagens de commit claras e integra√ß√£o recomendada com o log modular (C√©lula 1).\n",
        "- **Atomicidade** em opera√ß√µes batch, evitando inconsist√™ncias de dados no reposit√≥rio.\n",
        "- **Pronto para integra√ß√£o com pipelines CI/CD**, webhooks e controles de auditoria.\n",
        "- **Mensagens e tratamento de erros detalhados** facilitam o diagn√≥stico e a evolu√ß√£o do sistema.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1aQn1G6yI6Gz",
      "metadata": {
        "id": "1aQn1G6yI6Gz"
      },
      "outputs": [],
      "source": [
        "# ================================================================\n",
        "# C√©lula 5: Commit e Push Autom√°ticos (rec.json, posters, etc.)\n",
        "# ================================================================\n",
        "# Objetivo:\n",
        "# - Automatizar o processo de commit e push dos arquivos modificados (rec.json, posters, etc.) para o reposit√≥rio GitHub\n",
        "# - Suportar tanto commit de arquivo √∫nico como em lote, permitindo estrat√©gia de batch commit baseada em thresholds\n",
        "# - Garantir rastreabilidade, atomicidade e integra√ß√£o segura (CI/CD)\n",
        "#\n",
        "# Estrat√©gia aplicada:\n",
        "# - Fun√ß√£o modular e robusta, preparada para integra√ß√£o com logs e auditoria\n",
        "# - Permite commit vazio por seguran√ßa, evitando falhas em pipelines sincronizados\n",
        "# - Mensagens e tratamento de erros detalhados para facilitar troubleshooting\n",
        "# - Utiliza√ß√£o de vari√°veis globais para caminhos, usu√°rio e token definidos nas c√©lulas anteriores\n",
        "# - Design pronto para evolu√ß√£o, reuso e integra√ß√£o com ferramentas externas (ex: webhooks, jobs, etc.)\n",
        "# ================================================================\n",
        "\n",
        "import os\n",
        "import subprocess\n",
        "\n",
        "def git_commit_and_push(file_paths, commit_message=\"Atualiza rec.json\"):\n",
        "    \"\"\"\n",
        "    Realiza git add, commit e push dos arquivos especificados.\n",
        "    - file_paths pode ser uma string (arquivo √∫nico) ou uma lista de arquivos.\n",
        "    - commit_message √© a mensagem de commit utilizada.\n",
        "\n",
        "    Estrat√©gia:\n",
        "    - Ajusta diret√≥rio para o reposit√≥rio local clonado no Colab\n",
        "    - Configura usu√°rio e e-mail do git (necess√°rios para CI/CD)\n",
        "    - Adiciona arquivos ao staging (aceita m√∫ltiplos arquivos)\n",
        "    - Realiza commit (permite commit vazio)\n",
        "    - Realiza push autenticado via token\n",
        "    \"\"\"\n",
        "    # ============================\n",
        "    # VALIDA√á√ÉO E AJUSTE DE ENTRADAS\n",
        "    # ============================\n",
        "    repo_dir = f\"/content/{GITHUB_REPO}\"\n",
        "    if not os.path.exists(repo_dir):\n",
        "        raise FileNotFoundError(f\"Reposit√≥rio '{repo_dir}' n√£o encontrado. Verifique se a c√©lula de clonagem foi executada.\")\n",
        "    os.chdir(repo_dir)\n",
        "\n",
        "    # Aceita string ou lista de arquivos\n",
        "    if isinstance(file_paths, str):\n",
        "        file_paths = [file_paths]\n",
        "    elif not isinstance(file_paths, list):\n",
        "        raise ValueError(\"file_paths deve ser uma string ou uma lista de caminhos.\")\n",
        "\n",
        "    # ============================\n",
        "    # CONFIGURA√á√ÉO DO USU√ÅRIO GIT (CI/CD)\n",
        "    # ============================\n",
        "    subprocess.run([\"git\", \"config\", \"user.email\", \"contato@aserio.work\"], check=True)\n",
        "    subprocess.run([\"git\", \"config\", \"user.name\", \"SamuelPassamani\"], check=True)\n",
        "\n",
        "    # ============================\n",
        "    # ADI√á√ÉO DOS ARQUIVOS AO STAGING\n",
        "    # ============================\n",
        "    for file_path in file_paths:\n",
        "        # Verifica se o arquivo existe antes de adicionar\n",
        "        if not os.path.exists(file_path):\n",
        "            print(f\"‚ö†Ô∏è Aviso: arquivo '{file_path}' n√£o existe e ser√° ignorado no commit.\")\n",
        "            continue\n",
        "        subprocess.run([\"git\", \"add\", file_path], check=True)\n",
        "\n",
        "    # ============================\n",
        "    # COMMIT (PERMITE COMMIT VAZIO)\n",
        "    # ============================\n",
        "    try:\n",
        "        subprocess.run(\n",
        "            [\"git\", \"commit\", \"-m\", commit_message, \"--allow-empty\"],\n",
        "            check=False  # N√£o for√ßa erro se n√£o houver mudan√ßas\n",
        "        )\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Erro ao tentar realizar commit: {e}\")\n",
        "\n",
        "    # ============================\n",
        "    # PUSH PARA O REPOSIT√ìRIO REMOTO (AUTENTICADO)\n",
        "    # ============================\n",
        "    try:\n",
        "        remote_url = f\"https://{GITHUB_USER}:{GITHUB_TOKEN}@github.com/{GITHUB_USER}/{GITHUB_REPO}.git\"\n",
        "        subprocess.run(\n",
        "            [\"git\", \"push\", remote_url],\n",
        "            check=True\n",
        "        )\n",
        "        print(f\"‚úÖ Push realizado com sucesso! ({commit_message})\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Erro ao tentar realizar push: {e}\")\n",
        "\n",
        "# ============================\n",
        "# FIM DA C√âLULA 5\n",
        "# ============================\n",
        "\n",
        "# Dicas e melhores pr√°ticas:\n",
        "# - Use commit_messages claros e informativos para facilitar a auditoria.\n",
        "# - Utilize a fun√ß√£o dentro de loops ou triggers de batch para commit em lote.\n",
        "# - Integre logs das a√ß√µes de commit/push usando o log √∫nico centralizado (C√©lula 1).\n",
        "# - Em caso de erro de autentica√ß√£o, revise o token e as permiss√µes do GitHub."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "BZ4c3Uk1I7AK",
      "metadata": {
        "id": "BZ4c3Uk1I7AK"
      },
      "source": [
        "# C√©lula 6: Busca de Transmiss√µes na API XCam, Blacklist Tempor√°ria, Fallback via liveInfo e Busca Inteligente/Unit√°ria\n",
        "\n",
        "**Objetivo:**  \n",
        "Realizar a busca das transmiss√µes ativas na API principal da XCam, mantendo o lote de transmiss√µes sempre completo at√© o `LIMIT_DEFAULT` e sem duplicidades, utilizando controle de blacklist tempor√°ria e log de transmiss√µes em processamento.  \n",
        "Inclui fun√ß√µes de busca unit√°ria/inteligente (para manter ‚Äúlote cheio‚Äù continuamente) e gerenciamento autom√°tico de poster, com gera√ß√£o via ffmpeg quando necess√°rio.\n",
        "\n",
        "## Estrat√©gia e melhorias implementadas\n",
        "\n",
        "- **Blacklist tempor√°ria e controle de falhas:**  \n",
        "  Usu√°rios problem√°ticos s√£o bloqueados temporariamente ap√≥s atingirem o limite de falhas (`BLACKLIST_MAX_FAILURES`), acelerando o processamento e evitando ciclos infinitos.\n",
        "- **Busca em lote e unit√°ria com fallback:**  \n",
        "  Consulta a API principal com limite alto para preencher o lote rapidamente. Caso necess√°rio, realiza fallback via `/liveInfo` para usu√°rios sem `src`.\n",
        "- **Controle de duplicidade e fila inteligente:**  \n",
        "  Antes de incluir qualquer transmiss√£o, verifica no log de processamento e na blacklist para evitar tentativas repetidas ou paradas em streams problem√°ticos.\n",
        "- **Poster garantido:**  \n",
        "  Se o poster estiver ausente, inv√°lido ou nulo, gera automaticamente uma imagem via ffmpeg a partir do stream, garantindo sempre um arquivo v√°lido.\n",
        "- **Efici√™ncia e paralelismo:**  \n",
        "  Todas as fun√ß√µes s√£o preparadas para processamento paralelo e integra√ß√£o total ao pipeline XCam.\n",
        "- **Compatibilidade:**  \n",
        "  Suporte total √† busca de usu√°rios espec√≠ficos, agora tamb√©m protegida pela blacklist e controle de falhas.\n",
        "- **Design modular:**  \n",
        "  Fun√ß√µes separadas para busca em lote (`get_broadcasts`), busca por usu√°rios (`buscar_usuarios_especificos`) e busca unit√°ria/primeira transmiss√£o livre (`buscar_proxima_transmissao_livre`), facilitando reuso e manuten√ß√£o.\n",
        "\n",
        "---\n",
        "\n",
        "## Como funciona cada fun√ß√£o\n",
        "\n",
        "- **get_broadcasts:**  \n",
        "  Retorna um lote de transmiss√µes v√°lidas, sempre checando blacklist, log de processamento e gerando poster se necess√°rio. Realiza fallback autom√°tico para `/liveInfo` se n√£o encontrar o src na API principal.\n",
        "- **buscar_usuarios_especificos:**  \n",
        "  Busca apenas os usu√°rios informados, respeitando sempre o controle de blacklist/falhas, e faz fallback via `/liveInfo` quando necess√°rio.\n",
        "- **buscar_proxima_transmissao_livre:**  \n",
        "  Busca rapidamente a pr√≥xima transmiss√£o livre para processamento, sempre utilizando os mesmos crit√©rios de controle, garantindo agilidade na fila e efici√™ncia m√°xima.\n",
        "\n",
        "---\n",
        "\n",
        "## Detalhes t√©cnicos e recomenda√ß√µes\n",
        "\n",
        "- **Blacklist tempor√°ria e controle de falhas:**  \n",
        "  Fun√ß√µes `register_failure`, `clear_failure`, `add_to_blacklist`, `is_in_blacklist`, `load_blacklist` e `save_blacklist` garantem rastreabilidade e bloqueio eficiente de usu√°rios problem√°ticos.\n",
        "- **Arquitetura limpa e modular:**  \n",
        "  C√≥digo preparado para integra√ß√£o futura com log √∫nico centralizado e processamento concorrente.\n",
        "- **Poster sempre v√°lido:**  \n",
        "  Fun√ß√µes utilit√°rias garantem que cada transmiss√£o s√≥ √© liberada para grava√ß√£o se houver poster v√°lido (baixado ou gerado).\n",
        "- **Tratamento de erros robusto:**  \n",
        "  Toda etapa cr√≠tica possui tratamento de exce√ß√µes e mensagens claras para facilitar manuten√ß√£o e monitoramento.\n",
        "\n",
        "---\n",
        "\n",
        "## Exemplo de uso das fun√ß√µes\n",
        "\n",
        "```python\n",
        "# Buscar lote completo de transmiss√µes v√°lidas\n",
        "streams = get_broadcasts(limit=LIMIT_DEFAULT)\n",
        "\n",
        "# Buscar apenas usu√°rios espec√≠ficos\n",
        "streams_especificos = buscar_usuarios_especificos([\"user1\", \"user2\"])\n",
        "\n",
        "# Buscar a pr√≥xima transmiss√£o livre dispon√≠vel\n",
        "proxima_stream = buscar_proxima_transmissao_livre()\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Rastreabilidade, manuten√ß√£o e integra√ß√£o\n",
        "\n",
        "- Blacklist e falhas podem ser migrados para o log centralizado para m√°xima rastreabilidade.\n",
        "- Todas as fun√ß√µes s√£o compat√≠veis com execu√ß√£o paralela e integra√ß√£o CI/CD.\n",
        "- Mensagens detalhadas e arquitetura modular facilitam manuten√ß√£o e futuras expans√µes no pipeline do XCam.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "h1jr7D0pJ7jS",
      "metadata": {
        "id": "h1jr7D0pJ7jS"
      },
      "outputs": [],
      "source": [
        "# =====================================================================================\n",
        "# XCam REC - C√©lula 6: Busca Inteligente e Controle de Falhas\n",
        "# =====================================================================================\n",
        "# [@author]      Samuel Passamani / Um Projeto do Estudio A.S√©rio [AllS Company]\n",
        "# [@info]        https://aserio.work/\n",
        "# [@version]     4.6.2\n",
        "# [@lastupdate]  2025-07-01\n",
        "#\n",
        "# [@description]\n",
        "# Esta c√©lula implementa a l√≥gica de aquisi√ß√£o de transmiss√µes. √â respons√°vel por\n",
        "# consultar a API da XCam, filtrar os resultados com base em um sistema robusto de\n",
        "# controle de falhas e blacklist tempor√°ria, e garantir que cada transmiss√£o\n",
        "# selecionada para grava√ß√£o tenha um p√¥ster (thumbnail) v√°lido. Ela cont√©m\n",
        "# fun√ß√µes para buscar em lote, buscar usu√°rios espec√≠ficos e encontrar a pr√≥xima\n",
        "# transmiss√£o livre de forma otimizada para o supervisor din√¢mico.\n",
        "#\n",
        "# [@mode]\n",
        "# As fun√ß√µes desta c√©lula s√£o utilizadas pelo supervisor (C√©lula 9) em todos os modos\n",
        "# de opera√ß√£o, seja na busca autom√°tica por transmiss√µes ou na busca por uma lista\n",
        "# espec√≠fica de usu√°rios fornecida.\n",
        "# =====================================================================================\n",
        "\n",
        "\n",
        "# =====================================================================================\n",
        "# 2. Configura√ß√µes & Vari√°veis Globais (Depend√™ncias)\n",
        "# =====================================================================================\n",
        "\n",
        "# Esta c√©lula depende das seguintes vari√°veis globais definidas na C√©lula 1:\n",
        "# - BLACKLIST_LOG_FILE: Caminho para o arquivo de log da blacklist.\n",
        "# - FAILURE_LOG_FILE: Caminho para o arquivo de log de contagem de falhas.\n",
        "# - PROCESSING_LOG_FILE: Caminho para o arquivo de log de usu√°rios em processamento.\n",
        "# - BLACKLIST_TIMEOUT: Dura√ß√£o em segundos que um usu√°rio fica na blacklist.\n",
        "# - BLACKLIST_MAX_FAILURES: N√∫mero de falhas para um usu√°rio entrar na blacklist.\n",
        "# - As fun√ß√µes utilit√°rias (download_and_save_poster, etc.) da C√©lula 3.\n",
        "\n",
        "\n",
        "# =====================================================================================\n",
        "# 3. Corpo\n",
        "# =====================================================================================\n",
        "\n",
        "# --- Bloco de Gerenciamento da Blacklist Tempor√°ria ---\n",
        "# Este bloco cont√©m fun√ß√µes CRUD para o arquivo de log da blacklist.\n",
        "# NOTA: Em uma vers√£o futura, esta l√≥gica pode ser migrada para o log central.\n",
        "\n",
        "def load_blacklist():\n",
        "    \"\"\"\n",
        "    Carrega a lista de usu√°rios em blacklist do arquivo.\n",
        "    Filtra e remove automaticamente entradas que j√° expiraram com base no BLACKLIST_TIMEOUT.\n",
        "    \"\"\"\n",
        "    # Se o arquivo n√£o existe, retorna um dicion√°rio vazio.\n",
        "    if not os.path.exists(BLACKLIST_LOG_FILE): return {}\n",
        "    # Abre o arquivo para leitura.\n",
        "    with open(BLACKLIST_LOG_FILE, \"r\") as f:\n",
        "        now = time.time() # Obt√©m o timestamp atual para comparar.\n",
        "        # L√™ cada linha, separando usu√°rio e timestamp.\n",
        "        lines = [line.strip().split(\",\") for line in f if line.strip()]\n",
        "        # Retorna um dicion√°rio apenas com os usu√°rios cuja blacklist ainda n√£o expirou.\n",
        "        return {user: float(ts) for user, ts in lines if now - float(ts) < BLACKLIST_TIMEOUT}\n",
        "\n",
        "def save_blacklist(blacklist):\n",
        "    \"\"\"Salva o dicion√°rio da blacklist de volta no arquivo de log.\"\"\"\n",
        "    with open(BLACKLIST_LOG_FILE, \"w\") as f:\n",
        "        for user, ts in blacklist.items():\n",
        "            f.write(f\"{user},{ts}\\\\n\")\n",
        "\n",
        "def add_to_blacklist(username):\n",
        "    \"\"\"Adiciona um usu√°rio √† blacklist com o timestamp atual.\"\"\"\n",
        "    blacklist = load_blacklist() # Carrega a blacklist atual.\n",
        "    blacklist[username] = time.time() # Adiciona/atualiza o usu√°rio com o novo timestamp.\n",
        "    save_blacklist(blacklist) # Salva a blacklist atualizada.\n",
        "    print(f\"‚ö†Ô∏è Usu√°rio '{username}' adicionado √† blacklist tempor√°ria.\")\n",
        "\n",
        "def is_in_blacklist(username):\n",
        "    \"\"\"Verifica de forma r√°pida se um usu√°rio est√° atualmente na blacklist.\"\"\"\n",
        "    return username in load_blacklist()\n",
        "\n",
        "# --- Bloco de Gerenciamento de Falhas de Grava√ß√£o ---\n",
        "# Controla quantas vezes consecutivas a grava√ß√£o de um usu√°rio falhou.\n",
        "\n",
        "def load_failures():\n",
        "    \"\"\"Carrega o dicion√°rio de contagem de falhas (usu√°rio: contagem) do arquivo.\"\"\"\n",
        "    if not os.path.exists(FAILURE_LOG_FILE): return {}\n",
        "    with open(FAILURE_LOG_FILE, \"r\") as f:\n",
        "        return {user: int(count) for user, count in (line.strip().split(\",\") for line in f if line.strip())}\n",
        "\n",
        "def save_failures(failures):\n",
        "    \"\"\"Salva o dicion√°rio de falhas de volta no arquivo de log.\"\"\"\n",
        "    with open(FAILURE_LOG_FILE, \"w\") as f:\n",
        "        for user, count in failures.items():\n",
        "            f.write(f\"{user},{count}\\\\n\")\n",
        "\n",
        "def register_failure(username):\n",
        "    \"\"\"\n",
        "    Registra uma falha para um usu√°rio. Se o limite for atingido,\n",
        "    o usu√°rio √© movido para a blacklist e seu contador de falhas √© zerado.\n",
        "    \"\"\"\n",
        "    failures = load_failures() # Carrega as falhas atuais.\n",
        "    failures[username] = failures.get(username, 0) + 1 # Incrementa o contador.\n",
        "    # Verifica se o limite de falhas foi atingido.\n",
        "    if failures[username] >= BLACKLIST_MAX_FAILURES:\n",
        "        add_to_blacklist(username) # Adiciona √† blacklist.\n",
        "        failures.pop(username, None) # Remove do contador de falhas.\n",
        "    save_failures(failures) # Salva o estado atualizado.\n",
        "\n",
        "def clear_failure(username):\n",
        "    \"\"\"Limpa o contador de falhas para um usu√°rio (usado ap√≥s uma grava√ß√£o bem-sucedida).\"\"\"\n",
        "    failures = load_failures() # Carrega as falhas.\n",
        "    if username in failures: # Se o usu√°rio tiver um registro de falha...\n",
        "        failures.pop(username) # ...remove o registro.\n",
        "        save_failures(failures) # Salva o estado limpo.\n",
        "\n",
        "# --- Fun√ß√µes de Busca na API XCam ---\n",
        "\n",
        "def get_broadcasts(limit=LIMIT_DEFAULT, page=PAGE_DEFAULT, usuarios_especificos=None, temp_folder=DRIVE_POSTERS_TEMP_PATH):\n",
        "    \"\"\"\n",
        "    Fun√ß√£o principal de busca em lote.\n",
        "    Retorna uma lista de transmiss√µes v√°lidas, prontas para grava√ß√£o.\n",
        "    \"\"\"\n",
        "    # Carrega a lista de usu√°rios que j√° est√£o em processo de grava√ß√£o para evitar duplicidade.\n",
        "    transmissao_em_proc = set()\n",
        "    if os.path.exists(PROCESSING_LOG_FILE):\n",
        "        with open(PROCESSING_LOG_FILE, \"r\") as f:\n",
        "            transmissao_em_proc = set([line.strip() for line in f if line.strip()])\n",
        "\n",
        "    # Define a URL da API, ajustando o limite se for uma busca por usu√°rios espec√≠ficos.\n",
        "    api_url_main = f\"https://api.xcam.gay/?limit={API_SEARCH_LIMIT if usuarios_especificos else 1500}&page=1\"\n",
        "    print(f\"üåê Acessando API: {api_url_main}\")\n",
        "\n",
        "    streams_from_main = []      # Lista para streams com URL direta.\n",
        "    streams_without_preview = [] # Lista para streams que precisar√£o de fallback.\n",
        "\n",
        "    try:\n",
        "        # Faz a requisi√ß√£o para a API principal.\n",
        "        response_main = requests.get(api_url_main, timeout=30)\n",
        "        response_main.raise_for_status() # Lan√ßa um erro se a resposta n√£o for 2xx.\n",
        "        items = response_main.json().get(\"broadcasts\", {}).get(\"items\", [])\n",
        "\n",
        "        # Processa cada item retornado pela API.\n",
        "        for item in items:\n",
        "            username = item.get(\"username\")\n",
        "            # Pula se o usu√°rio for inv√°lido, estiver em processamento ou na blacklist.\n",
        "            if not username or username in transmissao_em_proc or is_in_blacklist(username):\n",
        "                continue\n",
        "            # Se for uma busca espec√≠fica, pula usu√°rios que n√£o est√£o na lista.\n",
        "            if usuarios_especificos and username not in usuarios_especificos:\n",
        "                continue\n",
        "\n",
        "            src = item.get(\"preview\", {}).get(\"src\")\n",
        "            # Se o item j√° tem uma URL de stream...\n",
        "            if src:\n",
        "                # ... tenta obter um p√¥ster v√°lido.\n",
        "                poster_url = item.get(\"preview\", {}).get(\"poster\")\n",
        "                poster_path = download_and_save_poster(poster_url, username, temp_folder) or generate_poster_with_ffmpeg(src, username, temp_folder)\n",
        "                if is_poster_valid(poster_path):\n",
        "                    streams_from_main.append({\"username\": username, \"src\": src, \"poster\": poster_path})\n",
        "                    clear_failure(username) # Limpa falhas se obteve dados v√°lidos.\n",
        "                else:\n",
        "                    register_failure(username) # Registra falha se n√£o conseguiu obter o p√¥ster.\n",
        "            else:\n",
        "                # Se n√£o tem URL, adiciona √† lista de fallback.\n",
        "                streams_without_preview.append({\"username\": username})\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Erro ao acessar API principal: {e}\")\n",
        "\n",
        "    # Processo de Fallback para streams sem URL direta.\n",
        "    if streams_without_preview:\n",
        "        print(f\"üîÅ Buscando liveInfo para {len(streams_without_preview)} streams...\")\n",
        "        for stream_info in streams_without_preview:\n",
        "            username = stream_info[\"username\"]\n",
        "            # Novamente, verifica se o usu√°rio deve ser processado.\n",
        "            if username in transmissao_em_proc or is_in_blacklist(username):\n",
        "                continue\n",
        "            \n",
        "            # Tenta a API de liveInfo.\n",
        "            try:\n",
        "                live_info_url = f\"https://api.xcam.gay/user/{username}/liveInfo\"\n",
        "                response_liveinfo = requests.get(live_info_url, timeout=10)\n",
        "                response_liveinfo.raise_for_status()\n",
        "                data_liveinfo = response_liveinfo.json()\n",
        "                m3u8_url = data_liveinfo.get(\"cdnURL\") or data_liveinfo.get(\"edgeURL\")\n",
        "                \n",
        "                if m3u8_url:\n",
        "                    poster_path = generate_poster_with_ffmpeg(m3u8_url, username, temp_folder)\n",
        "                    if is_poster_valid(poster_path):\n",
        "                        streams_from_main.append({\"username\": username, \"src\": m3u8_url, \"poster\": poster_path})\n",
        "                        clear_failure(username)\n",
        "                    else:\n",
        "                        register_failure(username)\n",
        "                else:\n",
        "                    register_failure(username)\n",
        "            except Exception as ex:\n",
        "                print(f\"‚ùå Erro no fallback liveInfo para {username}: {ex}\")\n",
        "                register_failure(username)\n",
        "            time.sleep(0.5) # Pequena pausa para n√£o sobrecarregar a API.\n",
        "\n",
        "    # Combina e filtra a lista final.\n",
        "    final_streams_list = []\n",
        "    seen_usernames = set()\n",
        "    for stream in streams_from_main:\n",
        "        if stream[\"username\"] not in seen_usernames:\n",
        "            final_streams_list.append(stream)\n",
        "            seen_usernames.add(stream[\"username\"])\n",
        "            if len(final_streams_list) >= limit:\n",
        "                break\n",
        "    \n",
        "    print(f\"üîé Selecionadas {len(final_streams_list)} streams v√°lidas para processamento (limite: {limit}).\")\n",
        "    return final_streams_list\n",
        "\n",
        "def buscar_usuarios_especificos(usuarios_lista, temp_folder=DRIVE_POSTERS_TEMP_PATH):\n",
        "    \"\"\"Fun√ß√£o de conveni√™ncia para buscar uma lista espec√≠fica de usu√°rios.\"\"\"\n",
        "    return get_broadcasts(limit=len(usuarios_lista), usuarios_especificos=usuarios_lista, temp_folder=temp_folder)\n",
        "\n",
        "def buscar_proxima_transmissao_livre(temp_folder=DRIVE_POSTERS_TEMP_PATH):\n",
        "    \"\"\"\n",
        "    Busca de forma otimizada apenas a PR√ìXIMA transmiss√£o livre,\n",
        "    ideal para preencher vagas no lote do supervisor.\n",
        "    \"\"\"\n",
        "    # Chama a fun√ß√£o principal com limite 1 para retornar assim que encontrar a primeira v√°lida.\n",
        "    streams = get_broadcasts(limit=1, temp_folder=temp_folder)\n",
        "    if streams:\n",
        "        print(f\"üéØ Pr√≥xima transmiss√£o livre encontrada: {streams[0]['username']}\")\n",
        "        return streams[0]\n",
        "    else:\n",
        "        print(\"üö´ Nenhuma transmiss√£o livre encontrada no momento.\")\n",
        "        return None\n",
        "\n",
        "# =====================================================================================\n",
        "# 4. Rodap√© / Fim do C√≥digo\n",
        "# =====================================================================================\n",
        "# @log de mudan√ßas\n",
        "# - v4.6.2 (01/07/2025): Refatora√ß√£o completa para o padr√£o de documenta√ß√£o XCam.\n",
        "#   Adi√ß√£o de coment√°rios detalhados e organiza√ß√£o estrutural.\n",
        "# - v4.6.1: Atualiza√ß√£o dos caminhos de log para usar as vari√°veis globais da C√©lula 1.\n",
        "# - v4.6.0: Vers√£o inicial com l√≥gica de busca e blacklist.\n",
        "#\n",
        "# @roadmap futuro\n",
        "# - Centralizar 100% a l√≥gica de `blacklist` e `failures` no sistema de log √∫nico da\n",
        "#   C√©lula 1, eliminando os arquivos `xcam_blacklist.log` e `xcam_failures.log`.\n",
        "# - Implementar um cache para as respostas da API para reduzir o n√∫mero de requisi√ß√µes\n",
        "#   em execu√ß√µes muito pr√≥ximas.\n",
        "# ====================================================================================="
      ]
    },
    {
      "cell_type": "markdown",
      "id": "jGFyqOUoKEF7",
      "metadata": {
        "id": "jGFyqOUoKEF7"
      },
      "source": [
        "# C√©lula 7: Grava√ß√£o da Stream, Poster Autom√°tico, Controle de Falhas, Log Seguro e Blacklist Inteligente\n",
        "\n",
        "**Objetivo:**  \n",
        "Automatizar a grava√ß√£o de transmiss√µes ao vivo com ffmpeg, garantindo robustez, rastreabilidade e integra√ß√£o com a l√≥gica de blacklist tempor√°ria e controle de falhas. A c√©lula tamb√©m assegura o gerenciamento seguro do log de transmiss√µes em processamento e a limpeza de arquivos tempor√°rios.\n",
        "\n",
        "## Estrat√©gia e melhorias implementadas\n",
        "\n",
        "- **Gerenciamento seguro de log:**  \n",
        "  O usu√°rio √© registrado no log de transmiss√µes em processamento antes da grava√ß√£o e removido dele ao final (tanto em sucesso quanto em erro), evitando duplicidade e permitindo paralelismo seguro.\n",
        "- **Poster sempre v√°lido:**  \n",
        "  O sistema tenta baixar o poster da API. Se o poster estiver ausente, inv√°lido ou nulo, gera automaticamente uma imagem via ffmpeg, assegurando que toda transmiss√£o tenha um poster associado e v√°lido.\n",
        "- **Controle de tempo m√≠nimo:**  \n",
        "  Se a grava√ß√£o resultar em v√≠deo muito curto, tanto o arquivo de v√≠deo quanto o poster s√£o descartados imediatamente, e uma falha √© registrada para o usu√°rio.\n",
        "- **Tratamento robusto de falhas:**  \n",
        "  Qualquer falha (ffmpeg, exceptions, etc.) √© registrada. Ao atingir o n√∫mero m√°ximo de falhas consecutivas (`BLACKLIST_MAX_FAILURES`), o usu√°rio entra automaticamente na blacklist tempor√°ria, evitando tentativas infinitas e desperd√≠cio de recursos.\n",
        "- **Limpeza automatizada:**  \n",
        "  Ap√≥s upload ou erro, todos os arquivos tempor√°rios (v√≠deo e poster) s√£o removidos, otimizando o uso do disco e mantendo o ambiente do Colab limpo.\n",
        "- **Reset de falhas em caso de sucesso:**  \n",
        "  Quando a grava√ß√£o √© v√°lida, o contador de falhas do usu√°rio √© limpo, evitando blacklist indevida.\n",
        "- **Coment√°rios detalhados e c√≥digo modular:**  \n",
        "  O fluxo √© completamente documentado, facilitando manuten√ß√£o, revis√£o e entendimento por toda a equipe.\n",
        "\n",
        "---\n",
        "\n",
        "## Fluxo resumido da fun√ß√£o principal\n",
        "\n",
        "1. **Registra o usu√°rio** no log de transmiss√µes em processamento.\n",
        "2. **Garante um poster v√°lido** (download ou gera√ß√£o autom√°tica).\n",
        "3. **Executa o ffmpeg** para gravar a transmiss√£o e monitora o progresso em tempo real.\n",
        "4. **Valida a grava√ß√£o**:\n",
        "   - Se falhar, registra falha e trata blacklist.\n",
        "   - Se for curta demais, descarta e registra falha.\n",
        "   - Se for v√°lida, limpa contador de falhas e prossegue normalmente.\n",
        "5. **Ap√≥s upload ou erro**, remove o usu√°rio do log e limpa arquivos tempor√°rios.\n",
        "\n",
        "---\n",
        "\n",
        "## Exemplo de uso\n",
        "\n",
        "```python\n",
        "resultado = gravar_stream(username=\"user123\", m3u8_url=\"https://cdn.xcam.gay/m3u8/...\", poster_url=\"https://api.xcam.gay/poster/...\")\n",
        "if resultado['upload_success']:\n",
        "    print(\"Grava√ß√£o e upload realizados com sucesso!\")\n",
        "else:\n",
        "    print(\"Falha na grava√ß√£o ou upload:\", resultado['abyss_response'])\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Seguran√ßa, rastreabilidade e integra√ß√£o\n",
        "\n",
        "- **Pronto para CI/CD e execu√ß√£o paralela:**  \n",
        "  Controle rigoroso de log e blacklist garante execu√ß√£o concorrente, segura e rastre√°vel por todo o pipeline XCam.\n",
        "- **Integra√ß√£o total com as fun√ß√µes globais:**  \n",
        "  Utiliza fun√ß√µes de blacklist e falha da C√©lula 6, promovendo rastreabilidade e controle centralizado.\n",
        "- **Diagn√≥stico facilitado:**  \n",
        "  Mensagens e logs detalhados em cada etapa do processo.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eJ_jrfNgKZNr",
      "metadata": {
        "id": "eJ_jrfNgKZNr"
      },
      "outputs": [],
      "source": [
        "# =====================================================================================\n",
        "# XCam REC - C√©lula 7: Worker de Grava√ß√£o (ffmpeg)\n",
        "# =====================================================================================\n",
        "# [@author]      Samuel Passamani / Um Projeto do Estudio A.S√©rio [AllS Company]\n",
        "# [@info]        https://aserio.work/\n",
        "# [@version]     4.6.2\n",
        "# [@lastupdate]  2025-07-01\n",
        "#\n",
        "# [@description]\n",
        "# Esta c√©lula cont√©m a l√≥gica principal do worker de grava√ß√£o. Cada processo paralelo\n",
        "# executar√° a fun√ß√£o `gravar_stream` para realizar as seguintes tarefas:\n",
        "#   1. Registrar-se como \"em processamento\" para evitar grava√ß√µes duplicadas.\n",
        "#   2. Garantir a exist√™ncia de um p√¥ster (thumbnail) v√°lido, baixando ou gerando via ffmpeg.\n",
        "#   3. Executar o comando `ffmpeg` para gravar o stream de v√≠deo.\n",
        "#   4. Monitorar o progresso da grava√ß√£o em tempo real.\n",
        "#   5. Validar o arquivo de v√≠deo final, checando sua dura√ß√£o m√≠nima.\n",
        "#   6. Interagir com o sistema de controle de falhas e blacklist (C√©lula 6).\n",
        "#   7. Passar os artefatos para a pr√≥xima etapa (upload e p√≥s-processamento, C√©lula 8).\n",
        "#   8. Garantir a limpeza de todos os arquivos tempor√°rios, independentemente do resultado.\n",
        "#\n",
        "# [@mode]\n",
        "# As fun√ß√µes desta c√©lula s√£o o \"trabalho pesado\" do notebook e s√£o executadas\n",
        "# pelos processos paralelos gerenciados pelo supervisor (C√©lula 9).\n",
        "# =====================================================================================\n",
        "\n",
        "\n",
        "# =====================================================================================\n",
        "# 2. Configura√ß√µes & Vari√°veis Globais (Depend√™ncias)\n",
        "# =====================================================================================\n",
        "\n",
        "# Esta c√©lula depende das seguintes vari√°veis e fun√ß√µes globais:\n",
        "# - Definidas na C√©lula 1:\n",
        "#   - PROCESSING_LOG_FILE: Caminho para o log de usu√°rios em processamento.\n",
        "#   - DRIVE_RECORDS_TEMP_PATH: Pasta para salvar os v√≠deos tempor√°rios.\n",
        "#   - DRIVE_POSTERS_TEMP_PATH: Pasta para salvar os p√¥steres tempor√°rios.\n",
        "#   - RECORD_SECONDS: Dura√ß√£o m√°xima da grava√ß√£o.\n",
        "#   - RECORD_SECONDS_MIN: Dura√ß√£o m√≠nima para um v√≠deo ser considerado v√°lido.\n",
        "# - Definidas na C√©lula 3:\n",
        "#   - download_and_save_poster(), generate_poster_with_ffmpeg(), is_poster_valid()\n",
        "#   - format_seconds(), log_progress()\n",
        "# - Definidas na C√©lula 6:\n",
        "#   - register_failure(), clear_failure()\n",
        "# - Definidas na C√©lula 8:\n",
        "#   - upload_to_abyss_and_update_json()\n",
        "\n",
        "\n",
        "# =====================================================================================\n",
        "# 3. Corpo\n",
        "# =====================================================================================\n",
        "\n",
        "def get_video_duration(filepath):\n",
        "    \"\"\"\n",
        "    Retorna a dura√ß√£o real de um arquivo de v√≠deo em segundos, utilizando o ffprobe.\n",
        "    √â o m√©todo mais confi√°vel para validar a grava√ß√£o.\n",
        "    Retorna None em caso de erro ou se o arquivo n√£o for encontrado.\n",
        "    \"\"\"\n",
        "    # Verifica se o arquivo de fato existe antes de tentar analis√°-lo.\n",
        "    if not os.path.exists(filepath):\n",
        "        print(f\"‚ö†Ô∏è Arquivo para ffprobe n√£o encontrado: {filepath}\")\n",
        "        return None\n",
        "    try:\n",
        "        # Comando ffprobe para extrair a dura√ß√£o do formato em formato JSON.\n",
        "        cmd = [\"ffprobe\", \"-v\", \"error\", \"-show_entries\", \"format=duration\", \"-of\", \"json\", filepath]\n",
        "        # Executa o comando com um timeout para evitar travamentos.\n",
        "        result = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True, timeout=60)\n",
        "        # Converte a sa√≠da JSON para um dicion√°rio Python.\n",
        "        info = json.loads(result.stdout)\n",
        "        # Retorna a dura√ß√£o como um n√∫mero inteiro.\n",
        "        return int(round(float(info[\"format\"][\"duration\"])))\n",
        "    except Exception as e:\n",
        "        # Em caso de erro (arquivo corrompido, etc.), loga e retorna None.\n",
        "        print(f\"‚ö†Ô∏è Erro no ffprobe para {filepath}: {e}\")\n",
        "        return None\n",
        "\n",
        "def gravar_stream(username, m3u8_url, poster_url=None, poster_frame_time=7):\n",
        "    \"\"\"\n",
        "    Fun√ß√£o principal do worker: orquestra a grava√ß√£o de um √∫nico stream.\n",
        "    \"\"\"\n",
        "    # --- Etapa 1: Registro de Processamento ---\n",
        "    # Adiciona o usu√°rio ao log de processamento para evitar que outro worker o pegue.\n",
        "    with open(PROCESSING_LOG_FILE, \"a\") as f:\n",
        "        f.write(f\"{username}\\\\n\")\n",
        "\n",
        "    # Define nomes de arquivos e caminhos tempor√°rios usando as vari√°veis globais.\n",
        "    start_time_dt = datetime.now()\n",
        "    temp_filename = f\"{username}_{start_time_dt.strftime('%Y%m%d_%H%M%S')}_temp.mp4\"\n",
        "    filepath = os.path.join(DRIVE_RECORDS_TEMP_PATH, temp_filename)\n",
        "    print(f\"\\\\nüé¨ Iniciando grava√ß√£o de: {username} em {filepath}\")\n",
        "\n",
        "    # --- Etapa 2: Garantia de P√¥ster V√°lido ---\n",
        "    poster_temp_path = None\n",
        "    # Tenta primeiro baixar o p√¥ster da URL fornecida.\n",
        "    if poster_url:\n",
        "        poster_temp_path = download_and_save_poster(poster_url, username, DRIVE_POSTERS_TEMP_PATH)\n",
        "    # Se o download falhar ou n√£o houver URL, tenta gerar via ffmpeg como fallback.\n",
        "    if not is_poster_valid(poster_temp_path) and m3u8_url:\n",
        "        poster_temp_path = generate_poster_with_ffmpeg(m3u8_url, username, DRIVE_POSTERS_TEMP_PATH, frame_time=poster_frame_time)\n",
        "\n",
        "    # --- Etapa 3: Execu√ß√£o do FFmpeg ---\n",
        "    # Constr√≥i o comando ffmpeg para a grava√ß√£o.\n",
        "    # -c copy: copia o stream diretamente sem re-encodar, o que √© muito mais r√°pido e leve.\n",
        "    ffmpeg_cmd = [\"ffmpeg\", \"-i\", m3u8_url, \"-t\", str(RECORD_SECONDS), \"-c\", \"copy\", \"-y\", filepath]\n",
        "    \n",
        "    # O bloco try/finally garante que a limpeza ocorrer√° mesmo se a grava√ß√£o falhar.\n",
        "    try:\n",
        "        # Inicia o processo ffmpeg.\n",
        "        process = subprocess.Popen(\n",
        "            ffmpeg_cmd,\n",
        "            stdout=subprocess.PIPE,\n",
        "            stderr=subprocess.STDOUT,\n",
        "            text=True,\n",
        "            bufsize=1,\n",
        "            universal_newlines=True\n",
        "        )\n",
        "\n",
        "        # Monitora a sa√≠da do ffmpeg em tempo real para exibir o progresso.\n",
        "        last_log_time = time.time()\n",
        "        for line in iter(process.stdout.readline, ''):\n",
        "            if \"time=\" in line:\n",
        "                # Loga o progresso a cada minuto para n√£o poluir o console.\n",
        "                if time.time() - last_log_time > 60:\n",
        "                    try:\n",
        "                        match = re.search(r\"time=(\\\\d+):(\\\\d+):(\\\\d+)\", line)\n",
        "                        if match:\n",
        "                            h, m, s = map(int, match.groups())\n",
        "                            elapsed_seconds = h * 3600 + m * 60 + s\n",
        "                            log_progress(username, elapsed_seconds, RECORD_SECONDS)\n",
        "                            last_log_time = time.time()\n",
        "                    except Exception:\n",
        "                        pass # Ignora erros de parsing de progresso.\n",
        "        \n",
        "        # Espera o processo ffmpeg terminar.\n",
        "        process.wait()\n",
        "\n",
        "        # --- Etapa 4: Valida√ß√£o P√≥s-Grava√ß√£o ---\n",
        "        # Verifica se o ffmpeg terminou com erro.\n",
        "        if process.returncode != 0:\n",
        "            raise Exception(f\"FFmpeg falhou com c√≥digo {process.returncode}\")\n",
        "\n",
        "        # Valida a dura√ß√£o real do arquivo gerado.\n",
        "        elapsed_seconds_real = get_video_duration(filepath)\n",
        "        if elapsed_seconds_real is None or elapsed_seconds_real < RECORD_SECONDS_MIN:\n",
        "            raise ValueError(f\"Grava√ß√£o muito curta ({elapsed_seconds_real}s)\")\n",
        "\n",
        "        # --- Etapa 5: Sucesso ---\n",
        "        # Se a grava√ß√£o foi bem-sucedida, limpa o contador de falhas do usu√°rio.\n",
        "        clear_failure(username)\n",
        "        # Formata o nome final do arquivo com data, hora e dura√ß√£o.\n",
        "        data_str = start_time_dt.strftime(\"%d-%m-%Y\")\n",
        "        horario_str = start_time_dt.strftime(\"%H-%M\")\n",
        "        tempo_formatado = format_seconds(elapsed_seconds_real)\n",
        "        final_filename = f\"{username}_{data_str}_{horario_str}_{tempo_formatado}.mp4\"\n",
        "        final_filepath = os.path.join(DRIVE_RECORDS_TEMP_PATH, final_filename)\n",
        "        # Renomeia o arquivo tempor√°rio para o nome final.\n",
        "        os.rename(filepath, final_filepath)\n",
        "        filepath = final_filepath # Atualiza o ponteiro para o novo nome.\n",
        "\n",
        "        # Passa os artefatos para a pr√≥xima c√©lula (upload e p√≥s-processamento).\n",
        "        success, abyss_resp, slug = upload_to_abyss_and_update_json(\n",
        "            final_filepath, username, elapsed_seconds_real, poster_temp_path=poster_temp_path\n",
        "        )\n",
        "        # Retorna um dicion√°rio com o resultado completo da opera√ß√£o.\n",
        "        return {'upload_success': success, 'abyss_response': abyss_resp, 'slug': slug, 'username': username, 'filename': final_filename}\n",
        "\n",
        "    except Exception as e:\n",
        "        # --- Etapa 6: Tratamento de Falha ---\n",
        "        # Se qualquer erro ocorrer, registra uma falha para o usu√°rio.\n",
        "        print(f\"‚ùå Erro na grava√ß√£o de {username}: {e}\")\n",
        "        register_failure(username)\n",
        "        # Retorna um dicion√°rio indicando a falha.\n",
        "        return {'upload_success': False, 'abyss_response': str(e), 'username': username, 'filename': temp_filename}\n",
        "\n",
        "    finally:\n",
        "        # --- Etapa 7: Limpeza Robusta ---\n",
        "        # Este bloco √© executado sempre, garantindo a limpeza do ambiente.\n",
        "        \n",
        "        # Remove o usu√°rio do log de processamento.\n",
        "        if os.path.exists(PROCESSING_LOG_FILE):\n",
        "            with open(PROCESSING_LOG_FILE, \"r\") as f: lines = f.readlines()\n",
        "            with open(PROCESSING_LOG_FILE, \"w\") as f:\n",
        "                for line in lines:\n",
        "                    if line.strip() != username: f.write(line)\n",
        "        \n",
        "        # Remove o arquivo de v√≠deo tempor√°rio, se ainda existir.\n",
        "        if os.path.exists(filepath):\n",
        "            try:\n",
        "                os.remove(filepath)\n",
        "                print(f\"üóëÔ∏è V√≠deo tempor√°rio removido: {filepath}\")\n",
        "            except OSError as e:\n",
        "                print(f\"‚ö†Ô∏è Falha ao remover v√≠deo tempor√°rio: {e}\")\n",
        "\n",
        "        # Remove o arquivo de p√¥ster tempor√°rio, se ainda existir.\n",
        "        if poster_temp_path and os.path.exists(poster_temp_path):\n",
        "            try:\n",
        "                os.remove(poster_temp_path)\n",
        "                print(f\"üóëÔ∏è Poster tempor√°rio removido: {poster_temp_path}\")\n",
        "            except OSError as e:\n",
        "                print(f\"‚ö†Ô∏è Falha ao remover poster tempor√°rio: {e}\")\n",
        "\n",
        "\n",
        "# =====================================================================================\n",
        "# 4. Rodap√© / Fim do C√≥digo\n",
        "# =====================================================================================\n",
        "# @log de mudan√ßas\n",
        "# - v4.6.2 (01/07/2025): Refatora√ß√£o completa para o padr√£o de documenta√ß√£o XCam,\n",
        "#   com coment√°rios detalhados em cada etapa da fun√ß√£o de grava√ß√£o.\n",
        "# - v4.6.1: Atualiza√ß√£o dos caminhos de arquivo para usar as vari√°veis globais\n",
        "#   do Google Drive definidas na C√©lula 1.\n",
        "# - v4.6.0: Vers√£o inicial da fun√ß√£o de grava√ß√£o.\n",
        "#\n",
        "# @roadmap futuro\n",
        "# - Implementar um parsing mais avan√ßado da sa√≠da do ffmpeg para extrair mais\n",
        "#   metadados, como bitrate e resolu√ß√£o, e salv√°-los no `rec.json`.\n",
        "# - Adicionar uma verifica√ß√£o de espa√ßo em disco no Google Drive antes de iniciar\n",
        "#   uma nova grava√ß√£o para evitar falhas por falta de armazenamento.\n",
        "# ====================================================================================="
      ]
    },
    {
      "cell_type": "markdown",
      "id": "YjGKDlbIKaLs",
      "metadata": {
        "id": "YjGKDlbIKaLs"
      },
      "source": [
        "# C√©lula 8: Upload para Abyss.to, Atualiza√ß√£o do rec.json, Commit Poster e Sincroniza√ß√£o com Google Drive\n",
        "\n",
        "**Objetivo:**  \n",
        "Realizar upload do v√≠deo gravado para Abyss.to, registrar e atualizar todos os metadados relevantes no arquivo `rec.json` do usu√°rio, garantir a movimenta√ß√£o/renomea√ß√£o adequada do poster e executar o commit/push automatizado de arquivos alterados, sincronizando tamb√©m com o Google Drive.  \n",
        "O processo √© otimizado para processamento em lote: os arquivos modificados s√≥ s√£o enviados quando o n√∫mero atingir o limiar (`COMMIT_PUSH_THRESHOLD`), promovendo efici√™ncia e integridade do reposit√≥rio, mesmo em execu√ß√£o paralela.\n",
        "\n",
        "---\n",
        "\n",
        "## Estrat√©gia e melhorias implementadas\n",
        "\n",
        "- **Commit/push em lote otimizado:**  \n",
        "  Arquivos alterados s√£o acumulados em um buffer. O commit e push s√£o executados automaticamente apenas quando a quantidade de arquivos atinge o threshold configurado, reduzindo conflitos e otimizando o workflow CI/CD.\n",
        "- **Sincroniza√ß√£o autom√°tica com o Google Drive:**  \n",
        "  Sempre que `rec.json` ou poster s√£o atualizados, uma c√≥pia √© feita para o diret√≥rio correspondente do usu√°rio no Google Drive (se dispon√≠vel), garantindo redund√¢ncia, persist√™ncia e facil acesso externo aos metadados e imagens.\n",
        "- **Atomicidade e seguran√ßa em concorr√™ncia:**  \n",
        "  O acesso ao buffer de commit √© protegido por lock (`threading.Lock`), assegurando integridade mesmo em processamento paralelo ou m√∫ltiplos workers.\n",
        "- **Poster sempre correto e rastre√°vel:**  \n",
        "  O poster utilizado √© sempre movido/renomeado para o local definitivo e associado ao v√≠deo pelo nome (`slug`). O caminho √© sincronizado tanto no reposit√≥rio quanto no Drive.\n",
        "- **Atualiza√ß√£o robusta do rec.json:**  \n",
        "  O hist√≥rico do usu√°rio √© preenchido com todos os campos, incluindo poster, urlIframe, data, hor√°rio e tempo formatado. O padr√£o da estrutura JSON √© rigorosamente seguido, facilitando a integra√ß√£o, an√°lise e exporta√ß√£o dos dados.\n",
        "- **Limpeza autom√°tica de arquivos tempor√°rios:**  \n",
        "  Ap√≥s mover, copiar e commitar os arquivos, os tempor√°rios s√£o removidos, mantendo o ambiente Colab limpo e eficiente.\n",
        "\n",
        "---\n",
        "\n",
        "## Como funciona o fluxo principal\n",
        "\n",
        "1. **Faz upload do v√≠deo para Abyss.to** e recebe a confirma√ß√£o (slug, url, urlIframe).\n",
        "2. **Move/renomeia o poster** para o local definitivo no reposit√≥rio, associando ao v√≠deo pelo slug.\n",
        "3. **Atualiza ou cria `rec.json`** do usu√°rio, preenchendo todos os metadados da grava√ß√£o.\n",
        "4. **Adiciona arquivos alterados ao buffer de commit** (com lock para evitar concorr√™ncia).\n",
        "5. **Sincroniza** `rec.json` e poster no Google Drive, mantendo redund√¢ncia e facilidade de acesso.\n",
        "6. **Executa commit/push autom√°tico em lote** ao atingir o limiar definido; ao final do processamento faz o commit/push dos arquivos restantes.\n",
        "7. **Limpa arquivos tempor√°rios** garantindo efici√™ncia e organiza√ß√£o do ambiente.\n",
        "\n",
        "---\n",
        "\n",
        "## Exemplo de uso recomendado\n",
        "\n",
        "```python\n",
        "# Ap√≥s concluir o upload e gerar poster:\n",
        "upload_success, abyss_response, slug = upload_to_abyss_and_update_json(\n",
        "    filepath=arquivo_video,\n",
        "    username=\"usuario\",\n",
        "    duration_seconds=duracao,\n",
        "    poster_temp_path=caminho_poster_temp\n",
        ")\n",
        "\n",
        "# Ao final do processamento, para garantir commit dos arquivos restantes:\n",
        "commit_push_restantes()\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Seguran√ßa, rastreabilidade e integra√ß√£o\n",
        "\n",
        "- **Processo compat√≠vel com execu√ß√£o concorrente** e pipelines CI/CD.\n",
        "- **Commit/push protegido contra condi√ß√µes de corrida**, garantindo atomicidade dos dados no reposit√≥rio.\n",
        "- **Sincroniza√ß√£o Drive robusta**, ideal para ambientes colaborativos ou para garantir backup.\n",
        "- **Mensagens e logs claros** facilitam manuten√ß√£o, auditoria e diagn√≥stico r√°pido em todo o pipeline XCam.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "vMTiCrJ5Kp81",
      "metadata": {
        "id": "vMTiCrJ5Kp81"
      },
      "outputs": [],
      "source": [
        "# =====================================================================================\n",
        "# XCam REC - C√©lula 8: P√≥s-processamento, Upload e Sincroniza√ß√£o\n",
        "# =====================================================================================\n",
        "# [@author]      Samuel Passamani / Um Projeto do Estudio A.S√©rio [AllS Company]\n",
        "# [@info]        https://aserio.work/\n",
        "# [@version]     4.6.2\n",
        "# [@lastupdate]  2025-07-01\n",
        "#\n",
        "# [@description]\n",
        "# Esta c√©lula executa o p√≥s-processamento de uma grava√ß√£o bem-sucedida. Suas\n",
        "# responsabilidades s√£o:\n",
        "#   1. Fazer o upload do v√≠deo para o servi√ßo de armazenamento externo (Abyss.to).\n",
        "#   2. Atualizar o arquivo de metadados do usu√°rio (`rec.json`) com as informa√ß√µes da nova grava√ß√£o.\n",
        "#   3. Gerenciar o p√¥ster final, renomeando-o com o slug do v√≠deo e movendo-o para a pasta correta.\n",
        "#   4. Sincronizar os metadados e o p√¥ster com o Google Drive para persist√™ncia.\n",
        "#   5. Adicionar os arquivos modificados a um buffer de commit para serem enviados em lote ao GitHub.\n",
        "#   6. Limpar os arquivos tempor√°rios remanescentes.\n",
        "#\n",
        "# [@mode]\n",
        "# Esta c√©lula √© chamada no final do ciclo de vida de cada worker de grava√ß√£o bem-sucedido.\n",
        "# A l√≥gica de commit em lote √© projetada para funcionar de forma segura em ambientes\n",
        "# de processamento paralelo.\n",
        "# =====================================================================================\n",
        "\n",
        "\n",
        "# =====================================================================================\n",
        "# 2. Configura√ß√µes & Vari√°veis Globais (Depend√™ncias)\n",
        "# =====================================================================================\n",
        "\n",
        "# Esta c√©lula depende das seguintes vari√°veis globais definidas nas c√©lulas anteriores:\n",
        "# - ABYSS_UPLOAD_URL: URL do servi√ßo de upload.\n",
        "# - BASE_REPO_FOLDER: Caminho do reposit√≥rio clonado no ambiente Colab.\n",
        "# - DRIVE_ARCHIVE_BASE_PATH: Caminho base no Google Drive para arquivamento final.\n",
        "# - COMMIT_PUSH_THRESHOLD: Limiar para o commit em lote.\n",
        "# - As fun√ß√µes utilit√°rias (format_seconds) e de commit (git_commit_and_push).\n",
        "\n",
        "# --- Controle de Concorr√™ncia ---\n",
        "# Cria um \"lock\" (trava) para garantir que o buffer de commit seja modificado por\n",
        "# apenas um processo de cada vez. Isso √© essencial para evitar condi√ß√µes de corrida\n",
        "# (race conditions) quando v√°rios workers paralelos terminam ao mesmo tempo.\n",
        "commit_lock = threading.Lock()\n",
        "\n",
        "\n",
        "# =====================================================================================\n",
        "# 3. Corpo\n",
        "# =====================================================================================\n",
        "\n",
        "def upload_to_abyss_and_update_json(\n",
        "    filepath, username, duration_seconds, poster_temp_path=None\n",
        "):\n",
        "    \"\"\"\n",
        "    Orquestra o upload, atualiza√ß√£o de metadados, gerenciamento de p√¥ster e\n",
        "    o ac√∫mulo de arquivos para o commit em lote.\n",
        "    \"\"\"\n",
        "    # Extrai o nome do arquivo e define o tipo de m√≠dia.\n",
        "    file_name = os.path.basename(filepath)\n",
        "    file_type = 'video/mp4'\n",
        "    print(f\"‚¨ÜÔ∏è Upload de: {file_name} para Abyss.to...\")\n",
        "\n",
        "    # Inicializa vari√°veis de controle do resultado do upload.\n",
        "    upload_success = False\n",
        "    abyss_response = \"Upload falhou - Sem resposta\"\n",
        "    uploaded_url = None\n",
        "    slug = None\n",
        "\n",
        "    # --- Etapa 1: Upload do V√≠deo para o Servi√ßo Externo ---\n",
        "    try:\n",
        "        # Abre o arquivo de v√≠deo em modo de leitura bin√°ria ('rb').\n",
        "        with open(filepath, 'rb') as f:\n",
        "            # Prepara o payload para a requisi√ß√£o POST multipart/form-data.\n",
        "            files = { 'file': (file_name, f, file_type) }\n",
        "            # Envia a requisi√ß√£o para a URL de upload.\n",
        "            response = requests.post(ABYSS_UPLOAD_URL, files=files, timeout=300) # Timeout de 5 min.\n",
        "            response.raise_for_status() # Lan√ßa erro para status HTTP 4xx/5xx.\n",
        "            resp_json = response.json()\n",
        "            abyss_response = resp_json\n",
        "            \n",
        "            # Verifica se o upload foi bem-sucedido com base na resposta da API.\n",
        "            if resp_json.get('status'):\n",
        "                upload_success = True\n",
        "                uploaded_url = resp_json.get('url') or resp_json.get('urlIframe')\n",
        "                slug = resp_json.get('slug') or resp_json.get('video')\n",
        "                print(f\"üì§ Upload bem-sucedido. URL: {uploaded_url} | SLUG: {slug}\")\n",
        "            else:\n",
        "                print(f\"‚ùå Falha no upload. Mensagem: {resp_json.get('message', 'Sem mensagem de erro')}\")\n",
        "    except Exception as e:\n",
        "        abyss_response = f\"Erro no upload: {e}\"\n",
        "        print(f\"‚ùå Erro cr√≠tico no upload: {e}\")\n",
        "\n",
        "    # --- Etapa 2: Gerenciamento do P√¥ster Final ---\n",
        "    poster_final_relpath = None\n",
        "    # Este bloco s√≥ √© executado se o upload do v√≠deo tiver sido um sucesso.\n",
        "    if upload_success and is_poster_valid(poster_temp_path) and slug:\n",
        "        try:\n",
        "            # Define o caminho final do p√¥ster dentro do reposit√≥rio clonado.\n",
        "            user_folder = os.path.join(BASE_REPO_FOLDER, \"xcam-db\", \"user\", username)\n",
        "            os.makedirs(user_folder, exist_ok=True)\n",
        "            # O nome final do p√¥ster ser√° o slug do v√≠deo, para f√°cil associa√ß√£o.\n",
        "            poster_final_name = f\"{slug}.jpg\"\n",
        "            poster_final_path = os.path.join(user_folder, poster_final_name)\n",
        "            \n",
        "            # Move o p√¥ster tempor√°rio para sua localiza√ß√£o final.\n",
        "            shutil.move(poster_temp_path, poster_final_path)\n",
        "            # Obt√©m o caminho relativo para adicionar ao Git.\n",
        "            poster_final_relpath = os.path.relpath(poster_final_path, BASE_REPO_FOLDER)\n",
        "            print(f\"üñºÔ∏è P√¥ster movido para: {poster_final_path}\")\n",
        "\n",
        "            # Copia o p√¥ster para o Google Drive para persist√™ncia.\n",
        "            drive_user_dir = os.path.join(DRIVE_ARCHIVE_BASE_PATH, username)\n",
        "            os.makedirs(drive_user_dir, exist_ok=True)\n",
        "            poster_drive_path = os.path.join(drive_user_dir, poster_final_name)\n",
        "            shutil.copy2(poster_final_path, poster_drive_path)\n",
        "            print(f\"üóÇÔ∏è P√¥ster tamb√©m salvo no Drive: {poster_drive_path}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Erro ao mover/renomear p√¥ster: {e}\")\n",
        "            poster_final_relpath = None # Zera em caso de erro.\n",
        "            \n",
        "    # --- Etapa 3: Atualiza√ß√£o do rec.json ---\n",
        "    if upload_success:\n",
        "        try:\n",
        "            # Define o caminho do arquivo rec.json para o usu√°rio.\n",
        "            user_folder = os.path.join(BASE_REPO_FOLDER, \"xcam-db\", \"user\", username)\n",
        "            os.makedirs(user_folder, exist_ok=True)\n",
        "            json_filepath = os.path.join(user_folder, \"rec.json\")\n",
        "\n",
        "            # Constr√≥i a nova entrada de v√≠deo para o JSON.\n",
        "            new_video_entry = {\n",
        "                \"video\": slug,\n",
        "                \"title\": os.path.basename(filepath).replace('.mp4', ''),\n",
        "                \"file\": file_name,\n",
        "                \"url\": uploaded_url,\n",
        "                \"poster\": f\"https://cdn.xcam.gay/0:/user/{username}/{slug}.jpg\" if slug else \"\",\n",
        "                \"urlIframe\": f\"https://short.icu/{slug}?thumbnail={poster_url}\" if slug else \"\",\n",
        "                \"data\": datetime.now().strftime(\"%d-%m-%Y\"),\n",
        "                \"horario\": datetime.now().strftime(\"%H-%M\"),\n",
        "                \"tempo\": format_seconds(duration_seconds)\n",
        "            }\n",
        "\n",
        "            # Carrega o rec.json existente ou cria um novo se n√£o existir.\n",
        "            # Esta l√≥gica robusta previne a corrup√ß√£o do arquivo.\n",
        "            rec_data = {\"username\": username, \"records\": 0, \"videos\": []}\n",
        "            if os.path.exists(json_filepath):\n",
        "                try:\n",
        "                    with open(json_filepath, 'r', encoding='utf-8') as f:\n",
        "                        rec_data = json.load(f)\n",
        "                        if not isinstance(rec_data.get(\"videos\"), list): # Valida√ß√£o\n",
        "                           rec_data[\"videos\"] = []\n",
        "                except json.JSONDecodeError:\n",
        "                    print(f\"‚ö†Ô∏è rec.json de {username} estava corrompido e ser√° recriado.\")\n",
        "            \n",
        "            # Adiciona o novo v√≠deo e atualiza o contador.\n",
        "            rec_data[\"videos\"].append(new_video_entry)\n",
        "            rec_data[\"records\"] = len(rec_data[\"videos\"])\n",
        "            \n",
        "            # Salva o arquivo JSON atualizado.\n",
        "            with open(json_filepath, 'w', encoding='utf-8') as f:\n",
        "                json.dump(rec_data, f, indent=2, ensure_ascii=False)\n",
        "            print(f\"‚úÖ rec.json para {username} atualizado.\")\n",
        "\n",
        "            # Copia o rec.json atualizado para o Google Drive.\n",
        "            drive_user_dir = os.path.join(DRIVE_ARCHIVE_BASE_PATH, username)\n",
        "            os.makedirs(drive_user_dir, exist_ok=True)\n",
        "            shutil.copy2(json_filepath, os.path.join(drive_user_dir, \"rec.json\"))\n",
        "            print(f\"üóÇÔ∏è rec.json tamb√©m salvo no Drive.\")\n",
        "\n",
        "            # --- Etapa 4: Adiciona Arquivos ao Buffer de Commit ---\n",
        "            # O bloco `with commit_lock:` garante que esta se√ß√£o seja at√¥mica.\n",
        "            with commit_lock:\n",
        "                # Inicializa o buffer de commit se for a primeira vez.\n",
        "                if not hasattr(upload_to_abyss_and_update_json, 'commit_buffer'):\n",
        "                    upload_to_abyss_and_update_json.commit_buffer = []\n",
        "                \n",
        "                # Adiciona o rec.json e o p√¥ster (se houver) ao buffer.\n",
        "                json_rel_path = os.path.relpath(json_filepath, BASE_REPO_FOLDER)\n",
        "                if json_rel_path not in upload_to_abyss_and_update_json.commit_buffer:\n",
        "                    upload_to_abyss_and_update_json.commit_buffer.append(json_rel_path)\n",
        "                if poster_final_relpath and poster_final_relpath not in upload_to_abyss_and_update_json.commit_buffer:\n",
        "                    upload_to_abyss_and_update_json.commit_buffer.append(poster_final_relpath)\n",
        "\n",
        "                # Verifica se o threshold foi atingido para disparar o commit.\n",
        "                buffer = upload_to_abyss_and_update_json.commit_buffer\n",
        "                if len(buffer) >= COMMIT_PUSH_THRESHOLD:\n",
        "                    print(f\"üöÄ Limiar de commit atingido ({len(buffer)} arquivos). Enviando para o GitHub...\")\n",
        "                    git_commit_and_push(list(buffer), commit_message=\"[AUTO] Batch commit de metadados\")\n",
        "                    buffer.clear() # Limpa o buffer ap√≥s o push.\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Erro cr√≠tico ao atualizar rec.json ou gerenciar buffer: {e}\")\n",
        "            abyss_response = f\"Upload sucesso, mas falha no JSON: {e}\"\n",
        "\n",
        "    return upload_success, abyss_response, slug\n",
        "\n",
        "def commit_push_restantes():\n",
        "    \"\"\"\n",
        "    Fun√ß√£o para ser chamada no final do notebook para garantir que\n",
        "    qualquer arquivo restante no buffer seja comitado e enviado.\n",
        "    \"\"\"\n",
        "    # Acessa o buffer de forma segura.\n",
        "    buffer = getattr(upload_to_abyss_and_update_json, 'commit_buffer', [])\n",
        "    if buffer:\n",
        "        print(f\"üîî Realizando commit/push final de {len(buffer)} arquivos pendentes...\")\n",
        "        # Usa o lock para garantir seguran√ßa, embora seja menos prov√°vel\n",
        "        # ter concorr√™ncia nesta fase final.\n",
        "        with commit_lock:\n",
        "            git_commit_and_push(buffer, commit_message=\"[AUTO] Commit final de pend√™ncias da sess√£o\")\n",
        "            buffer.clear()\n",
        "    else:\n",
        "        print(\"‚úÖ Sem arquivos pendentes para o commit final.\")\n",
        "\n",
        "# =====================================================================================\n",
        "# 4. Rodap√© / Fim do C√≥digo\n",
        "# =====================================================================================\n",
        "# @log de mudan√ßas\n",
        "# - v4.6.2 (01/07/2025): Refatora√ß√£o completa para o padr√£o de documenta√ß√£o XCam,\n",
        "#   com coment√°rios detalhados em cada etapa da fun√ß√£o de p√≥s-processamento.\n",
        "# - v4.6.1: Atualiza√ß√£o dos caminhos para usar as vari√°veis globais do Google Drive.\n",
        "# - v4.6.0: Vers√£o inicial da fun√ß√£o de upload e atualiza√ß√£o de JSON.\n",
        "#\n",
        "# @roadmap futuro\n",
        "# - Abstrair a l√≥gica de upload para uma classe `Uploader`, permitindo\n",
        "#   adicionar facilmente novos provedores de armazenamento (ex: S3, Backblaze)\n",
        "#   no futuro, sem alterar o fluxo principal.\n",
        "# - Implementar um mecanismo de \"write-ahead-log\" ou escrita transacional\n",
        "#   para o `rec.json` (escrever em um `.tmp` e renomear) para garantir 100% de\n",
        "#   integridade mesmo se o notebook for interrompido durante a escrita do arquivo.\n",
        "# ====================================================================================="
      ]
    },
    {
      "cell_type": "markdown",
      "id": "iwgt8f8iKq4y",
      "metadata": {
        "id": "iwgt8f8iKq4y"
      },
      "source": [
        "# C√©lula 9: Processamento Autom√°tico, Paralelismo e Supervisor Din√¢mico com Blacklist\n",
        "\n",
        "**Objetivo:**  \n",
        "Controlar e orquestrar todo o pipeline do notebook, garantindo processamento cont√≠nuo, paralelo, eficiente e seguro de transmiss√µes ao vivo. O supervisor din√¢mico mant√©m o lote sempre cheio, respeita a blacklist tempor√°ria e o log central, e integra todas as fun√ß√µes cr√≠ticas das c√©lulas anteriores, garantindo m√°xima resili√™ncia e rastreabilidade.\n",
        "\n",
        "---\n",
        "\n",
        "## Estrat√©gia e melhorias implementadas\n",
        "\n",
        "- **Paralelismo seguro e eficiente:**  \n",
        "  Utiliza m√∫ltiplos processos para gravar e processar transmiss√µes simultaneamente, otimizando o uso de recursos e acelerando o processamento em lote.\n",
        "- **Supervisor din√¢mico e lote sempre cheio:**  \n",
        "  O supervisor monitora constantemente as vagas livres no lote e preenche em tempo real com novas transmiss√µes v√°lidas, evitando ociosidade e maximizando a efici√™ncia.\n",
        "- **Controle centralizado de duplicidade:**  \n",
        "  Antes de processar qualquer transmiss√£o, consulta o log central de processamento para evitar duplicidade, mesmo em ambientes concorrentes ou paralelos.\n",
        "- **Respeito integral √† blacklist tempor√°ria:**  \n",
        "  Transmiss√µes de usu√°rios em blacklist n√£o s√£o tentadas novamente durante o ciclo vigente, economizando recursos e evitando loops problem√°ticos.\n",
        "- **Logs robustos e detalhados:**  \n",
        "  Cada etapa do processamento √© registrada com timestamp, status e contexto, facilitando auditoria, troubleshooting e acompanhamento em produ√ß√£o.\n",
        "- **Commit/push autom√°tico e seguro:**  \n",
        "  Ao final do ciclo (ou quando atingido o threshold), todos os arquivos alterados s√£o enviados ao reposit√≥rio, garantindo consist√™ncia e persist√™ncia dos dados.\n",
        "- **Design modular e Clean Architecture:**  \n",
        "  Fun√ß√µes separadas para supervis√£o, workers, busca, commit, log, etc., facilitando manuten√ß√£o, reuso e integra√ß√£o com CI/CD.\n",
        "\n",
        "---\n",
        "\n",
        "## Como funciona o fluxo principal\n",
        "\n",
        "1. **Inicializa√ß√£o:**  \n",
        "   - Determina o modo de opera√ß√£o: grava√ß√£o de usu√°rios espec√≠ficos ou busca autom√°tica.\n",
        "   - Calcula o tamanho do lote alvo (`LIMIT_DEFAULT` ou `API_SEARCH_LIMIT`).\n",
        "\n",
        "2. **Preenchimento do lote:**  \n",
        "   - Busca transmiss√µes v√°lidas (n√£o duplicadas, n√£o em blacklist) e lan√ßa workers para cada uma, registrando no log de processamento.\n",
        "   - Utiliza fun√ß√µes otimizadas de busca (`buscar_proxima_transmissao_livre` e `buscar_usuarios_especificos`), integradas √† blacklist e ao log.\n",
        "\n",
        "3. **Supervis√£o din√¢mica:**  \n",
        "   - Monitora o ciclo de vida dos workers/processos.\n",
        "   - Preenche imediatamente cada vaga livre com nova transmiss√£o dispon√≠vel, at√© esgotar as op√ß√µes v√°lidas.\n",
        "\n",
        "4. **Respeito √† blacklist:**  \n",
        "   - Antes de qualquer grava√ß√£o, verifica se o usu√°rio est√° em blacklist tempor√°ria.\n",
        "   - Usu√°rios problem√°ticos nunca s√£o tentados duas vezes no mesmo ciclo.\n",
        "\n",
        "5. **Logs detalhados:**  \n",
        "   - Todas as opera√ß√µes geram logs padronizados com n√≠vel (INFO, WORKER, BUSCA, ERRO, etc.) e timestamp.\n",
        "\n",
        "6. **Finaliza√ß√£o segura:**  \n",
        "   - Ao final do processamento, executa commit/push dos arquivos pendentes, garantindo persist√™ncia e integridade do reposit√≥rio.\n",
        "\n",
        "---\n",
        "\n",
        "## Exemplo de uso recomendado\n",
        "\n",
        "```python\n",
        "# Fun√ß√£o principal do notebook: dispara o supervisor din√¢mico\n",
        "main()\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Seguran√ßa, rastreabilidade e integra√ß√£o\n",
        "\n",
        "- **Pronto para execu√ß√£o concorrente e ambientes CI/CD.**\n",
        "- **A l√≥gica de blacklist e commit est√° totalmente integrada ao fluxo, garantindo m√°xima resili√™ncia.**\n",
        "- **Logs detalhados e arquitetura modular facilitam diagn√≥stico, manuten√ß√£o e evolu√ß√£o do pipeline XCam.**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5WKQV9g_LB9M",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5WKQV9g_LB9M",
        "outputId": "0b41c450-0b4b-4502-b207-6e7edaf7b5ac"
      },
      "outputs": [],
      "source": [
        "# =====================================================================================\n",
        "# XCam REC - C√©lula 9: Supervisor Din√¢mico e Orquestra√ß√£o\n",
        "# =====================================================================================\n",
        "# [@author]      Samuel Passamani / Um Projeto do Estudio A.S√©rio [AllS Company]\n",
        "# [@info]        https://aserio.work/\n",
        "# [@version]     4.6.2\n",
        "# [@lastupdate]  2025-07-01\n",
        "#\n",
        "# [@description]\n",
        "# Esta c√©lula √© o c√©rebro do pipeline de grava√ß√£o. Ela cont√©m o \"supervisor\",\n",
        "# um orquestrador que gerencia m√∫ltiplos processos de grava√ß√£o (workers) em paralelo.\n",
        "# A sua principal responsabilidade √© manter o lote de grava√ß√µes sempre cheio,\n",
        "# preenchendo vagas em tempo real com novas transmiss√µes v√°lidas. O supervisor\n",
        "# integra todas as l√≥gicas das c√©lulas anteriores: busca de transmiss√µes, controle\n",
        "# de blacklist, grava√ß√£o, e commit final, garantindo um fluxo de trabalho\n",
        "# cont√≠nuo, resiliente e altamente eficiente.\n",
        "#\n",
        "# [@mode]\n",
        "# O supervisor opera em dois modos principais, definidos pela fun√ß√£o `main()`:\n",
        "#   1. Modo Autom√°tico: Busca e grava continuamente as transmiss√µes dispon√≠veis.\n",
        "#   2. Modo Espec√≠fico: Foca em gravar apenas uma lista de usu√°rios fornecida.\n",
        "# =====================================================================================\n",
        "\n",
        "\n",
        "# =====================================================================================\n",
        "# 2. Configura√ß√µes & Vari√°veis Globais (Depend√™ncias)\n",
        "# =====================================================================================\n",
        "\n",
        "# Esta c√©lula depende das seguintes vari√°veis e fun√ß√µes globais:\n",
        "# - Definidas na C√©lula 1:\n",
        "#   - LIMIT_DEFAULT: Tamanho do lote de grava√ß√µes paralelas.\n",
        "#   - PROCESSING_LOG_FILE: Arquivo que rastreia usu√°rios em processamento.\n",
        "# - Definidas nas C√©lulas Anteriores:\n",
        "#   - perguntar_transmissoes_especificas(): Para o modo interativo.\n",
        "#   - gravar_stream(): A fun√ß√£o executada por cada worker.\n",
        "#   - buscar_proxima_transmissao_livre(), buscar_usuarios_especificos(): Para encontrar alvos.\n",
        "#   - commit_push_restantes(): Para a finaliza√ß√£o segura do processo.\n",
        "\n",
        "\n",
        "# =====================================================================================\n",
        "# 3. Corpo\n",
        "# =====================================================================================\n",
        "\n",
        "def log_supervisor(msg, level=\"INFO\"):\n",
        "    \"\"\"Fun√ß√£o de log padronizada para o supervisor, facilitando o monitoramento.\"\"\"\n",
        "    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "    print(f\"[{timestamp}] [{level}] {msg}\")\n",
        "\n",
        "def worker(username, m3u8_url, poster_url, results):\n",
        "    \"\"\"\n",
        "    Fun√ß√£o alvo de cada processo paralelo.\n",
        "    Ela invoca `gravar_stream` e armazena o resultado em uma lista compartilhada.\n",
        "    \"\"\"\n",
        "    # Loga o in√≠cio do trabalho do worker.\n",
        "    log_supervisor(f\"Iniciando grava√ß√£o: {username}\", \"WORKER\")\n",
        "    # Chama a fun√ß√£o de grava√ß√£o principal (da C√©lula 7).\n",
        "    result = gravar_stream(username, m3u8_url, poster_url)\n",
        "    # Loga o resultado final da opera√ß√£o.\n",
        "    log_supervisor(f\"Finalizou grava√ß√£o: {username} | Sucesso: {result.get('upload_success')}\", \"WORKER\")\n",
        "    # Adiciona o dicion√°rio de resultado √† lista gerenciada (thread-safe).\n",
        "    results.append(result)\n",
        "\n",
        "def supervisor_dinamico(usuarios_especificos=None):\n",
        "    \"\"\"\n",
        "    Orquestra o processamento paralelo, mantendo o lote de grava√ß√µes sempre cheio\n",
        "    e respeitando as regras de blacklist e duplicidade.\n",
        "    \"\"\"\n",
        "    # Define o tamanho do lote de processos paralelos.\n",
        "    pool_size = LIMIT_DEFAULT if not usuarios_especificos else len(usuarios_especificos)\n",
        "    running_processes = []\n",
        "    # Usa uma lista gerenciada por `multiprocessing.Manager` para coletar resultados de forma segura.\n",
        "    results = Manager().list()\n",
        "    # Conjunto para rastrear todos os usu√°rios que j√° foram tentados nesta sess√£o.\n",
        "    seen_usernames = set()\n",
        "    \n",
        "    # Carrega a lista de usu√°rios que j√° estavam em processamento de uma execu√ß√£o anterior (se houver).\n",
        "    if os.path.exists(PROCESSING_LOG_FILE):\n",
        "        with open(PROCESSING_LOG_FILE, \"r\") as f:\n",
        "            seen_usernames.update([line.strip() for line in f])\n",
        "\n",
        "    log_supervisor(f\"Supervisor iniciado | Lote: {pool_size} | Modo: {'espec√≠fico' if usuarios_especificos else 'autom√°tico'}\")\n",
        "    \n",
        "    # --- Loop Principal de Supervis√£o ---\n",
        "    # Este loop continuar√° at√© que n√£o haja mais processos rodando e n√£o haja mais transmiss√µes para buscar.\n",
        "    is_active = True\n",
        "    while is_active:\n",
        "        # ---- Gerenciamento de Processos Finalizados ----\n",
        "        # Filtra a lista de processos, mantendo apenas os que ainda est√£o vivos.\n",
        "        alive_before = len(running_processes)\n",
        "        running_processes = [p for p in running_processes if p.is_alive()]\n",
        "        alive_after = len(running_processes)\n",
        "        \n",
        "        # Se algum processo terminou, loga a informa√ß√£o.\n",
        "        if alive_before > alive_after:\n",
        "            log_supervisor(f\"{alive_before - alive_after} grava√ß√µes finalizaram. Vagas livres: {pool_size - alive_after}\", \"SUPERVISOR\")\n",
        "\n",
        "        # ---- L√≥gica de \"Lote Sempre Cheio\" ----\n",
        "        # Calcula quantas vagas est√£o livres no lote de processamento.\n",
        "        vagas_livres = pool_size - len(running_processes)\n",
        "        if vagas_livres > 0:\n",
        "            # Tenta preencher cada vaga livre.\n",
        "            for _ in range(vagas_livres):\n",
        "                # Busca a pr√≥xima transmiss√£o v√°lida.\n",
        "                stream = buscar_proxima_transmissao_livre() if not usuarios_especificos else None # Adicionar l√≥gica para espec√≠ficos se necess√°rio\n",
        "                \n",
        "                # Se n√£o encontrar nenhuma transmiss√£o nova, para de tentar preencher.\n",
        "                if not stream:\n",
        "                    log_supervisor(\"N√£o h√° mais transmiss√µes dispon√≠veis para preencher as vagas.\", \"SUPERVISOR\")\n",
        "                    break # Sai do loop de preenchimento de vagas.\n",
        "                \n",
        "                username = stream[\"username\"]\n",
        "                # Dupla verifica√ß√£o para garantir que n√£o processe novamente.\n",
        "                if username in seen_usernames:\n",
        "                    continue\n",
        "                \n",
        "                # Adiciona √† lista de vistos e lan√ßa um novo worker.\n",
        "                seen_usernames.add(username)\n",
        "                log_supervisor(f\"Lan√ßando novo worker para: {username} | Vaga preenchida {len(running_processes) + 1}/{pool_size}\", \"SUPERVISOR\")\n",
        "                \n",
        "                p = Process(target=worker, args=(username, stream[\"src\"], stream.get(\"poster\"), results))\n",
        "                p.start()\n",
        "                running_processes.append(p)\n",
        "\n",
        "        # ---- Condi√ß√£o de Parada ----\n",
        "        # Se n√£o h√° mais processos rodando e n√£o h√° mais transmiss√µes para buscar (is_active se tornaria False).\n",
        "        if not running_processes:\n",
        "            log_supervisor(\"Todos os workers terminaram e n√£o h√° novas transmiss√µes. Encerrando.\", \"SUPERVISOR\")\n",
        "            is_active = False\n",
        "\n",
        "        # Pausa para n√£o sobrecarregar a CPU com verifica√ß√µes constantes.\n",
        "        time.sleep(5)\n",
        "\n",
        "    # --- Etapa Final: Commit de Arquivos Pendentes ---\n",
        "    log_supervisor(f\"Processamento din√¢mico conclu√≠do! Total de {len(results)} transmiss√µes processadas.\", \"FINAL\")\n",
        "    try:\n",
        "        log_supervisor(\"Executando commit final de arquivos pendentes...\", \"FINAL\")\n",
        "        commit_push_restantes() # Chama a fun√ß√£o da C√©lula 8.\n",
        "        log_supervisor(\"Commit final realizado com sucesso.\", \"FINAL\")\n",
        "    except Exception as e:\n",
        "        log_supervisor(f\"Falha no commit final: {e}\", \"ERRO\")\n",
        "    \n",
        "    log_supervisor(\"Supervisor finalizado.\", \"END\")\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Fun√ß√£o principal que inicia todo o pipeline do notebook.\n",
        "    \"\"\"\n",
        "    # Pergunta ao usu√°rio se ele quer focar em usu√°rios espec√≠ficos.\n",
        "    usuarios_especificos = perguntar_transmissoes_especificas()\n",
        "    log_supervisor(\"Iniciando pipeline de grava√ß√£o XCam...\", \"MAIN\")\n",
        "    # Inicia o supervisor no modo apropriado.\n",
        "    supervisor_dinamico(usuarios_especificos=usuarios_especificos)\n",
        "\n",
        "# Bloco de execu√ß√£o principal: garante que `main()` seja chamada ao executar a c√©lula no Colab.\n",
        "if __name__ == '__main__' and 'google.colab' in str(get_ipython()):\n",
        "    main()\n",
        "\n",
        "\n",
        "# =====================================================================================\n",
        "# 4. Rodap√© / Fim do C√≥digo\n",
        "# =====================================================================================\n",
        "# @log de mudan√ßas\n",
        "# - v4.6.2 (01/07/2025): Refatora√ß√£o completa para o padr√£o de documenta√ß√£o XCam.\n",
        "#   Adi√ß√£o de coment√°rios detalhados e organiza√ß√£o da l√≥gica do supervisor.\n",
        "# - v4.6.1: Atualiza√ß√£o para usar o `PROCESSING_LOG_FILE` centralizado.\n",
        "# - v4.6.0: Vers√£o inicial do supervisor din√¢mico.\n",
        "#\n",
        "# @roadmap futuro\n",
        "# - Implementar um sistema de prioridade para a fila de grava√ß√µes, permitindo,\n",
        "#   por exemplo, priorizar usu√°rios com mais espectadores.\n",
        "# - Adicionar uma interface de controle mais visual (talvez com `ipywidgets`) para\n",
        "#   monitorar os workers em tempo real e pausar/retomar o supervisor.\n",
        "# ====================================================================================="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eXVBhXjsAuAY",
      "metadata": {
        "id": "eXVBhXjsAuAY"
      },
      "outputs": [],
      "source": [
        "# C√©lula extra: Commit final de pend√™ncias\n",
        "def commit_final_pendencias():\n",
        "    commit_buffer = getattr(upload_to_abyss_and_update_json, 'commit_buffer', [])\n",
        "    if commit_buffer:\n",
        "        print(f\"üîî Realizando commit/push final de {len(commit_buffer)} pend√™ncias...\")\n",
        "        git_commit_and_push(commit_buffer, commit_message=\"Commit final de pend√™ncias\")\n",
        "        commit_buffer.clear()\n",
        "    else:\n",
        "        print(\"‚úÖ Sem pend√™ncias para commit final.\")\n",
        "\n",
        "# Execute isto ao final do processamento\n",
        "# commit_final_pendencias()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "cell_execution_strategy": "setup",
      "collapsed_sections": [
        "c9hve1ySGVAs"
      ],
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
