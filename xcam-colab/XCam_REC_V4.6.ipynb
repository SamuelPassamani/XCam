{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SamuelPassamani/XCam/blob/main/xcam-colab/XCam_REC_V4.6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c9hve1ySGVAs",
      "metadata": {
        "id": "c9hve1ySGVAs"
      },
      "source": [
        "# Célula 1: Configurações Auxiliares, Parâmetros Globais e Log Centralizado\n",
        "\n",
        "**Objetivo:**  \n",
        "Esta célula inicializa e centraliza todas as variáveis globais, parâmetros essenciais e agora também fornece um utilitário robusto para o log único do notebook XCam.  \n",
        "Permite ajuste rápido e seguro do comportamento do notebook, incluindo limites de processamento, controle de gravação, commit automático e mecanismos de resiliência contra transmissões problemáticas.\n",
        "\n",
        "## Principais pontos e melhorias implementadas\n",
        "\n",
        "- **Centralização dos parâmetros globais:**  \n",
        "  Todos os valores críticos (limites, thresholds, caminhos) são definidos e propagados como globais pelo notebook.\n",
        "- **Log único modular e estruturado (`xcam_master.log`):**  \n",
        "  Todas as operações relevantes (busca, gravação, blacklist, commit, erros, etc.) agora são registradas em um único arquivo JSON Lines.  \n",
        "  Cada entrada inclui sessão, evento, id, username, timestamps, status e detalhes.\n",
        "- **Funções utilitárias para o log:**  \n",
        "  Adição, busca, remoção e atualização de eventos são facilitadas por funções modulares (CRUD), promovendo robustez, rastreabilidade e fácil manutenção.\n",
        "- **Blacklist, falhas e processamento padronizados por `id`:**  \n",
        "  Toda lógica de controle é feita via identificador único, com `username` para exibição, garantindo unicidade e eliminando inconsistências.\n",
        "- **Função interativa para seleção de transmissões específicas:**  \n",
        "  Permite ao usuário informar nomes de usuários para filtrar transmissões antes do processamento.\n",
        "- **Comentários detalhados:**  \n",
        "  Cada etapa do código está documentada para orientar ajustes, manutenção e integração por toda a equipe.\n",
        "\n",
        "---\n",
        "\n",
        "## Parâmetros globais controlados nesta célula\n",
        "\n",
        "- **`LIMIT_DEFAULT`**: Quantidade máxima de transmissões processadas em paralelo/lote.\n",
        "- **`PAGE_DEFAULT`**: Página inicial para busca na API.\n",
        "- **`RECORD_SECONDS`**: Tempo máximo de gravação de cada vídeo (em segundos).\n",
        "- **`RECORD_SECONDS_MIN`**: Tempo mínimo exigido para considerar o vídeo válido (em segundos).\n",
        "- **`API_SEARCH_LIMIT`**: Limite de transmissões retornadas ao buscar usuários específicos.\n",
        "- **`COMMIT_PUSH_THRESHOLD`**: Quantidade de transmissões processadas até realizar commit/push automático (0 = commit imediato a cada gravação).\n",
        "- **`LOG_PATH`**: Caminho do arquivo único de log (JSONL).\n",
        "- **`BLACKLIST_TIMEOUT`**: Tempo de expiração da blacklist (em segundos).\n",
        "- **`BLACKLIST_MAX_FAILURES`**: Quantidade de falhas consecutivas antes de banir temporariamente o usuário.\n",
        "\n",
        "---\n",
        "\n",
        "## Estrutura do log único (`xcam_master.log`)\n",
        "\n",
        "Cada entrada segue o modelo:\n",
        "```json\n",
        "{\n",
        "  \"timestamp\": \"2025-06-06T06:15:00Z\",\n",
        "  \"sessao\": \"busca|gravação|blacklist|commit|erro|...\",\n",
        "  \"evento\": \"...\",\n",
        "  \"id\": \"...\",         // identificador único (primário)\n",
        "  \"username\": \"...\",   // nome do usuário para exibição\n",
        "  \"status\": \"...\",     // ok|erro|blacklisted|expirado|...\n",
        "  \"detalhes\": \"...\",   // informações adicionais\n",
        "}\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Funções utilitárias para o log\n",
        "\n",
        "- **`append_log(entry, log_path=LOG_PATH)`**: Adiciona uma nova entrada ao log central.\n",
        "- **`read_logs(log_path=LOG_PATH)`**: Lê todas as entradas do log.\n",
        "- **`query_logs(...)`**: Consulta entradas do log por filtros opcionais (sessão, id, status, etc).\n",
        "- **`remove_logs(condition_fn, log_path=LOG_PATH)`**: Remove todas as entradas que satisfaçam a condição.\n",
        "- **`update_log_entry(match_fn, update_fn, log_path=LOG_PATH)`**: Atualiza entradas do log conforme regra.\n",
        "\n",
        "---\n",
        "\n",
        "## Exemplo de uso das funções (a serem aplicadas nas próximas células)\n",
        "\n",
        "```python\n",
        "append_log({\n",
        "    \"sessao\": \"busca\",\n",
        "    \"evento\": \"encontrado\",\n",
        "    \"id\": \"abc123\",\n",
        "    \"username\": \"Manugic_\",\n",
        "    \"status\": \"ok\",\n",
        "    \"detalhes\": \"URL válida\"\n",
        "})\n",
        "\n",
        "# Consultar blacklist:\n",
        "logs_blacklist = query_logs(sessao=\"blacklist\", status=\"blacklisted\")\n",
        "\n",
        "# Remover registros expirados:\n",
        "remove_logs(lambda entry: entry[\"sessao\"] == \"processing\" and expirou(entry), log_path=LOG_PATH)\n",
        "\n",
        "# Atualizar status:\n",
        "update_log_entry(lambda e: e[\"id\"]==\"abc123\", lambda e: e.update({\"status\":\"ok\"}))\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Função interativa\n",
        "\n",
        "Permite ao usuário informar transmissões específicas a serem gravadas antes de iniciar o processamento.\n",
        "\n",
        "---\n",
        "\n",
        "## Segurança, rastreabilidade e manutenção\n",
        "\n",
        "- Todos os parâmetros globais são definidos no início e propagados para todo o notebook, garantindo consistência.\n",
        "- O log único fornece rastreabilidade detalhada e elimina arquivos dispersos (blacklist, falha, etc).\n",
        "- Ajuste qualquer valor diretamente nesta célula para alterar o comportamento global do notebook de forma segura.\n",
        "- Comentários detalhados auxiliam a compreensão, integração e manutenção por toda a equipe.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "j5pPh353GLMD",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5pPh353GLMD",
        "outputId": "44655413-5f22-4c54-9d44-2a2fc00f759c"
      },
      "outputs": [],
      "source": [
        "# =====================================================================================\n",
        "# XCam REC - Célula de Configuração Global e Logs\n",
        "# =====================================================================================\n",
        "# [@author]      Samuel Passamani / Um Projeto do Estudio A.Sério [AllS Company]\n",
        "# [@info]        https://aserio.work/\n",
        "# [@version]     4.6.2\n",
        "# [@lastupdate]  2025-07-01\n",
        "#\n",
        "# [@description]\n",
        "# Esta célula é o núcleo de configuração e controle para todo o notebook de gravação.\n",
        "# Ela centraliza todos os parâmetros, limites, timeouts e caminhos de arquivos,\n",
        "# garantindo que todas as operações subsequentes sejam consistentes e facilmente ajustáveis.\n",
        "# Além disso, implementa um sistema de logging robusto e centralizado em um único\n",
        "# arquivo (JSONL), com funções utilitárias para manipulação (CRUD), promovendo\n",
        "# máxima rastreabilidade e facilitando a depuração.\n",
        "#\n",
        "# [@mode]\n",
        "# Esta célula funciona como a base de setup para todos os modos de operação do\n",
        "# notebook, seja em modo de busca automática ou gravação de usuários específicos.\n",
        "# =====================================================================================\n",
        "\n",
        "# =====================================================================================\n",
        "# 2. Configurações & Variáveis Globais\n",
        "# =====================================================================================\n",
        "\n",
        "# --- Imports Essenciais ---\n",
        "from google.colab import drive  # Módulo para interagir com o Google Drive\n",
        "import os                       # Módulo para interações com o sistema operacional (pastas, arquivos)\n",
        "import json                     # Módulo para manipulação de dados no formato JSON\n",
        "from datetime import datetime   # Módulo para trabalhar com datas e horas\n",
        "import time                     # Módulo para funções relacionadas a tempo (ex: sleep, timestamps)\n",
        "\n",
        "# --- Montagem do Google Drive ---\n",
        "# Garante que o Google Drive esteja acessível para persistência dos dados.\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# --- Parâmetros Globais Editáveis ---\n",
        "# Ajuste estes valores para controlar o comportamento de todo o notebook.\n",
        "\n",
        "# Limites e thresholds de processamento\n",
        "LIMIT_DEFAULT = 50              # Define a quantidade máxima de gravações que podem ocorrer em paralelo.\n",
        "PAGE_DEFAULT = 1                # Define a página inicial para buscas na API do XCam.\n",
        "RECORD_SECONDS = 12780          # Define o tempo máximo de gravação de cada vídeo, em segundos (aprox. 3.5 horas).\n",
        "RECORD_SECONDS_MIN = 660        # Define o tempo mínimo que um vídeo precisa ter para ser considerado válido.\n",
        "API_SEARCH_LIMIT = 1500         # Limite de resultados ao buscar por usuários específicos na API.\n",
        "COMMIT_PUSH_THRESHOLD = 25      # Número de gravações concluídas para disparar um commit automático para o GitHub.\n",
        "\n",
        "# Configurações da Blacklist\n",
        "BLACKLIST_TIMEOUT = 15 * 60     # Tempo que um usuário permanece na blacklist, em segundos (15 minutos).\n",
        "BLACKLIST_MAX_FAILURES = 3      # Número de falhas consecutivas de gravação para um usuário ser adicionado à blacklist.\n",
        "\n",
        "# --- Caminhos Centralizados (Google Drive) ---\n",
        "# Define todos os caminhos de forma centralizada para fácil manutenção.\n",
        "DRIVE_BASE_PATH = \"/content/drive/MyDrive/XCam.Drive/src\"               # Pasta raiz do projeto no Drive.\n",
        "DRIVE_LOGS_PATH = os.path.join(DRIVE_BASE_PATH, \"logs\")                 # Pasta para todos os arquivos de log.\n",
        "DRIVE_POSTERS_TEMP_PATH = os.path.join(DRIVE_BASE_PATH, \"temp\", \"posters\") # Pasta para pôsteres temporários.\n",
        "DRIVE_RECORDS_TEMP_PATH = os.path.join(DRIVE_BASE_PATH, \"temp\", \"records\") # Pasta para vídeos temporários.\n",
        "DRIVE_ARCHIVE_BASE_PATH = \"/content/drive/MyDrive/XCam.Drive/user\"      # Pasta de arquivamento final dos dados por usuário.\n",
        "\n",
        "# --- Nomes de Arquivos de Log Específicos ---\n",
        "# Define os nomes dos arquivos de log que serão criados dentro de DRIVE_LOGS_PATH.\n",
        "MASTER_LOG_FILE = os.path.join(DRIVE_LOGS_PATH, \"xcam_master.log\")         # Log principal com todos os eventos.\n",
        "BLACKLIST_LOG_FILE = os.path.join(DRIVE_LOGS_PATH, \"xcam_blacklist.log\")   # Log de usuários em blacklist.\n",
        "FAILURE_LOG_FILE = os.path.join(DRIVE_LOGS_PATH, \"xcam_failures.log\")     # Log de contagem de falhas.\n",
        "PROCESSING_LOG_FILE = os.path.join(DRIVE_LOGS_PATH, \"xcam_processing.log\")  # Log de usuários em processamento.\n",
        "\n",
        "# --- Verificação e Criação de Diretórios ---\n",
        "# Garante que as pastas de destino existam para evitar erros de \"Arquivo não encontrado\".\n",
        "os.makedirs(DRIVE_LOGS_PATH, exist_ok=True)\n",
        "os.makedirs(DRIVE_POSTERS_TEMP_PATH, exist_ok=True)\n",
        "os.makedirs(DRIVE_RECORDS_TEMP_PATH, exist_ok=True)\n",
        "os.makedirs(DRIVE_ARCHIVE_BASE_PATH, exist_ok=True)\n",
        "print(\"✅ Pastas do Google Drive verificadas/criadas com sucesso.\")\n",
        "\n",
        "# --- Propagação de Variáveis Globais ---\n",
        "# Torna todas as configurações acima acessíveis em qualquer outra célula do notebook.\n",
        "globals().update({\n",
        "    'LIMIT_DEFAULT': LIMIT_DEFAULT,\n",
        "    'PAGE_DEFAULT': PAGE_DEFAULT,\n",
        "    'RECORD_SECONDS': RECORD_SECONDS,\n",
        "    'RECORD_SECONDS_MIN': RECORD_SECONDS_MIN,\n",
        "    'API_SEARCH_LIMIT': API_SEARCH_LIMIT,\n",
        "    'COMMIT_PUSH_THRESHOLD': COMMIT_PUSH_THRESHOLD,\n",
        "    'BLACKLIST_TIMEOUT': BLACKLIST_TIMEOUT,\n",
        "    'BLACKLIST_MAX_FAILURES': BLACKLIST_MAX_FAILURES,\n",
        "    'DRIVE_LOGS_PATH': DRIVE_LOGS_PATH,\n",
        "    'DRIVE_POSTERS_TEMP_PATH': DRIVE_POSTERS_TEMP_PATH,\n",
        "    'DRIVE_RECORDS_TEMP_PATH': DRIVE_RECORDS_TEMP_PATH,\n",
        "    'DRIVE_ARCHIVE_BASE_PATH': DRIVE_ARCHIVE_BASE_PATH,\n",
        "    'MASTER_LOG_FILE': MASTER_LOG_FILE,\n",
        "    'BLACKLIST_LOG_FILE': BLACKLIST_LOG_FILE,\n",
        "    'FAILURE_LOG_FILE': FAILURE_LOG_FILE,\n",
        "    'PROCESSING_LOG_FILE': PROCESSING_LOG_FILE\n",
        "})\n",
        "\n",
        "\n",
        "# =====================================================================================\n",
        "# 3. Corpo\n",
        "# =====================================================================================\n",
        "\n",
        "# --- Funções Utilitárias para Log Centralizado (JSONL) ---\n",
        "\n",
        "def now_iso():\n",
        "    \"\"\"Retorna o timestamp atual em formato UTC ISO 8601, padrão para logs.\"\"\"\n",
        "    return datetime.utcnow().isoformat() + \"Z\"\n",
        "\n",
        "def append_log(entry, log_path=MASTER_LOG_FILE):\n",
        "    \"\"\"Adiciona uma nova entrada ao arquivo de log especificado.\"\"\"\n",
        "    # Garante que toda entrada de log tenha um timestamp.\n",
        "    entry.setdefault(\"timestamp\", now_iso())\n",
        "    # Garante que os campos essenciais para rastreabilidade existam na entrada.\n",
        "    for field in [\"sessao\", \"evento\", \"id\", \"username\", \"status\"]:\n",
        "        entry.setdefault(field, \"\")\n",
        "    # Abre o arquivo em modo 'append' (a) e escreve a nova entrada como uma linha JSON.\n",
        "    with open(log_path, \"a\", encoding=\"utf-8\") as f:\n",
        "        f.write(json.dumps(entry, ensure_ascii=False) + \"\\\\n\")\n",
        "\n",
        "def read_logs(log_path=MASTER_LOG_FILE):\n",
        "    \"\"\"Lê e retorna todas as entradas de um arquivo de log JSONL.\"\"\"\n",
        "    # Se o arquivo não existir, retorna uma lista vazia para evitar erros.\n",
        "    if not os.path.exists(log_path):\n",
        "        return []\n",
        "    # Abre o arquivo para leitura e converte cada linha de JSON para um dicionário Python.\n",
        "    with open(log_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        return [json.loads(line) for line in f if line.strip()]\n",
        "\n",
        "def query_logs(sessao=None, id=None, username=None, evento=None, status=None, after=None, before=None, log_path=MASTER_LOG_FILE):\n",
        "    \"\"\"Consulta entradas de log com base em múltiplos filtros opcionais.\"\"\"\n",
        "    # Lê todos os logs do arquivo.\n",
        "    logs = read_logs(log_path)\n",
        "    filtered_logs = []\n",
        "    # Itera sobre cada entrada de log para aplicar os filtros.\n",
        "    for entry in logs:\n",
        "        if sessao and entry.get(\"sessao\") != sessao: continue\n",
        "        if id and entry.get(\"id\") != id: continue\n",
        "        if username and entry.get(\"username\") != username: continue\n",
        "        if evento and entry.get(\"evento\") != evento: continue\n",
        "        if status and entry.get(\"status\") != status: continue\n",
        "        # Filtra por intervalo de tempo, se especificado.\n",
        "        ts = entry.get(\"timestamp\")\n",
        "        if after and ts < (after.isoformat() if isinstance(after, datetime) else after): continue\n",
        "        if before and ts > (before.isoformat() if isinstance(before, datetime) else before): continue\n",
        "        filtered_logs.append(entry)\n",
        "    return filtered_logs\n",
        "\n",
        "def remove_logs(condition_fn, log_path=MASTER_LOG_FILE):\n",
        "    \"\"\"Remove entradas de um log que satisfaçam uma função de condição.\"\"\"\n",
        "    logs = read_logs(log_path)\n",
        "    # Cria uma nova lista apenas com os logs que devem ser mantidos.\n",
        "    kept_logs = [entry for entry in logs if not condition_fn(entry)]\n",
        "    # Reescreve o arquivo de log com a lista filtrada.\n",
        "    with open(log_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        for entry in kept_logs:\n",
        "            f.write(json.dumps(entry, ensure_ascii=False) + \"\\\\n\")\n",
        "    # Retorna o número de entradas removidas.\n",
        "    return len(logs) - len(kept_logs)\n",
        "\n",
        "def update_log_entry(match_fn, update_fn, log_path=MASTER_LOG_FILE):\n",
        "    \"\"\"Atualiza uma ou mais entradas de log que correspondam a uma função de busca.\"\"\"\n",
        "    logs = read_logs(log_path)\n",
        "    updated_count = 0\n",
        "    # Itera sobre os logs e aplica a função de atualização.\n",
        "    for entry in logs:\n",
        "        if match_fn(entry):\n",
        "            update_fn(entry)\n",
        "            updated_count += 1\n",
        "    # Reescreve o arquivo com os logs atualizados.\n",
        "    with open(log_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        for entry in logs:\n",
        "            f.write(json.dumps(entry, ensure_ascii=False) + \"\\\\n\")\n",
        "    return updated_count\n",
        "\n",
        "# --- Função Interativa para Seleção de Usuários ---\n",
        "\n",
        "def perguntar_transmissoes_especificas():\n",
        "    \"\"\"Pergunta ao usuário se deseja gravar transmissões específicas.\"\"\"\n",
        "    # Captura a resposta do usuário.\n",
        "    resp = input('Deseja gravar alguma transmissão específica? (sim/não): ').strip().lower()\n",
        "    # Se a resposta for afirmativa, solicita a lista de usuários.\n",
        "    if resp.startswith('s'):\n",
        "        usuarios_input = input('Informe o(s) nome(s) de usuário, separados por vírgula: ')\n",
        "        # Limpa e formata a entrada do usuário em uma lista de nomes.\n",
        "        return [u.strip() for u in usuarios_input.split(',') if u.strip()]\n",
        "    # Retorna uma lista vazia se a resposta for negativa.\n",
        "    return []\n",
        "\n",
        "# =====================================================================================\n",
        "# 4. Rodapé / Fim do Código\n",
        "# =====================================================================================\n",
        "# @log de mudanças\n",
        "# - v4.6.2 (01/07/2025): Refatoração para o padrão de documentação XCam. Adição de\n",
        "#   comentários detalhados, centralização de caminhos do Drive e organização\n",
        "#   estrutural para melhor clareza e manutenção.\n",
        "# - v4.6.1 (01/07/2025): Centralização dos caminhos de arquivos temporários e logs\n",
        "#   para subpastas dedicadas no Google Drive, melhorando a organização.\n",
        "# - v4.6.0: Versão inicial da Célula 1 com sistema de log centralizado.\n",
        "#\n",
        "# @roadmap futuro\n",
        "# - Migrar a lógica de controle de blacklist e falhas (atualmente em arquivos\n",
        "#   separados na Célula 6) para usar exclusivamente o MASTER_LOG_FILE,\n",
        "#   centralizando 100% da lógica de estado.\n",
        "# - Refatorar as funções de log para uma classe `Logger` dedicada, melhorando\n",
        "#   o encapsulamento e a organização do código.\n",
        "# ====================================================================================="
      ]
    },
    {
      "cell_type": "markdown",
      "id": "WXs0o6OPHXbi",
      "metadata": {
        "id": "WXs0o6OPHXbi"
      },
      "source": [
        "# Célula 2: Instalação e Validação do ffmpeg\n",
        "\n",
        "**Objetivo:**  \n",
        "Esta célula garante que o utilitário `ffmpeg` esteja instalado e disponível no ambiente Google Colab. O ffmpeg é indispensável para a gravação dos vídeos das transmissões e para o processamento de mídia ao longo do pipeline do notebook XCam.\n",
        "\n",
        "## Pontos principais e melhorias implementadas\n",
        "\n",
        "- **Verificação pré-instalação:**  \n",
        "  Antes de instalar, verifica se o ffmpeg já está disponível no ambiente, tornando o processo idempotente e eficiente.\n",
        "- **Instalação automatizada:**  \n",
        "  Efetua a instalação via `apt-get` apenas se necessário, reduzindo o tempo de setup em execuções futuras.\n",
        "- **Validação pós-instalação:**  \n",
        "  Exibe a versão instalada do ffmpeg, garantindo transparência e rastreabilidade.\n",
        "- **Mensagens detalhadas:**  \n",
        "  O usuário recebe logs informativos sobre cada etapa, facilitando o diagnóstico em caso de erros.\n",
        "- **Design modular:**  \n",
        "  Estrutura pronta para ser utilizada em outros ambientes (Colab, local, server) com pequenas adaptações.\n",
        "\n",
        "---\n",
        "\n",
        "## Como funciona a célula\n",
        "\n",
        "- **Verifica se o ffmpeg está instalado (no PATH do sistema).**\n",
        "- **Se não estiver, instala automaticamente via apt-get.**\n",
        "- **Valida e exibe a versão instalada após o processo.**\n",
        "- **Em caso de falha, exibe erro detalhado e interrompe o fluxo para evitar inconsistências futuras.**\n",
        "\n",
        "---\n",
        "\n",
        "## Exemplo de uso das funções nesta célula\n",
        "\n",
        "```python\n",
        "if not is_ffmpeg_installed():\n",
        "    install_ffmpeg()\n",
        "show_ffmpeg_version()\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Segurança, rastreabilidade e manutenção\n",
        "\n",
        "- A célula torna o setup do ambiente mais robusto, impedindo falhas silenciosas relacionadas à ausência de ffmpeg.\n",
        "- Mensagens e validações ajudam a equipe a identificar rapidamente problemas de ambiente ou permissões.\n",
        "- O padrão modular facilita a reutilização do código em diferentes notebooks ou pipelines do projeto XCam.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "vIODn0c2HiHz",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vIODn0c2HiHz",
        "outputId": "8461c69a-d669-487a-d6be-095e29eaccdb"
      },
      "outputs": [],
      "source": [
        "# ================================================================\n",
        "# Célula 2: Instalação e Validação do FFMPEG no Colab\n",
        "# ================================================================\n",
        "# Objetivo:\n",
        "# - Garantir que o utilitário ffmpeg está instalado e disponível no ambiente\n",
        "# - Validar a instalação e exibir a versão instalada\n",
        "# - Tornar a etapa idempotente, evitando instalações desnecessárias\n",
        "# - Fornecer feedback claro e orientações em caso de erro\n",
        "#\n",
        "# Estratégia aplicada:\n",
        "# - Instalação via apt-get apenas se ffmpeg não estiver disponível\n",
        "# - Validação pós-instalação\n",
        "# - Logs claros e comentários detalhados para rastreabilidade\n",
        "# ================================================================\n",
        "\n",
        "import subprocess\n",
        "\n",
        "def is_ffmpeg_installed():\n",
        "    \"\"\"\n",
        "    Verifica se o ffmpeg está instalado e disponível no PATH do sistema.\n",
        "    Retorna True se estiver, False caso contrário.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        result = subprocess.run([\"ffmpeg\", \"-version\"], capture_output=True, text=True)\n",
        "        return result.returncode == 0\n",
        "    except FileNotFoundError:\n",
        "        return False\n",
        "\n",
        "def install_ffmpeg():\n",
        "    \"\"\"\n",
        "    Instala o ffmpeg via apt-get caso não esteja presente.\n",
        "    \"\"\"\n",
        "    print(\"[INFO] Instalando ffmpeg via apt-get...\")\n",
        "    # Atualiza pacotes e instala ffmpeg silenciosamente\n",
        "    !apt-get update -y > /dev/null\n",
        "    !apt-get install -y ffmpeg > /dev/null\n",
        "    print(\"[INFO] ffmpeg instalado com sucesso.\")\n",
        "\n",
        "def show_ffmpeg_version():\n",
        "    \"\"\"\n",
        "    Exibe a versão instalada do ffmpeg.\n",
        "    \"\"\"\n",
        "    print(\"[INFO] Versão do ffmpeg instalada:\")\n",
        "    !ffmpeg -version | head -n 2\n",
        "\n",
        "# ============================\n",
        "# EXECUÇÃO DA ETAPA DE SETUP\n",
        "# ============================\n",
        "\n",
        "if not is_ffmpeg_installed():\n",
        "    print(\"[WARN] ffmpeg não encontrado no ambiente.\")\n",
        "    install_ffmpeg()\n",
        "    if not is_ffmpeg_installed():\n",
        "        raise RuntimeError(\"[ERRO] Falha ao instalar o ffmpeg. Verifique permissões ou tente novamente.\")\n",
        "else:\n",
        "    print(\"[OK] ffmpeg já está instalado no ambiente.\")\n",
        "\n",
        "# Validação final e exibição da versão\n",
        "show_ffmpeg_version()\n",
        "\n",
        "# ============================\n",
        "# FIM DA CÉLULA 2\n",
        "# ============================\n",
        "\n",
        "# Dica: ffmpeg deve estar disponível para todas as células subsequentes.\n",
        "# Se precisar de um caminho específico, utilize `which ffmpeg` para obter o path absoluto."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "90qvXC0rHtWb",
      "metadata": {
        "id": "90qvXC0rHtWb"
      },
      "source": [
        "# Célula 3: Imports Essenciais, Utilitários e Preparação do Ambiente\n",
        "\n",
        "**Objetivo:**  \n",
        "Importa todas as bibliotecas essenciais do Python necessárias para o funcionamento do notebook, incluindo módulos para requisições HTTP, processamento paralelo, manipulação de datas, controle de subprocessos e exibição interativa.  \n",
        "Centraliza funções utilitárias robustas e padronizadas para processamento, download de poster, geração automática de poster com ffmpeg e exibição de progresso.  \n",
        "\n",
        "## Principais pontos e melhorias implementadas\n",
        "\n",
        "- **Centralização de imports essenciais:**  \n",
        "  Todos os módulos fundamentais (os, requests, multiprocessing, datetime, json, time, subprocess, math, re, IPython) estão disponíveis e prontos para uso global.\n",
        "- **Funções utilitárias padronizadas:**  \n",
        "  Funções para formatação de segundos, exibição de progresso, download e validação de poster e geração de poster via ffmpeg foram refatoradas e documentadas, seguindo arquitetura modular e Clean Architecture.\n",
        "- **Remoção de logs temporários dispersos:**  \n",
        "  O antigo arquivo de log de processamento temporário foi descontinuado em favor do log único centralizado definido na Célula 1, promovendo rastreabilidade e controle total.\n",
        "- **Robustez e clareza:**  \n",
        "  Todas as funções possuem tratamento de erros, mensagens amigáveis e são preparadas para uso concorrente e integração com as próximas etapas do pipeline.\n",
        "- **Pronto para uso em todo o notebook:**  \n",
        "  As funções aqui definidas são utilizadas em toda a automação, garantindo reuso, legibilidade e manutenção facilitada.\n",
        "\n",
        "---\n",
        "\n",
        "## Funções utilitárias disponíveis nesta célula\n",
        "\n",
        "- **`format_seconds(seconds)`**: Formata um valor em segundos para string legível (ex: \"1h23m45s\").\n",
        "- **`log_progress(username, elapsed_seconds, total_seconds)`**: Exibe o progresso da gravação de cada transmissão.\n",
        "- **`download_and_save_poster(poster_url, username, temp_folder)`**: Baixa e salva o poster da transmissão a partir de uma URL remota ou retorna se for um caminho local.\n",
        "- **`generate_poster_with_ffmpeg(m3u8_url, username, temp_folder, frame_time=7, timeout=20)`**: Gera automaticamente um poster usando ffmpeg, após validar a disponibilidade do stream.\n",
        "- **`is_poster_valid(poster_path)`**: Verifica se o arquivo de poster é válido (existe e não está vazio).\n",
        "\n",
        "---\n",
        "\n",
        "## Exemplo de uso das funções\n",
        "\n",
        "```python\n",
        "# Formatar segundos em string legível\n",
        "tempo = format_seconds(385)\n",
        "# Exibir progresso\n",
        "log_progress(\"userNovo234\", 385, 12780)\n",
        "# Download do poster\n",
        "poster_path = download_and_save_poster(url_poster, \"userNovo234\", \"/content/temp\")\n",
        "# Geração automática de poster via ffmpeg (se necessário)\n",
        "if not is_poster_valid(poster_path):\n",
        "    poster_path = generate_poster_with_ffmpeg(m3u8_url, \"userNovo234\", \"/content/temp\")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Segurança, rastreabilidade e manutenção\n",
        "\n",
        "- Todas as funções são preparadas para tratamento de erros e integração com processos concorrentes.\n",
        "- O log temporário de processamento foi removido, garantindo que todo o rastreio e auditoria sejam feitos via log único centralizado da Célula 1.\n",
        "- Comentários detalhados facilitam manutenção, entendimento e evolução do notebook.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hOetz0nGICkz",
      "metadata": {
        "id": "hOetz0nGICkz"
      },
      "outputs": [],
      "source": [
        "# =====================================================================================\n",
        "# XCam REC - Célula 3: Utilitários Essenciais e Preparação do Ambiente\n",
        "# =====================================================================================\n",
        "# [@author]      Samuel Passamani / Um Projeto do Estudio A.Sério [AllS Company]\n",
        "# [@info]        https://aserio.work/\n",
        "# [@version]     4.6.1\n",
        "# [@lastupdate]  2025-07-01\n",
        "#\n",
        "# [@description]\n",
        "# Esta célula é responsável por importar todas as bibliotecas Python essenciais para\n",
        "# a execução do pipeline de gravação e por definir um conjunto de funções\n",
        "# utilitárias robustas e padronizadas. As funções aqui presentes são usadas\n",
        "# em todo o notebook para tarefas como formatação de tempo, exibição de progresso,\n",
        "# download de pôsteres e geração automática de thumbnails via ffmpeg, garantindo\n",
        "# modularidade, reuso de código e fácil manutenção.\n",
        "#\n",
        "# [@mode]\n",
        "# As funções e imports definidos nesta célula são de propósito geral e servem de\n",
        "# base para todas as operações do notebook, independentemente do modo de execução.\n",
        "# =====================================================================================\n",
        "\n",
        "# =====================================================================================\n",
        "# 2. Configurações & Variáveis Globais (Imports)\n",
        "# =====================================================================================\n",
        "\n",
        "# --- Imports Essenciais ---\n",
        "import os                          # Módulo para interações com o sistema operacional (pastas, arquivos).\n",
        "import requests                    # Biblioteca para fazer requisições HTTP de forma simples e elegante.\n",
        "from multiprocessing import Manager, Process # Módulos para habilitar o processamento paralelo e acelerar as gravações.\n",
        "from datetime import datetime      # Módulo para trabalhar com datas e horas.\n",
        "import json                        # Módulo para manipulação de dados no formato JSON.\n",
        "import time                        # Módulo para funções relacionadas a tempo (ex: sleep, timestamps).\n",
        "import subprocess                  # Módulo para executar processos externos, como o ffmpeg.\n",
        "import math                        # Módulo com funções matemáticas (ex: arredondamento).\n",
        "import re                          # Módulo para trabalhar com expressões regulares, útil para extrair dados de texto.\n",
        "import shutil                      # Módulo com operações de alto nível em arquivos e coleções de arquivos.\n",
        "import threading                   # Módulo para trabalhar com threads, usado para controle de concorrência (locks).\n",
        "\n",
        "# --- Imports Específicos do Ambiente (IPython/Colab) ---\n",
        "from IPython import get_ipython    # Função para obter a instância atual do IPython (útil para detectar o ambiente).\n",
        "from IPython.display import display # Função para renderizar objetos de forma rica no notebook.\n",
        "\n",
        "\n",
        "# =====================================================================================\n",
        "# 3. Corpo\n",
        "# =====================================================================================\n",
        "\n",
        "# --- Funções Utilitárias de Formatação e Progresso ---\n",
        "\n",
        "def format_seconds(seconds):\n",
        "    \"\"\"\n",
        "    Converte um número total de segundos em uma string de formato amigável (ex: \"1h23m45s\").\n",
        "    Ideal para logs e exibição de duração de vídeos.\n",
        "    \"\"\"\n",
        "    total_seconds = int(seconds)  # Garante que estamos trabalhando com um número inteiro.\n",
        "    # Usa divmod para obter horas e o resto da divisão.\n",
        "    hours, remainder = divmod(total_seconds, 3600)\n",
        "    # Usa divmod novamente no resto para obter minutos e segundos.\n",
        "    minutes, seconds = divmod(remainder, 60)\n",
        "    \n",
        "    parts = [] # Lista para armazenar as partes do tempo formatado.\n",
        "    if hours > 0: parts.append(f\"{hours}h\")\n",
        "    if minutes > 0: parts.append(f\"{minutes}m\")\n",
        "    # Adiciona os segundos se houver, ou se for a única unidade de tempo.\n",
        "    if seconds > 0 or not parts: parts.append(f\"{seconds}s\")\n",
        "    \n",
        "    return \"\".join(parts) # Junta as partes em uma única string.\n",
        "\n",
        "def log_progress(username, elapsed_seconds, total_seconds):\n",
        "    \"\"\"\n",
        "    Imprime uma linha de progresso formatada para uma gravação em andamento.\n",
        "    Inclui nome de usuário, tempo decorrido, tempo restante e porcentagem.\n",
        "    \"\"\"\n",
        "    # Calcula a porcentagem, garantindo que não ultrapasse 100%.\n",
        "    percent = min((elapsed_seconds / total_seconds) * 100, 100)\n",
        "    # Formata o tempo decorrido.\n",
        "    tempo = format_seconds(elapsed_seconds)\n",
        "    # Calcula os minutos gravados e restantes para uma visão rápida.\n",
        "    minutos_gravados = math.floor(elapsed_seconds / 60)\n",
        "    minutos_restantes = max(0, math.ceil((total_seconds - elapsed_seconds) / 60))\n",
        "    # Imprime a linha de log formatada.\n",
        "    print(f\"⏱️ [{username}] Gravados: {minutos_gravados} min | Restantes: {minutos_restantes} min | Tempo total: {tempo} — 📊 {percent:.1f}% concluído\")\n",
        "\n",
        "# --- Funções Utilitárias para Manipulação de Pôsteres ---\n",
        "\n",
        "def download_and_save_poster(poster_url, username, temp_folder=DRIVE_POSTERS_TEMP_PATH):\n",
        "    \"\"\"\n",
        "    Baixa um pôster de uma URL e o salva em uma pasta temporária.\n",
        "    Retorna o caminho do arquivo salvo ou None em caso de falha.\n",
        "    \"\"\"\n",
        "    # Se a URL já for um caminho de arquivo local existente, apenas o retorna.\n",
        "    if os.path.exists(poster_url):\n",
        "        return poster_url\n",
        "    \n",
        "    # Verifica se a URL é uma string e começa com \"http\".\n",
        "    if isinstance(poster_url, str) and poster_url.startswith(\"http\"):\n",
        "        try:\n",
        "            # Faz a requisição GET para a URL do pôster com um timeout.\n",
        "            response = requests.get(poster_url, timeout=15)\n",
        "            # Levanta um erro se a resposta não for bem-sucedida (status code não for 2xx).\n",
        "            response.raise_for_status()\n",
        "            \n",
        "            # Padroniza a extensão do arquivo para .jpg para consistência.\n",
        "            ext = \".jpg\"\n",
        "            # Constrói o caminho completo para o arquivo temporário.\n",
        "            poster_temp_path = os.path.join(temp_folder, f\"{username}_poster_temp{ext}\")\n",
        "            \n",
        "            # Salva o conteúdo da resposta no arquivo.\n",
        "            with open(poster_temp_path, \"wb\") as f:\n",
        "                f.write(response.content)\n",
        "            \n",
        "            print(f\"🖼️ Poster baixado em: {poster_temp_path}\")\n",
        "            return poster_temp_path\n",
        "        except Exception as e:\n",
        "            # Em caso de qualquer erro (timeout, status ruim, etc.), loga e retorna None.\n",
        "            print(f\"❌ Erro ao baixar poster {poster_url}: {e}\")\n",
        "            return None\n",
        "    else:\n",
        "        # Se a URL não for válida, loga o erro e retorna None.\n",
        "        print(f\"❌ poster_url inválido: {poster_url}\")\n",
        "        return None\n",
        "\n",
        "def generate_poster_with_ffmpeg(m3u8_url, username, temp_folder=DRIVE_POSTERS_TEMP_PATH, frame_time=7, timeout=20):\n",
        "    \"\"\"\n",
        "    Gera um pôster (thumbnail) a partir de um stream de vídeo usando o ffmpeg.\n",
        "    Primeiro, verifica se o stream está online para evitar chamadas desnecessárias ao ffmpeg.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Faz uma requisição HEAD (mais leve) para verificar a disponibilidade do stream.\n",
        "        head_resp = requests.head(m3u8_url, timeout=5)\n",
        "        if not head_resp.ok:\n",
        "            # Se o stream não estiver acessível, loga e retorna None.\n",
        "            print(f\"⚠️ Stream offline para {username} (status {head_resp.status_code})\")\n",
        "            return None\n",
        "    except Exception as e:\n",
        "        # Se houver um erro de conexão, loga e retorna None.\n",
        "        print(f\"⚠️ Erro de conexão ao stream de {username}: {e}\")\n",
        "        return None\n",
        "\n",
        "    # Define o caminho de saída para o pôster gerado.\n",
        "    poster_ffmpeg_path = os.path.join(temp_folder, f\"{username}_poster_ffmpeg.jpg\")\n",
        "    # Constrói o comando ffmpeg para capturar um único frame do vídeo.\n",
        "    command = [\"ffmpeg\", \"-y\", \"-ss\", str(frame_time), \"-i\", m3u8_url, \"-vframes\", \"1\", \"-q:v\", \"2\", poster_ffmpeg_path]\n",
        "    \n",
        "    try:\n",
        "        print(f\"🎬 Gerando poster com ffmpeg para {username}...\")\n",
        "        # Executa o comando ffmpeg com um timeout para evitar que o processo trave.\n",
        "        result = subprocess.run(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, timeout=timeout)\n",
        "        # Se o comando foi bem-sucedido e o arquivo foi criado...\n",
        "        if result.returncode == 0 and os.path.exists(poster_ffmpeg_path):\n",
        "            print(f\"🖼️ Poster gerado via ffmpeg: {poster_ffmpeg_path}\")\n",
        "            return poster_ffmpeg_path\n",
        "        else:\n",
        "            # Caso contrário, loga a saída de erro do ffmpeg.\n",
        "            print(f\"❌ ffmpeg falhou para {username}. STDERR: {result.stderr.decode(errors='ignore')}\")\n",
        "            return None\n",
        "    except subprocess.TimeoutExpired:\n",
        "        # Se o comando demorar demais, loga o timeout.\n",
        "        print(f\"⏰ Tempo excedido ao gerar poster para {username}.\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        # Lida com outros erros inesperados.\n",
        "        print(f\"❌ Erro inesperado ao gerar poster: {e}\")\n",
        "        return None\n",
        "\n",
        "def is_poster_valid(poster_path):\n",
        "    \"\"\"\n",
        "    Verifica se um caminho de pôster é válido, ou seja, se o arquivo existe e não está vazio.\n",
        "    \"\"\"\n",
        "    return poster_path and os.path.exists(poster_path) and os.path.getsize(poster_path) > 0\n",
        "\n",
        "\n",
        "# =====================================================================================\n",
        "# 4. Rodapé / Fim do Código\n",
        "# =====================================================================================\n",
        "# @log de mudanças\n",
        "# - v4.6.1 (01/07/2025): Refatoração completa da célula para o padrão de documentação\n",
        "#   XCam, com adição de comentários detalhados e organização estrutural.\n",
        "#   Os caminhos temporários foram atualizados para usar as variáveis globais do Drive.\n",
        "# - v4.6.0: Versão inicial da Célula 3 com funções utilitárias.\n",
        "#\n",
        "# @roadmap futuro\n",
        "# - Refatorar as funções utilitárias em classes dedicadas (ex: `class VideoUtils`,\n",
        "#   `class PosterManager`) para melhorar o encapsulamento e a testabilidade.\n",
        "# - Integrar um sistema de cache para os pôsteres para reduzir o número de downloads\n",
        "#   e gerações via ffmpeg em execuções repetidas.\n",
        "# ====================================================================================="
      ]
    },
    {
      "cell_type": "markdown",
      "id": "hpRIMtyFIY0q",
      "metadata": {
        "id": "hpRIMtyFIY0q"
      },
      "source": [
        "# Célula 4: Clonagem do Repositório GitHub no Colab e Google Drive\n",
        "\n",
        "**Objetivo:**  \n",
        "Esta célula garante que o repositório do projeto XCam seja sempre clonado de forma limpa e sincronizada no ambiente local do Colab e, se disponível, também no Google Drive para persistência.  \n",
        "Assegura ambiente pronto, atualizado, seguro para gravações e processamento, e prepara diretórios padronizados para integração com o restante do pipeline.\n",
        "\n",
        "## Principais pontos e melhorias implementadas\n",
        "\n",
        "- **Clonagem idempotente e limpa:**  \n",
        "  Remove repositórios antigos antes de clonar para evitar conflitos, arquivos órfãos ou problemas de sincronização.\n",
        "- **Clonagem para ambiente temporário e persistente:**  \n",
        "  O repositório é clonado tanto para `/content` (Colab) quanto para o Drive (`/content/drive/MyDrive/XCam.Drive`) se o Drive estiver montado.\n",
        "- **Preparação de diretórios de gravação e processamento:**  \n",
        "  Estrutura de diretórios temporários criada automaticamente, garantindo organização dos dados.\n",
        "- **Exportação de variáveis globais:**  \n",
        "  Todos os caminhos, URLs e configurações relevantes são disponibilizados via `globals().update()` para uso em todo o notebook.\n",
        "- **Mensagens e validações detalhadas:**  \n",
        "  Feedback informativo sobre o status de cada etapa, facilitando o diagnóstico e a manutenção.\n",
        "- **Pronto para CI/CD e integrações futuras:**  \n",
        "  Token e URLs preparados para automações, integrações externas e uploads (Abyss.to, etc).\n",
        "\n",
        "---\n",
        "\n",
        "## Parâmetros globais definidos nesta célula\n",
        "\n",
        "- **`GITHUB_USER`**, **`GITHUB_REPO`**, **`GITHUB_BRANCH`**, **`GITHUB_TOKEN`**: Configurações do repositório e autenticação.\n",
        "- **`repo_url`**: URL do repositório autenticada para clone/push.\n",
        "- **`TEMP_OUTPUT_FOLDER`**: Pasta para gravações temporárias.\n",
        "- **`BASE_REPO_FOLDER`**: Localização do repositório no ambiente Colab.\n",
        "- **`DRIVE_MOUNT`**, **`DRIVE_REPO_FOLDER`**: Caminhos no Google Drive para persistência (se montado).\n",
        "- **`ABYSS_UPLOAD_URL`**: URL de upload para integração com sistemas externos.\n",
        "\n",
        "---\n",
        "\n",
        "## Como funciona a célula\n",
        "\n",
        "- **Remove repositórios antigos e diretórios temporários**, evitando resíduos de execuções anteriores.\n",
        "- **Clona o repositório do GitHub** para `/content` (Colab).\n",
        "- **Se o Google Drive estiver montado**, faz o mesmo clone no diretório persistente do Drive.\n",
        "- **Cria diretórios temporários necessários** para gravações e arquivos intermediários.\n",
        "- **Exporta todas as variáveis configuradas** para uso global no notebook.\n",
        "- **Exibe mensagens informativas** sobre cada etapa e alerta caso o Drive não esteja disponível.\n",
        "\n",
        "---\n",
        "\n",
        "## Exemplo de uso das variáveis globais\n",
        "\n",
        "```python\n",
        "print(BASE_REPO_FOLDER)        # Caminho do repositório clonado no Colab\n",
        "print(DRIVE_REPO_FOLDER)      # Caminho do repositório no Drive (se montado)\n",
        "print(TEMP_OUTPUT_FOLDER)     # Pasta temporária para gravações\n",
        "print(ABYSS_UPLOAD_URL)       # URL de upload para integração externa\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Segurança, rastreabilidade e manutenção\n",
        "\n",
        "- Garantia de ambiente limpo a cada execução, evitando conflitos de arquivos e branches.\n",
        "- Persistência dos dados no Drive (se montado), evitando perda de gravações em caso de reinicialização do Colab.\n",
        "- Comentários detalhados e estrutura modular facilitam a manutenção, integração com CI/CD e futuras expansões no pipeline do XCam.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Uof_0QCrIlf7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uof_0QCrIlf7",
        "outputId": "8c4fec8f-25ce-4649-a429-2a239eef6c23"
      },
      "outputs": [],
      "source": [
        "# =====================================================================================\n",
        "# XCam REC - Célula 4: Sincronização de Repositório (Git)\n",
        "# =====================================================================================\n",
        "# [@author]      Samuel Passamani / Um Projeto do Estudio A.Sério [AllS Company]\n",
        "# [@info]        https://aserio.work/\n",
        "# [@version]     4.6.2\n",
        "# [@lastupdate]  2025-07-01\n",
        "#\n",
        "# [@description]\n",
        "# Esta célula é responsável por preparar o ambiente de trabalho, garantindo que o\n",
        "# repositório do projeto XCam esteja sempre sincronizado e disponível. Ela realiza\n",
        "# uma clonagem limpa (removendo versões antigas para evitar conflitos) do\n",
        "# repositório do GitHub para dois locais estratégicos:\n",
        "#   1. O ambiente efêmero do Google Colab (/content) para execução rápida.\n",
        "#   2. O Google Drive do usuário para persistência de dados e metadados.\n",
        "# A célula também configura endpoints externos e propaga todas as variáveis de\n",
        "# caminho e configuração para o restante do notebook.\n",
        "#\n",
        "# [@mode]\n",
        "# Esta é uma célula de setup fundamental e deve ser executada antes de qualquer\n",
        "# outra célula de processamento, pois ela constrói a base do ambiente de execução.\n",
        "# =====================================================================================\n",
        "\n",
        "\n",
        "# =====================================================================================\n",
        "# 2. Configurações & Variáveis Globais\n",
        "# =====================================================================================\n",
        "\n",
        "# --- Configurações do Repositório GitHub ---\n",
        "# Define as credenciais e informações do repositório a ser clonado.\n",
        "GITHUB_USER = \"SamuelPassamani\"\n",
        "GITHUB_REPO = \"XCam\"\n",
        "GITHUB_BRANCH = \"main\"\n",
        "# NOTA DE SEGURANÇA: O token está hardcoded para facilitar. Em produção,\n",
        "# é recomendado usar os \"Secrets\" do Google Colab para armazená-lo com mais segurança.\n",
        "GITHUB_TOKEN = \"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\"\n",
        "\n",
        "# --- URL do Repositório com Autenticação ---\n",
        "# Constrói a URL de clonagem que inclui o token de acesso para permitir operações de push.\n",
        "repo_url = f\"https://{GITHUB_USER}:{GITHUB_TOKEN}@github.com/{GITHUB_USER}/{GITHUB_REPO}.git\"\n",
        "\n",
        "\n",
        "# =====================================================================================\n",
        "# 3. Corpo\n",
        "# =====================================================================================\n",
        "\n",
        "# --- Definição de Caminhos do Repositório ---\n",
        "# Caminho para o repositório no ambiente local e volátil do Colab.\n",
        "BASE_REPO_FOLDER = f\"/content/{GITHUB_REPO}\"\n",
        "# Caminho para o repositório no Google Drive, usando a variável definida na Célula 1 para persistência.\n",
        "DRIVE_REPO_FOLDER = f\"{DRIVE_BASE_PATH}/{GITHUB_REPO}\"\n",
        "\n",
        "# --- Bloco de Sincronização com o Ambiente Colab ---\n",
        "# Garante um ambiente limpo e atualizado a cada execução.\n",
        "print(f\"⏳ Limpando ambiente e clonando '{GITHUB_REPO}' para o Colab...\")\n",
        "# Remove qualquer pasta do repositório que possa ter sobrado de uma execução anterior.\n",
        "# Isso previne conflitos de git e garante uma cópia nova.\n",
        "!rm -rf {BASE_REPO_FOLDER}\n",
        "# Clona o branch especificado do repositório para a pasta base do Colab.\n",
        "!git clone -b {GITHUB_BRANCH} {repo_url} {BASE_REPO_FOLDER}\n",
        "print(f\"✅ Repositório clonado com sucesso em: {BASE_REPO_FOLDER}\")\n",
        "\n",
        "# --- Bloco de Sincronização com o Google Drive (Persistência) ---\n",
        "# Executa a mesma lógica de clonagem para o Google Drive, se estiver montado.\n",
        "if os.path.exists(DRIVE_BASE_PATH):\n",
        "    print(f\"⏳ Limpando e clonando '{GITHUB_REPO}' para o Google Drive para garantir persistência...\")\n",
        "    # Remove a versão antiga do repositório no Drive.\n",
        "    !rm -rf \"{DRIVE_REPO_FOLDER}\"\n",
        "    # Clona a nova versão para o Drive.\n",
        "    !git clone -b {GITHUB_BRANCH} {repo_url} \"{DRIVE_REPO_FOLDER}\"\n",
        "    print(f\"✅ Repositório também clonado no Drive: {DRIVE_REPO_FOLDER}\")\n",
        "else:\n",
        "    # Alerta o usuário caso o Drive não esteja montado, o que comprometeria a persistência.\n",
        "    print(f\"⚠️ Google Drive não está montado em {DRIVE_BASE_PATH}. A persistência do repositório no Drive está desativada.\")\n",
        "\n",
        "# --- Configuração de Endpoints Externos ---\n",
        "# Define a URL para o serviço de upload de vídeos.\n",
        "ABYSS_UPLOAD_URL = 'http://up.hydrax.net/0128263f78f0b426d617bb61c2a8ff43'\n",
        "\n",
        "# --- Propagação de Variáveis Globais ---\n",
        "# Torna todas as variáveis e caminhos definidos nesta célula acessíveis globalmente.\n",
        "globals().update({\n",
        "    'GITHUB_USER': GITHUB_USER,\n",
        "    'GITHUB_REPO': GITHUB_REPO,\n",
        "    'GITHUB_BRANCH': GITHUB_BRANCH,\n",
        "    'GITHUB_TOKEN': GITHUB_TOKEN,\n",
        "    'repo_url': repo_url,\n",
        "    'BASE_REPO_FOLDER': BASE_REPO_FOLDER,\n",
        "    'DRIVE_REPO_FOLDER': DRIVE_REPO_FOLDER,\n",
        "    'ABYSS_UPLOAD_URL': ABYSS_UPLOAD_URL\n",
        "})\n",
        "\n",
        "\n",
        "# =====================================================================================\n",
        "# 4. Rodapé / Fim do Código\n",
        "# =====================================================================================\n",
        "# @log de mudanças\n",
        "# - v4.6.2 (01/07/2025): Refatoração completa para o padrão de documentação XCam.\n",
        "#   Adição de comentários detalhados e organização estrutural. Removida a\n",
        "#   definição de TEMP_OUTPUT_FOLDER, que agora é gerenciada na Célula 1.\n",
        "# - v4.6.1: Código original da célula de clonagem.\n",
        "#\n",
        "# @roadmap futuro\n",
        "# - Mover a variável GITHUB_TOKEN para o sistema de \"Secrets\" do Google Colab para\n",
        "#   aumentar a segurança e evitar a exposição do token diretamente no código.\n",
        "# - Adicionar um bloco try/except para os comandos `git clone` para capturar\n",
        "#   possíveis erros de autenticação ou de rede e interromper a execução de forma\n",
        "#   controlada caso a clonagem falhe.\n",
        "# ====================================================================================="
      ]
    },
    {
      "cell_type": "markdown",
      "id": "M5iL_9BoIoj7",
      "metadata": {
        "id": "M5iL_9BoIoj7"
      },
      "source": [
        "# Célula 5: Commit e Push Automáticos (rec.json, posters, etc.)\n",
        "\n",
        "**Objetivo:**  \n",
        "Automatiza o processo de commit e push dos arquivos modificados (ex: rec.json, posters e demais artefatos importantes) para o repositório GitHub, garantindo rastreabilidade, atomicidade e integração contínua (CI/CD) do pipeline XCam.\n",
        "\n",
        "## Principais pontos e melhorias implementadas\n",
        "\n",
        "- **Função robusta e modular:**  \n",
        "  A função `git_commit_and_push()` aceita um caminho único (string) ou uma lista de arquivos, permitindo commit em lote e integração com estratégias de batch commit (threshold).\n",
        "- **Configuração automatizada de usuário e e-mail do git:**  \n",
        "  Garante commits válidos para rastreabilidade, auditoria e integração com pipelines automáticos.\n",
        "- **Validação de caminhos e mensagens informativas:**  \n",
        "  Apenas arquivos existentes são adicionados. Mensagens de sucesso, erro ou aviso detalhadas facilitam troubleshooting e manutenção.\n",
        "- **Compatível com commit vazio:**  \n",
        "  Permite o uso do parâmetro `--allow-empty` para garantir que o pipeline siga mesmo sem alterações detectadas, útil para sincronização e CI/CD.\n",
        "- **Push autenticado via token:**  \n",
        "  Utiliza o token pessoal fornecido nas variáveis globais para garantir push seguro e sem intervenção manual.\n",
        "- **Design pronto para integração com logs centralizados:**  \n",
        "  Recomenda-se registrar todas as ações relevantes de commit/push utilizando o log único modular definido na Célula 1.\n",
        "\n",
        "---\n",
        "\n",
        "## Parâmetros e variáveis globais utilizados\n",
        "\n",
        "- **`GITHUB_USER`**, **`GITHUB_REPO`**, **`GITHUB_TOKEN`**: Definidos nas células anteriores para autenticação e configuração do repositório.\n",
        "- **`repo_dir`**: Caminho absoluto do repositório clonado no ambiente Colab.\n",
        "- **`file_paths`**: String ou lista de arquivos a serem commitados e enviados.\n",
        "- **`commit_message`**: Mensagem do commit, customizável conforme a operação realizada.\n",
        "\n",
        "---\n",
        "\n",
        "## Como funciona a função principal\n",
        "\n",
        "- **Valida a existência do repositório local** antes de prosseguir.\n",
        "- **Aceita arquivos únicos ou múltiplos** para commit (string ou lista).\n",
        "- **Adiciona apenas arquivos existentes** ao staging, com avisos para arquivos não encontrados.\n",
        "- **Realiza commit (mesmo vazio) e push autenticado** para o repositório remoto.\n",
        "- **Emite mensagens claras** de sucesso, erro ou aviso ao longo do processo.\n",
        "\n",
        "---\n",
        "\n",
        "## Exemplo de uso típico\n",
        "\n",
        "```python\n",
        "# Commit e push de um único arquivo\n",
        "git_commit_and_push(\"data/rec.json\", \"Atualiza rec.json de gravação\")\n",
        "\n",
        "# Commit e push em lote (lista de arquivos)\n",
        "git_commit_and_push([\n",
        "    \"data/rec.json\",\n",
        "    \"posters/user1_poster.jpg\",\n",
        "    \"posters/user2_poster.jpg\"\n",
        "], \"Batch commit de múltiplos arquivos\")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Segurança, rastreabilidade e manutenção\n",
        "\n",
        "- **Rastreabilidade garantida** por mensagens de commit claras e integração recomendada com o log modular (Célula 1).\n",
        "- **Atomicidade** em operações batch, evitando inconsistências de dados no repositório.\n",
        "- **Pronto para integração com pipelines CI/CD**, webhooks e controles de auditoria.\n",
        "- **Mensagens e tratamento de erros detalhados** facilitam o diagnóstico e a evolução do sistema.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1aQn1G6yI6Gz",
      "metadata": {
        "id": "1aQn1G6yI6Gz"
      },
      "outputs": [],
      "source": [
        "# ================================================================\n",
        "# Célula 5: Commit e Push Automáticos (rec.json, posters, etc.)\n",
        "# ================================================================\n",
        "# Objetivo:\n",
        "# - Automatizar o processo de commit e push dos arquivos modificados (rec.json, posters, etc.) para o repositório GitHub\n",
        "# - Suportar tanto commit de arquivo único como em lote, permitindo estratégia de batch commit baseada em thresholds\n",
        "# - Garantir rastreabilidade, atomicidade e integração segura (CI/CD)\n",
        "#\n",
        "# Estratégia aplicada:\n",
        "# - Função modular e robusta, preparada para integração com logs e auditoria\n",
        "# - Permite commit vazio por segurança, evitando falhas em pipelines sincronizados\n",
        "# - Mensagens e tratamento de erros detalhados para facilitar troubleshooting\n",
        "# - Utilização de variáveis globais para caminhos, usuário e token definidos nas células anteriores\n",
        "# - Design pronto para evolução, reuso e integração com ferramentas externas (ex: webhooks, jobs, etc.)\n",
        "# ================================================================\n",
        "\n",
        "import os\n",
        "import subprocess\n",
        "\n",
        "def git_commit_and_push(file_paths, commit_message=\"Atualiza rec.json\"):\n",
        "    \"\"\"\n",
        "    Realiza git add, commit e push dos arquivos especificados.\n",
        "    - file_paths pode ser uma string (arquivo único) ou uma lista de arquivos.\n",
        "    - commit_message é a mensagem de commit utilizada.\n",
        "\n",
        "    Estratégia:\n",
        "    - Ajusta diretório para o repositório local clonado no Colab\n",
        "    - Configura usuário e e-mail do git (necessários para CI/CD)\n",
        "    - Adiciona arquivos ao staging (aceita múltiplos arquivos)\n",
        "    - Realiza commit (permite commit vazio)\n",
        "    - Realiza push autenticado via token\n",
        "    \"\"\"\n",
        "    # ============================\n",
        "    # VALIDAÇÃO E AJUSTE DE ENTRADAS\n",
        "    # ============================\n",
        "    repo_dir = f\"/content/{GITHUB_REPO}\"\n",
        "    if not os.path.exists(repo_dir):\n",
        "        raise FileNotFoundError(f\"Repositório '{repo_dir}' não encontrado. Verifique se a célula de clonagem foi executada.\")\n",
        "    os.chdir(repo_dir)\n",
        "\n",
        "    # Aceita string ou lista de arquivos\n",
        "    if isinstance(file_paths, str):\n",
        "        file_paths = [file_paths]\n",
        "    elif not isinstance(file_paths, list):\n",
        "        raise ValueError(\"file_paths deve ser uma string ou uma lista de caminhos.\")\n",
        "\n",
        "    # ============================\n",
        "    # CONFIGURAÇÃO DO USUÁRIO GIT (CI/CD)\n",
        "    # ============================\n",
        "    subprocess.run([\"git\", \"config\", \"user.email\", \"contato@aserio.work\"], check=True)\n",
        "    subprocess.run([\"git\", \"config\", \"user.name\", \"SamuelPassamani\"], check=True)\n",
        "\n",
        "    # ============================\n",
        "    # ADIÇÃO DOS ARQUIVOS AO STAGING\n",
        "    # ============================\n",
        "    for file_path in file_paths:\n",
        "        # Verifica se o arquivo existe antes de adicionar\n",
        "        if not os.path.exists(file_path):\n",
        "            print(f\"⚠️ Aviso: arquivo '{file_path}' não existe e será ignorado no commit.\")\n",
        "            continue\n",
        "        subprocess.run([\"git\", \"add\", file_path], check=True)\n",
        "\n",
        "    # ============================\n",
        "    # COMMIT (PERMITE COMMIT VAZIO)\n",
        "    # ============================\n",
        "    try:\n",
        "        subprocess.run(\n",
        "            [\"git\", \"commit\", \"-m\", commit_message, \"--allow-empty\"],\n",
        "            check=False  # Não força erro se não houver mudanças\n",
        "        )\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Erro ao tentar realizar commit: {e}\")\n",
        "\n",
        "    # ============================\n",
        "    # PUSH PARA O REPOSITÓRIO REMOTO (AUTENTICADO)\n",
        "    # ============================\n",
        "    try:\n",
        "        remote_url = f\"https://{GITHUB_USER}:{GITHUB_TOKEN}@github.com/{GITHUB_USER}/{GITHUB_REPO}.git\"\n",
        "        subprocess.run(\n",
        "            [\"git\", \"push\", remote_url],\n",
        "            check=True\n",
        "        )\n",
        "        print(f\"✅ Push realizado com sucesso! ({commit_message})\")\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Erro ao tentar realizar push: {e}\")\n",
        "\n",
        "# ============================\n",
        "# FIM DA CÉLULA 5\n",
        "# ============================\n",
        "\n",
        "# Dicas e melhores práticas:\n",
        "# - Use commit_messages claros e informativos para facilitar a auditoria.\n",
        "# - Utilize a função dentro de loops ou triggers de batch para commit em lote.\n",
        "# - Integre logs das ações de commit/push usando o log único centralizado (Célula 1).\n",
        "# - Em caso de erro de autenticação, revise o token e as permissões do GitHub."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "BZ4c3Uk1I7AK",
      "metadata": {
        "id": "BZ4c3Uk1I7AK"
      },
      "source": [
        "# Célula 6: Busca de Transmissões na API XCam, Blacklist Temporária, Fallback via liveInfo e Busca Inteligente/Unitária\n",
        "\n",
        "**Objetivo:**  \n",
        "Realizar a busca das transmissões ativas na API principal da XCam, mantendo o lote de transmissões sempre completo até o `LIMIT_DEFAULT` e sem duplicidades, utilizando controle de blacklist temporária e log de transmissões em processamento.  \n",
        "Inclui funções de busca unitária/inteligente (para manter “lote cheio” continuamente) e gerenciamento automático de poster, com geração via ffmpeg quando necessário.\n",
        "\n",
        "## Estratégia e melhorias implementadas\n",
        "\n",
        "- **Blacklist temporária e controle de falhas:**  \n",
        "  Usuários problemáticos são bloqueados temporariamente após atingirem o limite de falhas (`BLACKLIST_MAX_FAILURES`), acelerando o processamento e evitando ciclos infinitos.\n",
        "- **Busca em lote e unitária com fallback:**  \n",
        "  Consulta a API principal com limite alto para preencher o lote rapidamente. Caso necessário, realiza fallback via `/liveInfo` para usuários sem `src`.\n",
        "- **Controle de duplicidade e fila inteligente:**  \n",
        "  Antes de incluir qualquer transmissão, verifica no log de processamento e na blacklist para evitar tentativas repetidas ou paradas em streams problemáticos.\n",
        "- **Poster garantido:**  \n",
        "  Se o poster estiver ausente, inválido ou nulo, gera automaticamente uma imagem via ffmpeg a partir do stream, garantindo sempre um arquivo válido.\n",
        "- **Eficiência e paralelismo:**  \n",
        "  Todas as funções são preparadas para processamento paralelo e integração total ao pipeline XCam.\n",
        "- **Compatibilidade:**  \n",
        "  Suporte total à busca de usuários específicos, agora também protegida pela blacklist e controle de falhas.\n",
        "- **Design modular:**  \n",
        "  Funções separadas para busca em lote (`get_broadcasts`), busca por usuários (`buscar_usuarios_especificos`) e busca unitária/primeira transmissão livre (`buscar_proxima_transmissao_livre`), facilitando reuso e manutenção.\n",
        "\n",
        "---\n",
        "\n",
        "## Como funciona cada função\n",
        "\n",
        "- **get_broadcasts:**  \n",
        "  Retorna um lote de transmissões válidas, sempre checando blacklist, log de processamento e gerando poster se necessário. Realiza fallback automático para `/liveInfo` se não encontrar o src na API principal.\n",
        "- **buscar_usuarios_especificos:**  \n",
        "  Busca apenas os usuários informados, respeitando sempre o controle de blacklist/falhas, e faz fallback via `/liveInfo` quando necessário.\n",
        "- **buscar_proxima_transmissao_livre:**  \n",
        "  Busca rapidamente a próxima transmissão livre para processamento, sempre utilizando os mesmos critérios de controle, garantindo agilidade na fila e eficiência máxima.\n",
        "\n",
        "---\n",
        "\n",
        "## Detalhes técnicos e recomendações\n",
        "\n",
        "- **Blacklist temporária e controle de falhas:**  \n",
        "  Funções `register_failure`, `clear_failure`, `add_to_blacklist`, `is_in_blacklist`, `load_blacklist` e `save_blacklist` garantem rastreabilidade e bloqueio eficiente de usuários problemáticos.\n",
        "- **Arquitetura limpa e modular:**  \n",
        "  Código preparado para integração futura com log único centralizado e processamento concorrente.\n",
        "- **Poster sempre válido:**  \n",
        "  Funções utilitárias garantem que cada transmissão só é liberada para gravação se houver poster válido (baixado ou gerado).\n",
        "- **Tratamento de erros robusto:**  \n",
        "  Toda etapa crítica possui tratamento de exceções e mensagens claras para facilitar manutenção e monitoramento.\n",
        "\n",
        "---\n",
        "\n",
        "## Exemplo de uso das funções\n",
        "\n",
        "```python\n",
        "# Buscar lote completo de transmissões válidas\n",
        "streams = get_broadcasts(limit=LIMIT_DEFAULT)\n",
        "\n",
        "# Buscar apenas usuários específicos\n",
        "streams_especificos = buscar_usuarios_especificos([\"user1\", \"user2\"])\n",
        "\n",
        "# Buscar a próxima transmissão livre disponível\n",
        "proxima_stream = buscar_proxima_transmissao_livre()\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Rastreabilidade, manutenção e integração\n",
        "\n",
        "- Blacklist e falhas podem ser migrados para o log centralizado para máxima rastreabilidade.\n",
        "- Todas as funções são compatíveis com execução paralela e integração CI/CD.\n",
        "- Mensagens detalhadas e arquitetura modular facilitam manutenção e futuras expansões no pipeline do XCam.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "h1jr7D0pJ7jS",
      "metadata": {
        "id": "h1jr7D0pJ7jS"
      },
      "outputs": [],
      "source": [
        "# =====================================================================================\n",
        "# XCam REC - Célula 6: Busca Inteligente e Controle de Falhas\n",
        "# =====================================================================================\n",
        "# [@author]      Samuel Passamani / Um Projeto do Estudio A.Sério [AllS Company]\n",
        "# [@info]        https://aserio.work/\n",
        "# [@version]     4.6.2\n",
        "# [@lastupdate]  2025-07-01\n",
        "#\n",
        "# [@description]\n",
        "# Esta célula implementa a lógica de aquisição de transmissões. É responsável por\n",
        "# consultar a API da XCam, filtrar os resultados com base em um sistema robusto de\n",
        "# controle de falhas e blacklist temporária, e garantir que cada transmissão\n",
        "# selecionada para gravação tenha um pôster (thumbnail) válido. Ela contém\n",
        "# funções para buscar em lote, buscar usuários específicos e encontrar a próxima\n",
        "# transmissão livre de forma otimizada para o supervisor dinâmico.\n",
        "#\n",
        "# [@mode]\n",
        "# As funções desta célula são utilizadas pelo supervisor (Célula 9) em todos os modos\n",
        "# de operação, seja na busca automática por transmissões ou na busca por uma lista\n",
        "# específica de usuários fornecida.\n",
        "# =====================================================================================\n",
        "\n",
        "\n",
        "# =====================================================================================\n",
        "# 2. Configurações & Variáveis Globais (Dependências)\n",
        "# =====================================================================================\n",
        "\n",
        "# Esta célula depende das seguintes variáveis globais definidas na Célula 1:\n",
        "# - BLACKLIST_LOG_FILE: Caminho para o arquivo de log da blacklist.\n",
        "# - FAILURE_LOG_FILE: Caminho para o arquivo de log de contagem de falhas.\n",
        "# - PROCESSING_LOG_FILE: Caminho para o arquivo de log de usuários em processamento.\n",
        "# - BLACKLIST_TIMEOUT: Duração em segundos que um usuário fica na blacklist.\n",
        "# - BLACKLIST_MAX_FAILURES: Número de falhas para um usuário entrar na blacklist.\n",
        "# - As funções utilitárias (download_and_save_poster, etc.) da Célula 3.\n",
        "\n",
        "\n",
        "# =====================================================================================\n",
        "# 3. Corpo\n",
        "# =====================================================================================\n",
        "\n",
        "# --- Bloco de Gerenciamento da Blacklist Temporária ---\n",
        "# Este bloco contém funções CRUD para o arquivo de log da blacklist.\n",
        "# NOTA: Em uma versão futura, esta lógica pode ser migrada para o log central.\n",
        "\n",
        "def load_blacklist():\n",
        "    \"\"\"\n",
        "    Carrega a lista de usuários em blacklist do arquivo.\n",
        "    Filtra e remove automaticamente entradas que já expiraram com base no BLACKLIST_TIMEOUT.\n",
        "    \"\"\"\n",
        "    # Se o arquivo não existe, retorna um dicionário vazio.\n",
        "    if not os.path.exists(BLACKLIST_LOG_FILE): return {}\n",
        "    # Abre o arquivo para leitura.\n",
        "    with open(BLACKLIST_LOG_FILE, \"r\") as f:\n",
        "        now = time.time() # Obtém o timestamp atual para comparar.\n",
        "        # Lê cada linha, separando usuário e timestamp.\n",
        "        lines = [line.strip().split(\",\") for line in f if line.strip()]\n",
        "        # Retorna um dicionário apenas com os usuários cuja blacklist ainda não expirou.\n",
        "        return {user: float(ts) for user, ts in lines if now - float(ts) < BLACKLIST_TIMEOUT}\n",
        "\n",
        "def save_blacklist(blacklist):\n",
        "    \"\"\"Salva o dicionário da blacklist de volta no arquivo de log.\"\"\"\n",
        "    with open(BLACKLIST_LOG_FILE, \"w\") as f:\n",
        "        for user, ts in blacklist.items():\n",
        "            f.write(f\"{user},{ts}\\\\n\")\n",
        "\n",
        "def add_to_blacklist(username):\n",
        "    \"\"\"Adiciona um usuário à blacklist com o timestamp atual.\"\"\"\n",
        "    blacklist = load_blacklist() # Carrega a blacklist atual.\n",
        "    blacklist[username] = time.time() # Adiciona/atualiza o usuário com o novo timestamp.\n",
        "    save_blacklist(blacklist) # Salva a blacklist atualizada.\n",
        "    print(f\"⚠️ Usuário '{username}' adicionado à blacklist temporária.\")\n",
        "\n",
        "def is_in_blacklist(username):\n",
        "    \"\"\"Verifica de forma rápida se um usuário está atualmente na blacklist.\"\"\"\n",
        "    return username in load_blacklist()\n",
        "\n",
        "# --- Bloco de Gerenciamento de Falhas de Gravação ---\n",
        "# Controla quantas vezes consecutivas a gravação de um usuário falhou.\n",
        "\n",
        "def load_failures():\n",
        "    \"\"\"Carrega o dicionário de contagem de falhas (usuário: contagem) do arquivo.\"\"\"\n",
        "    if not os.path.exists(FAILURE_LOG_FILE): return {}\n",
        "    with open(FAILURE_LOG_FILE, \"r\") as f:\n",
        "        return {user: int(count) for user, count in (line.strip().split(\",\") for line in f if line.strip())}\n",
        "\n",
        "def save_failures(failures):\n",
        "    \"\"\"Salva o dicionário de falhas de volta no arquivo de log.\"\"\"\n",
        "    with open(FAILURE_LOG_FILE, \"w\") as f:\n",
        "        for user, count in failures.items():\n",
        "            f.write(f\"{user},{count}\\\\n\")\n",
        "\n",
        "def register_failure(username):\n",
        "    \"\"\"\n",
        "    Registra uma falha para um usuário. Se o limite for atingido,\n",
        "    o usuário é movido para a blacklist e seu contador de falhas é zerado.\n",
        "    \"\"\"\n",
        "    failures = load_failures() # Carrega as falhas atuais.\n",
        "    failures[username] = failures.get(username, 0) + 1 # Incrementa o contador.\n",
        "    # Verifica se o limite de falhas foi atingido.\n",
        "    if failures[username] >= BLACKLIST_MAX_FAILURES:\n",
        "        add_to_blacklist(username) # Adiciona à blacklist.\n",
        "        failures.pop(username, None) # Remove do contador de falhas.\n",
        "    save_failures(failures) # Salva o estado atualizado.\n",
        "\n",
        "def clear_failure(username):\n",
        "    \"\"\"Limpa o contador de falhas para um usuário (usado após uma gravação bem-sucedida).\"\"\"\n",
        "    failures = load_failures() # Carrega as falhas.\n",
        "    if username in failures: # Se o usuário tiver um registro de falha...\n",
        "        failures.pop(username) # ...remove o registro.\n",
        "        save_failures(failures) # Salva o estado limpo.\n",
        "\n",
        "# --- Funções de Busca na API XCam ---\n",
        "\n",
        "def get_broadcasts(limit=LIMIT_DEFAULT, page=PAGE_DEFAULT, usuarios_especificos=None, temp_folder=DRIVE_POSTERS_TEMP_PATH):\n",
        "    \"\"\"\n",
        "    Função principal de busca em lote.\n",
        "    Retorna uma lista de transmissões válidas, prontas para gravação.\n",
        "    \"\"\"\n",
        "    # Carrega a lista de usuários que já estão em processo de gravação para evitar duplicidade.\n",
        "    transmissao_em_proc = set()\n",
        "    if os.path.exists(PROCESSING_LOG_FILE):\n",
        "        with open(PROCESSING_LOG_FILE, \"r\") as f:\n",
        "            transmissao_em_proc = set([line.strip() for line in f if line.strip()])\n",
        "\n",
        "    # Define a URL da API, ajustando o limite se for uma busca por usuários específicos.\n",
        "    api_url_main = f\"https://api.xcam.gay/?limit={API_SEARCH_LIMIT if usuarios_especificos else 1500}&page=1\"\n",
        "    print(f\"🌐 Acessando API: {api_url_main}\")\n",
        "\n",
        "    streams_from_main = []      # Lista para streams com URL direta.\n",
        "    streams_without_preview = [] # Lista para streams que precisarão de fallback.\n",
        "\n",
        "    try:\n",
        "        # Faz a requisição para a API principal.\n",
        "        response_main = requests.get(api_url_main, timeout=30)\n",
        "        response_main.raise_for_status() # Lança um erro se a resposta não for 2xx.\n",
        "        items = response_main.json().get(\"broadcasts\", {}).get(\"items\", [])\n",
        "\n",
        "        # Processa cada item retornado pela API.\n",
        "        for item in items:\n",
        "            username = item.get(\"username\")\n",
        "            # Pula se o usuário for inválido, estiver em processamento ou na blacklist.\n",
        "            if not username or username in transmissao_em_proc or is_in_blacklist(username):\n",
        "                continue\n",
        "            # Se for uma busca específica, pula usuários que não estão na lista.\n",
        "            if usuarios_especificos and username not in usuarios_especificos:\n",
        "                continue\n",
        "\n",
        "            src = item.get(\"preview\", {}).get(\"src\")\n",
        "            # Se o item já tem uma URL de stream...\n",
        "            if src:\n",
        "                # ... tenta obter um pôster válido.\n",
        "                poster_url = item.get(\"preview\", {}).get(\"poster\")\n",
        "                poster_path = download_and_save_poster(poster_url, username, temp_folder) or generate_poster_with_ffmpeg(src, username, temp_folder)\n",
        "                if is_poster_valid(poster_path):\n",
        "                    streams_from_main.append({\"username\": username, \"src\": src, \"poster\": poster_path})\n",
        "                    clear_failure(username) # Limpa falhas se obteve dados válidos.\n",
        "                else:\n",
        "                    register_failure(username) # Registra falha se não conseguiu obter o pôster.\n",
        "            else:\n",
        "                # Se não tem URL, adiciona à lista de fallback.\n",
        "                streams_without_preview.append({\"username\": username})\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Erro ao acessar API principal: {e}\")\n",
        "\n",
        "    # Processo de Fallback para streams sem URL direta.\n",
        "    if streams_without_preview:\n",
        "        print(f\"🔁 Buscando liveInfo para {len(streams_without_preview)} streams...\")\n",
        "        for stream_info in streams_without_preview:\n",
        "            username = stream_info[\"username\"]\n",
        "            # Novamente, verifica se o usuário deve ser processado.\n",
        "            if username in transmissao_em_proc or is_in_blacklist(username):\n",
        "                continue\n",
        "            \n",
        "            # Tenta a API de liveInfo.\n",
        "            try:\n",
        "                live_info_url = f\"https://api.xcam.gay/user/{username}/liveInfo\"\n",
        "                response_liveinfo = requests.get(live_info_url, timeout=10)\n",
        "                response_liveinfo.raise_for_status()\n",
        "                data_liveinfo = response_liveinfo.json()\n",
        "                m3u8_url = data_liveinfo.get(\"cdnURL\") or data_liveinfo.get(\"edgeURL\")\n",
        "                \n",
        "                if m3u8_url:\n",
        "                    poster_path = generate_poster_with_ffmpeg(m3u8_url, username, temp_folder)\n",
        "                    if is_poster_valid(poster_path):\n",
        "                        streams_from_main.append({\"username\": username, \"src\": m3u8_url, \"poster\": poster_path})\n",
        "                        clear_failure(username)\n",
        "                    else:\n",
        "                        register_failure(username)\n",
        "                else:\n",
        "                    register_failure(username)\n",
        "            except Exception as ex:\n",
        "                print(f\"❌ Erro no fallback liveInfo para {username}: {ex}\")\n",
        "                register_failure(username)\n",
        "            time.sleep(0.5) # Pequena pausa para não sobrecarregar a API.\n",
        "\n",
        "    # Combina e filtra a lista final.\n",
        "    final_streams_list = []\n",
        "    seen_usernames = set()\n",
        "    for stream in streams_from_main:\n",
        "        if stream[\"username\"] not in seen_usernames:\n",
        "            final_streams_list.append(stream)\n",
        "            seen_usernames.add(stream[\"username\"])\n",
        "            if len(final_streams_list) >= limit:\n",
        "                break\n",
        "    \n",
        "    print(f\"🔎 Selecionadas {len(final_streams_list)} streams válidas para processamento (limite: {limit}).\")\n",
        "    return final_streams_list\n",
        "\n",
        "def buscar_usuarios_especificos(usuarios_lista, temp_folder=DRIVE_POSTERS_TEMP_PATH):\n",
        "    \"\"\"Função de conveniência para buscar uma lista específica de usuários.\"\"\"\n",
        "    return get_broadcasts(limit=len(usuarios_lista), usuarios_especificos=usuarios_lista, temp_folder=temp_folder)\n",
        "\n",
        "def buscar_proxima_transmissao_livre(temp_folder=DRIVE_POSTERS_TEMP_PATH):\n",
        "    \"\"\"\n",
        "    Busca de forma otimizada apenas a PRÓXIMA transmissão livre,\n",
        "    ideal para preencher vagas no lote do supervisor.\n",
        "    \"\"\"\n",
        "    # Chama a função principal com limite 1 para retornar assim que encontrar a primeira válida.\n",
        "    streams = get_broadcasts(limit=1, temp_folder=temp_folder)\n",
        "    if streams:\n",
        "        print(f\"🎯 Próxima transmissão livre encontrada: {streams[0]['username']}\")\n",
        "        return streams[0]\n",
        "    else:\n",
        "        print(\"🚫 Nenhuma transmissão livre encontrada no momento.\")\n",
        "        return None\n",
        "\n",
        "# =====================================================================================\n",
        "# 4. Rodapé / Fim do Código\n",
        "# =====================================================================================\n",
        "# @log de mudanças\n",
        "# - v4.6.2 (01/07/2025): Refatoração completa para o padrão de documentação XCam.\n",
        "#   Adição de comentários detalhados e organização estrutural.\n",
        "# - v4.6.1: Atualização dos caminhos de log para usar as variáveis globais da Célula 1.\n",
        "# - v4.6.0: Versão inicial com lógica de busca e blacklist.\n",
        "#\n",
        "# @roadmap futuro\n",
        "# - Centralizar 100% a lógica de `blacklist` e `failures` no sistema de log único da\n",
        "#   Célula 1, eliminando os arquivos `xcam_blacklist.log` e `xcam_failures.log`.\n",
        "# - Implementar um cache para as respostas da API para reduzir o número de requisições\n",
        "#   em execuções muito próximas.\n",
        "# ====================================================================================="
      ]
    },
    {
      "cell_type": "markdown",
      "id": "jGFyqOUoKEF7",
      "metadata": {
        "id": "jGFyqOUoKEF7"
      },
      "source": [
        "# Célula 7: Gravação da Stream, Poster Automático, Controle de Falhas, Log Seguro e Blacklist Inteligente\n",
        "\n",
        "**Objetivo:**  \n",
        "Automatizar a gravação de transmissões ao vivo com ffmpeg, garantindo robustez, rastreabilidade e integração com a lógica de blacklist temporária e controle de falhas. A célula também assegura o gerenciamento seguro do log de transmissões em processamento e a limpeza de arquivos temporários.\n",
        "\n",
        "## Estratégia e melhorias implementadas\n",
        "\n",
        "- **Gerenciamento seguro de log:**  \n",
        "  O usuário é registrado no log de transmissões em processamento antes da gravação e removido dele ao final (tanto em sucesso quanto em erro), evitando duplicidade e permitindo paralelismo seguro.\n",
        "- **Poster sempre válido:**  \n",
        "  O sistema tenta baixar o poster da API. Se o poster estiver ausente, inválido ou nulo, gera automaticamente uma imagem via ffmpeg, assegurando que toda transmissão tenha um poster associado e válido.\n",
        "- **Controle de tempo mínimo:**  \n",
        "  Se a gravação resultar em vídeo muito curto, tanto o arquivo de vídeo quanto o poster são descartados imediatamente, e uma falha é registrada para o usuário.\n",
        "- **Tratamento robusto de falhas:**  \n",
        "  Qualquer falha (ffmpeg, exceptions, etc.) é registrada. Ao atingir o número máximo de falhas consecutivas (`BLACKLIST_MAX_FAILURES`), o usuário entra automaticamente na blacklist temporária, evitando tentativas infinitas e desperdício de recursos.\n",
        "- **Limpeza automatizada:**  \n",
        "  Após upload ou erro, todos os arquivos temporários (vídeo e poster) são removidos, otimizando o uso do disco e mantendo o ambiente do Colab limpo.\n",
        "- **Reset de falhas em caso de sucesso:**  \n",
        "  Quando a gravação é válida, o contador de falhas do usuário é limpo, evitando blacklist indevida.\n",
        "- **Comentários detalhados e código modular:**  \n",
        "  O fluxo é completamente documentado, facilitando manutenção, revisão e entendimento por toda a equipe.\n",
        "\n",
        "---\n",
        "\n",
        "## Fluxo resumido da função principal\n",
        "\n",
        "1. **Registra o usuário** no log de transmissões em processamento.\n",
        "2. **Garante um poster válido** (download ou geração automática).\n",
        "3. **Executa o ffmpeg** para gravar a transmissão e monitora o progresso em tempo real.\n",
        "4. **Valida a gravação**:\n",
        "   - Se falhar, registra falha e trata blacklist.\n",
        "   - Se for curta demais, descarta e registra falha.\n",
        "   - Se for válida, limpa contador de falhas e prossegue normalmente.\n",
        "5. **Após upload ou erro**, remove o usuário do log e limpa arquivos temporários.\n",
        "\n",
        "---\n",
        "\n",
        "## Exemplo de uso\n",
        "\n",
        "```python\n",
        "resultado = gravar_stream(username=\"user123\", m3u8_url=\"https://cdn.xcam.gay/m3u8/...\", poster_url=\"https://api.xcam.gay/poster/...\")\n",
        "if resultado['upload_success']:\n",
        "    print(\"Gravação e upload realizados com sucesso!\")\n",
        "else:\n",
        "    print(\"Falha na gravação ou upload:\", resultado['abyss_response'])\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Segurança, rastreabilidade e integração\n",
        "\n",
        "- **Pronto para CI/CD e execução paralela:**  \n",
        "  Controle rigoroso de log e blacklist garante execução concorrente, segura e rastreável por todo o pipeline XCam.\n",
        "- **Integração total com as funções globais:**  \n",
        "  Utiliza funções de blacklist e falha da Célula 6, promovendo rastreabilidade e controle centralizado.\n",
        "- **Diagnóstico facilitado:**  \n",
        "  Mensagens e logs detalhados em cada etapa do processo.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eJ_jrfNgKZNr",
      "metadata": {
        "id": "eJ_jrfNgKZNr"
      },
      "outputs": [],
      "source": [
        "# =====================================================================================\n",
        "# XCam REC - Célula 7: Worker de Gravação (ffmpeg)\n",
        "# =====================================================================================\n",
        "# [@author]      Samuel Passamani / Um Projeto do Estudio A.Sério [AllS Company]\n",
        "# [@info]        https://aserio.work/\n",
        "# [@version]     4.6.2\n",
        "# [@lastupdate]  2025-07-01\n",
        "#\n",
        "# [@description]\n",
        "# Esta célula contém a lógica principal do worker de gravação. Cada processo paralelo\n",
        "# executará a função `gravar_stream` para realizar as seguintes tarefas:\n",
        "#   1. Registrar-se como \"em processamento\" para evitar gravações duplicadas.\n",
        "#   2. Garantir a existência de um pôster (thumbnail) válido, baixando ou gerando via ffmpeg.\n",
        "#   3. Executar o comando `ffmpeg` para gravar o stream de vídeo.\n",
        "#   4. Monitorar o progresso da gravação em tempo real.\n",
        "#   5. Validar o arquivo de vídeo final, checando sua duração mínima.\n",
        "#   6. Interagir com o sistema de controle de falhas e blacklist (Célula 6).\n",
        "#   7. Passar os artefatos para a próxima etapa (upload e pós-processamento, Célula 8).\n",
        "#   8. Garantir a limpeza de todos os arquivos temporários, independentemente do resultado.\n",
        "#\n",
        "# [@mode]\n",
        "# As funções desta célula são o \"trabalho pesado\" do notebook e são executadas\n",
        "# pelos processos paralelos gerenciados pelo supervisor (Célula 9).\n",
        "# =====================================================================================\n",
        "\n",
        "\n",
        "# =====================================================================================\n",
        "# 2. Configurações & Variáveis Globais (Dependências)\n",
        "# =====================================================================================\n",
        "\n",
        "# Esta célula depende das seguintes variáveis e funções globais:\n",
        "# - Definidas na Célula 1:\n",
        "#   - PROCESSING_LOG_FILE: Caminho para o log de usuários em processamento.\n",
        "#   - DRIVE_RECORDS_TEMP_PATH: Pasta para salvar os vídeos temporários.\n",
        "#   - DRIVE_POSTERS_TEMP_PATH: Pasta para salvar os pôsteres temporários.\n",
        "#   - RECORD_SECONDS: Duração máxima da gravação.\n",
        "#   - RECORD_SECONDS_MIN: Duração mínima para um vídeo ser considerado válido.\n",
        "# - Definidas na Célula 3:\n",
        "#   - download_and_save_poster(), generate_poster_with_ffmpeg(), is_poster_valid()\n",
        "#   - format_seconds(), log_progress()\n",
        "# - Definidas na Célula 6:\n",
        "#   - register_failure(), clear_failure()\n",
        "# - Definidas na Célula 8:\n",
        "#   - upload_to_abyss_and_update_json()\n",
        "\n",
        "\n",
        "# =====================================================================================\n",
        "# 3. Corpo\n",
        "# =====================================================================================\n",
        "\n",
        "def get_video_duration(filepath):\n",
        "    \"\"\"\n",
        "    Retorna a duração real de um arquivo de vídeo em segundos, utilizando o ffprobe.\n",
        "    É o método mais confiável para validar a gravação.\n",
        "    Retorna None em caso de erro ou se o arquivo não for encontrado.\n",
        "    \"\"\"\n",
        "    # Verifica se o arquivo de fato existe antes de tentar analisá-lo.\n",
        "    if not os.path.exists(filepath):\n",
        "        print(f\"⚠️ Arquivo para ffprobe não encontrado: {filepath}\")\n",
        "        return None\n",
        "    try:\n",
        "        # Comando ffprobe para extrair a duração do formato em formato JSON.\n",
        "        cmd = [\"ffprobe\", \"-v\", \"error\", \"-show_entries\", \"format=duration\", \"-of\", \"json\", filepath]\n",
        "        # Executa o comando com um timeout para evitar travamentos.\n",
        "        result = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True, timeout=60)\n",
        "        # Converte a saída JSON para um dicionário Python.\n",
        "        info = json.loads(result.stdout)\n",
        "        # Retorna a duração como um número inteiro.\n",
        "        return int(round(float(info[\"format\"][\"duration\"])))\n",
        "    except Exception as e:\n",
        "        # Em caso de erro (arquivo corrompido, etc.), loga e retorna None.\n",
        "        print(f\"⚠️ Erro no ffprobe para {filepath}: {e}\")\n",
        "        return None\n",
        "\n",
        "def gravar_stream(username, m3u8_url, poster_url=None, poster_frame_time=7):\n",
        "    \"\"\"\n",
        "    Função principal do worker: orquestra a gravação de um único stream.\n",
        "    \"\"\"\n",
        "    # --- Etapa 1: Registro de Processamento ---\n",
        "    # Adiciona o usuário ao log de processamento para evitar que outro worker o pegue.\n",
        "    with open(PROCESSING_LOG_FILE, \"a\") as f:\n",
        "        f.write(f\"{username}\\\\n\")\n",
        "\n",
        "    # Define nomes de arquivos e caminhos temporários usando as variáveis globais.\n",
        "    start_time_dt = datetime.now()\n",
        "    temp_filename = f\"{username}_{start_time_dt.strftime('%Y%m%d_%H%M%S')}_temp.mp4\"\n",
        "    filepath = os.path.join(DRIVE_RECORDS_TEMP_PATH, temp_filename)\n",
        "    print(f\"\\\\n🎬 Iniciando gravação de: {username} em {filepath}\")\n",
        "\n",
        "    # --- Etapa 2: Garantia de Pôster Válido ---\n",
        "    poster_temp_path = None\n",
        "    # Tenta primeiro baixar o pôster da URL fornecida.\n",
        "    if poster_url:\n",
        "        poster_temp_path = download_and_save_poster(poster_url, username, DRIVE_POSTERS_TEMP_PATH)\n",
        "    # Se o download falhar ou não houver URL, tenta gerar via ffmpeg como fallback.\n",
        "    if not is_poster_valid(poster_temp_path) and m3u8_url:\n",
        "        poster_temp_path = generate_poster_with_ffmpeg(m3u8_url, username, DRIVE_POSTERS_TEMP_PATH, frame_time=poster_frame_time)\n",
        "\n",
        "    # --- Etapa 3: Execução do FFmpeg ---\n",
        "    # Constrói o comando ffmpeg para a gravação.\n",
        "    # -c copy: copia o stream diretamente sem re-encodar, o que é muito mais rápido e leve.\n",
        "    ffmpeg_cmd = [\"ffmpeg\", \"-i\", m3u8_url, \"-t\", str(RECORD_SECONDS), \"-c\", \"copy\", \"-y\", filepath]\n",
        "    \n",
        "    # O bloco try/finally garante que a limpeza ocorrerá mesmo se a gravação falhar.\n",
        "    try:\n",
        "        # Inicia o processo ffmpeg.\n",
        "        process = subprocess.Popen(\n",
        "            ffmpeg_cmd,\n",
        "            stdout=subprocess.PIPE,\n",
        "            stderr=subprocess.STDOUT,\n",
        "            text=True,\n",
        "            bufsize=1,\n",
        "            universal_newlines=True\n",
        "        )\n",
        "\n",
        "        # Monitora a saída do ffmpeg em tempo real para exibir o progresso.\n",
        "        last_log_time = time.time()\n",
        "        for line in iter(process.stdout.readline, ''):\n",
        "            if \"time=\" in line:\n",
        "                # Loga o progresso a cada minuto para não poluir o console.\n",
        "                if time.time() - last_log_time > 60:\n",
        "                    try:\n",
        "                        match = re.search(r\"time=(\\\\d+):(\\\\d+):(\\\\d+)\", line)\n",
        "                        if match:\n",
        "                            h, m, s = map(int, match.groups())\n",
        "                            elapsed_seconds = h * 3600 + m * 60 + s\n",
        "                            log_progress(username, elapsed_seconds, RECORD_SECONDS)\n",
        "                            last_log_time = time.time()\n",
        "                    except Exception:\n",
        "                        pass # Ignora erros de parsing de progresso.\n",
        "        \n",
        "        # Espera o processo ffmpeg terminar.\n",
        "        process.wait()\n",
        "\n",
        "        # --- Etapa 4: Validação Pós-Gravação ---\n",
        "        # Verifica se o ffmpeg terminou com erro.\n",
        "        if process.returncode != 0:\n",
        "            raise Exception(f\"FFmpeg falhou com código {process.returncode}\")\n",
        "\n",
        "        # Valida a duração real do arquivo gerado.\n",
        "        elapsed_seconds_real = get_video_duration(filepath)\n",
        "        if elapsed_seconds_real is None or elapsed_seconds_real < RECORD_SECONDS_MIN:\n",
        "            raise ValueError(f\"Gravação muito curta ({elapsed_seconds_real}s)\")\n",
        "\n",
        "        # --- Etapa 5: Sucesso ---\n",
        "        # Se a gravação foi bem-sucedida, limpa o contador de falhas do usuário.\n",
        "        clear_failure(username)\n",
        "        # Formata o nome final do arquivo com data, hora e duração.\n",
        "        data_str = start_time_dt.strftime(\"%d-%m-%Y\")\n",
        "        horario_str = start_time_dt.strftime(\"%H-%M\")\n",
        "        tempo_formatado = format_seconds(elapsed_seconds_real)\n",
        "        final_filename = f\"{username}_{data_str}_{horario_str}_{tempo_formatado}.mp4\"\n",
        "        final_filepath = os.path.join(DRIVE_RECORDS_TEMP_PATH, final_filename)\n",
        "        # Renomeia o arquivo temporário para o nome final.\n",
        "        os.rename(filepath, final_filepath)\n",
        "        filepath = final_filepath # Atualiza o ponteiro para o novo nome.\n",
        "\n",
        "        # Passa os artefatos para a próxima célula (upload e pós-processamento).\n",
        "        success, abyss_resp, slug = upload_to_abyss_and_update_json(\n",
        "            final_filepath, username, elapsed_seconds_real, poster_temp_path=poster_temp_path\n",
        "        )\n",
        "        # Retorna um dicionário com o resultado completo da operação.\n",
        "        return {'upload_success': success, 'abyss_response': abyss_resp, 'slug': slug, 'username': username, 'filename': final_filename}\n",
        "\n",
        "    except Exception as e:\n",
        "        # --- Etapa 6: Tratamento de Falha ---\n",
        "        # Se qualquer erro ocorrer, registra uma falha para o usuário.\n",
        "        print(f\"❌ Erro na gravação de {username}: {e}\")\n",
        "        register_failure(username)\n",
        "        # Retorna um dicionário indicando a falha.\n",
        "        return {'upload_success': False, 'abyss_response': str(e), 'username': username, 'filename': temp_filename}\n",
        "\n",
        "    finally:\n",
        "        # --- Etapa 7: Limpeza Robusta ---\n",
        "        # Este bloco é executado sempre, garantindo a limpeza do ambiente.\n",
        "        \n",
        "        # Remove o usuário do log de processamento.\n",
        "        if os.path.exists(PROCESSING_LOG_FILE):\n",
        "            with open(PROCESSING_LOG_FILE, \"r\") as f: lines = f.readlines()\n",
        "            with open(PROCESSING_LOG_FILE, \"w\") as f:\n",
        "                for line in lines:\n",
        "                    if line.strip() != username: f.write(line)\n",
        "        \n",
        "        # Remove o arquivo de vídeo temporário, se ainda existir.\n",
        "        if os.path.exists(filepath):\n",
        "            try:\n",
        "                os.remove(filepath)\n",
        "                print(f\"🗑️ Vídeo temporário removido: {filepath}\")\n",
        "            except OSError as e:\n",
        "                print(f\"⚠️ Falha ao remover vídeo temporário: {e}\")\n",
        "\n",
        "        # Remove o arquivo de pôster temporário, se ainda existir.\n",
        "        if poster_temp_path and os.path.exists(poster_temp_path):\n",
        "            try:\n",
        "                os.remove(poster_temp_path)\n",
        "                print(f\"🗑️ Poster temporário removido: {poster_temp_path}\")\n",
        "            except OSError as e:\n",
        "                print(f\"⚠️ Falha ao remover poster temporário: {e}\")\n",
        "\n",
        "\n",
        "# =====================================================================================\n",
        "# 4. Rodapé / Fim do Código\n",
        "# =====================================================================================\n",
        "# @log de mudanças\n",
        "# - v4.6.2 (01/07/2025): Refatoração completa para o padrão de documentação XCam,\n",
        "#   com comentários detalhados em cada etapa da função de gravação.\n",
        "# - v4.6.1: Atualização dos caminhos de arquivo para usar as variáveis globais\n",
        "#   do Google Drive definidas na Célula 1.\n",
        "# - v4.6.0: Versão inicial da função de gravação.\n",
        "#\n",
        "# @roadmap futuro\n",
        "# - Implementar um parsing mais avançado da saída do ffmpeg para extrair mais\n",
        "#   metadados, como bitrate e resolução, e salvá-los no `rec.json`.\n",
        "# - Adicionar uma verificação de espaço em disco no Google Drive antes de iniciar\n",
        "#   uma nova gravação para evitar falhas por falta de armazenamento.\n",
        "# ====================================================================================="
      ]
    },
    {
      "cell_type": "markdown",
      "id": "YjGKDlbIKaLs",
      "metadata": {
        "id": "YjGKDlbIKaLs"
      },
      "source": [
        "# Célula 8: Upload para Abyss.to, Atualização do rec.json, Commit Poster e Sincronização com Google Drive\n",
        "\n",
        "**Objetivo:**  \n",
        "Realizar upload do vídeo gravado para Abyss.to, registrar e atualizar todos os metadados relevantes no arquivo `rec.json` do usuário, garantir a movimentação/renomeação adequada do poster e executar o commit/push automatizado de arquivos alterados, sincronizando também com o Google Drive.  \n",
        "O processo é otimizado para processamento em lote: os arquivos modificados só são enviados quando o número atingir o limiar (`COMMIT_PUSH_THRESHOLD`), promovendo eficiência e integridade do repositório, mesmo em execução paralela.\n",
        "\n",
        "---\n",
        "\n",
        "## Estratégia e melhorias implementadas\n",
        "\n",
        "- **Commit/push em lote otimizado:**  \n",
        "  Arquivos alterados são acumulados em um buffer. O commit e push são executados automaticamente apenas quando a quantidade de arquivos atinge o threshold configurado, reduzindo conflitos e otimizando o workflow CI/CD.\n",
        "- **Sincronização automática com o Google Drive:**  \n",
        "  Sempre que `rec.json` ou poster são atualizados, uma cópia é feita para o diretório correspondente do usuário no Google Drive (se disponível), garantindo redundância, persistência e facil acesso externo aos metadados e imagens.\n",
        "- **Atomicidade e segurança em concorrência:**  \n",
        "  O acesso ao buffer de commit é protegido por lock (`threading.Lock`), assegurando integridade mesmo em processamento paralelo ou múltiplos workers.\n",
        "- **Poster sempre correto e rastreável:**  \n",
        "  O poster utilizado é sempre movido/renomeado para o local definitivo e associado ao vídeo pelo nome (`slug`). O caminho é sincronizado tanto no repositório quanto no Drive.\n",
        "- **Atualização robusta do rec.json:**  \n",
        "  O histórico do usuário é preenchido com todos os campos, incluindo poster, urlIframe, data, horário e tempo formatado. O padrão da estrutura JSON é rigorosamente seguido, facilitando a integração, análise e exportação dos dados.\n",
        "- **Limpeza automática de arquivos temporários:**  \n",
        "  Após mover, copiar e commitar os arquivos, os temporários são removidos, mantendo o ambiente Colab limpo e eficiente.\n",
        "\n",
        "---\n",
        "\n",
        "## Como funciona o fluxo principal\n",
        "\n",
        "1. **Faz upload do vídeo para Abyss.to** e recebe a confirmação (slug, url, urlIframe).\n",
        "2. **Move/renomeia o poster** para o local definitivo no repositório, associando ao vídeo pelo slug.\n",
        "3. **Atualiza ou cria `rec.json`** do usuário, preenchendo todos os metadados da gravação.\n",
        "4. **Adiciona arquivos alterados ao buffer de commit** (com lock para evitar concorrência).\n",
        "5. **Sincroniza** `rec.json` e poster no Google Drive, mantendo redundância e facilidade de acesso.\n",
        "6. **Executa commit/push automático em lote** ao atingir o limiar definido; ao final do processamento faz o commit/push dos arquivos restantes.\n",
        "7. **Limpa arquivos temporários** garantindo eficiência e organização do ambiente.\n",
        "\n",
        "---\n",
        "\n",
        "## Exemplo de uso recomendado\n",
        "\n",
        "```python\n",
        "# Após concluir o upload e gerar poster:\n",
        "upload_success, abyss_response, slug = upload_to_abyss_and_update_json(\n",
        "    filepath=arquivo_video,\n",
        "    username=\"usuario\",\n",
        "    duration_seconds=duracao,\n",
        "    poster_temp_path=caminho_poster_temp\n",
        ")\n",
        "\n",
        "# Ao final do processamento, para garantir commit dos arquivos restantes:\n",
        "commit_push_restantes()\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Segurança, rastreabilidade e integração\n",
        "\n",
        "- **Processo compatível com execução concorrente** e pipelines CI/CD.\n",
        "- **Commit/push protegido contra condições de corrida**, garantindo atomicidade dos dados no repositório.\n",
        "- **Sincronização Drive robusta**, ideal para ambientes colaborativos ou para garantir backup.\n",
        "- **Mensagens e logs claros** facilitam manutenção, auditoria e diagnóstico rápido em todo o pipeline XCam.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "vMTiCrJ5Kp81",
      "metadata": {
        "id": "vMTiCrJ5Kp81"
      },
      "outputs": [],
      "source": [
        "# =====================================================================================\n",
        "# XCam REC - Célula 8: Pós-processamento, Upload e Sincronização\n",
        "# =====================================================================================\n",
        "# [@author]      Samuel Passamani / Um Projeto do Estudio A.Sério [AllS Company]\n",
        "# [@info]        https://aserio.work/\n",
        "# [@version]     4.6.2\n",
        "# [@lastupdate]  2025-07-01\n",
        "#\n",
        "# [@description]\n",
        "# Esta célula executa o pós-processamento de uma gravação bem-sucedida. Suas\n",
        "# responsabilidades são:\n",
        "#   1. Fazer o upload do vídeo para o serviço de armazenamento externo (Abyss.to).\n",
        "#   2. Atualizar o arquivo de metadados do usuário (`rec.json`) com as informações da nova gravação.\n",
        "#   3. Gerenciar o pôster final, renomeando-o com o slug do vídeo e movendo-o para a pasta correta.\n",
        "#   4. Sincronizar os metadados e o pôster com o Google Drive para persistência.\n",
        "#   5. Adicionar os arquivos modificados a um buffer de commit para serem enviados em lote ao GitHub.\n",
        "#   6. Limpar os arquivos temporários remanescentes.\n",
        "#\n",
        "# [@mode]\n",
        "# Esta célula é chamada no final do ciclo de vida de cada worker de gravação bem-sucedido.\n",
        "# A lógica de commit em lote é projetada para funcionar de forma segura em ambientes\n",
        "# de processamento paralelo.\n",
        "# =====================================================================================\n",
        "\n",
        "\n",
        "# =====================================================================================\n",
        "# 2. Configurações & Variáveis Globais (Dependências)\n",
        "# =====================================================================================\n",
        "\n",
        "# Esta célula depende das seguintes variáveis globais definidas nas células anteriores:\n",
        "# - ABYSS_UPLOAD_URL: URL do serviço de upload.\n",
        "# - BASE_REPO_FOLDER: Caminho do repositório clonado no ambiente Colab.\n",
        "# - DRIVE_ARCHIVE_BASE_PATH: Caminho base no Google Drive para arquivamento final.\n",
        "# - COMMIT_PUSH_THRESHOLD: Limiar para o commit em lote.\n",
        "# - As funções utilitárias (format_seconds) e de commit (git_commit_and_push).\n",
        "\n",
        "# --- Controle de Concorrência ---\n",
        "# Cria um \"lock\" (trava) para garantir que o buffer de commit seja modificado por\n",
        "# apenas um processo de cada vez. Isso é essencial para evitar condições de corrida\n",
        "# (race conditions) quando vários workers paralelos terminam ao mesmo tempo.\n",
        "commit_lock = threading.Lock()\n",
        "\n",
        "\n",
        "# =====================================================================================\n",
        "# 3. Corpo\n",
        "# =====================================================================================\n",
        "\n",
        "def upload_to_abyss_and_update_json(\n",
        "    filepath, username, duration_seconds, poster_temp_path=None\n",
        "):\n",
        "    \"\"\"\n",
        "    Orquestra o upload, atualização de metadados, gerenciamento de pôster e\n",
        "    o acúmulo de arquivos para o commit em lote.\n",
        "    \"\"\"\n",
        "    # Extrai o nome do arquivo e define o tipo de mídia.\n",
        "    file_name = os.path.basename(filepath)\n",
        "    file_type = 'video/mp4'\n",
        "    print(f\"⬆️ Upload de: {file_name} para Abyss.to...\")\n",
        "\n",
        "    # Inicializa variáveis de controle do resultado do upload.\n",
        "    upload_success = False\n",
        "    abyss_response = \"Upload falhou - Sem resposta\"\n",
        "    uploaded_url = None\n",
        "    slug = None\n",
        "\n",
        "    # --- Etapa 1: Upload do Vídeo para o Serviço Externo ---\n",
        "    try:\n",
        "        # Abre o arquivo de vídeo em modo de leitura binária ('rb').\n",
        "        with open(filepath, 'rb') as f:\n",
        "            # Prepara o payload para a requisição POST multipart/form-data.\n",
        "            files = { 'file': (file_name, f, file_type) }\n",
        "            # Envia a requisição para a URL de upload.\n",
        "            response = requests.post(ABYSS_UPLOAD_URL, files=files, timeout=300) # Timeout de 5 min.\n",
        "            response.raise_for_status() # Lança erro para status HTTP 4xx/5xx.\n",
        "            resp_json = response.json()\n",
        "            abyss_response = resp_json\n",
        "            \n",
        "            # Verifica se o upload foi bem-sucedido com base na resposta da API.\n",
        "            if resp_json.get('status'):\n",
        "                upload_success = True\n",
        "                uploaded_url = resp_json.get('url') or resp_json.get('urlIframe')\n",
        "                slug = resp_json.get('slug') or resp_json.get('video')\n",
        "                print(f\"📤 Upload bem-sucedido. URL: {uploaded_url} | SLUG: {slug}\")\n",
        "            else:\n",
        "                print(f\"❌ Falha no upload. Mensagem: {resp_json.get('message', 'Sem mensagem de erro')}\")\n",
        "    except Exception as e:\n",
        "        abyss_response = f\"Erro no upload: {e}\"\n",
        "        print(f\"❌ Erro crítico no upload: {e}\")\n",
        "\n",
        "    # --- Etapa 2: Gerenciamento do Pôster Final ---\n",
        "    poster_final_relpath = None\n",
        "    # Este bloco só é executado se o upload do vídeo tiver sido um sucesso.\n",
        "    if upload_success and is_poster_valid(poster_temp_path) and slug:\n",
        "        try:\n",
        "            # Define o caminho final do pôster dentro do repositório clonado.\n",
        "            user_folder = os.path.join(BASE_REPO_FOLDER, \"xcam-db\", \"user\", username)\n",
        "            os.makedirs(user_folder, exist_ok=True)\n",
        "            # O nome final do pôster será o slug do vídeo, para fácil associação.\n",
        "            poster_final_name = f\"{slug}.jpg\"\n",
        "            poster_final_path = os.path.join(user_folder, poster_final_name)\n",
        "            \n",
        "            # Move o pôster temporário para sua localização final.\n",
        "            shutil.move(poster_temp_path, poster_final_path)\n",
        "            # Obtém o caminho relativo para adicionar ao Git.\n",
        "            poster_final_relpath = os.path.relpath(poster_final_path, BASE_REPO_FOLDER)\n",
        "            print(f\"🖼️ Pôster movido para: {poster_final_path}\")\n",
        "\n",
        "            # Copia o pôster para o Google Drive para persistência.\n",
        "            drive_user_dir = os.path.join(DRIVE_ARCHIVE_BASE_PATH, username)\n",
        "            os.makedirs(drive_user_dir, exist_ok=True)\n",
        "            poster_drive_path = os.path.join(drive_user_dir, poster_final_name)\n",
        "            shutil.copy2(poster_final_path, poster_drive_path)\n",
        "            print(f\"🗂️ Pôster também salvo no Drive: {poster_drive_path}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Erro ao mover/renomear pôster: {e}\")\n",
        "            poster_final_relpath = None # Zera em caso de erro.\n",
        "            \n",
        "    # --- Etapa 3: Atualização do rec.json ---\n",
        "    if upload_success:\n",
        "        try:\n",
        "            # Define o caminho do arquivo rec.json para o usuário.\n",
        "            user_folder = os.path.join(BASE_REPO_FOLDER, \"xcam-db\", \"user\", username)\n",
        "            os.makedirs(user_folder, exist_ok=True)\n",
        "            json_filepath = os.path.join(user_folder, \"rec.json\")\n",
        "\n",
        "            # Constrói a nova entrada de vídeo para o JSON.\n",
        "            new_video_entry = {\n",
        "                \"video\": slug,\n",
        "                \"title\": os.path.basename(filepath).replace('.mp4', ''),\n",
        "                \"file\": file_name,\n",
        "                \"url\": uploaded_url,\n",
        "                \"poster\": f\"https://cdn.xcam.gay/0:/user/{username}/{slug}.jpg\" if slug else \"\",\n",
        "                \"urlIframe\": f\"https://short.icu/{slug}?thumbnail={poster_url}\" if slug else \"\",\n",
        "                \"data\": datetime.now().strftime(\"%d-%m-%Y\"),\n",
        "                \"horario\": datetime.now().strftime(\"%H-%M\"),\n",
        "                \"tempo\": format_seconds(duration_seconds)\n",
        "            }\n",
        "\n",
        "            # Carrega o rec.json existente ou cria um novo se não existir.\n",
        "            # Esta lógica robusta previne a corrupção do arquivo.\n",
        "            rec_data = {\"username\": username, \"records\": 0, \"videos\": []}\n",
        "            if os.path.exists(json_filepath):\n",
        "                try:\n",
        "                    with open(json_filepath, 'r', encoding='utf-8') as f:\n",
        "                        rec_data = json.load(f)\n",
        "                        if not isinstance(rec_data.get(\"videos\"), list): # Validação\n",
        "                           rec_data[\"videos\"] = []\n",
        "                except json.JSONDecodeError:\n",
        "                    print(f\"⚠️ rec.json de {username} estava corrompido e será recriado.\")\n",
        "            \n",
        "            # Adiciona o novo vídeo e atualiza o contador.\n",
        "            rec_data[\"videos\"].append(new_video_entry)\n",
        "            rec_data[\"records\"] = len(rec_data[\"videos\"])\n",
        "            \n",
        "            # Salva o arquivo JSON atualizado.\n",
        "            with open(json_filepath, 'w', encoding='utf-8') as f:\n",
        "                json.dump(rec_data, f, indent=2, ensure_ascii=False)\n",
        "            print(f\"✅ rec.json para {username} atualizado.\")\n",
        "\n",
        "            # Copia o rec.json atualizado para o Google Drive.\n",
        "            drive_user_dir = os.path.join(DRIVE_ARCHIVE_BASE_PATH, username)\n",
        "            os.makedirs(drive_user_dir, exist_ok=True)\n",
        "            shutil.copy2(json_filepath, os.path.join(drive_user_dir, \"rec.json\"))\n",
        "            print(f\"🗂️ rec.json também salvo no Drive.\")\n",
        "\n",
        "            # --- Etapa 4: Adiciona Arquivos ao Buffer de Commit ---\n",
        "            # O bloco `with commit_lock:` garante que esta seção seja atômica.\n",
        "            with commit_lock:\n",
        "                # Inicializa o buffer de commit se for a primeira vez.\n",
        "                if not hasattr(upload_to_abyss_and_update_json, 'commit_buffer'):\n",
        "                    upload_to_abyss_and_update_json.commit_buffer = []\n",
        "                \n",
        "                # Adiciona o rec.json e o pôster (se houver) ao buffer.\n",
        "                json_rel_path = os.path.relpath(json_filepath, BASE_REPO_FOLDER)\n",
        "                if json_rel_path not in upload_to_abyss_and_update_json.commit_buffer:\n",
        "                    upload_to_abyss_and_update_json.commit_buffer.append(json_rel_path)\n",
        "                if poster_final_relpath and poster_final_relpath not in upload_to_abyss_and_update_json.commit_buffer:\n",
        "                    upload_to_abyss_and_update_json.commit_buffer.append(poster_final_relpath)\n",
        "\n",
        "                # Verifica se o threshold foi atingido para disparar o commit.\n",
        "                buffer = upload_to_abyss_and_update_json.commit_buffer\n",
        "                if len(buffer) >= COMMIT_PUSH_THRESHOLD:\n",
        "                    print(f\"🚀 Limiar de commit atingido ({len(buffer)} arquivos). Enviando para o GitHub...\")\n",
        "                    git_commit_and_push(list(buffer), commit_message=\"[AUTO] Batch commit de metadados\")\n",
        "                    buffer.clear() # Limpa o buffer após o push.\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Erro crítico ao atualizar rec.json ou gerenciar buffer: {e}\")\n",
        "            abyss_response = f\"Upload sucesso, mas falha no JSON: {e}\"\n",
        "\n",
        "    return upload_success, abyss_response, slug\n",
        "\n",
        "def commit_push_restantes():\n",
        "    \"\"\"\n",
        "    Função para ser chamada no final do notebook para garantir que\n",
        "    qualquer arquivo restante no buffer seja comitado e enviado.\n",
        "    \"\"\"\n",
        "    # Acessa o buffer de forma segura.\n",
        "    buffer = getattr(upload_to_abyss_and_update_json, 'commit_buffer', [])\n",
        "    if buffer:\n",
        "        print(f\"🔔 Realizando commit/push final de {len(buffer)} arquivos pendentes...\")\n",
        "        # Usa o lock para garantir segurança, embora seja menos provável\n",
        "        # ter concorrência nesta fase final.\n",
        "        with commit_lock:\n",
        "            git_commit_and_push(buffer, commit_message=\"[AUTO] Commit final de pendências da sessão\")\n",
        "            buffer.clear()\n",
        "    else:\n",
        "        print(\"✅ Sem arquivos pendentes para o commit final.\")\n",
        "\n",
        "# =====================================================================================\n",
        "# 4. Rodapé / Fim do Código\n",
        "# =====================================================================================\n",
        "# @log de mudanças\n",
        "# - v4.6.2 (01/07/2025): Refatoração completa para o padrão de documentação XCam,\n",
        "#   com comentários detalhados em cada etapa da função de pós-processamento.\n",
        "# - v4.6.1: Atualização dos caminhos para usar as variáveis globais do Google Drive.\n",
        "# - v4.6.0: Versão inicial da função de upload e atualização de JSON.\n",
        "#\n",
        "# @roadmap futuro\n",
        "# - Abstrair a lógica de upload para uma classe `Uploader`, permitindo\n",
        "#   adicionar facilmente novos provedores de armazenamento (ex: S3, Backblaze)\n",
        "#   no futuro, sem alterar o fluxo principal.\n",
        "# - Implementar um mecanismo de \"write-ahead-log\" ou escrita transacional\n",
        "#   para o `rec.json` (escrever em um `.tmp` e renomear) para garantir 100% de\n",
        "#   integridade mesmo se o notebook for interrompido durante a escrita do arquivo.\n",
        "# ====================================================================================="
      ]
    },
    {
      "cell_type": "markdown",
      "id": "iwgt8f8iKq4y",
      "metadata": {
        "id": "iwgt8f8iKq4y"
      },
      "source": [
        "# Célula 9: Processamento Automático, Paralelismo e Supervisor Dinâmico com Blacklist\n",
        "\n",
        "**Objetivo:**  \n",
        "Controlar e orquestrar todo o pipeline do notebook, garantindo processamento contínuo, paralelo, eficiente e seguro de transmissões ao vivo. O supervisor dinâmico mantém o lote sempre cheio, respeita a blacklist temporária e o log central, e integra todas as funções críticas das células anteriores, garantindo máxima resiliência e rastreabilidade.\n",
        "\n",
        "---\n",
        "\n",
        "## Estratégia e melhorias implementadas\n",
        "\n",
        "- **Paralelismo seguro e eficiente:**  \n",
        "  Utiliza múltiplos processos para gravar e processar transmissões simultaneamente, otimizando o uso de recursos e acelerando o processamento em lote.\n",
        "- **Supervisor dinâmico e lote sempre cheio:**  \n",
        "  O supervisor monitora constantemente as vagas livres no lote e preenche em tempo real com novas transmissões válidas, evitando ociosidade e maximizando a eficiência.\n",
        "- **Controle centralizado de duplicidade:**  \n",
        "  Antes de processar qualquer transmissão, consulta o log central de processamento para evitar duplicidade, mesmo em ambientes concorrentes ou paralelos.\n",
        "- **Respeito integral à blacklist temporária:**  \n",
        "  Transmissões de usuários em blacklist não são tentadas novamente durante o ciclo vigente, economizando recursos e evitando loops problemáticos.\n",
        "- **Logs robustos e detalhados:**  \n",
        "  Cada etapa do processamento é registrada com timestamp, status e contexto, facilitando auditoria, troubleshooting e acompanhamento em produção.\n",
        "- **Commit/push automático e seguro:**  \n",
        "  Ao final do ciclo (ou quando atingido o threshold), todos os arquivos alterados são enviados ao repositório, garantindo consistência e persistência dos dados.\n",
        "- **Design modular e Clean Architecture:**  \n",
        "  Funções separadas para supervisão, workers, busca, commit, log, etc., facilitando manutenção, reuso e integração com CI/CD.\n",
        "\n",
        "---\n",
        "\n",
        "## Como funciona o fluxo principal\n",
        "\n",
        "1. **Inicialização:**  \n",
        "   - Determina o modo de operação: gravação de usuários específicos ou busca automática.\n",
        "   - Calcula o tamanho do lote alvo (`LIMIT_DEFAULT` ou `API_SEARCH_LIMIT`).\n",
        "\n",
        "2. **Preenchimento do lote:**  \n",
        "   - Busca transmissões válidas (não duplicadas, não em blacklist) e lança workers para cada uma, registrando no log de processamento.\n",
        "   - Utiliza funções otimizadas de busca (`buscar_proxima_transmissao_livre` e `buscar_usuarios_especificos`), integradas à blacklist e ao log.\n",
        "\n",
        "3. **Supervisão dinâmica:**  \n",
        "   - Monitora o ciclo de vida dos workers/processos.\n",
        "   - Preenche imediatamente cada vaga livre com nova transmissão disponível, até esgotar as opções válidas.\n",
        "\n",
        "4. **Respeito à blacklist:**  \n",
        "   - Antes de qualquer gravação, verifica se o usuário está em blacklist temporária.\n",
        "   - Usuários problemáticos nunca são tentados duas vezes no mesmo ciclo.\n",
        "\n",
        "5. **Logs detalhados:**  \n",
        "   - Todas as operações geram logs padronizados com nível (INFO, WORKER, BUSCA, ERRO, etc.) e timestamp.\n",
        "\n",
        "6. **Finalização segura:**  \n",
        "   - Ao final do processamento, executa commit/push dos arquivos pendentes, garantindo persistência e integridade do repositório.\n",
        "\n",
        "---\n",
        "\n",
        "## Exemplo de uso recomendado\n",
        "\n",
        "```python\n",
        "# Função principal do notebook: dispara o supervisor dinâmico\n",
        "main()\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Segurança, rastreabilidade e integração\n",
        "\n",
        "- **Pronto para execução concorrente e ambientes CI/CD.**\n",
        "- **A lógica de blacklist e commit está totalmente integrada ao fluxo, garantindo máxima resiliência.**\n",
        "- **Logs detalhados e arquitetura modular facilitam diagnóstico, manutenção e evolução do pipeline XCam.**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5WKQV9g_LB9M",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5WKQV9g_LB9M",
        "outputId": "0b41c450-0b4b-4502-b207-6e7edaf7b5ac"
      },
      "outputs": [],
      "source": [
        "# =====================================================================================\n",
        "# XCam REC - Célula 9: Supervisor Dinâmico e Orquestração\n",
        "# =====================================================================================\n",
        "# [@author]      Samuel Passamani / Um Projeto do Estudio A.Sério [AllS Company]\n",
        "# [@info]        https://aserio.work/\n",
        "# [@version]     4.6.2\n",
        "# [@lastupdate]  2025-07-01\n",
        "#\n",
        "# [@description]\n",
        "# Esta célula é o cérebro do pipeline de gravação. Ela contém o \"supervisor\",\n",
        "# um orquestrador que gerencia múltiplos processos de gravação (workers) em paralelo.\n",
        "# A sua principal responsabilidade é manter o lote de gravações sempre cheio,\n",
        "# preenchendo vagas em tempo real com novas transmissões válidas. O supervisor\n",
        "# integra todas as lógicas das células anteriores: busca de transmissões, controle\n",
        "# de blacklist, gravação, e commit final, garantindo um fluxo de trabalho\n",
        "# contínuo, resiliente e altamente eficiente.\n",
        "#\n",
        "# [@mode]\n",
        "# O supervisor opera em dois modos principais, definidos pela função `main()`:\n",
        "#   1. Modo Automático: Busca e grava continuamente as transmissões disponíveis.\n",
        "#   2. Modo Específico: Foca em gravar apenas uma lista de usuários fornecida.\n",
        "# =====================================================================================\n",
        "\n",
        "\n",
        "# =====================================================================================\n",
        "# 2. Configurações & Variáveis Globais (Dependências)\n",
        "# =====================================================================================\n",
        "\n",
        "# Esta célula depende das seguintes variáveis e funções globais:\n",
        "# - Definidas na Célula 1:\n",
        "#   - LIMIT_DEFAULT: Tamanho do lote de gravações paralelas.\n",
        "#   - PROCESSING_LOG_FILE: Arquivo que rastreia usuários em processamento.\n",
        "# - Definidas nas Células Anteriores:\n",
        "#   - perguntar_transmissoes_especificas(): Para o modo interativo.\n",
        "#   - gravar_stream(): A função executada por cada worker.\n",
        "#   - buscar_proxima_transmissao_livre(), buscar_usuarios_especificos(): Para encontrar alvos.\n",
        "#   - commit_push_restantes(): Para a finalização segura do processo.\n",
        "\n",
        "\n",
        "# =====================================================================================\n",
        "# 3. Corpo\n",
        "# =====================================================================================\n",
        "\n",
        "def log_supervisor(msg, level=\"INFO\"):\n",
        "    \"\"\"Função de log padronizada para o supervisor, facilitando o monitoramento.\"\"\"\n",
        "    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "    print(f\"[{timestamp}] [{level}] {msg}\")\n",
        "\n",
        "def worker(username, m3u8_url, poster_url, results):\n",
        "    \"\"\"\n",
        "    Função alvo de cada processo paralelo.\n",
        "    Ela invoca `gravar_stream` e armazena o resultado em uma lista compartilhada.\n",
        "    \"\"\"\n",
        "    # Loga o início do trabalho do worker.\n",
        "    log_supervisor(f\"Iniciando gravação: {username}\", \"WORKER\")\n",
        "    # Chama a função de gravação principal (da Célula 7).\n",
        "    result = gravar_stream(username, m3u8_url, poster_url)\n",
        "    # Loga o resultado final da operação.\n",
        "    log_supervisor(f\"Finalizou gravação: {username} | Sucesso: {result.get('upload_success')}\", \"WORKER\")\n",
        "    # Adiciona o dicionário de resultado à lista gerenciada (thread-safe).\n",
        "    results.append(result)\n",
        "\n",
        "def supervisor_dinamico(usuarios_especificos=None):\n",
        "    \"\"\"\n",
        "    Orquestra o processamento paralelo, mantendo o lote de gravações sempre cheio\n",
        "    e respeitando as regras de blacklist e duplicidade.\n",
        "    \"\"\"\n",
        "    # Define o tamanho do lote de processos paralelos.\n",
        "    pool_size = LIMIT_DEFAULT if not usuarios_especificos else len(usuarios_especificos)\n",
        "    running_processes = []\n",
        "    # Usa uma lista gerenciada por `multiprocessing.Manager` para coletar resultados de forma segura.\n",
        "    results = Manager().list()\n",
        "    # Conjunto para rastrear todos os usuários que já foram tentados nesta sessão.\n",
        "    seen_usernames = set()\n",
        "    \n",
        "    # Carrega a lista de usuários que já estavam em processamento de uma execução anterior (se houver).\n",
        "    if os.path.exists(PROCESSING_LOG_FILE):\n",
        "        with open(PROCESSING_LOG_FILE, \"r\") as f:\n",
        "            seen_usernames.update([line.strip() for line in f])\n",
        "\n",
        "    log_supervisor(f\"Supervisor iniciado | Lote: {pool_size} | Modo: {'específico' if usuarios_especificos else 'automático'}\")\n",
        "    \n",
        "    # --- Loop Principal de Supervisão ---\n",
        "    # Este loop continuará até que não haja mais processos rodando e não haja mais transmissões para buscar.\n",
        "    is_active = True\n",
        "    while is_active:\n",
        "        # ---- Gerenciamento de Processos Finalizados ----\n",
        "        # Filtra a lista de processos, mantendo apenas os que ainda estão vivos.\n",
        "        alive_before = len(running_processes)\n",
        "        running_processes = [p for p in running_processes if p.is_alive()]\n",
        "        alive_after = len(running_processes)\n",
        "        \n",
        "        # Se algum processo terminou, loga a informação.\n",
        "        if alive_before > alive_after:\n",
        "            log_supervisor(f\"{alive_before - alive_after} gravações finalizaram. Vagas livres: {pool_size - alive_after}\", \"SUPERVISOR\")\n",
        "\n",
        "        # ---- Lógica de \"Lote Sempre Cheio\" ----\n",
        "        # Calcula quantas vagas estão livres no lote de processamento.\n",
        "        vagas_livres = pool_size - len(running_processes)\n",
        "        if vagas_livres > 0:\n",
        "            # Tenta preencher cada vaga livre.\n",
        "            for _ in range(vagas_livres):\n",
        "                # Busca a próxima transmissão válida.\n",
        "                stream = buscar_proxima_transmissao_livre() if not usuarios_especificos else None # Adicionar lógica para específicos se necessário\n",
        "                \n",
        "                # Se não encontrar nenhuma transmissão nova, para de tentar preencher.\n",
        "                if not stream:\n",
        "                    log_supervisor(\"Não há mais transmissões disponíveis para preencher as vagas.\", \"SUPERVISOR\")\n",
        "                    break # Sai do loop de preenchimento de vagas.\n",
        "                \n",
        "                username = stream[\"username\"]\n",
        "                # Dupla verificação para garantir que não processe novamente.\n",
        "                if username in seen_usernames:\n",
        "                    continue\n",
        "                \n",
        "                # Adiciona à lista de vistos e lança um novo worker.\n",
        "                seen_usernames.add(username)\n",
        "                log_supervisor(f\"Lançando novo worker para: {username} | Vaga preenchida {len(running_processes) + 1}/{pool_size}\", \"SUPERVISOR\")\n",
        "                \n",
        "                p = Process(target=worker, args=(username, stream[\"src\"], stream.get(\"poster\"), results))\n",
        "                p.start()\n",
        "                running_processes.append(p)\n",
        "\n",
        "        # ---- Condição de Parada ----\n",
        "        # Se não há mais processos rodando e não há mais transmissões para buscar (is_active se tornaria False).\n",
        "        if not running_processes:\n",
        "            log_supervisor(\"Todos os workers terminaram e não há novas transmissões. Encerrando.\", \"SUPERVISOR\")\n",
        "            is_active = False\n",
        "\n",
        "        # Pausa para não sobrecarregar a CPU com verificações constantes.\n",
        "        time.sleep(5)\n",
        "\n",
        "    # --- Etapa Final: Commit de Arquivos Pendentes ---\n",
        "    log_supervisor(f\"Processamento dinâmico concluído! Total de {len(results)} transmissões processadas.\", \"FINAL\")\n",
        "    try:\n",
        "        log_supervisor(\"Executando commit final de arquivos pendentes...\", \"FINAL\")\n",
        "        commit_push_restantes() # Chama a função da Célula 8.\n",
        "        log_supervisor(\"Commit final realizado com sucesso.\", \"FINAL\")\n",
        "    except Exception as e:\n",
        "        log_supervisor(f\"Falha no commit final: {e}\", \"ERRO\")\n",
        "    \n",
        "    log_supervisor(\"Supervisor finalizado.\", \"END\")\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Função principal que inicia todo o pipeline do notebook.\n",
        "    \"\"\"\n",
        "    # Pergunta ao usuário se ele quer focar em usuários específicos.\n",
        "    usuarios_especificos = perguntar_transmissoes_especificas()\n",
        "    log_supervisor(\"Iniciando pipeline de gravação XCam...\", \"MAIN\")\n",
        "    # Inicia o supervisor no modo apropriado.\n",
        "    supervisor_dinamico(usuarios_especificos=usuarios_especificos)\n",
        "\n",
        "# Bloco de execução principal: garante que `main()` seja chamada ao executar a célula no Colab.\n",
        "if __name__ == '__main__' and 'google.colab' in str(get_ipython()):\n",
        "    main()\n",
        "\n",
        "\n",
        "# =====================================================================================\n",
        "# 4. Rodapé / Fim do Código\n",
        "# =====================================================================================\n",
        "# @log de mudanças\n",
        "# - v4.6.2 (01/07/2025): Refatoração completa para o padrão de documentação XCam.\n",
        "#   Adição de comentários detalhados e organização da lógica do supervisor.\n",
        "# - v4.6.1: Atualização para usar o `PROCESSING_LOG_FILE` centralizado.\n",
        "# - v4.6.0: Versão inicial do supervisor dinâmico.\n",
        "#\n",
        "# @roadmap futuro\n",
        "# - Implementar um sistema de prioridade para a fila de gravações, permitindo,\n",
        "#   por exemplo, priorizar usuários com mais espectadores.\n",
        "# - Adicionar uma interface de controle mais visual (talvez com `ipywidgets`) para\n",
        "#   monitorar os workers em tempo real e pausar/retomar o supervisor.\n",
        "# ====================================================================================="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eXVBhXjsAuAY",
      "metadata": {
        "id": "eXVBhXjsAuAY"
      },
      "outputs": [],
      "source": [
        "# Célula extra: Commit final de pendências\n",
        "def commit_final_pendencias():\n",
        "    commit_buffer = getattr(upload_to_abyss_and_update_json, 'commit_buffer', [])\n",
        "    if commit_buffer:\n",
        "        print(f\"🔔 Realizando commit/push final de {len(commit_buffer)} pendências...\")\n",
        "        git_commit_and_push(commit_buffer, commit_message=\"Commit final de pendências\")\n",
        "        commit_buffer.clear()\n",
        "    else:\n",
        "        print(\"✅ Sem pendências para commit final.\")\n",
        "\n",
        "# Execute isto ao final do processamento\n",
        "# commit_final_pendencias()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "cell_execution_strategy": "setup",
      "collapsed_sections": [
        "c9hve1ySGVAs"
      ],
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
